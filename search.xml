<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>IX9111 - Unit 10.Shared Memory Architecture</title>
      <link href="/2025/06/21/IX9111/10/"/>
      <url>/2025/06/21/IX9111/10/</url>
      
        <content type="html"><![CDATA[<p><strong>Shared Memory</strong></p><p>Shared memory is memory that is allocated by one process, yet can be accessed by any process with permission to do so.</p><p><code>共享内存是指由一个进程分配的内存空间，但任何获得相应权限的进程均可对其进行访问。</code></p><p>– One process creates shared memory by allocating one or more segments. Like regular files, shared memory segments are created with permissions, an owner ID, group ID, even a name.</p><p><code>一个进程通过分配一个或多个段(segment)来创建共享内存。与常规文件类似，共享内存段在创建时会设置访问权限、owner ID、group ID，甚至还可以指定 name。</code></p><p>– Any process with permission to do so can attach to the memory segments and treat them as its own.</p><p><code>任何获得相应权限的进程都可以 attach 到这些内存段，并将其视为自己的内存来使用。</code></p><p>– The OS does not let this get out of hand. Shared memory is a kernel resource. There are kernel-defined limits to the size of shared memory as a whole, the size of individual segments, the total number of segments in the system, and the number to which one process can attach.</p><p><code>操作系统不会让这种情况失去控制。共享内存是一种内核资源。对于共享内存的整体大小、单个段的大小、系统中段的总数以及一个进程能够 attach 的段数，内核都设定了相应的限制。</code></p><p><strong>Notes:</strong></p><p>Shared memory is truly one of the finest features of UNIX and Linux. In the past, it has been implemented in very different ways on different platforms, but with the most recent versions of UNIX, most shared memory features have become standardized.</p><p><code>共享内存确实是 UNIX 和 Linux 系统中最为出色的特性之一。在过去，不同平台对共享内存的实现方式大相径庭，但在最新版本的 UNIX 系统中，大多数共享内存特性都已实现了标准化。</code></p><p>Shared memory is built from separate <em>segments</em>. A shared memory segment is treated much like a regular file. Each is <em>created</em> and owned by a particular user, and can be read or even modified by other users depending on its permissions. A shared memory segment even has a <em>name</em>, a unique identifier chosen by the creating process.</p><p><code>共享内存由独立的段（segments）构成。共享内存段的处理方式与常规文件颇为相似。每个共享内存段都由特定用户创建并拥有，其他用户能否对其进行读取甚至修改，取决于该段的权限设置。共享内存段甚至还拥有一个名称，即由创建进程所选定的唯一标识符。</code></p><p>In shared memory lingo, a process <em>attaches</em> to a shared memory segment in order to access it. From the perspective of the process itself, the shared memory segment is attached to the memory space of the process. In fact, it looks no different to the process than private memory. Unless the process is programmed to find out, it need never know that other processes are accessing the same memory addresses.</p><p><code>在共享内存的专业术语中，一个进程若要访问共享内存段，需要先关联（attaches）到该共享内存段。从进程自身的角度来看，共享内存段会被关联到该进程的内存空间中。实际上，对于进程而言，共享内存段与私有内存看起来并无二致。除非进程被编程以进行特定检测，否则它无需知晓其他进程也在访问相同的内存地址。</code></p><p>When a process makes a request of the operating system to attach it to a shared memory segment, it tells the operating system where in its address space to map the memory.</p><p><code>当进程向操作系统提出关联（attach）到共享内存段的请求时，它会告知操作系统将该共享内存映射到其地址空间的哪个位置。</code></p><p><strong>Shared Memory Portions</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506211752067.png" alt="image-20250621175241975"></p><p><strong>Notes:</strong></p><p>Informix Dynamic Server shared memory is divided into three portions, the resident portion, the virtual portion, and the message portion. The term <em>portion</em> used in this context is nothing more than a collection of shared memory segments seen as a logical set of memory by the database server. Each portion contains a unique set of information about the server:</p><p><code>IDS 的共享内存被划分为三个部分，分别是驻留部分（resident portion）、虚拟部分（virtual portion）和消息部分（message portion）。在此上下文中，“部分（portion）”一词仅指 database server 视为一个逻辑内存集合的一组共享内存段。每个部分都包含关于 server 的独特信息集：</code></p><p> <strong>•</strong> The <em>resident portion</em> contains structures that are fixed in size, such as the lock table, the LRU structures, and most significantly, the buffer pool. It is termed <em>resident</em>, because you can set these shared memory segments to stay resident in memory, even if they are not being used. The structure of this portion of shared memory has not changed significantly since early versions of Informix Dynamic Server. </p><p><code>驻留部分（resident portion）包含一些大小固定的数据结构，例如 lock table、LRU structures，以及最为关键的 buffer pool。之所以称其为驻留，是因为你可以将这些共享内存段设置为始终驻留在内存中，即使它们当前并未被使用。自 IDS 的早期版本以来，这部分共享内存的结构并未发生显著变化。</code></p><p> <strong>•</strong> The <em>virtual portion</em> contains any shared information in the database server that can grow or shrink, or be allocated or de-allocated. The number of segments in the virtual portion can grow as needed during the life of the database server. We’ll discuss how memory is managed in this portion later in the chapter.</p><p><code>虚拟部分（virtual portion）包含数据库服务器中所有大小可变、能够动态增长或缩减、或是可被分配与释放的共享信息。在 database server 的运行期间，虚拟部分中的段（segment）数量可以根据需要进行动态增长。我们将在本章稍后部分讨论该部分内存是如何进行管理的。</code></p><blockquote><p>shrink 收缩 英[ʃrɪŋk]美[ʃrɪŋk]</p></blockquote><p> <strong>•</strong> The <em>message portion</em> contains message buffers that are used for shared memory communication. The segments in this portion have read&#x2F;write permissions for all users.</p><p><code>消息部分（message portion）包含用于共享内存通信的消息缓冲区。该部分中的段对所有用户均设有读写权限。</code></p><p><strong>Viewing Shared Memory</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506211803018.png" alt="image-20250621180328956"></p><p><strong>Notes:</strong></p><p>The <strong>onstat</strong> utility reads the Dynamic Server shared memory structures and report the contents of shared memory the instant it is run. This means the contents of shared memory could be changing as they are being printed (as no memory locking is done by <strong>onstat</strong>). If any strange circumstances are found from one run of <strong>onstat</strong>, you should not assume anything is wrong until several runs report the same situation.</p><p><code>onstat 工具会读取 Dynamic Server 的共享内存结构，并在运行该工具的瞬间报告共享内存的内容。这意味着在打印共享内存内容的过程中，这些内容可能会发生变化（因为 onstat 工具不会对内存进行锁定）。如果在使用 onstat 工具进行某次运行时发现了异常情况，你不应立即假定存在问题，而应多次运行该工具，只有在多次运行都报告相同情况时，才应考虑可能存在问题。</code></p><p>The <strong>onstat</strong> utility prints out the contents of the structures maintained in shared memory. Since these tables keep track of all activity in the database server, this tool gives a good picture of what is going on in the system at the time it is run. Any user can run <strong>onstat</strong>, but for security purposes, some options may not be available to non-<em>informix</em> users.</p><p><code>onstat 工具会输出存储在共享内存中的数据结构内容。由于这些数据结构（通常以表格形式存在）会跟踪 database server 中的所有活动，因此该工具能够清晰地展示在工具运行时刻系统内部正在发生的状况。任何用户都可以运行 onstat 工具，但出于安全考虑，对于非 informix 用户，某些选项可能不可用。</code></p><p>Generally, <strong>onstat</strong> does no disk I&#x2F;O of the database server; it reads from shared memory alone (there are a few options that read from disk files). Because it places no locks on shared memory resources, it does not impact the performance of any IDS applications.</p><p><code>通常情况下，onstat 工具不会对 database server 执行任何磁盘 I/O 操作；它仅从共享内存中读取数据（不过，有少数选项会从磁盘文件中读取数据）。由于该工具不会对共享内存资源施加任何锁，因此它不会对任何 IDS 应用程序的性能产生影响。</code></p><p>Another way to access the same data in shared memory is by querying the tables and views in the <strong>sysmaster</strong> database. Most of the tables in this database are not really tables, but cue the database server to look at shared memory structures instead.</p><p><code>另一种访问共享内存中相同数据的方法是查询 sysmaster 数据库中的表和视图。该数据库中的大多数“表”实际上并非传统意义上的存储数据的表，而是作为提示，引导 database server 去查看共享内存中的结构。</code></p><p><strong>Process Space: How Shared Memory Fits In</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221319780.png" alt="image-20250622131936662"></p><p><strong>Notes:</strong></p><p>The arrangement of the various segments within a process is highly dependent on machine architecture, but for the sake of an example, one possible layout is pictured above.</p><p><code>进程内各段(segment)的具体排列方式高度依赖于机器架构，不过，为了便于说明，上图展示了一种可能的布局示例。</code></p><p>The important point of the illustration to note is that once a process has attached to a particular group of shared memory segments, the memory is made to look and feel just like its own private memory.</p><p><code>该示意图需要关注的关键点在于，一旦一个进程附加到一组特定的共享内存段上，这些内存从外观和操作感受上就会如同该进程自身的私有内存一般。</code></p><p><strong>Shared memory base address</strong></p><p>As is true for each privately allocated block of memory within the heap, the operating system must provide the process with the starting address of the segment group. When attaching to shared memory segments with the <strong>shmat</strong> function, the process requests a particular base address. On success, <strong>shmat</strong> returns the address of the memory, which normally matches the requested address, but might have been adjusted for alignment or other purposes.</p><p><code>就如同堆（heap）内每一块私有分配的内存一样，操作系统必须向进程提供该 segment group 的起始地址。当进程使用 shmat 函数附加到共享内存段时，它会请求一个特定的基地址。如果操作成功，shmat 会返回该内存的地址，该地址通常与请求的地址一致，但可能为了对齐或其他目的而进行了调整。</code></p><p>Note that depending on its proximity to other process segments, a shared memory base address can have an effect on the amount of private memory and&#x2F;or stack space available. This explains why, on some platforms, raising the SHMBASE configuration parameter can cure o<em>ut of heap space</em> problems for engine processes. On most platforms, however, due to their process space layout, an <strong>oninit</strong> process does not benefit in the same way if SHMBASE is increased.</p><p><code>需要注意的是，共享内存基地址与其他进程段之间的邻近关系可能会影响可用的私有内存和/或栈空间的大小。这就解释了为什么在某些平台上，提高 SHMBASE 配置参数可以解决引擎进程出现的“堆空间不足”问题。然而，在大多数平台上，由于进程空间布局的原因，即使增加 SHMBASE 的值，oninit 进程也无法以同样的方式受益。</code></p><blockquote><p>proximity<br>英[prɒkˈsɪməti] 美[prɑːkˈsɪməti]<br>n.接近;(时间或空间)邻近;靠近;</p></blockquote><p><strong>Shared Memory Kernel Parameters</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221333022.png" alt="image-20250622133325804"></p><p><strong>Notes:</strong></p><p>Kernel parameters that impose limits on shared memory usage vary from platform to platform, but the four parameters pictured above are fairly common.</p><p><code>对共享内存使用量施加限制的内核参数因平台而异，但上图所示的四个参数相当常见。</code></p><blockquote><p>impose<br>英[ɪmˈpəʊz] 美[ɪmˈpoʊz]<br>v.把…强加于;使接受，使意识到;推行，采用(规章制度);迫使;强制实行;勉强（某人做某事）;使(别人)接受自己的意见;</p></blockquote><p><strong>•</strong> SHMMAX (bytes) – This value is the maximum size of a segment.</p><p><code>这个值表示段（segment）的最大大小。</code></p><p>上图10页，每页1K(1024字节)，所以是10240 bytes</p><p><strong>•</strong> SHMSEG (segments) This is the maximum number of segments to which one process can attach.</p><p><code>这是一个进程可以附加的共享内存段的最大数量。</code></p><p><strong>•</strong> SHMMNI (segments) – This is the maximum number of shared memory segments that can be created system wide.</p><p><code>这是整个系统范围内可以创建的共享内存段的最大数量。</code></p><p><strong>•</strong> SHMALL (clicks) – This is the maximum number of system pages that can be allocated for shared memory system wide. Remember that system pages have nothing to do with Informix Dynamic Server pages. The size of a system page is usually one kilobyte.</p><p><code>这是整个系统范围内可为共享内存分配的系统页面的最大数量。请注意，系统页面与 IDS 页面毫无关系。系统页面的大小通常为一千字节（即 1KB）。</code></p><p><strong>Shared Memory Key</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221351519.png" alt="image-20250622135131435"></p><p><strong>Notes:</strong></p><p>In order for multiple database server instances to run on the same machine without interfering with one another, each instance allocates shared memory segments that have unique key value.</p><p><code>为了让多个 database server 实例能够在同一台机器上运行且互不干扰，每个实例都会分配具有唯一键值的共享内存段。</code></p><p>Informix Dynamic Server uses a base shared memory key value of 0x52564801. This 4-byte key can be broken down into two parts. The first two bytes reflect a unique value for each database server instance. The last two bytes are incremented for each shared memory segment allocated to an instance.</p><p><code>IDS 采用的共享内存基键值为 0x52564801。这个由 4 字节组成的键值可以拆分为两部分。前两个字节反映了每个数据库服务器实例的唯一标识值，而后两个字节则针对分配给每个实例的每个共享内存段进行递增。</code></p><p>To produce the shared memory key for a database server, <strong>oninit</strong> simply adds the value of the SERVERNUM configuration parameter to the value of the first two bytes (0x5256). For example, a system with a SERVERNUM value of 3 has a shared memory key of 0x52594801 (0x5256 + 0x3 &#x3D; 0x5259).</p><p><code>为了生成 database server 的共享内存键值，oninit 进程只需将 SERVERNUM 配置参数的值加到前两个字节（0x5256）的值上。例如，在一个 SERVERNUM 值为 3 的系统中，其共享内存键值将是 0x52594801（0x5256 + 0x3 = 0x5259）。</code></p><p>When <strong>oninit</strong> allocates additional segments, it increments the value of the last two bytes in the shared memory key until all required segments have been allocated. For example, 0x52594801, 0x52594802, 0x525984803, and so forth.</p><p><code>当 oninit 分配额外的共享内存段时，它会递增共享内存键值中最后两个字节的值，直到所有需要的共享内存段都分配完毕。例如，键值会依次变为 0x52594801、0x52594802、0x52594803，以此类推。</code></p><p><strong>Shared Memory Creation and Initialization</strong></p><p><strong>oninit</strong> performs the following steps during Initialization mode:</p><p><code>oninit 在初始化模式（Initialization mode）期间执行以下步骤：</code></p><p>– Based on configuration values, it calculates the total size of memory required</p><p><code>根据配置值，它计算出所需内存的总大小。</code></p><p>– It determines the shared memory key based on SERVERNUM</p><p><code>它根据 SERVERNUM 确定共享内存键值。</code></p><p>– It creates necessary shared memory segments using the <strong>shmget</strong> function</p><p><code>它使用 shmget 函数创建必要的共享内存段。</code></p><p>– It attaches to new segments using the <strong>shmat</strong> function</p><p><code>它使用 shmat 函数附加到新的共享内存段。</code></p><p>– It initializes all shared memory structures; if the <strong>-i</strong> option has been used, it also initializes the root chunk</p><p><code>它初始化所有共享内存结构；如果使用了 -i 选项，它还会初始化 root chunk。</code></p><p>– Shared memory initialization fails unless <strong>shmat</strong> has mapped all segments oninit address space in one contiguous block</p><p><code>除非 shmat 将所有共享内存段一次性连续映射到 oninit 进程的地址空间中，否则共享内存初始化将会失败。</code></p><p><strong>Notes:</strong></p><p>When Informix Dynamic Server shared memory is initialized, more is involved than simply creating the segments. Once the memory has been allocated, the database server attaches to the segments and writes to them, giving the memory a structure. Most of the time required for server initialization is taken by this structure initialization process.</p><p><code>在初始化 IDS 的共享内存时，不仅仅是创建共享内存段那么简单。一旦内存分配完成，数据库服务器就会附加到这些段上并向其中写入数据，从而为内存赋予特定的结构。服务器初始化过程中所需的大部分时间都花在了这个结构初始化的步骤上。</code></p><blockquote><p>involve 涉及 英[ɪnˈvɒlv] 美[ɪnˈvɑːlv]</p></blockquote><p><strong>Allocating Shared Memory</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221420687.png" alt="image-20250622142059618"></p><p><strong>Notes:</strong></p><p>When allocating shared memory for each portion, the <strong>oninit</strong> process first attempts to create one segment that holds all the configured structures. If this attempt fails, <strong>oninit</strong>divides the requested size by two and retries until the allocation either succeeds, or the requested size is less than four kilobytes, in which case, <strong>oninit</strong> exits with an error.</p><p><code>在为各个部分分配共享内存时，oninit 进程首先会尝试创建一个能够容纳所有已配置结构的单个共享内存段。如果这一尝试失败，oninit 会将请求的内存大小减半，然后再次尝试分配，直到分配成功，或者请求的内存大小小于四千字节（4KB），在这种情况下，oninit 会以错误状态退出。</code></p><p>Once the first request succeeds, more segments might be required depending on how many times the requested size had to be reduced. The requested size is not reduced again, however, until what remains to be allocated is less than this size. In other words, each segment must be the same size as the first except for the last allocated segment.</p><p><code>一旦首次分配请求成功，后续可能还需要分配更多的共享内存段，这取决于请求的内存大小需要被减半多少次才能成功分配。然而，在剩余待分配的内存量小于首次成功分配的内存大小之前，不会再对请求的内存大小进行减半操作。换句话说，除了最后一个分配的段之外，每个后续分配的段的大小都必须与首次成功分配的段大小相同。</code></p><p>If any of those subsequent allocations fail, <strong>oninit</strong> exits with an error.If all goes well, <strong>oninit</strong> moves onto the next step in Initialization mode, which involves attaching to and writing to the newly-created segments.</p><p><code>如果这些后续的共享内存分配操作中有任何一个失败，oninit 进程将以错误状态退出。如果所有分配操作都顺利进行，oninit 将进入初始化模式的下一步，这包括附加到新创建的共享内存段并向其中写入数据。</code></p><p><strong>Attaching to Shared Memory</strong></p><ol><li><p>Calculate SHMKEY based on SERVERNUM.</p><p><code>根据 SERVERNUM 计算 SHMKEY。</code></p></li><li><p>Get the ID for a segment with this SHMKEY using <strong>shmget</strong></p><p><code>使用 shmget 获取具有此 SHMKEY 的共享内存段的标识符（ID）。</code></p></li><li><p>Attach the first segment at SHMBASE using <strong>shmat</strong></p><p><code>使用 shmat 将位于 SHMBASE 的首个共享内存段附加到进程的地址空间。</code></p></li><li><p>If <strong>shmat</strong> does not return SHMBASE, print error and exit</p><p><code>如果 shmat 没有返回 SHMBASE，则打印错误信息并退出程序。</code></p></li><li><p>Attach to additional segments.</p><p><code>附加（连接）到额外的共享内存段。</code></p></li></ol><p>​– The size of each segment is stored in the first segment</p><p>​<code>每个共享内存段的大小存储在首个共享内存段中。</code></p><p>​– Based on these sizes, calculate all desired base addresses</p><p>​<code>基于这些大小，计算所有期望的基地址。</code></p><p>​– By simply incrementing SHMKEY for each segment, obtain each ID from <strong>shmget</strong>, and pass the ID to <strong>shmat</strong></p><p>​<code>通过对每个共享内存段简单地递增 SHMKEY，从 shmget 获取每个段的标识符（ID），然后将该 ID 传递给 shmat。</code></p><p><strong>Notes:</strong></p><p>When a request is made to attach to shared memory, Informix Dynamic Server performs the following steps:</p><ol><li><p>The process calculates shared memory key based on SERVERNUM in configuration file.</p><p><code>该进程根据配置文件中的 SERVERNUM 计算 shared memory key。</code></p></li><li><p>Based on the shared memory key, the process uses <strong>shmget</strong> to find the shared memory ID for the first segment.</p><p><code>基于 shared memory key，该进程使用 shmget 来查找首个共享内存段的标识符（ID）。</code></p></li><li><p>Using <strong>shmat</strong>, the process tries to attach the first shared memory segment at SHMBASE.</p><p><code>该进程使用 shmat 尝试将首个共享内存段附加到 SHMBASE 地址处。</code></p></li><li><p>If the segment has been attached at a different address from SHMBASE, the process prints an error and exits.</p><p><code>如果该共享内存段已被附加到一个与 SHMBASE 不同的地址上，该进程会打印错误信息并退出。</code></p></li><li><p>Based on the size of the first attached segment that is stored in the segment itself, the process calculates the next shared memory base address, and continues attaching segments until it is finished.</p><p><code>基于首个已附加共享内存段中存储的该段大小信息，该进程会计算下一个共享内存段的基地址，并继续附加共享内存段，直到完成所有操作。</code></p></li></ol><p><strong>Multiple Segments</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251909621.png" alt="image-20250625190940501"></p><p><strong>Notes:</strong></p><p>When you first initialize a database server, it allocates segments for the resident portion, the virtual portion, and optionally, the message portion. Even though a single portion of shared memory can consist of multiple segments, it is logically viewed (addressed) by the process as if it was one contiguous block of memory. That is why all segments belonging to a shared memory portion must be contiguous when attached to the process. Segments from one <em>portion</em> of shared memory need not be contiguous to segments from other portions.</p><p><code>在首次初始化 database server 时，它会为驻留部分（resident portion）、虚拟部分（virtual portion）以及可选的消息部分（message portion）分配共享内存段。尽管共享内存的单个部分可能由多个段组成，但在逻辑上，进程会将其视为一个连续的内存块来进行访问（寻址）。这就是为什么属于同一共享内存部分的所有段在附加到进程时必须是连续的。然而，来自共享内存一个部分的段并不需要与来自其他部分的段保持连续。</code></p><p>The resident portion segments are the first segments attached to the <strong>oninit</strong> process. Next are the virtual portion segments, and finally the message segments.</p><p><code>驻留部分（resident portion）的段是首先附加到 oninit 进程的。接下来是虚拟部分（virtual portion）的段，最后是消息部分（message）的段。</code></p><p><strong>New virtual segments</strong></p><p>One exception to this rule is new virtual segments that are added to shared memory dynamically after the database server is initialized. They obviously can be attached in different locations within process memory. In the example above, virtual segment #3 was allocated dynamically.</p><p><code>这一规则的一个例外情况是，在 database server 初始化之后，动态添加到共享内存中的新 virtual segments。显然，这些新 segment 可以在进程内存的不同位置进行附加。在上面的例子中，virtual segment #3 就是动态分配的。</code></p><p><strong>Client processes</strong></p><p>Clients using a shared memory connection attach only to the message portion of shared memory. Instead of attaching at SHMBASE, they attach at a value that is platform-specific. You can modify the location where the client attaches by setting the INFORMIXSHMBASE environment variable.</p><p><code>使用共享内存连接的客户端仅附加到共享内存的消息部分。它们并不 attach 到 SHMBASE 地址，而是 attach 到一个与平台相关的特定值上。你可以通过设置 INFORMIXSHMBASE 环境变量来修改客户端 attach 的位置。</code></p><p><strong>Shared Memory Usage: onstat -g seg</strong></p><p>To monitor shared memory segments:</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251918133.png" alt="image-20250625191843067"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g seg</strong> command shows how shared memory is used within the Informix Dynamic Server.</p><p><code>onstat -g seg 命令用于显示 IDS 中共享内存的使用情况。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251922364.png" alt="image-20250625192241293"></p><p>addr: 该段内存附加到 Dynamic Server 可执行文件起始位置的地址</p><p>ovhd: 系统开销所需的字节数</p><p>The values in the <strong>id</strong> and <strong>key</strong> columns are similar to those columns returned by the <strong>ipcs -m</strong> command. The difference is that <strong>ipcs</strong> returns key values in hexadecimal notation.</p><p><code>id 列和 key 列中的值与通过 ipcs -m 命令返回的相应列中的值类似。不同之处在于，ipcs 命令返回的键值（key values）是以十六进制表示法显示的。</code></p><p><strong>Shared Memory Addresses</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251926925.png" alt="image-20250625192646856"></p><p><strong>Notes:</strong></p><p>Each shared memory element is located at a fixed offset into shared memory. In addition to displaying the information held in the shared memory structures themselves, <strong>onstat -k</strong> displays the address of each structure, which is essentially SHMBASE plus the offset.</p><p><code>每个共享内存元素都位于共享内存中的一个固定偏移量位置。除了显示共享内存结构本身所包含的信息外，onstat -k 命令还会显示每个结构的地址，这个地址本质上就是 SHMBASE 加上该结构的偏移量。</code></p><p>For example, the shared memory address of the first active lock structure in the example above is 0xa031dd4. A process attached to this shared memory would find the structure at that address within its memory space. Since the memory is attached at SHMBASE, which happens to be 0xa00000 in this case, we can tell that the user structure is located at an offset of 0x31dd4 bytes into shared memory.</p><p><code>例如，在上述示例中，第一个 active lock 结构的共享内存地址是 0xa031dd4。一个附加到该共享内存的进程会在其内存空间中的该地址处找到该结构。由于内存是附加在 SHMBASE 处的，而在这个例子中 SHMBASE 恰好是 0xa00000，因此我们可以推断出，该用户结构位于共享内存中偏移量为 0x31dd4 字节的位置。</code></p><p>The address location can also be used to determine the portion of shared memory in which the structure resides. Compare the address of the structure with the addresses of the shared memory portions shown in the <strong>onstat -g ses</strong> output.</p><p><code>该地址位置还可用于确定该结构位于共享内存的哪一部分。可以将该结构的地址与 onstat -g ses 命令输出中显示的共享内存各部分的地址进行比较。</code></p><p>The offset value of a particular structure is important to someone analyzing a shared memory dump file, but it is irrelevant to an attached process. Informix Dynamic Server processes access shared memory structures only by using the full shared memory address of the structure.</p><p><code>对于分析共享内存转储文件的人来说，特定结构的偏移量值非常重要，但对于已附加的进程而言，该偏移量值并无实际意义。IDS 进程仅通过使用结构的完整共享内存地址来访问共享内存结构。</code></p><p><strong>The Resident Portion</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251934017.png" alt="image-20250625193421945"></p><p><strong>Notes:</strong></p><p>The resident portion of shared memory consists mainly of <em>structure arrays</em>. For convenience, we sometimes refer to these arrays as <em>tables</em>.</p><p><code>共享内存的驻留部分主要由 structure arrays 构成。为方便起见，我们有时将这些数组称为 tables。</code></p><p><strong>Note</strong></p><p>These shared memory <em>tables</em> should not to be confused with database tables.</p><p><code>这些共享内存中的表（tables）不应与数据库表（database tables）相混淆。</code></p><p><strong>Tracking Shared Memory Segments</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251936937.png" alt="image-20250625193655853"></p><p><strong>Notes:</strong></p><p>The first segment of resident shared memory contains two structures at fixed addresses that allow access to all other portions of shared memory.</p><p><code>驻留共享内存的第一个段包含两个位于固定地址的 structure，这两个 structure 允许访问共享内存的所有其他部分。</code></p><p>The first of these structures resides at SHMBASE. This structure describes the first shared memory segment, which means it points to itself.</p><p><code>这些 structure 中的第一个位于 SHMBASE（共享内存基地址）。该 structure 描述了第一个共享内存段，这意味着它指向自身。</code></p><p>The second structure appears immediately following the first. This structure is the shared memory master control block. Some of the more significant entries in this structure are:</p><p><code>第二个 structure 紧接着第一个结构之后出现。这个 structure 是共享内存主控制块（shared memory master control block）。该结构中一些较为重要的条目包括：</code></p><p> <strong>•</strong> The size of the first and last shared memory segments</p><p><code>第一个和最后一个共享内存段的大小</code></p><p> <strong>•</strong> The total size of each shared memory portion</p><p><code>每个共享内存部分的总大小</code></p><p> <strong>•</strong> A pointer to a linked list that describes each segment</p><p><code>指向描述每个段的链表的指针</code></p><p> <strong>•</strong> A pointer to the linked list of shared memory pools</p><p><code>指向共享内存池链表的指针</code></p><p> <strong>•</strong> A pointer to the shared memory header table</p><p><code>指向共享内存头表的指针</code></p><p><strong>The Header Table</strong></p><p>The header table is the starting point for accessing IDS resources. It contains:</p><p><code>header table 是访问 IDS 资源的起点。它包含：</code></p><p>– Pointers to resources (chunks, dbspaces, rstcb, transactions, dynamic lock tables, etc.)</p><p><code>指向资源（如数据块、数据库空间、恢复控制块、事务、动态锁表等）的指针</code></p><p>– Pointers to a linked list of sessions and environment variables</p><p><code>指向会话和环境变量链表的指针</code></p><p>– Parameters and other information, such as boot time, current time, LRU parameters, read-ahead values, archive flags, etc.</p><p><code>参数以及其他信息，例如启动时间、当前时间、LRU 参数、预读值、归档标志等。</code></p><p><strong>Notes:</strong></p><p>The header table is the main source for accessing database server resources. Almost all access starts from here. Some of the information that can be accessed from the header table is shown above.</p><p><code>头表是访问数据库服务器资源的主要来源。几乎所有的访问都从这里开始。上面展示了一些可以从头表中访问到的信息。</code></p><p><strong>Physical Layout of the Virtual Portion</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251946064.png" alt="image-20250625194611011"></p><p><strong>Notes:</strong></p><p>The virtual portion is divided into a series of 4K memory <em>blocks</em>. When a thread needs memory for its individual tasks, it takes one or more <em>contiguous</em> blocks.</p><p><code>虚拟部分被划分为一系列 4K 大小的 memory blocks。当一个线程需要为其独立任务分配内存时，它会获取一个或多个连续的 memory blocks。</code></p><p>A bitmap tracks the usage of each 4K block.</p><p><code>位图用于跟踪每个4K内存块的使用情况。</code></p><p><strong>Shared Memory Pools</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251954485.png" alt="image-20250625195428400"></p><p><strong>Notes:</strong></p><p>A shared memory <em>pool</em> is a collection of memory blocks or <em>fragments</em>. A memory fragment can be any size, but the memory for that fragment must be contiguous. </p><p><code>共享内存池是一组内存块(blocks)或片段的集合。内存片段可以是任意大小，但该片段的内存必须是连续的。</code></p><p>Each memory fragment consists of:</p><p><code>每个内存片段由以下部分组成：</code></p><ul><li><p>Block header</p><p>The header tracks if the memory is used in the fragment, how much memory it contains, the type of data stored in it, and pointers to the next and previous fragment in the pool. Free blocks also contain a pointer to the next and previous free block.</p><p><code>该头部（或称为头信息）会跟踪内存片段中的内存是否被使用、该片段包含多少内存、其中存储的数据类型，以及指向内存池中下一个和上一个片段的指针。空闲块还包含指向下一个和上一个空闲块的指针。</code></p></li><li><p>Data</p><p>The data consists of any information appropriate to the pool. For example, a sort pool holds temporary data for a sort operation.</p><p><code>这些数据包含与该内存池相关的任何信息。例如，一个排序内存池会存储用于排序操作的临时数据。</code></p></li></ul><p>For new pools, the first fragment (or <em>overhead</em> fragment) contains the pool header. The pool header has a pointer to the first and last memory blocks in the pool. Also, the pool header contains a pointer to the free list in the first free block in the pool.</p><p><code>对于新建的内存池，首个内存片段（或称为开销片段）中包含内存池的头部信息。该内存池头部包含指向池中首个和最后一个内存块的指针。此外，内存池头部还包含一个指向池中首个空闲块内空闲链表的指针。</code></p><p><strong>Types of Shared Memory Pools</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506252001963.png" alt="image-20250625200157887"></p><p><strong>Notes:</strong></p><p>Shared memory pools can be classified into one of these three types:</p><p><code>共享内存池可以归类为以下三种类型之一：</code></p><p> <strong>•</strong> <em>System pools</em> are generally used by and are available to all threads in the database server. Usually these pools are initialized when the database server is started, and remain until the server is brought down.</p><p><code>系统内存池通常被 database server 中的所有线程使用，并且对这些线程都可用。通常，这些内存池在 database server 启动时进行初始化，并一直存在，直到服务器关闭。</code></p><p> <strong>•</strong> The <em>global pool</em> is used as a general area for threads that do not have a pool allocated for them. For example, network threads that need to allocate memory for internal uses use the global pool.</p><p><code>全局内存池被用作那些未分配专用内存池的线程的通用区域。例如，需要为内部用途分配内存的网络线程就会使用全局内存池。</code></p><p> <strong>•</strong> Each session has its own <em>session pool</em> that is used for any session-related information. The pool is created when the session is created, and the name of the pool is the same as the session number. The memory is returned to the virtual portion when the session terminates.</p><p><code>每个会话（session）都有其专属的会话内存池，用于存储与该会话相关的任何信息。该内存池在会话创建时被创建，且内存池的名称与会话编号相同。当会话结束时，内存会被归还给虚拟内存部分。</code></p><p><strong>Common shared memory pools</strong></p><p>The following list shows the most commonly used pools and their contents:</p><p><code>以下列表展示了最常用的内存池及其内容：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506252005732.png" alt="image-20250625200547618"></p><p><strong>Pool Usage: onstat -g mem</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261905744.png" alt="image-20250626190521615"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g mem</strong> command lists all allocated pools.</p><p><code>onstat -g mem 命令会列出所有已分配的内存池。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261906902.png" alt="image-20250626190639844"></p><p>To see information about the fragments allocated to a pool, you can execute the above command followed by the name of a pool. For example:</p><p><code>要查看分配给某个内存池的片段的相关信息，可以在执行上述命令后加上该内存池的名称。例如：</code></p><p>​onstat -g mem global</p><p><strong>Shared Memory Caches</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261908933.png" alt="image-20250626190805870"></p><p><strong>Notes:</strong></p><p>To help in improving database server performance, Informix Dynamic Server allows users to share certain types of objects by providing special pools, or <em>caches</em>, in shared memory.</p><p><code>为助力提升 database server 性能，IDS 允许用户通过在共享内存中提供特殊的池（或称为缓存）来共享某些类型的对象。</code></p><p><strong>Data Dictionary Cache</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261909297.png" alt="image-20250626190957222"></p><p><strong>Notes:</strong></p><p>The <em>data dictionary cache</em> is used to store system catalog table information. On an OLTP system, it is common for multiple users to access tables within the same database. Because all queries on tables require a request to a system catalog table (to locate the partition page of a table, for example, the <strong>systables</strong> table must be queried to find the table’s partition number), I&#x2F;O can be reduced by allowing system catalog information to reside in shared memory. </p><p><code>data dictionary cache 用于存储 system catalog table 的信息。在 OLTP 系统中，多个用户通常会访问同一数据库中的表。由于对表的所有查询都需要访问 system catalog table（例如，为了定位表的 partition page，必须查询 systables 表以找到该表的 partition number），因此通过允许 system catalog 信息驻留在共享内存中，可以减少 I/O 操作。</code></p><p>Unlike the shared memory buffer, the data dictionary cache does not store entire pages from the data dictionary. System catalog rows are stored as <em>entries</em> in one of several <em>lists</em> held within the data dictionary cache. The data dictionary cache has a default of 31 lists with each list having up to 10 entries. You can configure the number of lists by setting the DD_HASHSIZE configuration parameter to any <em>prime</em> number. The maximum number of items in each list is configured by setting the DD_HASHMAX parameter.</p><p><code>与共享内存 buffer 不同，data dictionary cache 并不会存储 data dictionary 中的完整页面。System catalog rows 是以条目的形式存储在 data dictionary cache 所持有的若干列表之一中的。data dictionary cache 默认有31个列表，每个列表最多可包含10个条目。你可以通过将 DD_HASHSIZE 配置参数设置为任意质数来配置列表的数量。每个列表中的最大条目数则通过设置 DD_HASHMAX 参数来进行配置。</code></p><p>When system catalog rows are modified, the pages that contain these rows are handled through the shared memory buffer like any other pages.</p><p><code>当 system catalog rows 被修改时，包含这些行的页面会像其他任何页面一样，通过共享内存 buffer 进行处理。</code></p><p>The data dictionary cache, as well as other object caches, are not pre-populated when the server is initialized. Entries are made into the data dictionary cache as requests are received. When the cache is filled, entries are replaced based on a least-recently-used basis.</p><p><code>data dictionary cache 以及其他对象缓存，在 server 初始化时并不会预先填充。当接收到请求时，才会将相应的条目存入 data dictionary cache 中。当缓存被填满时，会根据最近最少使用（LRU，Least Recently Used）的原则来替换条目。</code></p><p><strong>Stored Procedure Cache</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261918133.png" alt="image-20250626191825059"></p><p><strong>Notes:</strong></p><p>The <em>stored procedure cache</em> is responsible for maintaining information about user-defined routines from the <strong>sysprocedures</strong> and <strong>sysprocbody</strong> catalogs. This allows users who are sharing routines to access them directly from shared memory without having to read the catalog pages from disk. </p><p><code>procedure cache 负责维护来自 sysprocedures 和 sysprocbody 系统目录表(catalogs)的用户自定义例程（存储过程或函数）的相关信息。这使得共享这些例程的用户能够直接从共享内存中访问它们，而无需从磁盘读取目录页。</code></p><p>When routines are created or deleted, the pages that contain the routine definitions are handled through the shared memory buffer pool. </p><p><code>当创建或删除例程（存储过程或函数）时，包含这些例程定义的页面会通过共享内存 buffer pool 进行处理。</code></p><p>Like the data dictionary cache, the stored procedure cache maintains lists of entries; each entry contains the definition for a different user-defined routine. By default, the stored procedure cache can have up to 31 lists that contain a maximum of 127 entries. You can override these defaults by setting, respectively, the PC_HASHSIZE and PC_POOLSIZE configuration parameters. The PC_HASHSIZE must be a prime number.</p><p><code>与 data dictionary cache 类似，procedure cache 也会维护条目列表；每个条目都包含一个不同用户自定义例程（存储过程或函数）的定义。默认情况下，存储过程缓存最多可以有31个列表，每个列表最多包含127个条目。你可以分别通过设置 PC_HASHSIZE 和 PC_POOLSIZE 配置参数来覆盖这些默认值。其中，PC_HASHSIZE 必须是一个质数。</code></p><p><strong>Global Statement Cache</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261922980.png" alt="image-20250626192249908"></p><p><strong>Notes:</strong></p><p>The <em>global (SQL) statement cache</em> is a place where frequently executed SQL statements could be stored and shared. </p><p><code>global (SQL) statement cache 是一个用于存储和共享频繁执行的SQL语句的地方。</code></p><p>Every time an SQL statement is received by the database server, it must be checked for syntax, encoded, and optimized. When enabled, the statement cache receives these preprocessed statements and saves them in a text and encoded form. Repeated statements can then be executed directly from the global statement cache without having to be preprocessed.</p><p><code>每当 database server 接收到一条 SQL 语句时，都必须对其进行语法检查、编码和优化。当启用语句缓存功能后，语句缓存会接收这些经过预处理的语句，并以文本和编码的形式将它们保存起来。这样，对于重复执行的语句，就可以直接从全局语句缓存中执行，而无需再次进行预处理。</code></p><p>The global statement cache is enabled by setting the STMT_CACHE configuration parameter to either 1 or 2. A value of 1 enables the statement cache, but statement caching is disabled by default for sessions. A value of 2 enables the statement cache and sets the session default to enabled. Statement caching is disabled if STMT_CACHE is set to 0. The total size of the statement cache is configured by setting the STMT_CACHE_SIZE configuration parameter. The default size is 512K.</p><p><code>通过将 STMT_CACHE 配置参数设置为 1 或 2，可以启用全局语句缓存(global statement cache)。当该参数值为 1 时， statement cache 功能被启用，但默认情况下，会话级别的 statement caching 是禁用的。当该参数值为 2 时， statement cache 功能被启用，并且会话级别的默认设置也变为启用。如果将 STMT_CACHE 设置为 0，则 statement cache 功能将被禁用。 statement cache 的总大小可通过设置 STMT_CACHE_SIZE 配置参数来进行配置，其默认大小为 512K。</code></p><p>You can override the STMT_CACHE configuration parameter either by setting the STMT_CACHE environment variable to either 0 (disabled) or 1 (enabled), or by executing the SQL command:</p><p><code>你可以通过以下两种方式之一来覆盖 STMT_CACHE 配置参数：将 STMT_CACHE 环境变量设置为 0（禁用）或 1（启用）；或通过执行以下 SQL 命令：</code></p><p>​SET STATEMENT CACHE {ON|OFF};</p><p><strong>Private Memory Cache on CPU VPs</strong></p><p> Blocks of cache memory from 1 to 32 blocks in length</p><p><code>长度为 1 到 32 个块的缓存内存块</code></p><p> 4096 block size</p><p> Associated with each CPU virtual processor allocated</p><p><code>与每个已分配的 CPU 虚拟处理器相关联</code></p><p> Speeds up access to memory and performance of the CPU VPs</p><p><code>加快对内存的访问速度并提升 CPU 虚拟处理器（VPs）的性能</code></p><p><strong>Notes:</strong></p><p>The purpose of the private memory cache is to provide CPU VPs with their own blocks of shared memory that they can use to process their own memory allocation requests. The private cache provides a staging area for memory allocation requests that can be handled much faster than when competing with other CPU VP requests.</p><p><code>private memory cache 的目的是为每个 CPU 虚拟处理器（VPs）提供它们各自专用的共享内存块，这些内存块可用于处理它们自身的内存分配请求。私有缓存为内存分配请求提供了一个暂存区域，通过该区域处理内存分配请求的速度要比与其他 CPU 虚拟处理器的请求竞争时快得多。</code></p><p><strong>Note</strong></p><p>The private memory cache was introduced in version 11.10 of Informix Dynamic Server.</p><p><code>private memory cache 是在 IDS 的 11.10 版本中引入的。</code></p><p><strong>Private Memory Cache Implementation</strong></p><p> Static settings</p><p>– Configuration parameter: VP_MEMORY_CACHE_KB</p><p>– Default value is 0: feature is turned off </p><p>– 800 is the default minimum value (800 KB)</p><p>– Maximum value should not exceed 40% of SHMTOTAL</p><p> Dynamic tuning</p><p>– onmode –wm VP_MEMORY_CACHE_KB&#x3D; value</p><p>– onmode –wf VP_MEMORY_CACHE_KB&#x3D; value</p><p>– Setting to 0 disables the feature and empties caches</p><p><strong>Notes:</strong></p><p>To implement support for private memory caching, set the VP_MEMORY_CACHE_KB parameter to the amount of memory to allocate for all private memory caches. 800 kilobytes is the default size and the minimum setting for this parameter.</p><p><code>要实现对 private memory caching 的支持，需将 VP_MEMORY_CACHE_KB 参数设置为要为所有 private memory caches 分配的内存量。该参数的默认大小为 800 KB，同时也是其最小设置值。</code></p><p>You can also set the VP_MEMORY_CACHE_KB parameter by using the <strong>onmode -wm</strong> or <strong>-wf</strong> command.</p><p><code>你也可以通过使用 onmode -wm 或 -wf 命令来设置 VP_MEMORY_CACHE_KB 参数。</code></p><p><strong>Note</strong></p><p>The <strong>onmode -wm</strong> command changes the parameter for the current session only. Messages are written to the message log file and to the command line.</p><p>The <strong>onmode -wf</strong> command changes the value used by the database server and saves the value in the configuration file. A message is written only to the message log file.</p><p><strong>Monitoring the VP Memory Cache</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261938086.png" alt="image-20250626193826002"></p><p><strong>Notes:</strong></p><p>To view private memory cache statistics, use the <strong>onstat -g vpcache</strong> command. </p><p><code>要查看 private memory cache 的统计信息，请使用 onstat -g vpcache 命令。</code></p><p>The CPU VP memory block cache statistics report provides the following information:</p><p><code>CPU 虚拟处理器（VP）内存块(block)缓存统计信息报告提供以下信息：</code></p><p> <strong>• size</strong> – memory block size, based on 4096-byte blocks</p><p><code>内存块大小（基于 4096 字节的块）</code></p><p> <strong>• cur blks</strong> – current number of blocks—this is a multiple of the <strong>size</strong> field</p><p><code>当前 block 数量——这是 size 字段的倍数</code>（我的理解：size是1、2、3……个4096字节大小的块，即: n * 4096，cur blks: m * (n * 4096)）</p><p> <strong>• alloc</strong> – number of times a requestor was given a block of this size</p><p><code>请求者被分配到此大小内存块的次数</code></p><p> <strong>• miss</strong> – number of times a block was requested but none were available</p><p><code>请求内存块但无可用块时的次数</code></p><p> <strong>• free</strong> – number of times a memory block was placed into the cache</p><p><code>内存块被放入缓存的次数</code></p><p> <strong>• drain</strong> – number of times an aged block was forced out to make room</p><p><code>为腾出空间而强制移除老旧内存块的次数</code></p><p> <strong>• release</strong> – number of times the size limit was reached and a block couldn’t be inserted The report repeats for each CPU VP allocated.</p><p><code>达到大小限制且无法插入内存块的次数。该报告会针对每个已分配的 CPU 虚拟处理器（VP）重复列出此信息。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 11.Communications</title>
      <link href="/2025/06/21/IX9111/11/"/>
      <url>/2025/06/21/IX9111/11/</url>
      
        <content type="html"><![CDATA[<p><strong>Types of Client&#x2F;Server Communications</strong></p><p>Choices for client&#x2F;server connections:</p><p>– Shared memory</p><p>– Stream pipe </p><p>– TCP&#x2F;IP using</p><p>​• Sockets</p><p>​• TLI</p><p>– IPX&#x2F;SPX</p><p>– DRDA</p><p><strong>Notes:</strong></p><p>Clients can connect to the database server by one of the methods shown above.If clients are on the same machine as the database server, they most likely connect through shared memory or stream pipes. Shared memory is usually faster, but can be a security risk, as the shared memory message segment has read and write permissions for all clients. </p><p><code>客户端可通过上述其中一种方法连接到 database server。如果客户端与 database server 位于同一台机器上，那么它们最有可能通过共享内存或流管道进行连接。共享内存的速度通常更快，但可能存在安全风险，因为共享内存消息段对所有客户端均设有读写权限。</code></p><p>Remote clients connect using TCP&#x2F;IP or IPX&#x2F;SPX.In this chapter, we will take an in depth look at the shared memory connection, since it is a custom implementation of Informix Dynamic Server. We will also look at TCP&#x2F;IP and streams, but these implementations use generic function calls.</p><p><code>远程客户端使用 TCP/IP 或 IPX/SPX 协议进行连接。在本章中，我们将深入探讨共享内存连接方式，因为它是 IDS 的一种自定义实现方式。我们也会探讨 TCP/IP 和流（streams）连接方式，但这些实现方式使用的是通用函数调用。</code></p><p><strong>Shared Memory Message Segment</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281450953.png" alt="image-20250628145034847"></p><p><strong>Notes:</strong></p><p>Clients connect to the database server through the message portion of Informix Dynamic Server shared memory. The size of the message portion is dependent upon the number of users that are allowed to connect to shared memory, set in the NETTYPE parameter. The shared memory message segment has the following components:</p><p><code>客户端通过 IDS 共享内存的消息部分与 server 建立连接。消息部分的大小取决于允许连接到共享内存的用户数量，这一数量由 NETTYPE 参数设定。共享内存消息段包含以下组件：</code></p><p> <strong>•</strong> Shared memory data – There is one shared memory data structure for each poll thread configured for the IDS server. It contains the bitmap for the message buffers and a bitmap for the message status areas. It also has tables for message buffer addresses and message buffer system status areas.</p><p><code>针对为 IDS 服务器配置的每个轮询线程（poll thread），都存在一个共享内存数据结构。该数据结构包含 message buffers 的位图（bitmap）以及 message status areas 的位图。此外，它还包含 message buffer 地址表和 message buffer 系统状态区域表。</code></p><p> <strong>•</strong> Status area – The status area contains one structure for each client connection. This structure includes the client ID, the connection state, the semaphore the client sleeps on, and the buffers the client is reading and writing to. In addition, it keeps a list of each buffer owned by the client ID and its status.</p><p><code>状态区域为每个客户端连接都包含一个结构体。这个结构体包含客户端ID、连接状态、client sleeps on 时所使用的信号量（semaphore），以及客户端正在读写缓冲区（buffers）的相关信息。此外，它还会维护一个列表，记录客户端ID所拥有的每个缓冲区及其状态。</code></p><p> <strong>•</strong> Message buffers – This contains the actual message buffers. The number of message buffers allocated when the system is initialized is: 8 * <em>users</em> * 1.2. The value of <em>users</em> is the number of connections as specified in the NETTYPE configuration parameter times the number of poll threads.</p><p><code>这部分包含实际的消息缓冲区。系统初始化时分配的消息缓冲区数量计算公式为：8 * users * 1.2。其中，users 的值等于 NETTYPE 配置参数中指定的连接数乘以轮询线程（poll threads）的数量。</code></p><p><strong>How Message Buffers are Used</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281459157.png" alt="image-20250628145953088"></p><p><strong>Notes:</strong></p><p>The status area for a client contains pointers to buffers it <em>owns</em> in the message buffer pool. Buffers allocated to a client ID can be classified as either client buffers or server buffers.</p><p><code>客户端的 status area 包含指向该客户端在消息缓冲区池（message buffer pool）中“拥有”的缓冲区的指针。分配给某个客户端ID的缓冲区可以分为客户端缓冲区（client buffers）或服务器缓冲区（server buffers）。</code></p><p> <strong>•</strong> Client buffers are buffers that the client writes to and the server reads from.</p><p><code>客户端缓冲区（client buffers）是指客户端向其中写入数据，而服务器从中读取数据的缓冲区。</code></p><p> <strong>•</strong> Server buffers are buffers that the server writes to and the client reads from.</p><p><code>服务器缓冲区（server buffers）是指服务器向其中写入数据，而客户端从中读取数据的缓冲区。</code></p><p>Initially, a client connection is allocated 4 client buffers and 4 server buffers. If the session needs more buffers, the server allocates up to 10 buffers for the client and 10 buffers for the server. If the session needs more than 10 buffers, it waits on a semaphore until one is available.</p><p><code>最初，为每个客户端连接分配 4 个客户端缓冲区和 4 个服务器缓冲区。如果会话需要更多缓冲区，server 会为客户端分配最多 10 个缓冲区，为 server 分配最多 10 个缓冲区。如果会话需要的缓冲区数量超过 10 个，那么它会在信号量（semaphore）上等待，直到有可用的缓冲区为止。</code></p><p>Periodically, the server assigns buffers with a status of NOTINUSE back to the free list for the buffer pool and removes it from the allocated list for client connection.</p><p><code>server 会定期将状态为 NOTINUSE（未使用）的缓冲区重新分配回缓冲区池的空闲列表中，并从客户端连接的已分配列表中移除这些缓冲区。</code></p><p><strong>Shared Memory: How Clients Connect</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281503998.png" alt="image-20250628150322929"></p><p><strong>Notes:</strong></p><p>The following steps detail how the client connects to the database server.</p><ol><li><p>The client reads the file &#x2F;INFORMIXTMP&#x2F;.inf.servicename to get the number of <strong>poll</strong> threads running. If there is more than one <strong>poll</strong> thread running, it selects one. Each poll thread can take a limited number of connections (specified by NETTYPE). If the <strong>poll</strong> thread has reached the connection limit, the client must try another <strong>poll</strong> thread.</p><p><code>客户端会读取文件 /INFORMIXTMP/.inf.servicename 来获取正在运行的 poll（轮询）线程数量。如果存在多个正在运行的 poll 线程，客户端会从中选择一个。每个 poll 线程能够处理的连接数量是有限的（由 NETTYPE 参数指定）。如果某个 poll 线程已达到其连接数量上限，客户端就必须尝试选择另一个 poll 线程。</code></p></li><li><p>The client attaches to the message portion of shared memory.</p><p><code>客户端会附加到共享内存的消息部分。</code></p></li><li><p>The client looks for a free buffer to send a message and fills it.</p><p><code>客户端会寻找一个空闲的缓冲区来发送消息，并将消息填入该缓冲区。</code></p></li><li><p>The <strong>netscb</strong> (network session control block) is initialized for the connection. </p><p><code>netscb（网络会话控制块）会针对该连接进行初始化。</code></p></li><li><p>The client puts the location of the message buffer on the ready queue.</p><p><code>客户端将消息缓冲区的位置放入就绪队列中。</code></p></li><li><p>The client awakens the <strong>poll</strong> thread using a semaphore operation (<strong>semop)</strong>).</p><p><code>客户端使用信号量操作（semop）唤醒 poll 线程。</code></p></li><li><p>The client sleeps on a semaphore to wait for a response.At this point, the poll thread wakes the listen thread, which creates the <strong>sqlexec</strong> thread for the session. From this point on, the <strong>listen</strong> thread is no longer needed for communication.</p><p><code>客户端在信号量上休眠以等待响应。此时，轮询（poll）线程会唤醒监听（listen）线程，该监听线程会为会话创建 sqlexec 线程。从这一刻起，通信过程中就不再需要监听（listen）线程了。</code></p></li></ol><p><strong>Shared Memory: Client Communication</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281511261.png" alt="image-20250628151111193"></p><p><strong>Notes:</strong></p><p>Once a client connects to the message portion of shared memory, it can now communicate with the server through the message queues.</p><p><code>一旦客户端连接到共享内存的消息部分，它现在就可以通过消息队列与服务器进行通信。</code></p><ol><li><p>The client application places a message (SQL STATEMENT, for example) in a free message buffer in the message portion of shared memory. When it uses a buffer, it marks the buffer as used so that it is not overwritten by another client or by the poll thread.</p><p><code>客户端应用程序将一条消息（例如，SQL 语句）放入共享内存消息部分的一个空闲消息缓冲区中。当它使用某个缓冲区时，会将该缓冲区标记为“已使用”，以防止其他客户端或轮询（poll）线程覆盖它。</code></p></li><li><p>The client puts its ID on the message ready queue.</p><p><code>客户端将其标识符（ID）放入消息就绪队列中。</code></p></li><li><p>The client sleeps on a semaphore.</p><p><code>客户端在信号量上休眠（或等待）。</code></p></li><li><p>The poll thread periodically wakes up and looks through the message ready queue, checking to see if a message has been sent.</p><p><code>轮询（poll）线程会定期唤醒，并遍历消息就绪队列，检查是否有消息被发送。</code></p><p><strong>Note</strong></p><p>The poll thread can potentially have a lot of work to do, handling incoming messages; it checks the message ready queue quite often. Although it is generally more efficient for the poll thread to run on the CPU VP (in-line polling), a very busy poll thread could cause the <strong>sqlexec</strong> threads to wait longer for a free CPU VP.</p><p><code>轮询（poll）线程可能面临大量工作，负责处理传入的消息；它会非常频繁地检查消息就绪队列。尽管通常让轮询线程在 CPU 虚拟处理器（VP）上运行（in-line polling，即内联轮询）效率更高，但一个非常繁忙的轮询线程可能会导致 sqlexec 线程需要等待更长时间才能获得一个空闲的 CPU 虚拟处理器（VP）。</code></p></li><li><p>If there is a message, it takes the message entry off the ready queue, and copies the message from the message buffer to the session pool. It releases the message buffer and, if the <strong>sqlexec</strong> thread is waiting on the <strong>sm_read</strong> condition, it puts the <strong>sqlexec</strong> thread on the ready queue to process the message.</p><p><code>如果存在消息，它会从就绪队列中取出该消息条目，并将消息从消息缓冲区复制到会话池中。之后，它会释放该消息缓冲区，并且如果 sqlexec 线程正在等待 sm_read 条件，它会将 sqlexec 线程放入就绪队列中以处理该消息。</code></p></li></ol><p><strong>Shared Memory: Server Communication</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281520299.png" alt="image-20250628152035225"></p><p><strong>Notes:</strong></p><p>The <strong>sqlexec</strong> thread leaves the <strong>poll</strong> thread out of operations that write to the client application.</p><p><code>sqlexec 线程在执行向客户端应用程序写入数据的操作时，不会让 poll 线程参与其中（即 poll 线程不参与这些写入操作）。</code></p><ol><li><p>The <strong>sqlexec</strong> thread places the message to be sent to the client (usually SQL results) in the message buffer. </p><p><code>sqlexec 线程将待发送给客户端的消息（通常是 SQL 查询结果）放入消息缓冲区中。</code></p></li><li><p>The <strong>sqlexec</strong> thread wakes the client process.</p><p><code>sqlexec 线程唤醒客户端进程。</code></p></li><li><p>The client reads the message buffer.</p><p><code>客户端读取消息缓冲区。</code></p></li></ol><p><strong>How Utilities Communicate</strong></p><p>Utilities such as <strong>oncheck</strong> and <strong>ontape</strong> usually do not communicate to the server like other clients. Instead they rely on lower level functions.</p><p><code>像 oncheck 和 ontape 这样的工具通常不会像其他客户端那样与服务器进行通信。相反，它们依赖于底层函数。</code></p><p>– <strong>onbar</strong> uses stream buffers to move pages</p><p><code>onbar 使用 stream buffers 来移动数据页（pages）。</code></p><p>– <strong>onmode</strong> attaches directly to the resident segment and modifies structures itself</p><p><code>onmode 工具直接连接到常驻内存段（resident segment），并自行修改其中的数据结构。</code></p><p>– <strong>oncheck</strong> use lower-level calls to pass messages to its associated server thread</p><p><code>oncheck 使用较低级别的调用（lower-level calls）来向其关联的服务器线程传递消息。</code></p><p><strong>Notes:</strong></p><p>Informix Dynamic Server utilities do not usually connect and send messages like other clients. Instead, they use a variety of techniques, bypassing the high-level communication protocol.</p><p><code>IDS 工具通常不会像其他客户端那样进行连接并发送消息。相反，它们采用多种技术，绕过了高级通信协议。</code></p><p><strong>Files Used for Shared Memory</strong></p><p> &#x2F;INFORMIXTMP&#x2F;.inf.servicename</p><p> $INFORMIXDIR&#x2F;etc&#x2F;.infos.dbservername</p><p><strong>Notes:</strong></p><p>The following files are used in shared memory communications.</p><p><code>以下文件用于共享内存通信。</code></p><p> <strong>• .inf.servicename</strong> – Informix Dynamic Server creates this file when it initiates a shared memory poll thread and removes the file when you take the database server offline. The name of this file is derived from the <strong>servicename</strong> field of the <strong>sqlhosts</strong> file. IDS keeps information about client&#x2F;server connections in this file. If this file is accidently deleted, you must restart the server. This file includes the following information:</p><p><code>IDS 在启动共享内存轮询线程时会创建此文件，并在将数据库服务器置于离线状态时删除该文件。此文件的名称源自 sqlhosts 文件中的 servicename 字段。IDS 会在此文件中保存有关客户端/服务器连接的信息。如果此文件被意外删除，您必须重启服务器。此文件包含以下信息：</code></p><p> <strong>-</strong> Shared memory segment ID</p><p><code>共享内存段ID</code></p><p> <strong>-</strong> Semaphore information for the two semaphores needed by the server.</p><p><code>服务器所需的两个信号量的相关信息。</code></p><p> <strong>-</strong> Number of poll threads</p><p><code>轮询线程的数量</code></p><p> <strong>-</strong> Offset and size of bitmap in shared memory segment</p><p><code>共享内存段中位图（bitmap）的偏移量和大小。</code></p><p> <strong>-</strong> Offset of status area array in message segment</p><p><code>消息段中 status area array 的偏移量。</code></p><p> <strong>• .infos.dbservername</strong> – IDS creates this file when you initialize shared memory and removes the file when you take the server offline. The name of this file is derived from the DBSERVERNAME configuration parameter. These files allow utilities such as <strong>oncheck</strong>, <strong>onstat</strong>, and <strong>ontape</strong> to attach to the database server.</p><p><code>IDS 在初始化共享内存时会创建此文件，而在将服务器置于离线状态时会删除该文件。此文件的名称源自 DBSERVERNAME  配置参数。这些文件允许诸如 oncheck、onstat 和 ontape 之类的实用工具连接到 server。</code></p><p><strong>Semaphores Used for Connections</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302342834.png" alt="image-20250630234242729"></p><p><strong>Notes:</strong></p><p>Informix Dynamic Server uses semaphores for coordinating communication between the client and server when a shared memory connection is used. The semaphore is set to signal if a message is waiting in the message buffer for a client.</p><p><code>IDS 在使用共享内存连接时，会利用信号量（semaphores）来协调客户端与服务器之间的通信。当消息缓冲区中有等待客户端接收的消息时，该信号量会被触发（或置位）。</code></p><p>The number of semaphores used by a database server depends on the number of connections allocated in the NETTYPE configuration parameter. If NETTYPE is not set, the database server defaults to 50 user connections. The server allocates a semaphore set containing one semaphore for each connection.</p><p><code>database server 所使用的信号量数量，取决于在 NETTYPE 配置参数中分配的连接数。若未设置 NETTYPE 参数，database server 将默认采用 50 个用户连接。server 会为每个连接分配一个包含单个信号量的信号量集合。</code></p><p>Two additional semaphores are controlled in the <strong>&#x2F;INFORMIXTMP&#x2F;.inf.servicename</strong> file. </p><p><code>/INFORMIXTMP/.inf.servicename 文件中还控制着另外两个信号量。</code></p><p>Because client processes don’t know anything about mutexes, these semaphores are used by clients to lock the message buffers while connecting. The <strong>sm_discon</strong> thread also uses a semaphore to lock the message buffers when cleaning up after a client that has exited.</p><p><code>由于客户端进程对互斥锁（mutexes）一无所知，因此在连接过程中，客户端会使用这些信号量来锁定消息缓冲区。sm_discon 线程在清理已退出的客户端遗留的资源时，也会使用信号量来锁定消息缓冲区。</code></p><p><strong>How semaphores are allocated</strong></p><p>Semaphores are allocated as a set by the operating system. IDS attempts to allocate the semaphores in groups of 100, however depending upon operating system kernel parameters, you might see fewer semaphores in each set.</p><p><code>信号量由操作系统以集合形式进行分配。IDS 会尝试以每组100个的方式分配信号量，但根据操作系统内核参数的不同，每组中实际分配的信号量数量可能会减少。</code></p><p><strong>Other semaphores used</strong></p><p>Semaphores are used by a database server for other purposes as well. Informix Dynamic Server allocates one semaphore for each VP, and one semaphore in its own set for each VP that is added dynamically. The VP semaphores allow an idle VP to sleep, and allow another VP to wake it up when necessary.</p><p><code>database server 还会将信号量用于其他用途。IDS 会为每个虚拟处理器（VP）分配一个信号量，并且会为每个动态添加的虚拟处理器（VP）在其独立的信号量集合中再分配一个信号量。这些针对虚拟处理器（VP）的信号量使得空闲的虚拟处理器能够进入休眠状态，并在必要时允许其他虚拟处理器将其唤醒。</code></p><p>In the slide example, two semaphore sets were initially allocated. The first set includes one semaphore for each VP. Since NETTYPE was not set, the second set contains semaphores for 50 connections, plus two semaphores for the <strong>&#x2F;INFORMIXTMP</strong> file. The additional semaphore sets that contain only one semaphore each were likely allocated for dynamically-added VPs.</p><p><code>在幻灯片示例中，最初分配了两个信号量集合。第一个集合为每个虚拟处理器（VP）包含一个信号量。由于未设置NETTYPE参数，第二个集合包含为50个连接分配的信号量，再加上为 /INFORMIXTMP 文件分配的两个信号量。那些仅包含一个信号量的额外信号量集合，很可能是为动态添加的虚拟处理器（VP）分配的。</code></p><p><strong>Monitoring Shared Memory Connections</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302355128.png" alt="image-20250630235542068"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g nsc</strong> command, without any arguments, summarizes each connection with one line. It lists the following:</p><p><code>onstat -g nsc 命令（不带任何参数）会以每行一条记录的形式对各个连接进行汇总。它会列出以下信息：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302357186.png" alt="image-20250630235733128"></p><p><strong>Monitoring Individual Connections</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302358243.png" alt="image-20250630235811169"></p><p><strong>Notes:</strong></p><p>When you include a client ID, the <strong>onstat -g nsc</strong> command lists more detailed information about shared memory I&#x2F;O. In addition to the summary information (shown on the previous page), this command also shows the following:</p><p><code>当指定客户端ID作为参数时，onstat -g nsc 命令会列出有关共享内存I/O的更详细信息。除了（上一页所示的）汇总信息外，该命令还会显示以下内容：</code></p><table><thead><tr><th>title</th><th>desc</th></tr></thead><tbody><tr><td><strong>needbuf</strong></td><td>A flag that is set if the server is waiting for a buffer<br><code>若server正在等待缓冲区，则该标志会被置位</code></td></tr><tr><td><strong>segid</strong></td><td>The segment ID of the message shared memory segment. See <strong>ipcs</strong> to see the segment ID for each allocated segment.<br><code>消息共享内存段的段ID。可使用 ipcs 命令查看每个已分配内存段的段ID。</code></td></tr><tr><td><strong>semnum</strong></td><td>The semaphore number the client waits on<br><code>客户端等待的信号量编号</code></td></tr><tr><td><strong>semid</strong></td><td>The semaphore ID of the semaphore the client waits on. See <strong>ipcs</strong> for a list of semaphores and their IDs.<br><code>客户端所等待的信号量对应的信号量标识符ID。可使用 ipcs 命令查看信号量列表及其ID。</code></td></tr><tr><td><strong>be_curread</strong></td><td>The buffer ID of the message buffer the server is currently reading<br><code>server当前正在读取的消息缓冲区的 buffer ID</code></td></tr><tr><td><strong>be_curwrite</strong></td><td>The buffer ID of the message buffer the server is currently writing to<br><code>server当前正在写入的消息缓冲区的 buffer ID</code></td></tr><tr><td><strong>fe_curread</strong></td><td>The buffer ID of the message buffer the client is currently reading<br><code>client当前正在读取的消息缓冲区的 buffer ID</code></td></tr><tr><td><strong>fe_curwrite</strong></td><td>The buffer ID of the message buffer the client is currently writing to<br><code>client当前正在写入的消息缓冲区的 buffer ID</code></td></tr><tr><td><strong>next* columns</strong></td><td>The buffer IDs that the client and server will process next<br><code>客户端和服务器接下来将处理的 buffer IDs</code></td></tr><tr><td><strong>readyqueue</strong></td><td>The message ready queue. A value of <strong>-1</strong> indicates no entry.<br><code>消息就绪队列。值为 -1 表示没有条目（即队列为空）。</code></td></tr></tbody></table><p>The next set of information is a list of the buffers, their status (<strong>avail</strong>, <strong>inuse</strong>, or <strong>free</strong>), and their address.</p><p><code>接下来的一组信息是缓冲区列表，包括它们的状态可用（avail）、使用中（inuse）或 空闲（free）及其地址。</code></p><p><strong>onstat -g nss</strong></p><p>If you know the session ID, you can get the same information as <strong>onstat -g nsc</strong> by running <strong>onstat -g nss</strong> with the session ID.</p><p><code>如果你知道会话ID，那么通过将会话ID作为参数运行 onstat -g nss 命令，你可以获取到与 onstat -g nsc 命令相同的信息。</code></p><p><strong>Stream Pipes</strong></p><p> More secure connection than shared memory</p><p><code>比共享内存更安全的连接方式</code></p><p> Allows multiple connections from one client</p><p><code>允许一个客户端建立多个连接</code></p><p> Best for communication between two database servers on the same machine</p><p><code>最适合同一台机器上两 database server 之间的通信</code></p><p><strong>Notes:</strong></p><p>There are two flavors of implementation for the named stream pipe net driver—SVR4 &amp; BSD. The SVR4 stream pipe driver is implemented with a named stream pipe with the <strong>connld</strong> module pushed on the server end. The <strong>connld</strong> module provides unique connections between server and client processes. The BSD stream pipe driver is implemented using UNIX domain socket.</p><p><code>命名流管道网络驱动程序有两种实现形式——SVR4 和 BSD。SVR4 流管道驱动程序通过在 server 端加载 connld 模块来实现 named stream pipe。connld 模块为 server 和客户端进程之间提供唯一连接。BSD 流管道驱动程序则是使用 UNIX 域套接字（UNIX domain socket）来实现的。</code></p><p>Streams use a file names specified in the <strong>&#x2F;INFORMIXTMP</strong> directory. For both implementations, the name of the stream pipe is a UNIX filename, which is constructed from the service name field of the sqlhosts file, and placed in <strong>&#x2F;INFORMIXTMP</strong>.</p><p><code>流（Streams）使用在 /INFORMIXTMP 目录中指定的文件名。对于这两种实现方式，流管道的名称都是一个UNIX文件名，该文件名由 sqlhosts 文件中的服务名（service name）字段构造而成，并放置在 /INFORMIXTMP 目录中。</code></p><p>Although shared memory is a faster protocol, there are two areas where shared memory cannot be used and streams is a useful alternative:</p><p><code>尽管共享内存是一种速度更快的协议，但在以下两个领域中无法使用共享内存，而流（Streams）则是一种实用的替代方案：</code></p><p> <strong>•</strong> Because a stream pipes connection does not read or write to shared memory message buffers, it is considered to be more secure than a shared memory connection.</p><p><code>由于流管道连接不会读写共享内存消息缓冲区，因此它被认为比共享内存连接更加安全。</code></p><p> <strong>•</strong> A client cannot have multiple connections to the database via shared memory. Our shared memory protocol was never designed to multiplex, and we’ve never got around to changing that. However a front end can have multiple connections to the server via either streams, TLI or sockets.</p><p><code>客户端无法通过共享内存与数据库建立多个连接。我们的共享内存协议在设计之初就未考虑多路复用功能，而且我们至今也未着手对其进行修改。不过，前端应用程序可以通过流（Streams）、传输层接口（TLI）或套接字（Sockets）与服务器建立多个连接。</code></p><p><strong>•</strong> Two servers on the same machine cannot communicate with each other by shared memory. Streams is a good choice for this type of communication, rather than performing local loopbacks via sockets or TLI.</p><p><code>同一台机器上的两个 server 无法通过共享内存进行相互通信。对于此类通信需求，采用流（Streams）是更好的选择，而非通过套接字（Sockets）或传输层接口（TLI）进行本地回环通信。</code></p><p><strong>Network User Statistics: onstat -g ntu</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507011947948.png" alt="image-20250701194725824"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g ntu</strong> command displays network information about each user thread.</p><p><code>onstat -g ntu 命令显示每个用户线程的网络信息。</code></p><p><strong>#netscb</strong></p><p>Total current number of network session control blocks &#x2F; number of all network session control blocks ever allocated</p><p><code>当前已分配的网络会话控制块总数 / 曾分配过的所有网络会话控制块数量</code></p><p><strong>connects</strong></p><p>Total connects performed</p><p><code>已执行的总连接数</code></p><p><strong>read</strong></p><p>Total reads performed</p><p><code>已执行的总读取次数</code></p><p><strong>write</strong></p><p>Total writes performed</p><p><code>已执行的总写入次数</code></p><p><strong>q-free</strong></p><p>Number of free buffers currently on the queue &#x2F; greatest number of free buffers simultaneously on the queue since server initialization</p><p><code>当前队列中空闲缓冲区的数量 / 自服务器初始化以来队列中同时存在的空闲缓冲区的最大数量</code></p><blockquote><p>simultaneously 同时 英[ˌsɪməlˈteɪniəsli] 美[ˌsaɪməlˈteɪniəsli]</p></blockquote><p><strong>q-limits</strong></p><p>Maximum number of free buffers that can be on the queue &#x2F; maximum number of buffers that can be on the queue</p><p><code>队列中可存在的空闲缓冲区的最大数量 / 队列中可容纳的缓冲区的最大数量</code></p><p><strong>q-exceed</strong></p><p>Number of times free-buffer limit has been exceeded &#x2F; number of times buffer limit has been exceeded</p><p><code>空闲缓冲区限制被突破的次数 / 缓冲区限制被突破的次数</code></p><p><strong>alloc&#x2F;max</strong></p><p>Number of buffers currently allocated &#x2F; greatest number of buffers allocated simultaneously since server initialization</p><p><code>当前已分配的缓冲区数量 / 自服务器初始化以来同时分配的缓冲区最大数量</code></p><p><strong>netscb</strong></p><p>Address of the network session control block</p><p><code>网络会话控制块的地址</code></p><p><strong>type</strong> </p><p>Identifier of the protocol this thread uses</p><p><code>该线程所使用的协议的标识符</code></p><p><strong>thread name</strong> </p><p>Name of this thread</p><p><code>线程名</code></p><p><strong>sid</strong> </p><p>Session ID associated with this thread</p><p><code>与该线程关联的会话ID</code></p><p><strong>fd</strong> </p><p>File descriptor for the thread </p><p><code>该线程的文件描述符</code></p><p><strong>poll</strong> </p><p>Mail box number of the poll thread that services this network connection</p><p><code>服务于该网络连接的轮询线程的 Mail box number</code></p><p>Mail box number?</p><p><strong>reads</strong> </p><p>Number of reads for this thread</p><p><code>该线程的读取次数</code></p><p><strong>writes</strong> </p><p>Number of writes for this thread</p><p><code>该线程的写入次数</code></p><p><strong>q-nrm</strong> </p><p>Number of buffers &#x2F; maximum number of buffers on the normal data queue</p><p><code>普通数据队列上的缓冲区数量 / 普通数据队列上的缓冲区最大数量</code></p><p><strong>q-pvt</strong> </p><p>Number of private buffers&#x2F;maximum number of private buffers on the private data queue</p><p><code>私有数据队列上的私有缓冲区数量 / 私有数据队列上的私有缓冲区最大数量</code></p><p><strong>q-exp</strong> </p><p>Number of expedite buffers &#x2F; maximum number of buffers ever on the expedited data queue</p><p><code>加速数据队列上的加速缓冲区数量 / 加速数据队列上曾出现过的缓冲区最大数量</code></p><p><strong>Network User Times: onstat -g ntt</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507011959250.png" alt="image-20250701195901170"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g ntt</strong> command prints thread access times.</p><p><code>onstat -g ntt 命令会打印线程访问时间。</code></p><p><strong>netscb</strong> </p><p>Address of the network session control block</p><p><code>网络会话控制块的地址</code></p><p><strong>thread name</strong> </p><p>Name of the thread</p><p><code>线程名</code></p><p><strong>sid</strong> </p><p>Session ID of the thread</p><p><code>该线程的会话ID</code></p><p>The next three entries show only time if the event occurred today and a time and date if the event occurred prior to today. </p><p><code>接下来的三项条目仅显示当天发生事件的时间；若事件发生在当天之前，则同时显示时间和日期。</code></p><p><strong>open</strong> </p><p>Time of the last open event</p><p><code>最后一次开启事件的时间</code></p><p><strong>read</strong> </p><p>Time of the last close event </p><p><code>最后一次关闭事件的时间</code></p><p><strong>write</strong> </p><p>Time of the last write event</p><p><code>最后一次写入事件的时间</code></p><p><strong>address</strong> </p><p>Address of the server, only valid on listener thread</p><p><code>server 地址（仅在监听线程上有效）</code></p><p><strong>Network Statistics by Service: onstat -g ntd</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507012002983.png" alt="image-20250701200256892"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g ntd</strong> command prints network dispatch information.</p><p><code>onstat -g ntd 命令会打印网络分发信息。</code></p><p><strong>Client Type</strong> </p><p>Type of client service</p><p><code>客户端服务类型</code></p><p><strong>Calls</strong> </p><p><strong>yes</strong>: clients of this type are being allowed connections</p><p><code>此类客户端被允许建立连接</code></p><p><strong>no</strong>: connections of this type are not currently allowed</p><p><code>目前不允许此类连接</code></p><p><strong>Accepted</strong> </p><p>Number of times this client type has had a thread spawned</p><p><code>此类客户端类型已触发线程生成的次数</code></p><p><strong>Rejected</strong> </p><p>Number of times a connection to this client type has been rejected</p><p><code>针对此类客户端类型的连接被拒绝的次数</code></p><p><strong>Read</strong> </p><p>Total number of messages sent from this client type</p><p><code>此类客户端类型发送的消息总数</code></p><p><strong>Write</strong> </p><p>Total number of message sent to this client type</p><p><code>发送给此类客户端类型的消息总数</code></p><p>All statistics shown in this and other network reports are based on activity since the database server was last initialized.</p><p><code>本报告及其他网络报告中显示的所有统计数据均基于自数据库服务器上次初始化以来的活动情况。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 9. Virtual Processors and Threads</title>
      <link href="/2025/06/10/IX9111/9/"/>
      <url>/2025/06/10/IX9111/9/</url>
      
        <content type="html"><![CDATA[<p><strong>Processors (CPUs) and Processes</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102136917.png" alt="image-20250610213615829"></p><p><strong>Notes:</strong></p><p>On any computer, all processing of data is handled by one or more <em>processors</em>, sometimes called <em>CPUs</em> (<em>central processing units</em>). Each processor is responsible for handling the requests of many processes that are concurrently active on the system, but can only work on one process at a time. Therefore, a processor must determine when to work on one process, and when that process must yield to another. When a process yields, it copies information about what it was working on, called the process <em>context</em>, into memory. The processor then accepts the context from another process and continues work from where that process was previously interrupted. Moving the context of one process out of the CPU and moving another in is called a <em>context switch</em>.</p><p><code>在任何计算机上，所有数据的处理都由一个或多个处理器（有时也称为 CPU，即中央处理器）来完成。每个处理器负责处理系统中同时运行的多个进程的请求，但一次只能处理一个进程。因此，处理器必须决定何时处理某个进程，以及何时该进程需要让位给另一个进程。当一个进程让位时，它会将正在处理的工作相关信息（称为进程的上下文）复制到内存中。随后，处理器会接受另一个进程的上下文，并从该进程之前被中断的地方继续工作。将一个进程的上下文移出 CPU，并将另一个进程的上下文移入 CPU 的过程称为上下文切换。</code></p><p><strong>Virtual Processors and Threads</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506112343142.png" alt="image-20250611234339015"></p><p><strong>Notes:</strong></p><p>A <em>virtual processor (VP)</em> is a process that is designed to do work similar to the processor on a computer. While a processor is responsible for managing processes on the system, VPs are responsible for processing <em>threads</em>. A thread is the portion of a process that is responsible for a particular set of tasks. Like processes, threads compete for the attention of VPs, which can only process one thread at a time. Threads also have contexts associated with them, and <em>thread context switches</em> are performed to allow the virtual processors to interrupt work on one thread so that it can continue work with another. The scheduling of threads is managed by the threads themselves. A running thread is responsible for determining when to yield so that another thread has a chance to run on the VP.</p><p><code>虚拟处理器（Virtual Processor，简称 VP）是一种旨在执行与计算机处理器类似工作的进程。处理器负责管理系统中的进程，而VP则负责处理线程。线程是进程中负责特定任务集的部分。与进程类似，线程会竞争VP的关注，因为VP一次只能处理一个线程。线程也有与之关联的上下文，会执行线程上下文切换，以便VP能够中断对一个线程的处理，转而继续处理另一个线程。线程的调度由线程自身管理。正在运行的线程负责决定何时让出（yield），以便其他线程有机会在 VP 上运行。</code></p><p>Informix Dynamic Server uses several virtual processors to manage a database server. Each virtual processor is called <strong>oninit</strong>.</p><p><code>IDS 使用多个 VP 来管理 server。每个 VP 都称为 oninit。</code></p><p><strong>Thread Context Switching</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506122139040.png" alt="image-20250612213923903"></p><p><strong>Notes:</strong></p><p>Lets look deeper at the Informix Dynamic Server context-switching process. At a specific point of execution, the thread yields control of the virtual processor to another thread. The context switching algorithm consists of the following steps:</p><p><code>让我们更深入地探讨一下 IDS 中的上下文切换（context-switching）过程。在执行的某个特定时刻，线程会将其对虚拟处理器（virtual processor）的控制权让渡给另一个线程。上下文切换算法包含以下步骤：</code></p><ol><li><p>Once the thread decides to yield, it places its <em>state</em> information in a series of control block structures.</p><p><code>一旦线程决定让出（控制权），它会将其状态信息存入一系列的控制块结构中。</code></p></li><li><p>Next, it must put a pointer to itself on one of the wait queues, sleep queue or ready queue, depending on why the thread is yielding.</p><p><code>接下来，该线程必须根据让出（控制权）的原因，将其自身的指针放入等待队列（wait queue）、休眠队列（sleep queue）或就绪队列（ready queue）中的一个。</code></p></li><li><p>The running thread notifies the next thread waiting in the ready queue. (Actually there are multiple ready queues, one for each priority.) Once the thread ID of the waiting thread is determined, the running thread can get the program counter of the waiting thread.</p><p><code>正在运行的线程会通知就绪队列中下一个等待的线程。（实际上，存在多个就绪队列，每个优先级对应一个。）一旦确定了等待线程的线程ID，正在运行的线程就可以获取该等待线程的程序计数器（的值）。</code></p></li><li><p>Finally, the thread performs the actual context switch in the process. Since thread switching must occur quickly and efficiently, the thread switching algorithms are written in the assembly language, ported specifically to the platform the Informix Dynamic Server system runs on. The code in the thread switching functions is straightforward. It must simply:</p><p><code>最后，该线程会在进程中执行实际的上下文切换。由于线程切换必须快速且高效地进行，因此线程切换算法是用汇编语言编写的，并专门针对 IDS 系统运行的平台进行了移植。线程切换函数中的代码简洁明了，它只需：</code></p><p> <strong>-</strong> Flush the context of the currently running thread to its stack (<em>4a</em>)</p><p><code>将当前正在运行的线程的上下文刷到其栈中(4a)</code></p><p> <strong>-</strong> Load the context for the next thread to run from its stack (<em>4b</em>)</p><p><code>从下一个要运行的线程的栈中加载其上下文(4b)</code></p></li></ol><p><strong>When Threads Yield</strong></p><p>Some events that can cause the thread to yield are:</p><p><code>可能导致线程让出（控制权）的一些事件包括：</code></p><p>– Waiting for a disk read or write operation</p><p><code>等待磁盘读写操作完成</code></p><p>– Waiting for an SQL request from the client</p><p><code>等待来自客户端的 SQL 请求</code></p><p>– Waiting for a lock or other resource</p><p><code>等待锁或其他资源</code></p><p>– There is no more work to do</p><p><code>没有更多工作要做</code></p><p>But internally, the threads yield when:</p><p><code>但在内部，线程会在以下情况下让出（控制权）：</code></p><p>– Waiting on a mutex</p><p><code>等待互斥锁</code></p><p>– Waiting on a condition</p><p><code>等待条件变量满足</code></p><p>– A yield call is encountered in the Dynamic Server code</p><p><code>在 Dynamic Server 代码中遇到了一个 yield 调用</code></p><p><strong>Notes:</strong></p><p>下面这几行和上面重复</p><p>Some common actions that might cause the thread to yield are:</p><p> <strong>•</strong> Waiting for a disk read or write operation</p><p> <strong>•</strong> Waiting for an SQL request from the client</p><p> <strong>•</strong> Waiting for a lock or other resource</p><p> <strong>•</strong> There is no more work to do.</p><p>A thread also might yield control to another thread for no reason other than to give another thread a chance to run. The Informix Dynamic Server thread management code <em>does not</em> perform a <em>timesharing</em> version of thread scheduling. That is, threads do not yield the virtual processor after a certain period of time has elapsed. Nor can a thread be pre-empted (interrupted). </p><p><code>线程也可能仅仅是为了给其他线程一个运行的机会，就将控制权让给另一个线程，而无需其他任何理由。IDS 的线程管理代码并不执行线程调度的分时共享版本。也就是说，线程不会在经过一定时间后自动让出虚拟处理器。同样，线程也不会被抢占（即被中断）。</code></p><p>Internally, threads yield on one of the following cases:</p><p><code>在内部，线程会在以下情况之一中让出（控制权）:</code></p><p><strong>•</strong> The thread is waiting on a mutex. A mutex is a lock on an internal shared memory structure.</p><p><code>线程正在等待一个互斥锁（mutex）。互斥锁是一种对内部共享内存结构的锁定机制。</code></p><p><strong>•</strong> The thread is waiting on a condition. A condition is a method of waiting for an event to occur.</p><p><code>线程正在等待一个条件（变量）。条件（变量）是一种等待事件发生的方法。</code></p><p><strong>•</strong> To prevent a thread from using excessive processor time, there are many junctures in the Dynamic Server code at which running threads are required to yield.</p><p><code>为了防止线程占用过多的处理器时间，在 Dynamic Server 代码中有许多关键点要求正在运行的线程让出（VP）控制权。</code></p><p><strong>The IDS Thread Entity</strong></p><p>The physical entity known as a thread consists of:</p><p><code>线程这一物理实体由以下部分构成：</code></p><p>– A set of structures, or control blocks. The three important control blocks are:</p><p><code>一组结构体或控制块。其中三个重要的控制块是：</code></p><p>• Session control block (scb)</p><p>• Thread control block (tcb)</p><p>• RSAM thread control block (rstcb)</p><p>– The stack</p><p>– The memory pools</p><p><strong>Notes:</strong></p><p>Many manuals (this one included) explain threads using more humanistic terms—they sleep, they wait, they work. But as humans are able to function because of their brains, the brains of a thread enable it to function within a process.</p><p><code>许多手册（包括这本）都使用更具人文色彩的术语来解释线程——它们会sleep、会wait、会work。但正如人类因大脑而能够运作一样，线程的“大脑”也使其能够在进程内发挥作用。</code></p><p>The <em>brain</em> of a thread is the physical information stored in shared memory. Major components include:</p><p><code>线程的大脑指的是存储在共享内存中的物理信息。其主要组成部分包括：</code></p><p><strong>•</strong> Control blocks. A <em>control block</em> is just a fancy name for a structure used as a big scratch pad, or work area. These control blocks store a large amount of information about the thread. The important control blocks include:</p><p><code>控制块。所谓“控制块”，其实只是一个花哨的说法，它本质上就是一个被用作大型临时存储区（或工作区）的结构体。这些控制块存储了大量关于线程的信息。重要的控制块包括：</code></p><p> <strong>-</strong> Session control block. The <em>session control block</em>, or <em>scb</em>, contains information about the session. When you first connect, the database server creates a session for you, which means it creates a session control block.</p><p><code>会话控制块。这个“会话控制块”（Session Control Block），简称“scb”，包含了关于会话的信息。当你首次连接时，数据库服务器会为你创建一个会话，这意味着它会创建一个会话控制块。</code></p><p> <strong>-</strong> Thread control block. The <em>thread control block</em>, or <em>tcb</em>, contains information about the thread. There is one thread control block for every thread running in the database server.</p><p><code>线程控制块。这个“线程控制块”（Thread Control Block），简称“tcb”，包含了关于线程的信息。在数据库服务器中运行的每一个线程都有一个对应的线程控制块。</code></p><p><strong>-</strong> RSAM thread control block. Certain threads running in a database server need access to a layer of Dynamic Server called RSAM, which handles disk I&#x2F;O requests, index management, page management, buffer management, and data replication. Some system threads and all of the user threads (spawned for a session) need an <em>RSAM thread control block</em> (<em>rstcb</em>). </p><p><code>RSAM线程控制块。在 server 中运行的某些线程需要访问 Dynamic Server 的一个名为 RSAM 的层，该层负责处理磁盘I/O请求、索引管理、页管理、缓冲区管理以及数据复制。一些系统线程和所有用户线程（为会话而创建的）都需要一个“RSAM线程控制块”（RSAM Thread Control Block），简称“rstcb”。</code></p><p>There are other control blocks that hold additional information about the thread, such as the <em>network control block</em> (<em>netscb</em>) and the <em>SQL control block</em> (<em>sqscb</em>).</p><p><code>还有其他一些控制块用于存储关于线程的额外信息，例如“网络控制块”（network control block，简称 netscb）和“SQL 控制块”（SQL control block，简称 sqscb）。</code></p><p><strong>•</strong> Stack. The <em>stack</em> holds data for the functions that a thread executes. It is similar to the stack concept in a process, but because multiple threads are operating in one process, each thread must have its own stack.</p><p><code>栈（Stack）。线程在执行函数时所使用的数据存储在栈中。这与进程中的栈概念类似，但由于一个进程中可能有多个线程在同时运行，因此每个线程都必须拥有自己的栈。</code></p><p> <strong>•</strong> Memory pools. <em>Memory pools</em> are not really a separate component of a thread. In fact, all of the information, including the stack and control blocks, are stored in memory pools in the virtual portion of the database server shared memory.</p><p><code>内存池（Memory pools）。内存池实际上并非线程的一个独立组成部分。事实上，包括栈和控制块在内的所有信息，都存储在 server 共享内存的虚拟部分中的内存池里。</code></p><p><strong>Session (User) Threads</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506150008942.png" alt="image-20250615000841804"></p><p><em><strong>Notes:</strong></em></p><p>The session control block is created when an application connects to the database server. The scb has information about the session and pointers to the session pool (which holds data used by the threads started for the session) and to the RSAM thread control block. The rstcb has a pointer to the thread control block that stores additional information about the thread.</p><p><code>会话控制块（Session Control Block，简称 scb）是在应用程序连接到 server 时创建的。该会话控制块包含有关会话的信息，以及指向会话池（用于存储为该会话启动的线程所使用的数据）和 RSAM 线程控制块（RSAM Thread Control Block，简称 rstcb）的指针。而 RSAM 线程控制块（rstcb）则包含一个指向线程控制块（Thread Control Block）的指针，该线程控制块用于存储有关该线程的额外信息。</code></p><p><strong>The Stack</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151116747.png" alt="image-20250615111608624"></p><p><strong>Notes:</strong></p><p>The stack holds information about functions a thread has called, and the data associated with the functions. It is similar to the stack used in a UNIX process, except that every thread in the Informix Dynamic Server system has its own stack to track functions and data.</p><p><code>栈用于存储线程所调用函数的相关信息以及与这些函数关联的数据。它类似于 UNIX 进程中使用的栈，不同之处在于，在 IDS 系统中，每个线程都拥有自己独立的栈，用以跟踪函数调用及相关数据。</code></p><p>The <strong>onstat -g stk</strong> command dumps the contents of a stack for the thread ID you specify in the command. It lists:</p><p><code>onstat -g stk 命令会转储（显示）你在命令中指定的线程 ID 所对应的栈内容。它会列出：</code></p><table><thead><tr><th>Stack ID for thread</th><th>The thread ID and name</th></tr></thead><tbody><tr><td>base</td><td>The memory address of the base of the stack <code>栈底</code></td></tr><tr><td>len</td><td>The number of bytes allocated for the stack</td></tr><tr><td>pc</td><td>The program counter indicating our current location in the stack. When the thread yields the virtual processor (performs a context switch), this value is updated from the register for the process.<code>程序计数器用于指示我们在栈中的当前位置。当线程让出虚拟处理器（执行上下文切换）时，该值会从进程的寄存器中更新。</code></td></tr><tr><td>tos</td><td>The address in memory of the top of the stack. <code>栈顶</code></td></tr></tbody></table><p>In addition, the output lists the functions from which the thread has not returned and the data associated with the thread. The most current function call is shown at the top of the listing.</p><p><code>此外，输出还会列出线程尚未返回的函数以及与该线程关联的数据。最新的函数调用会显示在列表的顶部。</code></p><p><strong>How a Session is Created</strong></p><p>A poll thread picks up an incoming client message. For an existing connection, the request is simply passed to the appropriate sqlexec thread. For a new connection, the listen thread does the following:</p><p><code>一个轮询线程（poll thread）会接收传入的客户端消息。对于已存在的连接，请求会直接传递给相应的 sqlexec 线程。而对于新连接，监听线程（listen thread）会执行以下操作：</code></p><ol><li><p>It allocates a new session control block.</p><p><code>它会分配一个新的会话控制块。</code></p></li><li><p>It creates the session pool in the virtual portion of shared memory, giving it the same name as the session ID.</p><p><code>它在共享内存的虚拟部分创建会话池（session pool），并为其赋予与会话 ID 相同的名称。</code></p></li><li><p>It allocates a new RSAM thread control block.</p><p><code>它会分配一个新的 RSAM 线程控制块。</code></p></li><li><p>It allocates a new thread control block, initializing values such as the pointers to the previous and next tcbs, and the initial function to execute. The thread name specified in the thread control block is <strong>sqlexec</strong>.</p><p><code>它会分配一个新的线程控制块（Thread Control Block, TCB），并初始化其中的值，例如指向上一个和下一个线程控制块的指针，以及要执行的初始函数。在线程控制块中指定的线程名称是 sqlexec。</code></p></li><li><p>It allocates the stack for the thread</p><p><code>它会为该线程分配栈空间。</code></p></li><li><p>It sets the program counter in the stack to the location of the initial function to be executed.</p><p><code>它会将栈中的程序计数器（Program Counter）设置为待执行的初始函数的地址位置。</code></p></li><li><p>It puts the thread control block on the ready queue.When the thread is put on the ready queue, it is ready for work.</p><p><code>它将线程控制块（Thread Control Block, TCB）放入就绪队列（ready queue）。当线程被放入就绪队列时，它就已经准备好执行工作了。</code></p></li></ol><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151143243.png" alt="image-20250615114319182"></p><p><code>在 IDS 的后续版本中，会话及其相关结构会进行预分配，以减少客户端连接所需的时间。</code></p><p><strong>Monitoring Threads</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151155609.png" alt="image-20250615115542547"></p><p><strong>Notes:</strong></p><p>You can monitor the information stored in the three major control blocks for a thread in two ways: by using the <strong>onstat</strong> utility, or by querying <strong>sysmaster</strong> tables. The <strong>onstat</strong> utility hold a subset of the information stored in the control block. However, it shows only the information most relevant to administrators. Queries on the <strong>sysmaster</strong> tables can show all of the information in the control blocks.</p><p><code>你可以通过两种方式来监控线程的三个主要控制块中存储的信息：一种是使用 onstat 工具，另一种是查询 sysmaster 表。onstat 工具包含控制块中存储的部分信息，但它仅显示对管理员来说最为相关的信息。而对 sysmaster 表的查询则可以展示控制块中的全部信息。</code></p><p>If you write applications that include queries to <strong>sysmaster</strong>, it is recommended that you restrict queries to the views in <strong>sysmaster</strong> instead of tables. If there are any changes to the structure of system tables in future releases, your applications are less likely to be affected.</p><p><code>如果你编写的应用程序包含对 sysmaster 的查询，建议将查询限制在 sysmaster 的视图上，而不是直接查询表。这样，如果未来版本中系统表的结构发生任何变化，你的应用程序受到的影响将会更小。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151202695.png" alt="image-20250615120200644"></p><p>&#96;&#96;systcblst<code>、</code>sysrstcb<code>和</code>sysscblst<code>表中的列定义在</code>$GBASEDBTDIR&#x2F;etc&#x2F;sysmaster.sql 文件中。&#96;</p><p><strong>All Threads: onstat -g ath</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151218944.png" alt="image-20250615121852867"></p><p><strong>Notes:</strong></p><p>An easy way to monitor all threads on a database server is to run <strong>onstat -g ath</strong>. This command lists all system and user threads, the address of the tcb, the address of the rstcb, the priority, the status, the virtual class the thread is running on, and the thread name.</p><p><code>监控数据库服务器上所有线程的一个简便方法是运行 onstat -g ath 命令。此命令会列出所有系统线程和用户线程，包括线程控制块（TCB）的地址、RSTCB 的地址、优先级、状态、线程正在运行的虚拟类，以及线程名称。</code></p><p>You can easily identify system threads that do not access the RSAM layer because they do not have an rstcb address.</p><p><code>你可以轻松识别出那些不访问 RSAM 层的系统线程，因为这些线程没有 rstcb 地址。</code></p><p>You can also view lists of threads based on their state by using the following <strong>onstat -g</strong></p><p><code>你还可以使用以下 onstat -g 命令（通常需要配合特定选项）来根据线程的状态查看线程列表。</code></p><p>options:</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151219912.png" alt="image-20250615121958871"></p><p><strong>Common Threads</strong></p><table><thead><tr><th>Thread name</th><th>Virtual processor</th><th>Purpose</th></tr></thead><tbody><tr><td>sqlexec</td><td>CPU</td><td>Primary session thread that services SQL requests<br><code>服务于 SQL 请求的主会话线程</code></td></tr><tr><td>main_loop</td><td>CPU</td><td>Wakes up every second to see if certain tasks need to be performed, such as checkpoints, LRU cleaning, etc.<br><code>每秒唤醒一次，以检查是否需要执行某些任务，例如检查点（checkpoints）、最近最少使用（LRU）清理等。</code></td></tr><tr><td>flush_sub#</td><td>CPU</td><td>Page cleaning</td></tr><tr><td>kaio</td><td>CPU</td><td>Performs administrative tasks for kernel asynchronous I&#x2F;O<br><code>为内核异步 I/O 执行管理任务</code></td></tr><tr><td>btscanner</td><td>CPU</td><td>Cleans the b-tree scanner pool</td></tr><tr><td>onmode_mon</td><td>CPU</td><td>onmode servicing thread</td></tr><tr><td>lio vp #</td><td>LIO</td><td>Handles I&#x2F;O to the logical log</td></tr><tr><td>pio vp #</td><td>PIO</td><td>Handles I&#x2F;O to the physical log</td></tr><tr><td>aio vp #</td><td>AIO</td><td>Handles database I&#x2F;O; if kernel asynchronous I&#x2F;O is used, this thread handles I&#x2F;O to any file system files (e.g. sqlhosts)<br><code>处理数据库的 I/O 操作；如果使用了内核异步 I/O，则此线程负责处理与任何文件系统文件（例如 sqlhosts 文件）之间的 I/O 操作。</code></td></tr></tbody></table><p><strong>Notes:</strong></p><p>The table above and the one on the next page show some of the most commonly used threads. The threads used in communication between client and server are shown in the unit titled, <strong>Communications</strong>.</p><p><code>上表展示了一些最常用的线程。在标题为“Communications”的 Unit 中展示了在客户端与服务器之间通信时所使用的线程。</code></p><p><strong>Conditions</strong></p><p><strong>Notes:</strong></p><p>Conditions are mechanisms used in the database server that block threads from proceeding so that events can occur without interruption. Conditions, therefore, actually protect events. Conditions are structures that are created and destroyed dynamically in the virtual portion of shared memory.</p><p><code>条件（Conditions）是数据库服务器中使用的一种机制，用于阻塞线程的继续执行，以便事件能够在不被中断的情况下发生。因此，条件实际上起到了保护事件的作用。条件是在共享内存的虚拟部分中动态创建和销毁的结构。</code></p><p>“以便事件能够在不被中断的情况下发生” ，看不太懂，AI回答是：这线程wait，被唤醒后，安全的消费数据，不被中断。就像java的condition在lock和unlock之间。</p><p>A thread that is waiting on a condition is waiting for something to happen, such as the completion of a checkpoint, or for a user to send an SQL statement from the client. The condition structure is kept in shared memory and is created and destroyed dynamically. You can view a list of active conditions by running the command <strong>onstat -g con</strong>.</p><p><code>一个在条件（condition）上等待的线程，是在等待某件事情的发生，比如检查点（checkpoint）的完成，或者等待用户从客户端发送一条 SQL 语句。条件结构存储在共享内存中，并且是动态创建和销毁的。你可以通过运行命令 onstat -g con 来查看活动条件的列表。</code></p><p>A blocking checkpoint is one example of an event that is handled by a condition. To prevent threads from entering critical sections while transactions are blocked during a checkpoint, a condition called <strong>cp</strong> is used. Before a thread enters a critical section, it determines if a checkpoint has been requested. If so, it calls a function called <strong>mt_wait</strong> (passing a pointer to the <strong>cp</strong> condition). The <strong>mt_wait</strong> function modifies the condition structure, adding the thread to the wait queue.</p><p><code>阻塞式检查点（blocking checkpoint）就是由条件（condition）处理的事件的一个例子。为了防止在检查点执行期间事务被阻塞时，线程进入关键代码段（critical section），会使用一个名为 cp 的条件。在线程进入关键代码段之前，它会判断是否已请求执行检查点。如果是，线程会调用一个名为 mt_wait 的函数（并向该函数传递指向 cp 条件的指针）。mt_wait 函数会修改条件结构，将该线程添加到等待队列中。</code></p><p>新事务，由于检测到检查点已请求，就放进等待队列，所以这防止了阻塞</p><p>After the <strong>main_loop</strong> thread has released the global transaction block, it moves all threads waiting for the checkpoint condition from the wait queue to the ready queue.As each waiter runs again, it double-checks the status of the condition. If the condition is not satisfied, it waits again. This extra step is necessary because the state of the condition could have changed since the thread was moved from the wait queue to the ready queue.</p><p><code>在 main_loop 线程释放全局事务块（global transaction block）之后，它会将所有正在等待检查点条件（checkpoint condition）的线程从等待队列（wait queue）移动到就绪队列（ready queue）。当每个等待线程再次运行时，它会再次检查条件的当前状态。如果条件仍未满足，线程会再次进入等待状态。这一额外步骤是必要的，因为从线程被从等待队列移动到就绪队列的这段时间内，条件的状态可能已经发生了变化。</code></p><p><strong>Note</strong></p><p>With the introduction of non-blocking checkpoints in IDS 11, threads rarely have to wait on a <strong>cp</strong> condition.</p><p><code>在 IDS 11 中引入了非阻塞式检查点（non-blocking checkpoints）后，线程很少需要再在 cp 条件（condition）上等待。</code></p><p>Although the checkpoint condition is a good example of the value of condition structures, their most common use is as a simple communication mechanism between two threads. For instance, in a parallel database query (PDQ) operation, a producer thread, whose job is to feed data to a consumer thread, uses an <strong>awaitMC%d</strong> condition to notify the waiting consumer when data is available. Also, the shared memory poll thread, <strong>sm_poll</strong> uses a condition to notify an <strong>sqlexec</strong> thread that a front-end message has arrived for it.</p><p><code>虽然检查点条件很好地展示了条件结构的价值，但条件结构最常见的用途是作为两个线程之间的一种简单通信机制。例如，在并行数据库查询（PDQ）操作中，负责向消费者线程提供数据的生产者线程，会使用一个名为 awaitMC%d 的条件，在数据可用时通知正在等待的消费者线程。此外，共享内存轮询线程 sm_poll 也会利用一个条件来通知 sqlexec 线程，有前端发送的消息已到达，供其处理。</code></p><p><strong>Internal Locking Through Mutexes</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172210348.png" alt="image-20250617221021215"></p><p><strong>Notes:</strong></p><p>A <em>mutex</em> (short for mutually exclusive) is a fancy name for a method that protects a memory structure from other threads. Dynamic Server uses mutexes to protect many memory structures, such as the lock list, or the session control block.</p><p><code>互斥量（mutex，是mutually exclusive（互斥）的缩写）是一种用于保护内存结构免受其他线程干扰的方法，这一称谓听起来颇为专业。Dynamic Server 使用互斥量来保护许多内存结构，例如 lock list 或 session control block。</code></p><p><strong>Locking a mutex</strong></p><p>Locking a mutex is a multi-step process:</p><p><code>锁定一个互斥量是一个多步骤的过程：</code></p><ol><li><p>First the thread must lock the mutex lock just to see if the mutex itself is locked. A mutex is a structure like any other and needs to be protected from multiple threads attempting to obtain the mutex at the same time.</p><p><code>首先，线程必须先尝试锁定互斥量（即获取互斥锁），以此判断该互斥量本身是否已被锁定。互斥量和其他任何结构一样，需要防止多个线程同时尝试获取它。</code></p></li><li><p>Once the thread obtains the mutex lock, it checks to see if any thread holds the mutex. </p><p><code>一旦线程获取了互斥锁，它就会检查是否有其他线程持有该互斥量。</code></p></li><li><p>If there is no holder, the thread can designate itself as the holder.</p><p><code>如果没有持有者，该线程就可以将自己指定为持有者。</code></p></li><li><p>If there is a holder, the thread can put itself on the wait queue for the mutex.</p><p><code>如果已经有持有者，该线程可以把自己加入到该互斥量的等待队列中。</code></p></li><li><p>The thread unlocks the mutex lock.</p><p><code>该线程释放（或解开）互斥锁。</code></p></li></ol><p><strong>How long do mutexes stay around?</strong></p><p><code>互斥量会保留（或存在）多久？</code></p><p>Mutex structures are generally embedded in the structures they’re meant to protect. Those structures are constantly being allocated and freed as threads are spawned, perform work, and exit. An example of a fairly volatile mutex is the one embedded in a thread control block. Each instance of that mutex only lives as long as the thread lives. Some mutexes, such as the one protecting the buffer header structure, are allocated for the life of the database server.</p><p><code>互斥量结构通常嵌入在它们旨在保护的那些结构中。随着线程的创建、执行任务和退出，这些结构会不断地被分配和释放。一个相当“易变”（即频繁创建和销毁）的互斥量示例是嵌入在 thread control block 中的那个互斥量。该互斥量的每个实例仅在其所属线程的生命周期内存在。而有些互斥量，例如用于保护缓冲区头结构的互斥量，则会在数据库服务器的整个生命周期内被分配并持续存在。</code></p><p>There are other cases in which the mutex is not part of another structure; the mutex memory is allocated when the mutex is needed and removed when it is no longer used.</p><p><code>在其他情况下，互斥量并不是另一个结构的一部分；当需要互斥量时，会为其分配内存，而当不再需要它时，则会释放该内存。</code></p><p><strong>The example diagram</strong></p><p>In the example shown in the slide, Thread 1 holds the mutex, while Thread 2, Thread 3, and Thread 4 are waiting.</p><p><code>在幻灯片所示的示例中，线程 1 持有互斥量，而线程 2、线程 3 和线程 4 正在等待。</code></p><p><strong>Monitoring Mutexes and Conditions</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172228820.png" alt="image-20250617222837748"></p><p><strong>Notes:</strong></p><p>The chart above shows the <strong>onstat</strong> options and <strong>sysmaster</strong> tables you can use to view mutexes and conditions.</p><p><code>上图展示了可用于查看互斥量和条件变量的 onstat options 以及 sysmaster tables。</code></p><p><strong>Monitoring Locked Mutexes: onstat –g lmx</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172237476.png" alt="image-20250617223745406"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g lmx</strong> command shows all locked mutexes.</p><p>The <strong>onstat -g wmx</strong> command shows only locked mutexes that have waiting threads.</p><p><code>onstat -g wmx 命令仅显示有线程等待的已锁定互斥量。</code></p><p><strong>All Mutexes</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172240553.png" alt="image-20250617224002494"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g amx</strong> command shows all mutexes, even if they are not held by any thread. If a mutex is not held, the value in the holder column is <strong>-1</strong>.</p><p><code>onstat -g amx 命令会显示所有的互斥量，即使它们当前没有被任何线程持有。如果一个互斥量未被持有，那么在持有者（holder）列中显示的值将是 -1。</code></p><p><strong>Configuration Parameters Affecting Mutexes</strong></p><p> QSTATS – collects mutex statistics</p><p> SINGLE_CPU_VP – If set to &gt;0, fewer mutexes are acquired</p><p><strong>Notes:</strong></p><p>The QSTATS parameter is a configuration parameter that causes mutex statistics to be collected. Set the QSTATS parameter to any value. For example:</p><p><code>QSTATS 参数是一个配置参数，用于触发互斥量（mutex）统计信息的收集。可将 QSTATS 参数设置为任意值。例如：</code></p><p>​QSTATS 1</p><p>QSTATS should not be set in a production system, because it can slow performance.If the SINGLE_CPU_VP configuration parameter is set to 1, the need to acquire many mutexes is not necessary because there is no contention with other CPU VP threads.This is true for the following reasons:</p><p><code>在生产系统中不应设置 QSTATS 参数，因为它可能会降低系统性能。如果将 SINGLE_CPU_VP 配置参数设置为 1，那么由于不存在与其他 CPU 虚拟处理器（VP）线程的竞争，也就无需获取多个互斥量。原因如下：</code></p><p> <strong>•</strong> A thread never yields while holding a mutex </p><p><code>线程在持有互斥量（mutex）期间永远不会让出（CPU）执行权</code></p><p> <strong>•</strong> With only one CPU VP only one thread (of the CPU VP class) can be running</p><p><code>在只有一个 CPU 虚拟处理器（CPU VP）的情况下，同一时间只能有一个属于该 CPU VP 类的线程在运行。</code></p><p><strong>Mutex Queue Statistics: onstat –g qst</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192213146.png" alt="image-20250619221343021"></p><p><strong>Notes:</strong></p><p>The mutex structure contains a number of statistics that can give developers an idea of which mutexes might be causing a bottleneck in the server. Normally, these statistics fields are not populated, but turning on queuing statistics for mutexes is as simple as setting QSTATS.</p><p><code>互斥量（mutex）结构中包含多个统计信息字段，这些字段能够帮助开发者识别出 server 中可能导致瓶颈的互斥量。通常情况下，这些统计信息字段是空的，但开启互斥量的排队统计信息非常简单，只需设置 QSTATS 参数即可。</code></p><p><strong>Warning</strong></p><p><em>Setting QSTATS might cause some degradation in performance. As a rule, you should not</em> <em>set QSTATS on servers in which performance is critical.</em></p><p><code>设置 QSTATS 可能会导致性能有所下降。一般来说，在性能至关重要的 server 上，不应设置 QSTATS。</code></p><p>Once you have set this configuration parameter and restarted the database server, you can execute the following command to show statistics for any mutex that is currently allocated in memory.</p><p><code>一旦你设置了该配置参数并重新启动了 database server，你就可以执行以下命令来显示当前在内存中分配的任何互斥量的统计信息。</code></p><p>​onstat -g qst</p><p>Statistics include the following information:</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192219161.png" alt="image-20250619221951093"></p><p><strong>Mutex queue statistics and tuning</strong></p><p>Mutex queue statistics don’t offer much information to an administrator, except to show which shared memory structures are being accessed the most. The mutex wait queues increase when the database server is heavily used. This isn’t a bad thing—just an indication of a busy database server. </p><p><code>互斥量队列统计信息对管理员来说提供的信息并不多，除了能显示哪些共享内存结构被访问得最频繁之外。当 database server 使用繁忙时，互斥量等待队列的长度会增加。这并不是一件坏事——它只是表明 database server 处于繁忙状态。</code></p><p>Developers can use mutex statistics to make sure that threads are not locking shared memory structures too long.</p><p><strong>Why Are Threads Waiting?</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192223296.png" alt="image-20250619222338229"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g wst</strong> command displays statistics about the time a thread is waiting and the reason why it is waiting.</p><p><code>onstat -g wst 命令会显示线程等待的时间以及线程等待原因的相关统计信息。</code></p><p>Statistics on thread waits are not normally collected because of the overhead required to calculate and store them. To collect statistics for this report, you must add a line in the configuration file to set the WSTATS parameter to a non-zero value. For example:</p><p><code>通常情况下，由于计算和存储线程等待统计信息会产生额外的开销，因此不会收集这些统计信息。若要为这份报告收集统计信息，你必须在配置文件中添加一行，将 </code>WSTATS<code> 参数设置为非零值。例如：</code></p><p>​WSTATS 1</p><p><strong>Warning</strong></p><p><em>Setting the WSTATS parameter might cause performance degradation. You should not set</em> <em>this parameter on servers in which performance is critical.</em></p><p><code>设置 WSTATS 参数可能会导致性能下降。你不应在性能至关重要的 server 上设置此参数。</code></p><p>Each thread is listed once per <em>state</em>, such as <strong>yield</strong>, <strong>ready</strong>, or <strong>run</strong>. The average and maximum times are usually listed in millionths of a second. If an <strong>s</strong> follows the number, the unit is seconds.</p><p><code>每个线程会按照其状态（如 yield、ready 或 run）分别列出一次。平均时间和最大时间通常以百万分之一秒为单位列出。如果数字后面跟着一个 s，则单位是秒。</code></p><p>The <strong>onstat -g wst</strong> report is useful for troubleshooting. It’s the only way, for example, that you can tell if the thread had a chance to run, and how often it runs compared to other threads. Also, if a thread’s maximum or average run time really stands out as high, it could be an indication of a runaway thread.</p><p><code>onstat -g wst 报告对于故障排查非常有用。例如，这是你唯一能够判断线程是否有机会运行，以及与其他线程相比其运行频率的方法。此外，如果某个线程的最大或平均运行时间显著偏高，这可能表明该线程是一个失控线程（runaway thread）。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 8. Sbspaces</title>
      <link href="/2025/06/07/IX9111/8/"/>
      <url>/2025/06/07/IX9111/8/</url>
      
        <content type="html"><![CDATA[<p><strong>Unit 8. Sbspaces</strong></p><p><strong>Sbspace Chunk Layout</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072051497.png" alt="image-20250607205138379"></p><p><strong>Notes:</strong></p><p>A <em>smart blobspace</em>, or <em>sbspace</em>, is a logical collection of chunks that is used to store <em>smart</em> <em>large objects</em> (also called <em>smart LOs</em> or <em>smart blobs</em>).</p><p><code>智能大对象空间（smart blobspace，简称 sbspace）是一个由多个 chunk 构成的逻辑集合，用于存储智能大对象。</code></p><p>When an sbspace is initially created, it assigns space for header data, <em>metadata</em>, and user data. The first chunk of an sbspace always contains a 53-page header, also known as the sbspace reserved pages. Subsequent chunks require only 3 reserved pages.</p><p><code>在最初创建 sbspace 时，它会为 header data、metadata 以及 user data 分配空间。sbspace 的第一个 chunk 始终包含一个由 53 页组成的 header，也称为sbspace 的保留页。而后续的 chunk 则仅需 3 页保留页。</code></p><p>There is always a metadata area stored within the first chunk of an sbspace. The default location is near the middle of the chunk to optimize access time. The location and size can be determined during the creation of the sbspace. A metadata area can contain information for one or more chunks within the sbspace. Once it is allocated, the metadata area cannot be changed in size or location.</p><p><code>sbspace 的第一个 chunk 中，始终会存储一个 metadata 区域。默认情况下，该 metadata 区域位于 chunk 接近中间的位置，以优化访问时间。其具体位置和大小可在创建 sbspace 时确定。一个 metadata 区域可以包含 sbspace 内一个或多个 chunk 的相关信息。一旦 metadata 区域被分配，其大小和位置便无法再更改。</code></p><p>Any space remaining after the header pages and the metadata are allocated is used for storing user data, that is, the smart large objects.</p><p><code>在分配完 header pages 和 metadata 之后所剩余的空间，均用于存储 user data，即智能大对象（smart large objects）。</code></p><p><strong>Sbspace Reserved Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072101662.png" alt="image-20250607210141608"></p><p><strong>Notes:</strong></p><p>The first few pages of an sbspace are laid out much like other spaces in the server. There are 3 header pages at the beginning of every chunk in an sbspace. These include two unused reserved pages and one chunk free-list page. This page doesn’t track all pages used in the chunk. It only tracks the pages in the chunk that are not allocated for metadata or preassigned user data. This is the first of two levels of free-space tracking. The second level is within the metadata itself where smart LO subsystem tracking is handled.</p><p><code>sbspace 的前几页布局与 server 中的其他空间颇为相似。在 sbspace 的每个 chunk 开头，都设有3个 header pages。这其中包括两个 unused reserved pages 和一个 chunk free-list page。需要注意的是，这个 chunk free-list page 并不追踪 chunk 中使用的所有页面，它仅追踪那些未被分配给 metadata 或预先分配的 user data 的页面。这是空闲空间追踪的第一级机制。而第二级追踪机制则位于 metadata 内部，由智能大对象（smart LO）子系统负责处理。</code></p><p>A tblspace tblspace is found only in the first chunk of each sbspace. It is used to track information about tables within the metadata area. Information about archives taken for this sbspace are also stored here.</p><p><code>在每个 sbspace 的第一个 chunk 中，会存在一个 tblspace tblspace。该结构用于在 metadata 区域内追踪与 tables 相关的信息。此外，针对该 sbspace 所进行的归档（archives）信息也会被存储在此处。</code></p><p><strong>Types of Sbspace Pages</strong></p><p> Standard pages</p><p> Metadata partitions</p><p> Smart LO pages</p><p> Smart LO data stored in rows</p><p><strong>Notes:</strong></p><p>There are four different types of pages used to store and manage large objects in an sbspace. These are discussed in the following pages.</p><p><code>sbspace 中，用于存储和管理 large objects 的页面共有四种不同类型。以下页面将对这些类型进行讨论。</code></p><p><strong>Standard Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072118900.png" alt="image-20250607211850828"></p><p><strong>Notes:</strong></p><p>The pages in an sbspace that are considered <em>standard</em> are those that look like and are handled similarly to the pages in a dbspace. These pages contain page headers, timestamps, and slot tables. There are data pages, partition pages, and index pages found in various sbspace structures.</p><p><code>sbspace 中，被视为标准页面的，是那些在外观和处理方式上与数据库空间（dbspace）中的页面相似的页面。这些标准页面包含页头（page headers）、时间戳（timestamps）以及 slot tables。在 sbspace 的各种结构中，可以找到数据页（data pages）、分区页（partition pages）以及索引页（index pages）。</code></p><p><strong>Metadata Area</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072123110.png" alt="image-20250607212332036"></p><p><strong>Notes:</strong></p><p>The <em>metadata area</em> is preallocated at the time the sbspace is created. It cannot be enlarged by allocating more unused user-data space; another chunk with a new metadata area must be allocated. The metadata for the sbspace contains tables for handling four types of information. These tables are stored in the sbspace as regular tblspaces (partitions).</p><p><code>元数据区域（metadata area）在创建 sbspace 时即被预先分配。它无法通过分配更多未使用的用户数据空间来扩大；若需扩展，必须分配一个包含新 metadata area 的新 chunk。sbspace 的 metadata 包含用于处理四种类型信息的表。这些表以常规 tblspaces (partitions) 的形式存储在 sbspace 中。</code></p><p><strong>•</strong> Sbspace description partition (<strong>sbspace_desc</strong>) – This partition contains a single structure that describes the smart blobspace. It includes special attributes for the sbspace (the <strong>onspaces -Df</strong> attributes used when the sbspace was created), the location of the chunk adjunct partition, and sbspace flags. This partition uses only one page and is stored in the first chunk of the sbspace.</p><p><code>此分区包含一个单一结构，用于描述 smart blobspace。它包 space 的特殊属性（即创建智能块空间时使用的 onspaces -Df 属性）、数据块附属分区（chunk adjunct partition）的位置，以及 sbspace 的标志位（flags）。该 partition 仅占用一页，并存储在 sbspace 的第一个 chunk 中。</code></p><p> <strong>•</strong> Chunk adjunct partition (<strong>chunk_adjunc</strong>) – This partition stores information about each chunk in the sbspace. It includes the location and size of the user-data metadata areas, and the location of the LO header partition for the chunk. The chunk adjunct partition contains one row for each chunk and is stored in the first chunk of the sbspace.</p><p><code>该 partition 用于存储 sbspace 中每个 chunk 的相关信息。这些信息包括 user-data metadata areas 的位置和大小，以及每个 chunk 中 LO header partition 的位置。chunk adjunct partition 为每个 chunk 包含一行记录，并且该分区存储在 sbspace 的第一个 chunk 中。</code></p><p> <strong>•</strong> LO header partition (<strong>LO_hdr_partn</strong>) – For each smart LO in the chunk, this table describes the time and date the LO was created, the size of the LO, and other attributes. It also includes an extent list that is allocated to the smart LO. There is one LO header partition allocated for each chunk in the sbspace.</p><p><code>对于 sbspace 中的每个智能大对象（smart LO），此表均会描述该大对象的创建时间和日期、大小以及其他属性。此外，它还包含一个分配给该智能大对象的 extent list。在 sbspace 的每个 chunk 中，都会分配一个这样的 LO header partition。</code></p><p><strong>•</strong> UD free-list partition (<strong>LO_ud_free</strong>) – This partition tracks free extents in the user-data areas of a chunk; it is very similar to the chunk free list. There is one UD free-list partition for each chunk in the sbspace.</p><p><code>该 partition 负责追踪 chunk 的 user-data areas 中的 free extents；其功能与 chunk free list 非常相似。在 sbspace 的每个 chunk 中，都会分配一个这样的 UD free-list partition。</code></p><p>Use the <strong>oncheck -cS</strong> command to display the partition numbers and space usage for these partitions.</p><p><code>使用 oncheck -cS 命令可以显示这些 partition 的 partition numbers 以及空间使用情况（space usage）。</code></p><p><strong>Smart LO Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072204946.png" alt="image-20250607220400881"></p><p><strong>Notes:</strong></p><p>Smart LO pages have the same format as a dbspace data page that contains rows of data. It has a twenty-four-byte header and a four-byte timestamp trailer. The page size is specified when the sbspace is created. A smart LO can span multiple pages within the sbspace. The LO is simply stored in pieces that fit on a page. The pages are read and written by the smart LO subsystem via the dynamic buffer manager. I&#x2F;O for the metadata subsystem, on the other hand, is handled by the regular RSAM I&#x2F;O subsystem.</p><p><code>智能大对象（smart LO）页面的格式与包含数据行的 dbspace 数据页面相同。它具有一个 24 字节的页头（header）和一个 4 字节的时间戳尾记（timestamp trailer）。页面大小在创建 sbspace 时指定。一个智能大对象可以跨越 sbspace 内的多个页面。该大对象只是被拆分成适合存储在单个页面上的片段进行存储。智能大对象子系统通过动态缓冲区管理器（dynamic buffer manager）来读写这些页面。另一方面，metadata 子系统的输入/输出（I/O）操作则由常规的 RSAM 输入/输出子系统来处理。</code></p><p><strong>Large Object Data Stored on Data Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072207241.png" alt="image-20250607220742169"></p><p><strong>Notes:</strong></p><p>Both simple LOs (data of type BYTE or TEXT) and smart LOs (types BLOB and CLOB) contain information in the data row to locate the large object data. For simple large objects, there is a 56-byte descriptor that is stored in the data row. Smart large objects have a 72-byte descriptor structure. Depending on byte-alignment requirements, the descriptor could be preceded with up to 4 bytes of padding.</p><p><code>无论是简单大对象（数据类型为 BYTE 或 TEXT）还是智能大对象（数据类型为 BLOB 和 CLOB），其数据行中均包含用于定位大对象数据的信息。对于简单大对象，数据行中存储有一个 56 字节的描述符（descriptor）。而智能大对象则具有一个 72 字节的描述符结构。根据字节对齐（byte-alignment）的要求，描述符前面可能会添加最多 4 字节的填充（padding）。</code></p><p>The LO descriptor contains a 12-byte structure called the <em>smart LO handle</em>. This handle consists of three integer values: an sbspace number, a chunk number, and a sequence number. These values indicate the location (sbspace and chunk) of the LO header partition that describes the smart LO, and the <em>logical sequence number</em>, which is assigned based on the logical position within the partition.</p><p><code>大对象（LO）描述符中包含一个 12 字节的结构，称为智能大对象句柄（smart LO handle）。该句柄由三个整数值组成：一个 sbspace number、chunk number 以及一个序列号（sequence number）。这些值用于指示描述该智能大对象的 LO header partition 的位置（sbspace and chunk），以及逻辑序列号（logical sequence number），该序列号是根据该智能大对象在分区内的逻辑位置分配的。</code></p><p><strong>Locating a Smart Large Object</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506092035208.png" alt="image-20250609203539067"></p><p><strong>Notes:</strong></p><p>The figure above shows how the smart LO handle is used to locate and retrieve a smart large object from a table.</p><p><code>上图展示了智能大对象句柄如何用于从表上定位并取回智能大对象。</code></p><ol><li><p>When a row containing a smart LO is requested, the database server reads the page containing the row into shared memory. </p><p><code>当请求包含智能大对象的某一行数据时，server 会将包含该行数据的页面读入共享内存。</code></p></li><li><p>The server locates the smart LO descriptor and extracts the LO handle. The handle is used to look up the entry for the smart large object in the LO header partition. </p><p><code>server 定位智能大对象描述符，并提取出大对象句柄。该句柄用于在 LO header partition 中查找智能大型对象的条目。</code></p></li><li><p>This partition contains the location of each extent of the large object. With this information, the smart LO can be retrieved from the sbspace.</p><p><code>该 partition 包含大对象的每个 extent 的位置信息。借助这些信息，即可从 sbspace 中检索出智能大对象。</code></p></li></ol><p><strong>Inserting a Smart Large Object</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506092043588.png" alt="image-20250609204313509"></p><p><strong>Notes:</strong></p><p>When a request is received to insert a new row into a table that contains a smart LO, an insert is required in both a page in the tblspace as well as an insert to the sbspace. The figure above shows how smart LOs are inserted.</p><p><code>当收到向包含智能大对象的表中插入新行的请求时，不仅需要在 tblspace中的一个页面进行插入操作，还需要在 sbspace 中进行插入操作。上图展示了智能大对象是如何被插入的。</code></p><ol><li><p>When the INSERT request is received, a data page with available space is read into shared memory and a slot is allocated for the new row. </p><p><code>当接收到 INSERT 请求时，会将一个有可用空间的数据页读入共享内存，并为新行分配一个 slot。</code></p></li><li><p>To insert the smart LO into the sbspace, the database server examines the UD free-list partition to locate available space for the large object. </p><p><code>为了将智能大对象插入到 sbspace 中，server 会检查 UD free-list partition，以定位该大对象可用的空间。</code></p></li><li><p>If a single free extent cannot be found that is large enough for the object, then multiple extents are allocated. The smart LO is inserted into the free extents, and the free-extent information is updated in the UD free-list partition. </p><p><code>如果找不到一个足够大的单个空闲 extent 来容纳该对象，那么就会分配多个 extent。智能大对象会被插入到这些空闲 extent 中，并且 UD free-list partition 中的 free-extent 信息也会随之更新。</code></p></li><li><p>Extent information for the new LO are added to a new row in the LO header partition.</p><p><code>该新大对象的 extent 信息会被添加到 LO header partition 中的一个新行中。</code></p></li><li><p>Finally, the smart LO descriptor on the data page is updated with information about the smart LO, including the smart LO handle.</p><p><code>最后，数据页上的 smart LO descriptor 会被更新，添加关于该智能大对象的信息，包括智能大对象句柄。</code></p></li></ol><p><strong>Sbspace Example</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102052633.png" alt="image-20250610205239507"></p><p><strong>Notes:</strong></p><p>Above is a sample of output from an <strong>onstat -d</strong> command. An <strong>oncheck -pe</strong> report for the sbspace in this system is shown on the following page. The information for the user data free list was obtained right after the sbspace was created and appears as FREE USER DATA in an <strong>oncheck -pe</strong> report. </p><p><code>以上是 onstat -d 命令输出的一个示例。该系统 sbspace 的 oncheck -pe 报告内容展示在下一页。user data free list 的相关信息是在创建该 sbspace 后立即获取的，并以 oncheck -pe 报告中的“FREE USER DATA”形式呈现。</code></p><p>The database server reserves 40 percent of the user-data area as a RESERVED USER DATA area. This space can be used for either the metadata or user data. Space in the metadata area gets used up as smart large objects are added to that sbspace. When the database server runs out of metadata or user-data space, it moves a block of the reserved space to the corresponding area.</p><p><code>server 会将用户数据区的 40% 预留为“RESERVED USER DATA”区域。该空间既可用于 metadata，也可用于 user data。随着向该 sbspace 添加智能大对象（smart large objects），metadata 区的空间会逐渐被占用。当 server 的 metadata 区或 user data 区空间耗尽时，它会将预留空间中的一块区域移动到相应的区域（元metadata 区或 user data 区）以供使用。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102101138.png" alt="image-20250610210106034"></p><p>The three values in brackets after each LO listing together represent the smart LO handle, which is used to uniquely identify every large object on the database server. In the example above, you can see smart LOs that have a <em>physical</em> order that is different from their <em>logical</em>order. The database server tries to balance the load of the sbspace by inserting into both user-data areas on a chunk.</p><p><code>每个大对象条目后方括号内的三个值共同构成了智能大对象句柄，该句柄用于在 server 上唯一标识每一个大对象。在上述示例中，你可以看到智能大对象的物理顺序与其逻辑顺序并不相同。server 会尝试通过在 chunk 的两个 user-data 区中插入数据来平衡 sbspace 的负载。</code></p><p><strong>Monitoring Sbspaces: oncheck</strong></p><p>Use oncheck to view:</p><p>– Metadata information</p><p>– Pages on disk</p><p>– General chunk layout</p><p><strong>Notes:</strong></p><p>The <strong>oncheck</strong> utility provides options to generate reports on sbspaces and elements within sbspaces.</p><p><code>oncheck utility 提供了生成有关 sbspace 以及 sbspace 内元素的报告的选项。</code></p><table><thead><tr><th><strong>-cs sbspace</strong></th><th align="left">Checks metadata information</th></tr></thead><tbody><tr><td><strong>-cS sbspace</strong></td><td align="left">Checks metadata and extent information</td></tr><tr><td><strong>-ps&#x2F;-pS sbspace</strong></td><td align="left">Prints metadata information</td></tr><tr><td><strong>-pp partnum logical_offset</strong></td><td align="left">View a page on disk</td></tr><tr><td><strong>-pP chunk page_offset</strong></td><td align="left">View a page on disk</td></tr><tr><td><strong>-pd&#x2F;-pD partnum</strong></td><td align="left">View contents of metadata tables. The partnum for the LO partition header is needed and can be obtained from -cs options. For example: oncheck -pD 0x200004</td></tr><tr><td><strong>-ce&#x2F;-pe sbspace</strong></td><td align="left">General chunk layout</td></tr></tbody></table><p>The <strong>oncheck -pS</strong> command is used to display tblspace information for metadata tables (like <strong>oncheck -pt</strong>) and displays additional information about smart LO extents. Here is an example:</p><p><code>oncheck -pS 命令用于显示 metadata tables 的 tblspace 信息（类似于 oncheck -pt 命令），同时还会显示有关智能大对象 extent 的额外信息。以下是一个示例：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102128798.png" alt="image-20250610212815669"></p><p><strong>oncheck –g smb</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102129908.png" alt="image-20250610212957842"></p><p><strong>Notes:</strong></p><p>The <strong>onstat -g smb</strong> command can be used with any of the above options to obtain statistical information about sbspaces. The <strong>e</strong> and <strong>lod</strong> options provide a list of the entries in the LO header table. These represent the smart LOs that have been stored in sbspaces. An example is shown on the next page.</p><p><code>onstat -g smb 命令可与上述任意选项配合使用，以获取有关 sbspace 的统计信息。其中，e 和 lod 选项会提供 LO header table 中的条目列表。这些条目代表存储在 sbspace 中的智能大对象。示例将在下一页展示。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102131931.png" alt="image-20250610213146849"></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 7. Blobspaces</title>
      <link href="/2025/06/02/IX9111/7/"/>
      <url>/2025/06/02/IX9111/7/</url>
      
        <content type="html"><![CDATA[<p><strong>Blobspace Architecture</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022236155.png" alt="image-20250602223600067"></p><p><strong>Notes:</strong></p><p>Every blob chunk has the same basic layout, yet it still manages to baffle the best of us because of similar terms for its relatively few elements. A blob chunk begins with a <em>blobpage map</em>, followed by a blob <em>bitmap</em>, followed by the actual <em>blobpages</em>. The blobpage map (1) tracks blobpages (3). The blob bitmap (2) tracks pages in the blobspace map (1). The blobpages store blob data.</p><p><code>每个 blob chunk 都具有相同的基本布局，但由于其元素数量相对较少且术语相似，仍会让我们感到困惑。blob chunk 以 blobpage map 开头，接着是一个 BLOB bitmap，最后是实际的 blobpages。blobpage map（1）用于跟踪 blobpages（3）。blob bitmap（2）用于跟踪 blobspace map（1） 里的页 。blobpages 则用于存储 blob 数据。</code></p><p>Clear as mud? It is best to divide and conquer.</p><p><code>还是一头雾水吗？最好的办法就是分而治之（逐个击破、逐一理解）。</code></p><p><strong>Blob chunk overhead pages</strong></p><p>When a blob chunk is created, all overhead pages are allocated up front. These are regular-sized Dynamic Server pages. Only blobpages, which come after the blob chunk overhead pages, are potentially larger than the database server page size.</p><p><code>在创建 blob chunk 时，会预先分配所有开销页（overhead pages）。这些开销页都是常规大小的 Dynamic Server 页。只有位于 blob chunk overhead pages 之后的 blobpages，其大小才可能超过 database server 页的大小。</code></p><p><strong>The blobpage map</strong></p><p>The first of the two overhead elements is the blobpage map. It is an extent of pages that tracks all blobpages in the chunk, essentially describing each one as either used or free. The number of separate pages allocated for the blobpage map depends on the number of blobpages that must be tracked, of course, and the size of each tracking page in the map, which is the server page size.</p><p><code>两个 overhead elements 中的第一个是 blobpage map。它是一组连续的页面，用于跟踪 chunk 中的所有 blobpage，实质上会记录每个 blobpage 是处于“已使用”还是“空闲”状态。当然，为 blobpage map 分配的独立页面数量，取决于需要跟踪的 blobpage 数量，以及 map 中每个跟踪页面的大小（该大小即 server 页面大小）。</code></p><p><strong>The blob bitmap</strong></p><p>Picture a large blob chunk. It would begin with a fairly large blobpage map, consisting of possibly hundreds of pages. As the chunk began to get full, it would be a pain to search every page of the blobpage map looking for those scarce references to free blobpages. So the blobpage map itself has a bitmap describing each of its pages as either 0, which means it contains at least one reference to a free blobpage, or 1, which means it is worthless to search through, containing no reference to a free spot.</p><p><code>设想一个大的 blob chunk。它会以一个相当庞大的 blobpage map 作为起始，可能由数百个页面组成。当这个 chunk 逐渐被填满时，若要搜索 blobpage map 的每一页以寻找那些稀少的指向空闲 blobpage 的引用，将会是一件非常繁琐的事情。因此，blobpage map 本身设有一个位图（bitmap），用于描述其每一页的状态：若某页标记为 0，则表示该页至少包含一个指向空闲 blobpage 的引用；若标记为 1，则意味着搜索该页毫无价值，因为它不包含任何指向空闲位置的引用。</code></p><blockquote><p>scarce 英[skeəs] 美[skers]<br>adj.稀少的;缺乏的;不足的;<br>adv.几乎不;刚;简直不;勉强;</p></blockquote><p><strong>Blobpages</strong></p><p>Blobpages are what the fighting is all about. They store blobspace blob data. We will get to lower-level blobpage details in a few minutes. In the meantime, here are a few tidbits to tide you over:</p><p><code>Blobpages（二进制大对象页）正是这场“存储之战”的核心所在。它们用于存储 blobspace（二进制大对象空间）中的 blob 数据（二进制大对象数据）。几分钟后，我们将深入探讨 blobpage 更底层的细节。在此期间，先分享几个小知识点，让你先睹为快：</code></p><p> <strong>•</strong> Their size is configurable, but only to intervals of the system page size and only at the blobspace level. </p><p><code>它们（指 blobpages）的大小是可配置的，但只能按照系统页面大小的间隔进行配置，并且这种配置只能在 blobspace（二进制大对象空间）级别进行。</code></p><p> <strong>•</strong> Their size is not trivial; unlike blobs stored with the data, a blobspace blobpage can store data from only one blob.</p><p><code>它们的大小并非微不足道；与和数据一起存储的二进制大对象（blobs）不同，一个二进制大对象空间（blobspace）中的 blobpage 只能存储来自一个二进制大对象（blob）的数据。</code></p><p> <strong>•</strong> They are never found in the shared memory buffer pool. Blobs stored in a blobspace are read and written there directly.</p><p><code>它们永远不会出现在共享内存缓冲区池（shared memory buffer pool）中。存储在二进制大对象空间（blobspace）中的二进制大对象（blobs）是直接在那里（即 blobspace 中）进行读写操作的。</code></p><p><strong>A Typical Blobpage Map Page</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032123759.png" alt="image-20250603212316620"></p><p><strong>Notes:</strong></p><p>Every blobpage in the chunk is represented by one 8-byte blob <em>free-map structure</em> in the blobpage map. Not surprisingly, the first blobpage is tracked by the first blob free-map structure in the first page of the blobpage map. The second structure tracks the second blobpage, and so on.</p><p><code>chunk 中的每一个 blobpage，都会在 blobpage map 中由一个 8 字节的 blob free-map structure 来表示。不出所料，blobpage map 第一页中的第一个 blob free-map structure 会负责跟踪第一个 blobpage。第二个 structure 则负责跟踪第二个 blobpage，依此类推。</code></p><p><strong>The blob free-map structure</strong></p><p>Each blob free-map structure, which consists of two 4-byte integers, contains three pieces of information about the blobpage it represents; it is meant to convey the <em>state</em> of the blobpage.</p><p><code>每个由两个 4 字节整数构成的 blob free-map structure 都包含关于其所代表的 blobpage 的三部分信息；该 structure 旨在传达该 blobpage 的状态。</code></p><p><strong>Blobpage state</strong></p><p>Blobspace blob data is never actually <em>modified</em>. An update of blob data involves inserting new data into a new chain of blobpages, then freeing the old blobpages. Think of blob data as having a state that toggles back and forth between used and free.</p><p><code>blobspace 中的 blob 数据实际上从未被真正修改过。对 blob 数据的更新操作涉及将新数据插入到一个新的 blobpage 链中，然后释放旧的 blobpage。可以将 blob 数据的状态想象为在“已使用”和“空闲”之间来回切换。</code></p><p><strong>Used bit</strong></p><p>The most significant bit of the first integer in the blob free-map structure indicates whether the blobpage is used (1) or free (0). Recall that a 4-byte integer with only the most significant bit set has a hex value of 0x80000000.</p><p><code>blob free-map structure 中第一个 4 字节整数的最高有效位（most significant bit）用于指示该 blobpage 是否正在被使用（值为 1）或处于空闲状态（值为 0）。回想一下，一个仅最高有效位被置为 1 的 4 字节整数，其十六进制值为 0x80000000。</code></p><p><strong>Loguniq</strong></p><p>Even with the sign bit unavailable, there is plenty of room in the first integer of the structure to store a logical log unique ID. This ID, stored only for blobs in databases being logged, represents the logical log that was current when the state of the blobpage last changed.</p><p><code>即便符号位（sign bit）不可用，该结构中第一个整数的剩余空间也足以存储一个 logical log unique ID。这个 ID 仅针对处于被记录日志状态的数据库中的二进制大对象（blobs）进行存储，它表示在该 blobpage 状态最后一次发生变更时，当前处于活动状态的逻辑日志。</code></p><blockquote><p>plenty 大量 英[ˈplenti] 美[ˈplenti]</p></blockquote><p><strong>Why store a loguniq?</strong></p><p>Blobspace blob data, because its size is practically unlimited, is never written to the logical log files. When a blobspace blob is inserted, deleted, or updated in a database created with logging, the record of the operation that is written to the current log file contains only a miniature representation of the blob data: the home row’s 56-byte descriptor. </p><p><code>blobspace 中的 blob 数据大小实际上不受限制，因此这些数据从不会被写入到逻辑日志文件中。当在一个启用了日志记录功能的数据库中对 blobspace 中的 blob 进行插入、删除或更新操作时，写入到当前日志文件中的操作记录仅包含该 blob 数据的一个微型表示：即其所在行的 56 字节描述符（56-byte descriptor）。</code></p><p>Meanwhile, in the blobspace, the operation has changed the state of a number of blobpages. The blob free-map structures tracking those blobpages are updated to include the current logical log unique ID. Thus, the blob data is not included in, but <em>associated with</em> the log containing its descriptor. Then, when that logical log file is backed up, the appropriate blobpages tag along. (They are actually written to tape before the log is.) The mechanism that determines which blobpages are appropriate for a particular logical log hinges on the <strong>loguniq</strong> values stored in the blob free-map structures.</p><p><code>与此同时，在 blobspace 中，这些操作已改变了多个 blobpage 的状态。跟踪这些 blobpage 的 blob free-map structures 会被更新，以包含当前的 logical log unique ID。因此，虽然 blob 数据本身并未被包含在日志文件中，但它却与包含其描述符（descriptor）的日志文件相关联。随后，当该逻辑日志文件被备份时，相应的 blobpage 也会随之一起备份（实际上，它们会在日志文件之前被写入到磁带中）。确定哪些 blobpage 适用于特定逻辑日志的机制，依赖于存储在 blob free-map structures 中的 loguniq（逻辑日志唯一标识符）值。</code></p><p><strong>Partition number</strong></p><p>This is the partition number of the tblspace that contains the blob data. The purpose of storing this information is to speed the freeing of blobpages when a tblspace is dropped.</p><p><code>这是包含 blob 数据的 tblspace 的 partition number。存储此信息的目的是在表空间被删除时，能够加速释放（freeing）相关的 blobpage。</code></p><p><strong>Blobpage Addressing</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032147823.png" alt="image-20250603214703763"></p><p><strong>Notes:</strong></p><p>A blobpage is referred to mainly by its <em>blobpage address</em>, which is close to, but never quite the same as its physical address. For instance, imagine an Informix Dynamic Server system’s third chunk is a blob chunk beginning with five overhead pages. The first blobpage in the chunk has a physical address of 0x00300005 and a blobpage address of 0x00300000. Assume the size of a blobpage in this chunk is 6 x BUFFSIZE. The second blobpage in the chunk has a physical address of 0x0030000b, and a blobpage address of 0x00300001.</p><p><code>一个 blobpage 主要通过其 blobpage address 来引用，该地址与它的物理地址相近，但并不完全相同。例如，假设一个 IDS 系统的第3个 chunk 是一个 blob chunk，该 chunk 以五个 overhead pages 开头。该 chunk 中的第一个 blobpage 的物理地址是 0x00300005，而其 blobpage address 是 0x00300000。假设该数据块中一个 blobpage 的大小为 6 倍的 BUFFSIZE（缓冲区大小）。那么，该数据块中的第二个 blobpage 的物理地址是 0x0030000b，而其 blobpage address 是 0x00300001。</code></p><p>Like a physical address, a blobpage address is a 4-byte code. The most significant one and a half bytes (3 nibbles) contain the chunk number, and the low order two and a half bytes (5 nibbles) contain the blobpage number.</p><p><code>与物理地址类似，一个 blobpage 地址是一个 4 字节（32 位）的编码。其中，最高有效的 1.5 字节（即 3 个半字节，nibble，每个 nibble 为 4 位）包含 chunk 的编号，而最低有效的 2.5 字节（即 5 个半字节）则包含 blobpage 的编号。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032153800.png" alt="image-20250603215341754"></p><p><strong>Viewing a Blobpage</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042159319.png" alt="image-20250604215910188"></p><p><strong>Notes:</strong></p><p>Unfortunately there is no supported method by which you can display an entire blobspace blobpage, as we have been displaying all other types of pages. The output from <strong>oncheck</strong> <strong>-pP</strong> is more confusing than helpful; it prints only header information, most of which is inaccurate because the header structure on a blobpage is not the one expected by <strong>oncheck -pP</strong>. The only <strong>oncheck</strong> command that displays any blobpage information of value is <strong>oncheck -pD</strong>.</p><p><code>遗憾的是，目前并没有受支持的方法能像展示其他所有类型的页面那样，完整显示一个 blobspace 中的 blobpage。oncheck -pP 命令的输出结果不仅没有起到多大帮助，反而令人困惑；它仅打印页头信息，而且其中大部分信息都不准确，这是因为 blobpage 的页头结构并非 oncheck -pP 命令所预期的结构。在所有 oncheck 命令中，唯一能显示有价值 blobpage 信息的命令是 oncheck -pD。</code></p><p>Run <strong>oncheck -pD</strong> on your <strong>stores_demo:bsblob</strong> tblspace and pipe the output to <strong>tail -16</strong>. These last 16 lines should be the information for the last home row in your table. Below the hex dump of the blob descriptor, your output should resemble the slide above.</p><p><code>对你的 stores_demo:bsblob tblspace 运行 oncheck -pD 命令，并将输出结果通过管道传输给 tail -16。最后这 16 行应该是你表中 home row 的信息。在 blob 描述符的十六进制转储（hex dump）下方，你的输出结果应该与上面的幻灯片内容相似。</code></p><p><strong>TBLOB</strong></p><p>TBLOB stands for the blob descriptor structure. Here are some useful fields in the TBLOB section.</p><p><code>TBLOB 代表的是 blob 描述符结构。以下是 TBLOB 部分中一些有用的字段。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042206692.png" alt="image-20250604220608650"></p><p><strong>BLOBPAGE</strong></p><p>These fields can be found in the BLOBPAGE section.</p><p><code>这些字段可以在 BLOBPAGE 部分中找到。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042209829.png" alt="image-20250604220908771"></p><p><strong>Blobspace Behavior: Logging and Backup</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042210740.png" alt="image-20250604221040674"></p><p><strong>Notes:</strong></p><p>Blobspace blob data is never written to the logical log files. Instead, Informix Dynamic Server writes minimal reference information about the blobspace blob to the logical log files: the blob descriptor structure from the home row, and any associated blob free-map structures from the blobspace. However, blob data does manage to sneak its way onto the appropriate logical log tape while nobody is watching.</p><p><code>Blobspace 中的 blob 数据从来不会被写入逻辑日志文件。相反，IDS 仅将关于 blobspace 中 blob 的最少引用信息写入逻辑日志文件：这些信息包括 home row 中的 blob descriptor structure，以及 blobspace 中与之相关的任何 blob free-map structures。然而，在无人察觉的情况下，blob 数据还是会设法“潜入”到相应的逻辑日志磁带上。</code></p><blockquote><p>sneak 英[sniːk] 美[sniːk]<br>v.溜;偷走(不重要的或小的东西);偷拿;偷偷地走;偷带;（儿童向成人）打小报告，告状;偷偷地做;<br>n.打小报告的人，告状者(尤指儿童);<br>adj.突然的;出其不意的;</p></blockquote><p>You might assume that at log backup time, <strong>ontape</strong> determines which blobpages belong with a particular logical log by scanning the log records for descriptor structures, tracking down their blobpages and whisking them off to the tape. But there is a much faster way to do this. </p><p><code>你可能会认为，在进行日志备份时，ontape 工具会通过扫描日志记录中的 descriptor structures，来确定哪些 blobpage 属于某个特定的逻辑日志，然后追踪这些 blobpage 并将它们快速传输到磁带上。但实际上，有一种更快的方法可以实现这一目的。</code></p><p>Before backing up each log, <strong>ontape</strong> searches the blobpage map for any blobpages, whether used or free, whose <strong>loguniq</strong> (logical log unique ID) matches the log waiting to go to tape. Any blobpages that fit the criteria are sent first, followed by the logical log that presumably contains all the associated blob descriptor structures.</p><p><code>在备份每个日志之前，ontape 工具会在 blobpage map 中搜索任何其 loguniq（逻辑日志唯一标识符）与等待写入磁带的日志相匹配的 blobpage，无论这些 blobpage 是已使用状态还是空闲状态。任何符合条件的 blobpage 都会被优先发送，随后才会发送可能包含所有相关 blob descriptor structures 的逻辑日志。</code></p><p>This should explain why blobpages that are freed during a delete operation cannot be reused until the current logical log is backed up to tape.</p><p><code>这应该能解释为什么在执行删除操作后被释放的 blobpages，在当前逻辑日志备份到磁带之前无法被重新使用。</code></p><p>This should also explain why you must switch to the next logical log before writing blob data to a brand new blobspace. Can you make the connection?</p><p><code>这也应该能解释为什么在向一个全新的 blobspace 写入 blob 数据之前，必须切换到下一个逻辑日志。你能理清其中的关联吗？</code></p><p>When you create a blobspace, a record of the event is written to the current logical log. </p><p><code>当你创建一个 blobspace 时，该事件的一个记录会被写入当前的逻辑日志。</code></p><p>Now imagine a scenario in which you are allowed to immediately write blob data to the new blobspace.</p><p><code>现在设想这样一个场景：你被允许立即向这个全新的 blobspace 写入 blob 数据。</code></p><p>When that logical log is backed up, a number of blobpages are written to the tape ahead of the log.</p><p><code>当那个逻辑日志被备份时，会有多个 blobpage 在日志之前被写入磁带。</code></p><p>If that logical log is applied after the restore of an archive, the blobpages appear on the tape long before the blobspace creation record is applied. As the archive API reads blobpages, it expects to put them somewhere. The current design guarantees that there is always a blobspace in which to put them.</p><p><code>如果在恢复一个归档文件之后应用该逻辑日志，那么在 blobspace 创建记录被应用之前很久，blobpage 就已经出现在磁带上了。由于归档文件接口在读取 blobpage 时，期望能将它们放置到某个位置，而当前的设计确保了总有一个 blobspace 可以用来放置这些 blobpage。</code></p><p>大概这个意思，按之前说的，备份每个逻辑日志之前，先备 blobpage，所以，即使在这同一逻辑日志里，刚刚新建的 blobspace 这个操作，要在备份 blobspace 之后才备份，所以恢复时，先恢复 blobpage，但此时 blobspace 创建的这个操作还没重做呢。这解释了上边第二个问题。</p><p>至于第一个问题 ：“执行删除操作后被释放的 blobpages，在当前逻辑日志备份到磁带之前无法被重新使用”  ，不理解，如果全删了，一直不备份，岂不是所有 blobpage 都用不了了</p><p><strong>Advantages of Partition Storage</strong></p><p><code>分区存储的优点</code></p><p> Small blobs are usually best stored in the tblspace:</p><p><code>小的 blob 通常最好存储在 tblspace 中：</code></p><p>– PNBLOB pages take advantage of the data cache, traveling through the buffer pool like any other dbspace page.</p><p><code>PNBLOB 页会利用数据缓存，像其他任何 dbspace page 一样在缓冲池中传递。</code></p><p>– PNBLOB pages can store more than one blob piece.</p><p><code>PNBLOB 页可以存储多个 blob 片段。</code></p><p> PNBLOB pages are physically logged, so there are no special archiving issues</p><p><code>PNBLOB 页会进行物理日志记录，因此不存在特殊的归档问题</code></p><p> PNBLOB pages are truly updated. It is not necessary to have double the space available for a blob that is being modified</p><p><code>PNBLOB 页确实会被真正更新。对于正在修改的 blob，无需预留双倍的空间。</code></p><p>突然蹦出来个 PNBLOB 莫名其妙，看不懂</p><p><strong>Notes:</strong></p><p>Some of the advantages of storing blobs in a tblspace as opposed to a blobspace are listed above.</p><p><code>上述内容列出了将 blobs 存储在 tblspace 而非 blobspace 中的一些优势。</code></p><p><strong>Advantages of Blobspace Storage</strong></p><p>Large blobs are usually best stored in a blobspace when:</p><p><code>以下情况通常最好将 blobs 存储在 blobspace 中：</code></p><p>– The unit of storage is configurable, at the blobspace level, in multiples of the server page size. A properly configured blob page size could mean more efficient I&#x2F;O and far fewer locks per blob operation.</p><p><code>存储单元在 blobspace 级别是可配置的，其大小以 server page size 的整数倍为单位。适当配置 blob page size 可能意味着更高效的输入/输出（I/O）操作，以及每个 blob 操作所需的锁数量大幅减少。</code></p><p>– Blobspace blob data is written directly to disk, which can be more efficient for large blobs.</p><p><code>blobspace 中的 blob 数据会直接写入磁盘，这对于大型二进制大对象而言可能更为高效。</code></p><p>– Only blob free-map pages and blob descriptors are logged, so logs do not fill up as quickly as they might with PNBLOBs.</p><p><code>只有 blob 的 free-map pages 和 blob descriptors 会被记录到日志中，因此与使用 PNBLOBs 的情况相比，日志不会那么快被填满。</code></p><p>– The same goes for physical logging. PNBLOBs can cause so much physical logging that checkpoints are triggered prematurely.</p><p><code>物理日志记录的情况也是如此。PNBLOBs 可能会导致大量的物理日志记录，从而过早触发检查点（checkpoints）。</code></p><p><strong>Notes:</strong></p><p>A good rule for deciding whether a blob should be stored in a blobspace or in with the tblspace is this: if the average blob size for a table is greater than two pages, store it in a blobspace. If the average blob size is less than one-half of a page, store it in the tblspace. Blobs that are generally in between these sizes, or blobs that are highly variable in size pose a more difficult decision and might require benchmark tests to determine the more efficient storage method.</p><p><code>以下是一个用于决定 blob 应存储在 blobspace 还是 tblspace 中的良好准则：如果表中 blob 的平均大小超过两页，则将其存储在 blobspace 中；如果平均大小小于半页，则将其存储在 tblspace 中。对于大小通常介于这两者之间的二进制 blob，或者大小高度可变的二进制大对象，做出决定则更为困难，可能需要进行基准测试以确定更高效的存储方法。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 6. Fragmented Tables and Indexes</title>
      <link href="/2025/06/01/IX9111/6/"/>
      <url>/2025/06/01/IX9111/6/</url>
      
        <content type="html"><![CDATA[<p><strong>System Catalog</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506012328374.png" alt="image-20250601232814236"></p><p><strong>Notes:</strong></p><p>A table or index that is not fragmented is confined to a single dbspace and has only one partition page in the tblspace tblspace for that dbspace. In a <em>fragmented</em> table, the physical data for the table is distributed across multiple dbspaces. Each dbspace contains a fragment of that table, and each fragment has its own partition page. The partnum for each fragment is stored in the <strong>partn</strong> column of the <strong>sysfragments</strong> system catalog. Because it uniquely identifies each fragment, the <strong>sysfragments.partn</strong> value is sometimes known as the <em>fragid</em>. The <strong>partnum</strong> column in <strong>systables</strong> is zero (0) for tables and indexes that are fragmented.</p><p><code>未分片的表或索引仅局限于单个 dbspace，且在该 dbspace 对应的 tblspace 中仅有一个分区页。而在分片表中，表的物理数据会分布在多个 dbspace 中。每个 dbspace 包含该表的一个分片，且每个分片都有自己独立的分区页（partition page）。每个分片的分片号（partnum）存储在系统目录表 sysfragments 的 partn 列中。由于该值能唯一标识每个分片，因此 sysfragments.partn 的值有时也被称为分片标识符（fragid）。对于已分片的表和索引，systables 表中的 partnum 列值为零（0）。</code></p><p><strong>Checking Tblspaces: oncheck -pt&#x2F;-pT</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022044772.png" alt="image-20250602204354649"></p><p><strong>Notes:</strong></p><p>The <strong>oncheck -pT</strong> command (or <strong>oncheck -pt</strong>) lists each fragment separately. The information about pages allocated, pages used, data pages, rows, and the partition partnum is for the fragment currently listed. The <strong>oncheck -pT</strong> command is an excellent way to monitor the size and use of an individual fragment.</p><p><code>oncheck -pT 命令（或 oncheck -pt）会单独列出每个片段（fragment）。对于当前列出的片段，它会显示已分配页数（pages allocated）、已使用页数（pages used）、数据页数（data pages）、行数（rows）以及分区标识号（partition partnum）等信息。oncheck -pT 命令是监控单个片段大小和使用情况的绝佳工具。</code></p><p>Notice in the example that the <strong>partition lockid</strong> is now different from the <strong>Partition</strong> <strong>partnum</strong>. The oncheck report shows that each fragment of a table or index has a different partnum value, but they all have the same lockid value.</p><p><code>请注意，在示例中，分区锁标识号（partition lockid）现在与分区标识号（Partition partnum）不同。oncheck 报告显示，表或索引的每个片段都有不同的 partnum 值，但它们的 lockid 值都相同。</code></p><p><strong>Partition Layout</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022151315.png" alt="image-20250602215113216"></p><p><strong>Notes:</strong></p><p>Each fragment has its own bitmap page on logical page 0. The rest of the pages (except for additional bitmap pages) contain data for the fragment.</p><p><code>每个片段在逻辑页 0 上都有其自己的位图页（bitmap page）。其余的页（除了额外的位图页）都包含该片段的数据。</code></p><p><strong>Indexes in a Fragmented Table</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022153517.png" alt="image-20250602215300455"></p><p><strong>Notes:</strong></p><p>Any indexes built on a fragmented table are stored in their own separate partitions. There is no case in which a table fragment has data pages and index pages intermingled.</p><p><code>在分片表上创建的任何索引都存储在它们各自独立的分区（partition）中。不存在表片段的数据页和索引页相互混杂的情况。</code></p><p>The number of index fragments built depends on how the administrator created the index with the CREATE INDEX statement. If the CREATE INDEX statement does not include the FRAGMENT clause, the index is fragmented in the same way as the table and there is one index partition for every data partition (as shown in the example above). You can also specify a unique fragmentation strategy for the index, or you can store the entire index in a separate dbspace.</p><p><code>所构建的索引片段数量取决于管理员如何使用 </code>CREATE INDEX<code> 语句来创建索引。如果 CREATE INDEX 语句中未包含 FRAGMENT 子句，那么索引将按照与表相同的方式进行分区，即每个数据分区对应一个索引分区（如上例所示）。此外，你也可以为索引指定一种独特的分区策略，或者将整个索引存储在一个单独的数据库空间（dbspace）中。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022157326.png" alt="image-20250602215758277"></p><p><code>在 IDS 的早期版本中，非分片表（non-fragmented tables）的索引页和数据页位于同一个表空间（tblspace）中。</code></p><p><strong>The Index Entry</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022200964.png" alt="image-20250602220001908"></p><p><strong>Notes:</strong></p><p>If a table is fragmented and the index is not fragmented the same way as the table, the rowid is no longer sufficient to locate a row. Why? Because the rowid describes a logical page and slot number within a partition, but not the partition. In a non-fragmented table, there is only one partition per table; a fragmented table has multiple partitions.</p><p><code>如果表被分片了，而索引却没有按照与表相同的方式进行分区，那么 rowid 就不再足以定位一行数据了。这是为什么呢？因为 rowid 描述的是 partition 内的一个逻辑页和槽位号，但它并不包含 partition 信息。在非分片表中，每个表只有一个 partition；而在分区表中，一个表会有多个 partition。</code></p><p>As you might have guessed, the additional piece of information that must be included in the index entry is the partition number. This is why an index for a fragmented table could be much larger than an index for a non-fragmented table.</p><p><code>正如你可能已经猜到的，索引条目中必须包含的额外信息就是分区号（partition number）。这就是为什么分片表的索引可能比非分片表的索引大得多的原因。</code></p><p>When an index and a table are fragmented identically, the index does not require the partition number to locate a row because the server knows that rowids referenced in an index partition refer to rows in corresponding table partitions on the same dbspace.</p><p><code>当索引和表以相同的方式进行分片时，索引不需要使用分区号（partition number）来定位一行数据，因为 server 知道索引分区中引用的 rowid 指的是与该索引分区（index partition）位于同一数据库空间（dbspace）的对应表分区（partition）中的行。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 5. Index Architecture</title>
      <link href="/2025/05/25/IX9111/5/"/>
      <url>/2025/05/25/IX9111/5/</url>
      
        <content type="html"><![CDATA[<p>163 - 167 页讲 <strong>B-Tree</strong>，跳过</p><p><strong>B+ Trees</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505252131910.png" alt="image-20250525213144822"></p><p><strong>Notes:</strong></p><p>The ability to move right or left from a node to its adjacent node puts the <em>plus</em> in B+ tree. All Informix Dynamic Server indexes are B+ trees.</p><p><code>从某个节点能够向左或向右移动到其相邻节点的能力，为B+树赋予了其特有的优势（这里的“plus”即指B+树相较于B树等结构的增强特性）。所有 IDS 的索引都是采用B+树结构实现的。</code></p><p><strong>Node contents</strong></p><p>A node page consists of slots, just as data pages do. A slot table is necessary on an index page because slots can vary in size, <em>not</em> because slots are accessed randomly. Unlike data rows, the slots on an index page are always read sequentially. Therefore, there is no rowid-type address that refers to a particular slot on a particular index node. This means an index page is not limited to 255 slots; it can contain as many slots as will fit. </p><p><code>node page 由 slots 组成，这一点与数据页（data pages）相同。索引页（index page）上需要一个 slot table，这是因为 slot 的大小可能各不相同，并非因为槽是随机访问的。与数据行（data rows）不同，索引页上的槽总是按顺序读取的。因此，不存在指向特定索引节点上特定 slot 的 rowid 类型的地址。这意味着索引页并不局限于255个 slot；它可以包含尽可能多的 slot，只要这些 slot 能够容纳得下。</code></p><p>Though they can vary greatly in size, every slot in a node page is essentially the same structure: a key value followed by a series of references. (A unique index has only one reference per key.) Each reference <em>points down</em> to another part of the tree. The type of reference depends on the index level occupied by the node.</p><p><code>尽管 node page 中的每个 slot 在大小上可能存在很大差异，但它们本质上具有相同的结构：一个键值（key value）后面跟着一系列引用（references）。（唯一索引（unique index）中，每个键值仅对应一个引用。）每个引用都指向树中的另一部分。引用的类型取决于节点在索引层级中所处的位置。</code></p><p><strong>Questions</strong></p><p>How do Dynamic Server nodes point down? </p><p><code>Dynamic Server节点是如何向下指向的？</code></p><p>A node points down either to data rows that are referenced by rowid, or to nodes that are referenced by logical page number.</p><p><code>一个节点要么向下指向通过 rowid 引用的数据行，要么向下指向通过逻辑页号（logical page number）引用的其他节点。</code></p><p>How do Dynamic Server nodes point across?</p><p><code>Dynamic Server节点是如何横向指向（或相互连接）的？</code></p><p>Here is where those omnipresent <strong>pg_next</strong> and <strong>pg_prev</strong> elements in the Dynamic Server page header come in. Picture an index node whose logical page number is 0x9, and whose adjacent node to the right is logical page 0x4a. In the header of node 0x9, <strong>pg_next</strong> is 0x4a. In the header of node 0x4a, <strong>pg_prev</strong> is 0x9. (An index page’s <em>node</em> <em>number</em> is simply its logical page number.)</p><p><code>这时，Dynamic Server页头中无处不在的 pg_next 和 pg_prev 元素就派上用场了。想象一下，有一个索引节点，其逻辑页号为0x9，而其右侧的相邻节点的逻辑页号为0x4a。在节点0x9的页头中，pg_next 的值就是0x4a。同样，在节点0x4a的页头中，pg_prev 的值就是0x9。（索引页的 node number 实际上就是其逻辑页号。）</code></p><p><strong>The Tree After Clustering the Index</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505252154178.png" alt="image-20250525215457105"></p><p><strong>Notes:</strong></p><p>Although index nodes might in reality be scattered haphazardly throughout the table, they are always drawn in their idealized B+ tree arrangement. The data pages to which they refer, however, have been drawn in previous slides as they would likely be arranged physically on disk, in an order unrelated to the index.</p><p><code>尽管索引节点在实际存储中可能零散分布在表的各处，但在图示中，它们始终以理想的B+树结构呈现。而它们所指向的数据页（如前几页幻灯片所示），则更接近磁盘上的物理存储排列方式，其顺序与索引逻辑无关。</code></p><p>Clustering the index temporarily changes the picture as shown. Although the index nodes could have shifted around physically in the rewritten table, by definition the B+ tree picture stays the same. But the data pages are now physically rearranged such that their true order is the ideal order.</p><p><code>聚簇索引会暂时改变图示的存储布局。尽管在表重写后，索引节点的物理位置可能已发生变动，但根据定义，其B+树的逻辑结构保持不变。而此时，数据页会按索引的理想顺序重新物理排列，使得实际存储顺序与逻辑顺序完全一致。</code></p><p>Of course, forcing the data pages to fit nicely into this picture does more than make the slide easier to read. It can improve the efficiency of the index&#x2F;data combination by reducing the amount of I&#x2F;O when scanning for a range of values, and reducing the expense of the I&#x2F;O that is performed.</p><p><code>当然，将数据页强制对齐到这种理想布局的作用远不止让幻灯片更易读。它还能通过减少范围扫描时的I/O操作量，以及降低所执行I/O操作的开销，来提高索引与数据组合的效率。</code></p><p><strong>A One-Level Index</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262025860.png" alt="image-20250526202545746"></p><p><strong>Notes:</strong></p><p>An Informix Dynamic Server index that refers to a small number of data rows requires only one node, and therefore only one node level: the root. The root node alters the structure of its contents to point directly to data rows instead of to nodes.</p><p><code>对于一个引用少量数据行的 IDS 索引而言，它仅需一个节点，因此也只有一个节点层级，即根节点。该根节点会调整其内容结构，使其直接指向数据行，而非指向其他节点。</code></p><p><strong>A Two-Level Index</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262028127.png" alt="image-20250526202809034"></p><p><strong>Notes:</strong></p><p>In order to show all the named levels of a B+ tree (root, branch, leaf), we have been picturing 3-level indexes all along. But an Informix Dynamic Server index that refers to a moderate number of data rows (roughly between 300 and 100,000) requires only two node levels: root and leaf.</p><p><code>为了展示 B+ 树中所有命名的层级（根节点、分支节点、叶子节点），我们一直以来都以三层索引为例进行说明。然而，对于一个引用中等数量数据行（大约在 300 行到 100,000 行之间）的 IDS 索引而言，它仅需要两个节点层级：根节点和叶子节点。</code></p><p><strong>The Generic Index Node</strong></p><p><img src="C:\Users\49491\AppData\Roaming\Typora\typora-user-images\image-20250526203330803.png" alt="image-20250526203330803"></p><p><strong>Notes:</strong></p><p>Index nodes come in several different flavors, but there are many things that can be said about them in general. </p><p><code>索引节点有几种不同的类型，但总体而言，关于它们有很多可以阐述的共性内容。</code></p><p>Perhaps you can see from the slide above that an Informix Dynamic Server index node is structured similarly to a data page. Each slot on the page is described by one 4-byte slot table entry, which, as usual, contains a byte offset into the page and a length. But where each slot on a data page stores a row of data, each slot on an index node contains an <em>index entry</em>. </p><p><code>或许你可以从上面的幻灯片中看到，IDS 的索引节点结构与数据页的结构类似。页上的每个 slot 都由一个 4 字节的 slot table 条目来描述，该条目像往常一样，包含指向页内的字节偏移量和长度信息。不过，数据页上的每个 slot 存储的是一行数据，而索引节点上的每个 slot 则包含一个索引条目。</code></p><p>There are two types of index entries: <em>leaf-type entries</em> and <em>twig-type entries</em>, but they do not mix; all nodes on a particular level of the index have either leaf-type or twig-type entries. We will describe the structure of each entry type on the next few pages.</p><p><code>索引条目有两种类型：叶子类型条目（leaf-type entries）和枝节点类型条目（twig-type entries），但它们不会混合存在；索引中特定层级的所有节点要么只包含叶子类型条目，要么只包含枝节点类型条目。在接下来的几页中，我们将分别描述每种条目类型的结构。</code></p><blockquote><p>twig 英[twɪɡ] 美[twɪɡ]<br>n.细枝;嫩枝;小枝;<br>v.(突然地)懂得，理解，明白，意识到;</p></blockquote><p><strong>Page Flags for Index Pages</strong></p><p>Index page flags:</p><p>– 0x10 – B-tree node (on for all B-tree node types)</p><p>– 0x20 – Root node</p><p>– 0x40 – Branch (or twig) node</p><p>– 0x80 – Leaf node</p><p>And here is how they combine on real nodes:</p><p>– 0x30 – Root node</p><p>– 0x50 – Branch node</p><p>– 0x70 – Root node; also acting as a twig (two-level index)</p><p>– 0x90 – Leaf node</p><p>– 0xb0 – Root node; also acting as a leaf (one-level index)</p><p><strong>Notes:</strong></p><p>The page flags on a node reveal the index level it occupies. The flags shown above are specific to index pages.</p><p><code>节点上的页标志（page flags）揭示了该节点在索引中所处的层级。上述所示的标志是专门针对索引页的。</code></p><blockquote><p>occupy 占据 英[ˈɒkjupaɪ] 美[ˈɑːkjupaɪ]</p><p>reveal 揭示 英[rɪˈviːl] 美[rɪˈviːl]</p></blockquote><p>Every index page has the first flag (0x10) set. And, depending upon the role the node plays in the index, it has one or more additional flags. For example, in a small index, the root node can also be a leaf node (giving it a flag setting of 0xb0, or 0x10 + 0x20 + 0x80).</p><p><code>每个索引页都会设置第一个标志位（0x10）。此外，根据节点在索引中所扮演的角色，它还会设置一个或多个额外的标志位。例如，在一个小型索引中，根节点也可以同时是叶子节点（此时其标志位设置为 0xb0，即 0x10 + 0x20 + 0x80）。</code></p><p><strong>The Root-Leaf Node</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262050829.png" alt="image-20250526204942852"></p><p><strong>Notes:</strong></p><p>Let us look closely at the root node of a one-level index.</p><p><code>让我们仔细研究一下单层索引的根节点。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262201528.png" alt="image-20250526220154376"></p><p><code>除了页类型为 0xb0（表示该页既是节点页，又是根节点页，还是叶子节点页）且没有相邻的兄弟节点之外，它的结构与叶子节点完全相同，每个 slot 中都包含一个叶子类型的条目。</code></p><p>Each leaf-type entry, also known as an <em>index item</em>, contains the following components:</p><p><code>每个叶子类型的条目，也称为索引项（index item），包含以下组成部分：</code></p><p> <strong>•</strong> A key value.</p><p> <strong>•</strong> One or more rowids. A duplicate index can have multiple rowids in a leaf-type entry. A unique index can have only one rowid per entry. The index page shown in the example above must be a duplicate index, because the third index item has two rowids.</p><p><code>一个或多个rowid。在重复索引（duplicate index）中，一个叶子类型的条目可以包含多个 rowid；而在唯一索引（unique index）中，每个条目只能包含一个 rowid。上述示例中展示的索引页必定是一个重复索引，因为第三个索引项中包含两个行标识符。</code></p><blockquote><p>gemini</p><p>“duplicate index”（或者更准确地说，是 “允许重复值的索引” 或 “非唯一索引”）指的是<strong>索引列中允许存在重复值</strong>的索引。</p></blockquote><p><strong>•</strong> A delete flag (<strong>df</strong>) for each rowid listed. Rather than deleting a key value immediately, Informix Dynamic Server marks it as deleted by setting the delete flag to 1. The delete flag is only operational if the database is logged and the table is not locked in EXCLUSIVE MODE.</p><p><code>对于列出的每个rowid，都有一个删除标志(df）。IDS 不会立即删除键值，而是通过将删除标志设置为 1 来标记该键值为已删除。不过，删除标志仅在数据库处于日志记录模式（logged）且表未以独占模式（EXCLUSIVE MODE）锁定的情况下才会生效。</code></p><p>Except for data rows whose indexed column is null, each row in the tblspace has exactly one corresponding item in the index. Add another index to the tblspace, and the same rule applies to that index.</p><p><code>除了那些索引列值为 NULL 的数据行之外，表空间（tblspace）中的每一行在索引中都有且仅有一个对应的条目。如果再为该表空间添加一个索引，那么同样的规则也适用于这个新索引。</code></p><p><strong>Term review</strong></p><p>These many similar index terms have probably begun to get confusing. An Informix Dynamic Server index is made of index pages, called <em>nodes</em>. Index nodes contain <em>index</em> <em>entries</em>: one per slot. There are two types of index entries. The entry type found on the last level of an index is called a <em>leaf-type entry</em>. Leaf-type entries have a slightly different structure than do <em>twig-type entries</em>, which are found on all non-leaf levels of an index. We will describe the structure of twig-type entries in a few pages.</p><p><code>如此众多的相似索引术语可能已开始让人感到困惑。IDS 的索引由索引页构成，这些索引页被称为 节点。索引节点包含 索引条目，每个 slot 对应一个索引条目。索引条目分为两种类型。位于索引最后一层的条目类型称为 叶型条目。叶型条目的结构与位于索引所有非叶层的 枝型条目 略有不同。我们将在后续几页中介绍枝型条目的结构。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262247826.png" alt="image-20250526224716736"></p><p><code>尽管上面准确描绘了每个 4 字节 rowid 的大小，但所显示的 key 值大小（3 字节）是随意选定的。</code></p><p><strong>The Root-Leaf Node: oncheck –pp Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272039907.png" alt="image-20250527203900751"></p><p><strong>Notes:</strong></p><p>Above is a real output from <strong>oncheck -pp</strong>, which is equivalent to the picture on the previous slide. The meaning of each slot on this particular root node should be clear. In this case, the indexed column is apparently a CHAR(3). Each key is stored in a separate slot in order of its value. A series of rowids is included in the same slot as the key value.</p><p><code>以上是 oncheck -pp 的实际输出结果，其内容与上一张幻灯片中的图片等效。对于这个特定根节点上的每个 slot，其含义应当十分清晰。在此例中，被索引的列显然是一个 CHAR(3) 类型。每个键值都按其数值顺序存储在单独的slot中。而与键值处于同一 slot 的，还有一系列的 rowid。</code></p><p>The first index entry in the output indicates that rowid 0x201 (the data row on logical page 2, slot 1) contains the character <strong>A</strong> in the indexed column.</p><p><code>输出结果中的第一条索引条目表明，rowid 为 0x201（位于逻辑页 2 的 slot 1 的数据行）在被索引列中包含字符 A。</code>(0x41 -&gt; 97 -&gt; A)</p><p>The third index entry indicates that two rows in the table contain the character <strong>C</strong> in the indexed column: one in slot 3 on page 2, and one in slot 4 on the same page.</p><p><code>第三条索引条目表明，表中有两行数据在被索引列中包含字符 C：一行位于第 2 页的 slot 3，另一行位于同一页的 slot 4。</code></p><p><strong>Key Value Storage</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272049916.png" alt="image-20250527204923813"></p><p><strong>Notes:</strong></p><p>Key values in indexes are compared as binary entities, which makes the key comparison algorithm much quicker and more versatile. For example, key values that you and I happen to know are integers are not compared as integers, but as a series of 4 bytes:</p><p><code>索引中的键值是以二进制实体的形式进行比较的，这使得键值比较算法更为迅速且通用。例如，你我恰好都知道是整数的那些键值，在比较时并不会被当作整数处理，而是被当作一系列的 4 字节数据来进行比较：</code></p><p>Steps required to compare 0x12345678 with 0x12345679:</p><ol><li><p>0x12 vs. 0x12 (No winner. We will have to keep comparing.)</p></li><li><p>0x34 vs. 0x34 (Still no winner. Maybe next time.)</p></li><li><p>0x56 vs. 0x56 (Will this ever end?)</p></li><li><p>0x78 vs. 0x79 (Aha! The second stream of bytes is greater.)</p></li></ol><p>The byte comparisons stop as soon as one of the two byte streams wins a comparison.</p><p><code>一旦两个字节流中的某一个在比较中胜出，字节比较就会立即停止。</code></p><p>Now, without some intervention, this algorithm would not work at all when comparing negative integers with positive ones, because of the way signed integers are normally stored in computer memory.</p><p><code>现在，如果不进行某种干预，在比较负整数与正整数时，这个算法将完全无法正常工作，这是因为有符号整数在计算机内存中通常的存储方式所致。</code></p><p><strong>Storing Integers in Columns: The Sign Bit</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272058161.png" alt="image-20250527205856071"></p><p><strong>Notes:</strong></p><p>At the binary level, all integer values look positive. Bits are either on (1) or off (0). It is impossible to make a bit less than off, though no doubt someone has tried. For now, at least, negative values are represented using software tricks and storage conventions.</p><p><code>在二进制层面上，所有的整数值看起来都是正数。比特位要么是 1，要么是 0。要让一个比特位处于比 0 更小是不可能的。至少在目前，负值是通过软件技巧和存储约定来表示的。</code></p><p>Early on it was decided that in order to represent signed numbers in binary, the most significant bit would be used as a flag called the <em>sign bit</em>.</p><p><code>早期人们就决定，为了在二进制中表示有符号数，将使用最高有效位作为标志位，称为符号位。</code></p><p>For negative numbers, the sign bit is <em>on</em>. For positive numbers, the sign bit is <em>off</em>. The price of this trick is paid in storage capacity. For example, sacrificing the most significant bit for use as a sign bit reduces the highest possible positive value of a 4-byte integer from 0xffffffff (4,294,967,295) to 0x7fffffff (2,147,483,647).</p><p><code>对于负数，符号位是1。对于正数，符号位是0。这种技巧的代价体现在存储容量上。例如，将最高有效位牺牲用作符号位后，一个4字节整数的最大可能正数值就从0xffffffff（即4,294,967,295）减少到了0x7fffffff（即2,147,483,647）。</code></p><p>There is still more to this storage method than you might think, however. Although intuition might tell you that -2147483647 is the sign bit turned <em>on</em> for the value 2147483647, and would therefore be stored as 0xffffffff, in fact 0xffffffff is the value -1. To most computer chips, signed arithmetic is a much cleaner operation if the <em>odometer flips over</em> when you add 1 to -1:</p><p><code>然而，这种存储方法背后的细节比你想象的要更多。尽管直觉可能会告诉你，-2147483647 是将 2147483647 的符号位开启后得到的值，因此可能会被存储为 0xffffffff，但实际上 0xffffffff 表示的是 -1。后边略。</code></p><p>Getting back to the problem this storage method would cause our comparison algorithm, let us say we were trying to determine whether -1 was greater than 1. Obviously it is not. But as shown above, the integer value 1 is stored in computer memory as 0x00000001, whereas the integer value -1 is stored as 0xffffffff. If we stored these values the same way in our index, a comparison would come out heavily on the side of -1.</p><p><code>回到这种存储方法给我们比较算法带来的问题上，假设我们试图判断 -1 是否大于 1。显然，它并不大于 1。但如上所述，整数值 1 在计算机内存中是以 0x00000001 的形式存储的，而整数值 -1 则是以 0xffffffff 的形式存储的。如果我们在索引中以同样的方式存储这些值，那么在进行比较时，结果会严重偏向于认为 -1 更大。</code></p><p><strong>So what goes into our index?</strong></p><p>The problem is solved by simply toggling the sign bit before we store the value in the key. A negative integer is stored in an index key with its sign bit turned <em>off</em>, and a positive integer has its sign bit turned <em>on</em>. For example the value -1, stored in the data row as 0xffffffff, is stored in the index as 0x7fffffff. The value 1, stored in the data row as 0x00000001, is stored in the index as 0x80000001. Now, as a byte stream, 1 beats -1 every time, and translating the key value back into an integer is just a matter of toggling the sign bit again.</p><p><code>这个问题可以通过在将值存入键之前简单翻转符号位来解决。在索引键中，负整数以其符号位0的形式存储，而正整数则以其符号位1的形式存储。例如，在数据行中以 0xffffffff 形式存储的值 -1，在索引中则以 0x7fffffff 的形式存储。同样，在数据行中以 0x00000001 形式存储的值 1，在索引中则以 0x80000001 的形式存储。现在，作为字节流来看，1 在每次比较中都会胜过 -1，而将键值转换回整数，也只需再次翻转符号位即可。</code></p><p><strong>The Root Node</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272119410.png" alt="image-20250527211936330"></p><p><strong>Notes:</strong></p><p>The vast majority of root nodes do not lead double lives as leaves. Most real indexes have more than one level, which means that a root node normally points down to other nodes, not to data rows. The page flags on the index node pictured above indicate this is simply a root node.</p><p><code>绝大多数根节点并不会同时作为叶子节点存在。大多数真实的索引结构都不止一层，这意味着根节点通常会指向其他节点，而不是直接指向数据行。上图所示索引节点上的页面标志表明，这仅仅是一个根节点(30)。</code></p><p>The structure of each slot on this page, also called a t<em>wig-type entry</em>, is similar to the structure of a leaf-type entry; a key value is followed by a 4-byte reference. But there are important differences. For instance, in this case the reference is to a node number, which is simply the logical page number of another index node. (One cannot tell from the data on this page whether the node numbers refer to branch nodes or leaf nodes.) </p><p><code>此页面上每个slot（也称为枝型条目）的结构与叶型条目的结构相似；一个键值后面跟着一个 4 字节的引用。但二者之间存在重要差异。例如，在这种情况下，该引用指向一个节点编号，而这个节点编号仅仅是另一个索引节点的逻辑页号。（仅凭此页面上的数据，无法判断这些节点编号指的是分支节点还是叶节点。）</code></p><p>An odd variety of the twig-type entry is shown on this slide: a key-less last slot, a.k.a. the <em>mini-slot</em> or <em>infinity slot</em>. The node number contained in the infinity slot leads to key values that are not infinite, but are nonetheless greater than any key value on this index level. The last slot on each non-leaf level of an index is a mini-slot.</p><p><code>本幻灯片展示了一种特殊的枝型条目变体：无键值的最后一个 slot，也被称为 mini slot 或 infinity slot。infinity slot 中包含的节点编号指向的键值并非无穷大，但这些键值仍大于本索引层级上的任何其他键值。索引结构中每个非叶层级的最后一个 slot 都是 mini-slot。</code></p><p><strong>The Root Node: oncheck -pp Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272138164.png" alt="image-20250527213817050"></p><p><strong>Notes:</strong></p><p>Above is the <strong>oncheck -pp</strong> output for a real root node. Translating what we find here, we know that:</p><p><code>以上是针对一个真实根节点的 oncheck -pp 命令输出结果。解读我们在这里发现的信息，我们可以得知：</code></p><ol><li><p>Node 0x6 leads to all keys with a value less than or equal to <strong>LLLLLLLL</strong>.</p><p><code>节点 0x6 指向所有键值小于或等于 LLLLLLLL 的条目。</code></p></li><li><p>Node 0xb leads to all keys with a value greater than <strong>LLLLLLLL</strong>, and less than or equal to <strong>aaaaaaaa</strong>.</p><p><code>节点 0xb 指向所有键值大于 LLLLLLLL 且小于或等于 aaaaaaaa 的条目。</code></p></li><li><p>Node 0x5 leads to keys that are greater than <strong>aaaaaaaa</strong>, and less than or equal to <strong>mmmmmmmm</strong>.</p><p><code>节点 0x5 指向所有键值大于 aaaaaaaa 且小于或等于 mmmmmmmm 的条目。</code></p></li><li><p>Node 0x9 leads to keys greater than <strong>mmmmmmmm</strong>, and less than or equal to <strong>ssssssss</strong>.</p><p>略</p></li><li><p>Since this is the right-most node in level 0 (being the only node in level 0), its last slot contains a node number without a key, whose value is assumed to be infinite. The node number specified in the level-0 mini-slot leads to real key values, all of which are greater than <strong>ssssssss</strong>.</p><p><code>由于这是第 0 层（也是唯一一层节点所在的层级）中最右边的节点，因此其最后一个 slot 包含一个不带键值的节点编号，该编号的值被假定为无穷大。第 0 层 mini-slot 中指定的节点编号指向实际的键值，这些键值均大于 ssssssss。</code></p></li></ol><p><strong>The Branch Node</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282107467.png" alt="image-20250528210710325"></p><p><strong>Notes:</strong></p><p>By definition, a branch node always points down to other nodes. Branch nodes have a page flag value of 0x50, and contain twig-type index entries.</p><p><code>根据定义，分支节点（branch node）始终向下指向其他节点。分支节点的页标志（page flag）值为 0x50，并且包含枝状（twig-type）类型的索引条目。</code></p><p>The basic twig-type entry is structured as follows:</p><p><code>基本的枝状（twig-type）类型条目的结构如下：</code></p><p>​<em>key_value</em> <em>node_number</em></p><p>The <em>key_value</em> is the same size as the key column value. The node number is 4 bytes.</p><p><code>key_value 的大小与 key column value 相同。节点编号（node number）为 4 字节。</code></p><p><strong>The Branch Node With Duplicates</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282113914.png" alt="image-20250528211344798"></p><p><strong>Notes:</strong></p><p>A duplicate index that contains many items (rowids) per key might contain several leaf nodes per key. In this case, the twig-type entries in the branch nodes above those leaves have to contain more than one reference to a node number. A twig-type entry referencing three leaf nodes, all of which contain items (rowids) for the same key value, looks like this:</p><p><code>对于每个 key 包含多个 rowid 的 duplicate index 而言，每个 key 可能包含多个叶子节点。在这种情况下，位于这些叶子节点上方的分支节点中的枝状类型条目必须包含对多个节点编号的引用。一个引用三个叶子节点的枝状类型条目（这三个叶子节点都包含针对同一键值的条目（rowids）如下所示：</code></p><p>​key value|<strong>rowid</strong>|<strong>node number</strong>|rowid|node number|node number</p><p>This is the last rowid stored on this node number.</p><p><code>这是存储在该节点编号上的最后一个 rowid。</code></p><p>Note that at the leaf level, all rowids associated with a particular key value are sorted. The rowids mentioned in a twig-type entry like the one shown above, therefore, increase in value as you scan right, and Informix Dynamic Server can assume that the last node number in the entry contains rowids that are all greater than the last rowid in the entry.</p><p><code>需要注意的是，在叶子层级，与特定键值相关联的所有 rowid 都是经过排序的。因此，在像上面所示的那种枝状类型条目中提及的 rowid，在从左到右扫描时会呈现递增趋势。IDS 可以据此假定，条目中的最后一个节点编号所包含的 rowid，其值均大于该条目（先前部分）中最后一个 rowid 的值。</code></p><p><strong>The Branch Node: oncheck -pp Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282132688.png" alt="image-20250528213209595"></p><p><strong>Notes:</strong></p><p>Above is the <strong>oncheck -pp</strong> output for a branch node. Analyzing what we find in the first slot, we can tell that:</p><p><code>以上是针对一个分支节点执行 oncheck -pp 命令后输出的结果。通过分析第一个 slot 中的信息，我们可以得出以下结论（或可判断出以下情况） 。</code></p><ol><li><p>Key value <strong>a</strong> can be found in quite a few data rows. A total of 5 nodes below this one are filled with rowids associated with the key value <strong>a</strong>.</p><p><code>键值 a 出现在许多数据行中。与该键值 a 相关联的 rowids 填满了其下方的总共 5 个节点。</code></p></li><li><p>Node 0x5 contains the lowest-valued rowids for the key. The last and greatest-valued rowid on that node is 0x8421.</p><p><code>节点 0x5 包含该键值对应的最小 rowids。该节点上的最后一个（也是值最大的）rowid 是 0x8421。</code></p></li><li><p>Node 0x85 contains rowids for the key that are all greater than 0x8421. The last rowid on that node is 0x10642.</p><p><code>节点 0x85 包含的该键值对应的所有 rowids 均大于 0x8421。该节点上的最后一个 rowid 是 0x10642。</code></p></li><li><p>Node 0x17 contains rowids that are all greater than 0x10642. The last rowid on that node is 0x1c98c.</p><p><code>节点 0x17 包含的该键值对应的所有 rowids 均大于 0x10642。该节点上的最后一个 rowid 是 0x1c98c。</code></p></li><li><p>Node 0x1ca contains rowids greater than 0x1c98c. The last one on the node is 0x1cc84.</p><p><code>节点 0x1ca 包含的该键值对应的所有 rowids 均大于 0x1c98c。该节点上的最后一个 rowid 是 0x1cc84。</code></p></li><li><p>Node 0x1cd contains all rowids for the key value that are greater than 0x1cc84.</p><p><code>节点 0x1cd 包含的所有 rowids 均对应于键值且这些 rowid 的值均大于 0x1cc84。</code></p></li></ol><p>不明白 branch node 为什么存 rowid？</p><p><strong>The Leaf Node</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282208212.png" alt="image-20250528220857112"></p><p><strong>Notes:</strong></p><p>By definition, leaf nodes point to data rows. The example of a root-leaf node presented earlier demonstrates references to the rowids of data rows.</p><p><code>根据定义，叶节点指向数据行。之前展示的 root-leaf 节点示例就演示了对数据行 rowids 的引用。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282210187.png" alt="image-20250528221034107"></p><p><code>上图所示的叶节点与之前分析的 root-leaf 节点之间存在两个差异。首先，这个叶节点有兄弟节点，因此 </code>pg_next<code>和</code>pg_prev<code> 分别包含指向右侧和左侧兄弟节点的节点编号。其次，页标志（0x90）表明这只是一个普通的叶节点，而不是 root-leaf 组合节点（页标志为 0xb0）。</code></p><p><strong>The Leaf Node: oncheck -pp Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282212001.png" alt="image-20250528221212843"></p><p><strong>Notes:</strong></p><p>Above is the <strong>oncheck -pp</strong> output for a leaf node. Analyzing what we find here, we can tell that:</p><ol><li><p>This is a duplicate index. Note that the index entry in slot 3 contains two rowids.</p><p><code>这是一个 duplicate index。请注意，slot 3 中的索引条目包含两个 rowid。</code></p><p>写错了，应该是 slot 4</p></li><li><p>The keys appear to be character data, and we could make an educated guess that the indexed column was a CHAR(5). Of course, Informix Dynamic Server does not need to guess. Based on the appropriate key descriptor on slot 4 of this table’s partition page, the database server knows what column type(s) make up this index key.</p><p><code>这些键值看起来像是字符数据，我们可以合理推测被索引的列是 CHAR(5) 类型。当然，IDS 并不需要靠猜测来确定。根据该表 partition page 上 slot 4 的适当键描述符，server 能够确切知道构成该索引键的列类型。</code></p></li><li><p>The index entry in slot 1 indicates that we could find the key value <strong>AAACi</strong> in slot 0x9b on logical page 2.</p><p><code>slot 1 中的索引条目表明，我们可以在逻辑页 2 的 slot 0x9b 处找到键值 AAACi。</code></p></li></ol><p><strong>The Root Node: oncheck -pK Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292201666.png" alt="image-20250529220135558"></p><p><strong>Notes:</strong></p><p>You can use <strong>oncheck -pK</strong> to produce what should now be a fairly readable report on all index nodes in a tblspace. Only the portion of a sample output that relates to the root node is shown above. The output for each node is topped with the following information.</p><p><code>你可以使用 oncheck -pK 命令生成一份如今应相当易读的报告，该报告会展示 tblspace 中所有索引节点的相关信息。上面仅展示了与根节点相关的样本输出片段。每个节点的输出内容开头都会包含以下信息。</code></p><p><strong>Level</strong></p><p>(Decimal) The index level of the node. Index levels begin with 0.</p><p><code>（十进制表示）该节点的索引层级。索引层级从 0 开始。</code></p><p><strong>Node</strong></p><p>(Hex) The node number (logical page number) of the node.</p><p><code>（十六进制表示）该节点的节点编号（逻辑页号）。</code></p><p><strong>Prev</strong></p><p>(Hex) The value of <strong>pg_prev</strong> in the header of this node, which, if it is not 0, is the node number of the adjacent node to the <em>left</em>.</p><p><code>（十六进制表示）该节点头信息中 pg_prev 的值，若此值不为 0，则表示相邻左侧节点的节点编号（逻辑页号）。</code></p><p><strong>Next</strong></p><p>(Hex) The value of <strong>pg_next</strong> in the header of this node, which, if it is not 0, is the node number of the adjacent node to the <em>right</em>.</p><p><code>（十六进制表示）该节点头信息中 pg_next 的值，若此值不为 0，则表示相邻右侧节点的节点编号（逻辑页号）。</code></p><p>After displaying this information, <strong>oncheck</strong> then sets up to display either twig-type entries, or leaf-type entries, in a very generic format. In the slide above, based on the page flags for the node, <strong>oncheck</strong> could sense the node contained twig-type entries. Neither entry is very long or complex, however. The first entry evidently contains the key value <strong>N</strong>, followed by the node number 0x2cd. Notice that the mini-slot is indicated by <strong>oncheck</strong>, and understood to contain no key value.</p><p><code>在显示完这些信息后，oncheck 会接着以一种非常通用的格式准备显示分支类型条目（twig-type entries）或叶子类型条目（leaf-type entries）。在上面的幻灯片中，根据该节点的页标志（page flags），oncheck 能够感知到该节点包含分支类型条目。不过，这两个条目都不算很长或很复杂。第一个条目显然包含键值 N，后面跟着节点编号 0x2cd。请注意，oncheck 指出了 mini-slot 的存在，并理解它不包含任何键值。</code></p><p><strong>The Branch Node: oncheck -pK Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292211708.png" alt="image-20250529221129639"></p><p><strong>Notes:</strong></p><p>More output from the same <strong>oncheck -pK</strong> report is shown above. We can see from the heading information that node 0x2cd is on level 1 of the index, with no sibling to its left, and an adjacent sibling to the right with node number 0x2cc.</p><p><code>上面展示的是同一份 oncheck -pK 报告的更多输出内容。从标题信息中我们可以看出，节点 0x2cd 位于索引的第 1 层，其左侧没有兄弟节点，而右侧有一个相邻的兄弟节点，节点编号为 0x2cc。</code></p><p>The twig-type entries on this level of the index reference multiple nodes for each key, so we can tell our index it contains duplicates.</p><p><code>在该索引层级的分支类型条目（twig-type entries）中，每个键值都对应多个节点的引用，因此我们可以判断出该索引中包含重复键值（即索引包含重复项）。</code></p><p>The first entry on the node points to node 0x1da. From the information here, we can tell that node 0x1da contains one index entry, whose key value is 0, and whose last rowid is 0x498d.</p><p><code>该节点上的第一个条目指向节点 0x1da。根据此处提供的信息，我们可以得知节点 0x1da 包含一个索引条目，该条目的键值为 0，且其最后一个 rowid 为 0x498d。</code></p><p><strong>The Leaf Node: oncheck -pK Output</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292216282.png" alt="image-20250529221632214"></p><p><strong>Notes:</strong></p><p>Yet more output from the <strong>oncheck -pK</strong> report is shown in the slide. The mid-portion of the entry has been removed from this output in order to show the last line, which does, indeed, end with 0x498d, the value promised by the branch node on the previous page.</p><p><code>幻灯片中展示了 oncheck -pK 报告的更多输出内容。为了显示最后一行（该行确实以 0x498d 结尾，这一值正是上一页分支节点所承诺的值），输出内容中删除了条目的中间部分。</code></p><p>Note, too, that node number 0x1d9, the adjacent sibling to the right of this node, is also referred to by the branch node shown on the previous page. Before you look, can you guess where the value 0x1d9 occurs on that branch node?</p><p><code>另外还需注意，节点编号 0x1d9（即该节点右侧的相邻兄弟节点）也在上一页所显示的分支节点中被提及。在你查看之前，能否猜猜看 0x1d9 这个值在该分支节点的哪里出现呢？</code></p><p><strong>Oncheck -pT</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292222440.png" alt="image-20250529222227383"></p><p><strong>Notes:</strong></p><p>The second portion of the extra output generated by <strong>oncheck -pT</strong> concentrates on the indexes. Again, all numbers here are in decimal.</p><p><code>oncheck -pT 命令生成的额外输出内容的第二部分主要聚焦于索引。同样，此处列出的所有数字均为十进制形式。</code></p><p>The first section you see above is for the ALTER TABLE statement. While the alter is going on, a page that has been altered has a later <em>version</em> than a page Informix Dynamic Server has not altered yet.</p><p><code>你上面看到的第一部分内容是关于 ALTER TABLE 语句的。在执行 ALTER 操作的过程中，已被修改的页面的“版本”（version）会比 IDS 尚未修改的页面的版本要新（即版本号更高）。</code></p><p><strong>Level</strong> – Unfortunately, <strong>oncheck -pT</strong> refers to the root level of an index as level 1, instead of level 0 as it is known practically everywhere else. It is not too confusing here, but be sure to avoid thinking the same way or you will make mistakes interpreting other index-related <strong>oncheck</strong> output.</p><p><code>遗憾的是，oncheck -pT 命令将索引的根层级称为第 1 层，而在其他几乎所有地方，根层级都被称为第 0 层。在这里，这种命名方式或许不会造成太大的混淆，但务必注意避免形成这样的思维定式，否则在解读其他与索引相关的 oncheck 输出时，你很可能会犯错误。</code></p><p><strong>Total</strong> – The total number of nodes on this particular level.</p><p><code>这一特定层级上的节点总数。</code></p><p><strong>Average No. Keys</strong> – This column is a bit misleading. Even if your index contains one key value, the <em>Average Number of Keys</em> on each level depends more on the number of rows in the table than the number of keys on that level. To arrive at the number for the leaf level, for instance, <strong>oncheck</strong> divides the total number of rows in the tblspace by the total number of leaf nodes. For non-leaf levels, the total number of node references is divided by the number of nodes on the level.</p><p><code>这一列的数据可能会让人产生误解。即便你的索引中只包含一个键值，但每一层上的“平均键数”（Average Number of Keys）更多地还是取决于表中记录的数量，而非该层上键的实际数量。举例来说，为了得出叶子层（leaf level）的平均 key 数，oncheck 命令会将 tblspace 中的总记录数除以叶子节点的总数。而对于非叶子层（non-leaf levels），则是将该层上的节点引用总数除以该层的节点数。</code></p><p><strong>Average Free Bytes</strong> – This title is accurate. The total number of free bytes in all the nodes on an index level is divided by the number of nodes on that level.</p><p><code>这个标题表述准确。它是将索引某一层级上所有节点中空闲字节（free bytes）的总数，除以该层级的节点数所得出的结果。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 4. Tblspaces</title>
      <link href="/2025/05/18/IX9111/4/"/>
      <url>/2025/05/18/IX9111/4/</url>
      
        <content type="html"><![CDATA[<p><strong>The Physical Elements in a Tblspace</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505181632526.png" alt="image-20250518163231397"></p><p><strong>Notes:</strong></p><p>For the Informix Dynamic Server user who never has a reason to manage a database table below the SQL level, it might be useful to picture a table as simply as a series of data rows. But an IDS administrator must understand tables at the RSAM (Relational Sequential Access Method) level.</p><p><code>对于那些从不需要在 SQL 层面之下管理数据库表的 IDS 用户而言，将表简单地看作是一系列数据行可能就足够了。但是，IDS 管理员必须在 RSAM（关系型顺序访问方法）级别上理解表。</code></p><p>An Informix Dynamic Server database table is actually a logical combination of several physical elements:</p><p><code>IDS 数据库表实际上是多个物理元素的逻辑组合：</code></p><ol><li><p>SQL level: any system catalog data related to the table (none, in the case of temp tables)</p><p><code>与该表相关的任何系统 catalog 数据（对于临时表而言，则没有）。</code></p></li><li><p>RSAM level: one or more partition pages</p><p><code>一个或多个 partition page</code></p></li><li><p>RSAM level: a number of extents</p><p><code>若干 extent</code></p></li></ol><p>A <em>tblspace</em> (or <em>partition</em>) is the logical collection of RSAM-level elements located in a single dbspace. A table can consist of one or more tblspaces, depending on if the table is fragmented.</p><p><code>一个 tblspace（或 partition）是位于单个 dbspace 中的 RSAM 级元素的逻辑集合。一个表可以由一个或多个 tblspace 组成，具体取决于表是否分片。</code></p><p><strong>How do these elements work together?</strong></p><p>An <strong>sqlexec</strong> thread intent on accessing tblspace data must first read the system catalog information related to the table. For each table in a database, there is a corresponding row in <strong>systables</strong>. The row contains information such as the name of the table, various statistics, and a partition number (partnum). </p><p><code>一个打算访问 tblspace 数据的 sqlexec 线程，首先必须读取与该表相关的系统目录（system catalog）信息。对于数据库中的每个表，systables 中都有一条对应的记录。该记录包含表名、各种统计信息以及一个分区号（partnum）等信息。</code></p><p>The partnum describes the location of that table’s partition page. Among other information on that page are the physical locations of each extent in the table. From those addresses, the thread can easily find the tblspace extents.</p><p><code>partnum 描述了该表 partition page 的位置。在该页所包含的其他信息中，还记录了表中每个 extent 的物理位置。通过这些地址，线程就可以轻松地找到 tblspace 的各个 extent。</code></p><p><strong>The Database Tblspace</strong></p><ul><li><p>There is only one database tblspace in the system. It contains information about all databases</p><p><code>系统中只有一个 database tblspace。它包含所有 database 的信息</code></p></li><li><p>The database tblspace partnum is always <strong>0x0100002</strong></p><p><code>database tblspace partnum 始终为 0x100002</code></p></li><li><p>It resides in the root dbspace</p><p><code>它位于 root dbspace</code></p></li><li><p>It can be viewed as a <strong>sysmaster</strong> table called <strong>sysdatabases</strong></p><p><code>可将其视为一个 sysmaster 的表，叫做 sysdatabases</code></p></li></ul><p><strong>Notes:</strong></p><p>In the root dbspace, partition number 0x0100002 is a special tblspace that is used for tracking all the databases created in a database server. This is known as the <em>database</em> <em>tblspace</em>. It can be thought of as a special, internal database table that can grow just like any other table can. A <strong>sysmaster</strong> table called <strong>sysdatabases</strong> allows users to view the contents of this table, but the table cannot be modified.</p><p><code>在 root dbspace 中，partnum 0x0100002 是一个特殊的 tblspace，用于跟踪 server 中创建的所有数据库。这就是 database tblspace。可以将其视为一个特殊的内部数据库表，它可以像其他表一样增长。sysdatabases 表允许用户查看该表的内容，但不能修改该表。</code></p><p>The database tblspace is initially four pages in size, but additional extents can be allocated (as with any tblspace) as the need arises.</p><p><code>数据库表空间（tablespace）初始大小为四页，但随着需求增长，可（如同任意 tblspace 一样）动态分配额外的 extents。</code></p><blockquote><p>arise 英[əˈraɪz] 美[əˈraɪz]<br>vi.发生;出现;(由…)引起;(因…)产生;发展;起床;（随着人走近而）逐渐显现;群起反对;</p></blockquote><p>The database tblspace contains all the information needed to identify any database created in the database server. Each row tracks the name of one database, its owner, the date and time of creation, flags related to its logging mode, and the partition number of <strong>systables</strong>. Once the server has found <strong>systables</strong>, all other tables in the database can be located.</p><p><code>数据库 tblspace 包含识别 server 中创建的任何数据库所需的所有信息。每一行都跟踪一个数据库的名称、所有者、创建日期和时间、与日志模式相关的标志以及 systables 的 partition number。一旦 server 找到 systables，就能找到数据库中的所有其他表。</code></p><p>The schema of the database tblspace includes a unique index on the database name.</p><p><code>database tblspace 的模式（schema）中包含一个基于数据库名称的唯一索引。</code></p><blockquote><p>gemini 2.5 pro</p><ul><li><strong>“模式 (schema)”</strong> 在这里指的就是这个<strong>特殊的系统级表空间（或其内部的系统表）的结构</strong>。这个结构定义了它有哪些列（比如数据库名称、所有者、创建日期等）。</li><li>句子强调了这个结构的一部分：<strong>“包含一个基于数据库名称的唯一索引”</strong>。这意味着在这个系统表空间（或其内部的系统表）的“数据库名称”这一列上，建立了一个唯一索引，以确保每个数据库的名称都是独一无二的。</li></ul></blockquote><p><strong>Tblspace Extent Allocation</strong></p><p>Speaking generally, when a tblspace requires more space, another extent of size NEXT SIZE is allocated. There are, however, three variations on this basic theme:</p><p><code>一般而言，当表空间（tblspace）需要更多空间时，会分配一个大小为 NEXT SIZE 的 extent。不过，这一基本机制存在三种变体情况：</code></p><p>– Extent size doubling</p><p><code>extent size 翻倍</code></p><p>– Extent size compliance – Not enough contiguous space for NEXT SIZE? The database server allocates what it can (but not less than 4 pages).</p><p><code>extent 大小合规性检查 —— 若没有足够连续空间来分配 NEXT SIZE (所指定的 extent)？ server会分配其所能分配的空间量（但不少于 4 页）。</code></p><p>– Extent concatenation</p><p><code>extent 连接</code></p><p><strong>Notes:</strong></p><p>After the first extent allocated to a tblspace fills, the database server attempts to allocate another extent. The amount of space it allocates is normally equal to the size configured for subsequent extents (NEXT SIZE). However, the allocation mechanism is affected by these factors:</p><p><code>在分配给 tblspace 的第一个 extent 填满后，server 会尝试分配另一个 extent。分配的空间大小通常等于为后续 extent 配置的大小（NEXT SIZE）。但是，分配机制会受到这些因素的影响：</code></p><p><strong>•</strong> The number of existing extents</p><p><code>现有 extent 的数量</code></p><p><strong>•</strong> The availability of contiguous space</p><p><code>连续空间的可用性</code></p><p><strong>•</strong> The location of existing TBLspace extents</p><p><code>现有表空间（TBLspace）中extents的位置</code></p><p><strong>Extent size doubling</strong></p><p>When the number of extents within a tblspace becomes large, Informix Dynamic Server attempts to compensate by doubling the value on the partition page. It doubles the next extent size after every 16 extents.</p><p><code>当表空间（tblspace）内的 extents 数量变得庞大时，IDS 会尝试通过在分区页（partition page）上将相关值加倍来进行补偿。具体来说，在每分配完 16 个 extent 之后，它会将下一个 extent 的大小加倍。。</code></p><blockquote><p>compensate 补偿 英[ˈkɒmpenseɪt] 美[ˈkɑːmpenseɪt]</p></blockquote><p><strong>Not enough space for full extent</strong></p><p>If the database server is unable to find the space requested for the extent in the first chunk of the dbspace, it searches the next chunk, and so on. If the server is unable to come up with enough space after searching the chunk free lists for all chunks in the dbspace, it settles for the largest available amount of contiguous space. If this is less than 4 pages, however, the allocation fails with an error indicating there is no free disk space available.</p><p><code>如果 server 在数据库空间（dbspace）的第一个 chunk 中无法找到为该 extent 请求的所需空间，它会继续搜索下一个 chunk，依此类推。如果服务器在遍历数据库空间中所有chunk的 chunk free lists 后，仍无法找到足够大的空间，那么它会选择当前可用的最大连续空间进行分配。然而，如果这个最大连续空间的大小小于 4 页，那么分配操作将失败，并返回一个错误，指示没有可用的空闲磁盘空间。</code></p><blockquote><p>settle<br>英[ˈsetl]<br>美[ˈsetl]<br>v.解决(分歧、纠纷等);定居;（使）沉降，下陷，变得密实;(最终)决定，确定，安排好;结束(争论、争端等);付清（欠款）;（使）平静下来，安静下来，定下心来;殖民;降落;把…放好;使处于舒适的位置;<br>n.高背长椅(老式木家具，有扶手，座下多带柜);</p></blockquote><p><strong>Existing extent locations</strong></p><p>When the database server allocates a new extent that is contiguous to the previously allocated extent, it does not create a new extent. Rather, it extends the size of the last one.</p><p><code>当 server 分配一个与先前已分配 extent 相邻的新 extent 时，它并不会创建一个全新的 extent。相反，它会扩展最后一个 extent 的大小。</code></p><p><strong>Extent Allocation Question</strong></p><p>Suppose a tblspace has 5 extents. What do you think would happen if the next allocated extent were contiguous to the thirdextent? Is this a situation in which extent concatenation can beused?</p><p><code>假设某个表空间（tblspace）已包含5个 extent。若接下来分配的extent与第三个 extent 在物理存储上直接相邻（contiguous），您认为会发生什么？这种场景是否属于可应用 extent concatenation 技术的情况？</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192105922.png" alt="image-20250519210524805"></p><p><strong>Notes:</strong></p><p>Here is an example showing a tblspace with five extents. The server determines that the next extent can be allocated in the pages that immediately follow the third extent.</p><p><code>以下示例展示了一个包含五个 extent 的表空间（tblspace）。server 判定，下一个 extent 可分配在与第三个 extent 物理地址直接相邻的后续存储页中。</code></p><p><strong>Index Tblspaces</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192109867.png" alt="image-20250519210937792"></p><p><strong>Notes:</strong></p><p>Indexes on tables created by users are stored in tblspaces that are separate from their base tables. An index tblspace can be stored in the same dbspace(s) as a data tblspace, or it can be created in a different dbspace. Indexes can also be fragmented into tblspaces located in different dbspaces.</p><p><code>用户创建的表上的索引会存储在与基表相互独立的表空间（tblspace）中。索引表空间（index tblspace）可以与数据表空间（data tblspace）共享同一dbspace，也可以单独创建于其他dbspace。此外，索引还支持跨dbspace分片，即索引的不同部分可分布于多个tblspace（这些表空间可位于不同dbspace内）。</code></p><p>Since indexes are stored in their own tblspaces, they also can be identified by a partition number. To find a partition number for an index, you can either run <strong>oncheck -pT</strong> on the table on which the index was created, or you can query the <strong>sysfragments</strong> database, as shown here:</p><p><code>由于索引存储在独立的表空间（tblspace）中，因此它们也可通过**分区号（partition number）**进行标识。若要查询某个索引的分区号，您可通过以下两种方式实现：对索引所基于的表运行 oncheck -pT 命令 或 查询数据库的系统目录表 sysfragments（具体方法见下文示例）。</code></p><p>​SELECT HEX(partn) FROM sysfragments WHERE indexname &#x3D; “index_name”;</p><p>Index extent sizes are not configurable; the size calculated for the index first and next extent sizes are based on the proportion of the key size in relation to the entire table. Index tblspaces use the same rules for adding extents as data tblspaces.</p><p><code>索引的 extent 大小不可配置；系统为索引计算的首个 extent 和 next extent）的大小，是基于索引键（key）大小与整表数据规模的比例关系动态确定的。索引表空间（index tblspace）在分配新 extent 时，遵循与数据表空间（data tblspace）完全相同的规则。</code></p><blockquote><p>proportion 比例 英[prəˈpɔːʃn] 美[prəˈpɔːrʃn]</p></blockquote><p>Indexes created on system catalog tables are stored in the same tblspace as their base tables. Extents allocated to system catalog tables contain both data and index pages.</p><p><code>在系统目录表（system catalog tables）上创建的索引会存储在与基表相同的表空间（tblspace）中。分配给系统目录表的 extents 会同时包含数据页（data pages）和索引页（index pages），即数据与索引共享同一存储单元。</code></p><p><strong>Bitmap Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192223826.png" alt="image-20250519222314760"></p><p><strong>Notes:</strong></p><p>An Informix Dynamic Server thread searching for a place to insert data within a tblspace uses that table’s <em>bitmap</em> pages to quickly identify a page with sufficient space. Along with inserts, actions that require bitmap searches include:</p><p><code>IDS 一个线程在表空间（tblspace）内搜索可插入数据的位置时，会利用该表的位图页（bitmap pages）快速定位具有足够空间的页。除插入操作外，需要执行位图搜索的其他操作还包括：</code></p><p><strong>•</strong> Updates whose resulting <em>tuple</em> (the internal term for a row) no longer fits into the existing slot.</p><p><code>更新操作导致生成的元组（tuple，即数据库内部对行的术语）无法再存入其原有的 slot。</code></p><p><strong>•</strong> Index operations that allocate new&#x2F;free tblspace pages, such as B-tree splits and index creations.</p><p><code>索引操作中需要分配新页或释放页的场景包括：B树分裂（B-tree splits）以及索引创建（index creations）等。</code></p><p><strong>•</strong> Tblspace usage reports.</p><p><code>Tblspace 使用报告。</code></p><p><strong>•</strong> Index and data checkers (<strong>oncheck</strong>).</p><p><code>索引与数据校验工具（oncheck）</code></p><p><strong>Myth buster</strong></p><p><code>误区澄清者</code></p><p>Every tblspace extent does not begin with a bitmap page. That would be a considerable waste of space, since each bitmap page can describe thousands of pages. So where do second and third bitmap pages appear in a tblspace, if they exist?</p><p><code>并不是每个表空间（tblspace）的 extent 都以一个位图页（bitmap page）开始。那样会造成相当大的空间浪费，因为每个位图页可以描述成千上万个页面。那么，如果存在第二个和第三个位图页，它们会出现在表空间的什么位置呢？</code></p><p><strong>Displaying Data Tblspace Bitmap Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192247198.png" alt="image-20250519224746044"></p><p><strong>Notes:</strong></p><p>You can view the contents of a bitmap page by running <strong>oncheck -pp</strong>. The syntax for this command is:</p><p><code>通过运行 oncheck -pp，可以查看位图页面的内容。该命令的语法为</code></p><p>​oncheck -pp <em>partnum</em> <em>logical_page_num</em></p><p>In every tblspace, logical page 0 is the first bitmap page. For smaller tables, it is probably the only bitmap page. In the case of larger tables, there could be several others. To display the first bitmap page for a particular tblspace, determine the partition number for the table, then run the command:</p><p><code>在每个 tblspace 中，逻辑页 0 是第一个位图页面。对于较小的表，它可能是唯一的位图页面。对于较大的表，可能还有其他几个页。要显示特定 tblspace 的第一个位图页面，请确定表的 partition number，然后运行该命令：</code></p><p>​oncheck -pp <em>partnum</em> 0</p><p>As usual, the first two lines displayed by <strong>oncheck</strong> show the page header. Next, <strong>oncheck</strong>displays one or more rows containing 32 values, each bit value representing one page in the table. The row(s) of 32 values are always complete—padded with several 0 values if necessary—whether the table contains 4 pages or exactly 64.</p><p><code>与往常一样，</code>oncheck<code> 输出的前两行会显示页头（page header）信息。 随后，</code>oncheck<code> 会输出一行或多行，每行包含 32 个位值（bit value），每个位值代表表中的一个页。 无论表包含 4 个页还是恰好 64 个页，这行（或多行）32 个位值始终是完整的——若不足 32 位，则会用若干个 0 值填充补齐。</code></p><p>To the left of each row of bit values is a <em>page offset</em>, akin to the byte offset you have seen in the slot output from <strong>oncheck</strong>. This decimal number indicates which logical page number is represented by the first bit value in the row, as shown here:</p><p><code>在每一行位值（bit value）的左侧，有一个页偏移量（page offset），类似于你在 oncheck 的 slot 输出中见过的字节偏移量（byte offset）。 这个十进制数表示该行中第一个位值所对应的逻辑页号（logical page number），具体示例如下：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192255582.png" alt="image-20250519225526534"></p><p><strong>Displaying Index Tblspace Bitmap Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202219055.png" alt="image-20250520221930894"></p><p><strong>Notes:</strong></p><p>Index tblspaces can contain bitmap pages, index pages, and free pages. Since the same bitmap value (8) is used to indicate both index pages and bitmap pages, the bitmap context is important. Page 0 is always a bitmap page, but all other pages with a bitmap value of 8 are index pages. If the table becomes so large that bitmap entries for index nodes fill the bitmap page, then another bitmap page is created.</p><p><code>索引表空间（index tablespace）可以包含位图页（bitmap pages）、索引页（index pages）和空闲页（free pages）。由于使用相同的位图值（8）来同时表示索引页和位图页，因此位图上下文（即页面所处的具体情境或类别）就显得尤为重要。具体而言，页面0始终是位图页，而所有其他位图值为8的页面则均为索引页。如果表变得非常大，以至于用于索引节点的位图条目填满了当前的位图页，那么就会创建另一个位图页。</code></p><p>To display the bitmap page for an index tblspace, you must first determine the partnum for the index. You can find this by either running <strong>oncheck -pT</strong> on the source table, or by querying the <strong>sysfragments</strong> system catalog.</p><p><code>要显示某个索引表空间（index tblspace）的位图页，首先必须确定该索引的分区号（partnum）。你可以通过在源表上运行 oncheck -pT 命令来查找该分区号，或者通过查询系统目录表 sysfragments 来获取。</code></p><p>The <strong>oncheck -pT</strong> command includes tblspace information for each index created on the table. An example is shown on the next page.</p><p><code>oncheck -pT 命令会包含在表上创建的每个索引的表空间（tblspace）信息。下一页将展示一个示例。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202225828.png" alt="image-20250520222526762"></p><p><strong>Displaying System Catalog Bitmap Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202226010.png" alt="image-20250520222622935"></p><p><strong>Notes:</strong></p><p>Unlike user-defined tables and indexes, each system catalog table and the indexes for the catalog are created in the same tblspace. The example above shows a bitmap page of a <strong>sysindexes</strong> table. Notice that data pages and index pages appear in the same bitmap. Indexes that share the same tblspace as their parent table are said to be <em>attached indexes</em>.</p><p><code>与用户自定义的表和索引不同，每个系统目录表及其对应的索引都是在同一个表空间（tblspace）中创建的。上面的示例展示了 sysindexes 表的一个位图页。请注意，数据页和索引页会出现在同一个位图中。那些与其父表共享同一个表空间的索引被称为附属索引（attached indexes）。</code></p><p>Indexes created by users are, by default, <em>detached</em> from their parent table. That is, they are created in separate tblspaces, as shown in previous examples. However, you can create indexes that are attached by using the IN TABLE option of the CREATE INDEX command.</p><p><code>用户创建的索引在默认情况下是与其父表分离（detached）的，也就是说，它们是在单独的表空间（tblspaces）中创建的，正如之前的示例所示。然而，你可以通过使用 CREATE INDEX 命令的 IN TABLE 选项来创建与父表关联（即附属）的索引。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202230431.png" alt="image-20250520223030371"></p><p><code>IDS 的第 11 版继续支持 DEFAULT_ATTACH 环境变量。当该变量设置为 1 时，所有创建的索引都会成为附属索引（即与父表关联）。不过，该变量在文档中已被标记为“已弃用”，未来版本可能不再支持。</code></p><p><strong>Home Data Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212138685.png" alt="image-20250521213844555"></p><p><strong>Notes:</strong></p><p>Remainder pages and blobpages are types of data pages because they contain portions of rows. But the data in these types of pages is second-tier. Without <em>home rows</em> pointing to them, remainder pieces and blobs would be orphaned. The rowids used by an index refer only to home rows, and never to remainder pieces or blobs.</p><p><code>剩余页（remainder pages）和大对象页（blobpages）均属于数据页类型，因为它们包含行数据的部分内容。不过，这些页面中的数据属于次级（非核心）数据。若没有“主行（home rows）”指向它们，剩余数据片段和大对象数据便会成为“无主（孤儿）”数据，无处可依。索引所使用的 rowid 仅指向主行，而绝不会指向剩余数据片段或大对象数据。</code></p><p>The <em>data</em> pages we have been talking about are known internally as <em>home data pages</em>, in an effort to distinguish between home rows, and the second-tier data to which home rows can refer.</p><p><code>我们一直在讨论的这些数据页在内部被称为主数据页（home data pages），这样做的目的是为了区分主行（home rows）以及主行可能引用的那些次级（第二层级）数据。</code></p><p>这一节莫名其妙，基本不懂</p><p><strong>Rowids</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212145897.png" alt="image-20250521214559846"></p><p><strong>Notes:</strong></p><p>A <em>rowid</em> is a 4-byte code, decipherable only when displayed in hexadecimal notation. The format for a rowid is <strong>0xPPPPPPSS</strong> where the <strong>PPPPPP</strong>, the most significant 3 bytes, contain the logical page number of the row, and the <strong>SS</strong>, the least significant byte, contains the slot number that the row occupies on the page.</p><p><code>rowid 是一个 4 字节的编码，只有在以十六进制格式显示时才能被解读。行标识符的格式为 0xPPPPPPSS，其中 PPPPPP（高 3 字节）表示该行所在的逻辑页号，而 SS（低 1 字节）则表示该行在页中所占用的 slot number。</code></p><p>A home data page consists of a page header, a slot table, and slots containing data rows. To access a specific slot on a specific data page, one must either stumble upon it during a sequential scan, or pass RSAM the correct rowid.</p><p><code>home data page 由页头（page header）、slot table 以及包含数据行的 slots 组成。若要访问特定数据页上的某个特定 slot，要么需在顺序扫描过程中偶然发现它，要么需向随机存储访问方法（RSAM，Random Storage Access Method）传递正确的 rowid。</code></p><blockquote><p>stumble upon 偶然发现 英[ˈstʌmbl əˈpɒn] 美[ˈstʌmbl əˈpɑːn]</p></blockquote><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212153391.png" alt="image-20250521215319325"></p><p><code>上一张幻灯片展示了一个 home data page 的示例。该页是来自一个未命名 tblspace 的逻辑页 3。slot table 中的第 2 个条目指向了一个被高亮显示的 slot。因此，这个 home row 的 rowid 为 0x00000302，简化表示即为 0x302。</code></p><p>别往上找，找不到对应</p><p><strong>The Data Row: Just a Byte Stream</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212209654.png" alt="image-20250521220956573"></p><p><strong>Notes:</strong></p><p>As you have had the opportunity to view Informix Dynamic Server data rows at the binary level, you may have noticed that columns are not aligned on any particular address boundaries. To a C programmer whose assumption is that rows in a tblspace are stored as C structures, this might come as a surprise.</p><p><code>既然你已有机会从二进制层面查看 IDS 的数据行，那么你可能已经注意到，列数据并没有对齐到任何特定的地址边界。对于那些原本假设 tblspace 中的行是以 C 语言结构体形式存储的 C 语言程序员来说，这可能会让他们感到意外。</code></p><p><strong>Structure alignment</strong></p><p>On most computer architectures, the needs of the data bus dictate that an instance of the 11-byte C structure defined in the slide above be stored in memory, as shown on the right. The 1-byte element beginning the structure (<strong>a</strong>) is <em>aligned</em> on an integer boundary, meaning that the memory address of that byte is evenly divisible by 4. The next element (<strong>b</strong>), a 4-byte long integer, must also be aligned on an integer boundary. Therefore, <strong>b</strong> cannot be stored immediately following <strong>c</strong>, and 3 bytes of wasted space separate the two elements. Short integers like the next element must be aligned on short-integer boundaries. Luckily, the address directly following the previous element suffices for <strong>c</strong>. However, the next element (<strong>d</strong>) has to be separated from <strong>c</strong> by 2 bytes, in order to be aligned on an integer boundary. Thus, in this particular case, 16 bytes are used in memory to store 11 bytes of real data.</p><p><code>在大多数计算机架构中，数据总线的需求决定了上一张幻灯片中定义的 11 字节 C 语言结构体实例在内存中的存储方式，就如同右侧所示的那样。结构体中以 1 字节元素开头的部分（a）是按整数边界对齐的，这意味着该字节的内存地址能够被 4 整除。接下来的元素（b）是一个 4 字节的长整型，它也必须按整数边界对齐。因此，b 不能紧跟在 a 之后存储，这两个元素之间需要浪费 3 字节的内存空间。像下一个元素这样的短整型（short integer）必须按短整型边界对齐。幸运的是，上一个元素之后的内存地址刚好满足 c 的对齐要求。然而，下一个元素（d）为了按整数边界对齐，必须与 c 间隔 2 字节。因此，在这个特定例子中，为了存储 11 字节的实际数据，内存中实际使用了 16 字节的空间。</code></p><p><strong>Data row storage</strong></p><p>In most cases, a Dynamic Server data row is not written, stored, or read as a C structure, but as a stream of bytes. Once read, the database server parses the bytes into separate columns based primarily on its knowledge of the schema. This binary method of storage not only saves space, but it puts total control of the data layout in the hands of the engine, making the Dynamic Server source code, and the data itself, more portable.</p><p><code>在大多数情况下，server 的数据行并非以 C 语言结构体的形式进行写入、存储或读取，而是以字节流（stream of bytes）的形式来处理。server 在读取数据后，会主要依据对模式（schema）的了解，将这些字节解析为独立的列。这种二进制存储方式不仅节省了空间，还将数据布局的完全控制权交给了数据库引擎，从而使得 server 的源代码以及数据本身具有更高的可移植性。</code></p><p><strong>VARCHAR Column Storage</strong></p><ul><li><p>Extra byte at beginning that contains data length</p><p><code>在开头有一个额外的字节，用于存储数据长度</code></p></li><li><p>Maximum size: 255 characters (maximum length value is <strong>0xff</strong>)</p><p><code>最大大小：255 个字符（最大长度值为 0xff）</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222154583.png" alt="image-20250522215405444"></p></li></ul><p><strong>Notes:</strong></p><p>VARCHAR storage is easier to understand than it might look. The first rule to remember is that, because the length of the column data is variable, an extra byte is added to the head of the column to store that length. This might explain why the maximum size of a VARCHAR column is 255 characters. The <em>length</em> byte can store a maximum value of 0xFF, or 255. The second rule relates to the minimum size and the padding required when a column contains less than the minimum configured number of characters. Note that the <em>row</em> is padded, not the VARCHAR column.</p><p><code>VARCHAR 类型的存储理解起来可能比看起来要简单。需要记住的第一条规则是，由于列数据的长度是可变的，因此在列的开头会额外添加一个字节来存储该长度。这或许可以解释为什么 VARCHAR 列的最大大小是 255 个字符。这个用于存储长度的字节最大可以存储的值是 0xFF，即 255。第二条规则与最小大小以及当列中包含的字符数少于配置的最小字符数时所需的填充有关。需要注意的是，进行填充的是 row（下段解释），而不是 VARCHAR 列本身。</code></p><p>For example, pictured above are three rows of data from the same table, which consists of an INTEGER column (4 bytes), followed by a VARCHAR column configured with a maximum size of 20 bytes and a minimum of 5 bytes, followed by a SMALLINT column (2 bytes). In the first row, the VARCHAR column contains only 3 characters, reflected in the value of the length byte. The configured minimum is 5, however, so while the column data is compressed together into only 10 bytes, a total slot length of 12 is stored in the slot table, effectively <em>padding</em> the row by simply including whatever 2 bytes happen to be out beyond the data.</p><p><code>例如，上图展示了来自同一张表的三行数据，这张表包含一个 INTEGER 列（占 4 字节），紧接着是一个配置了最大长度为 20 字节、最小长度为 5 字节的 VARCHAR 列，再接着是一个 SMALLINT 列（占 2 字节）。在第一行中，VARCHAR 列仅包含 3 个字符，这一点在长度字节的值中得到了体现。然而，由于配置的最小长度是 5 字节，所以尽管列数据被压缩到了仅 10 字节，但在 slot table 中存储的总 slot 长度却是 12 字节。这实际上是通过简单地包含超出数据部分的任意 2 字节来对行进行“填充”（padding）的。</code></p><p>The data in the padding bytes does not matter because as Informix Dynamic Server reads the row, it can easily tell, based on the length byte preceding each VARCHAR column and the known sizes of all other columns, how many bytes to consider.</p><p><code>填充字节中的数据并不重要，因为当 IDS 读取这行数据时，它能够很容易地根据每个 VARCHAR 列前面的长度字节以及所有其他列的已知大小，判断出需要考虑多少个字节。</code></p><p>Note that no padding is required for row 2 or 3 because, in each case, the number of characters in the VARCHAR column meets or exceeds the configured minimum of 5.</p><p><code>需要注意的是，对于第 2 行或第 3 行数据，并不需要进行填充，因为在每一种情况下，VARCHAR 列中的字符数都达到或超过了所配置的最小长度 5 字节。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222229057.png" alt="image-20250522222905998"></p><p>The bytes added for padding can contain any values. The server knows they do not contain any meaningful information and does not bother to initialize the bytes.</p><p><code>为填充而添加的字节可以包含任何值。服务器知道这些字节不包含任何有意义的信息，因此不会费心去初始化这些字节。</code></p><p><strong>Forward Pointers for VARCHAR Rows</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222250645.png" alt="image-20250522225020556"></p><p><strong>Notes:</strong></p><p>When a row containing a VARCHAR column is updated such that the VARCHAR column grows, as long as the page has room for the row’s expansion, no remainder page or forwarding pointer are needed. However, in the case of a home data page that is almost full, an expanding row is not able to remain intact on the home page.</p><p><code>当包含 VARCHAR 列的一行数据被更新，导致该 VARCHAR 列的内容增长时，只要数据页还有足够的空间容纳这行数据的扩展，就不需要使用剩余页（remainder page）或 forwarding pointer。然而，如果该行数据所在的主数据页（home data page）几乎已满，那么扩展后的行数据就无法完整地保留在主数据页上。</code></p><p>In this case, the <em>entire row</em> moves to a remainder page. All that is left in the original slot on the home data page is a 4-byte forwarding pointer.</p><p><code>在这种情况下，整行数据会移动到一个剩余页（remainder page）上。而在主数据页（home data page）上原来的 slot 中，仅留下一个 4 字节的 forwarding pointer。</code></p><p>Once a row has been forwarded to a remainder page like this, accessing the row of data involves 4 pointers.</p><p><code>一旦一行数据像这样被转发到剩余页（remainder page）上，访问该行数据就需要涉及 4 个指针。</code></p><ol><li><p>The rowid addresses the original slot table entry on the home page.</p><p><code>该 rowid 指向主数据页（home page）上原始 slot table 中的条目。</code></p></li><li><p>The slot table entry points to a forwarding pointer that has replaced the data row on the home page.</p><p><code>该 slot table 条目指向一个 forwarding pointer，这个 forwarding pointer 已经替换了主数据页（home page）上原来的数据行。</code></p></li><li><p>The forwarding pointer is yet another rowid, which points to a slot table entry on the relevant remainder page.</p><p><code>这个 forwarding pointer 实际上是另一个 rowid，它指向相关剩余页（remainder page）上的一个 slot table 条目。</code></p></li><li><p>The slot table entry on the remainder page points to the actual data row.</p><p><code>remainder page 上的 slot table 条目指向实际的数据行。</code></p></li></ol><p>根据之前讲的，前3个字节代表逻辑页号，最后1个字节代表 slot number</p><p>0x603，逻辑页6，第3个slot</p><p>0x701，逻辑页7，第1个slot</p><p>下面解释 8004 的 8</p><p>Note that a slot table entry that points to a slot containing a forwarding pointer is <em>flagged</em>with a special value: 0x8000 (however, the flag value shown for the slot in <strong>oncheck -pp</strong> is 2).</p><p><code>需要注意的是，指向包含 forwarding pointer 的 slot 的 slot table 条目会被标记上一个特殊值：0x8000（然而，在 oncheck -pp 命令中显示该槽的标记值时为 2）。</code></p><p>Also note that a deleted slot is indicated by a 0 length in its slot table entry.</p><p><code>另外还需注意，slot table 条目中若长度为 0，则表示该 slot 已被删除。</code></p><p><strong>Forward Pointers for Large Rows</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232238710.png" alt="image-20250523223814560"></p><p><strong>Notes:</strong></p><p>For rows larger than a page, it is not practical to replace the entire home row with a forwarding pointer. Instead, the first 4 bytes are devoted to the forwarding pointer, followed by as much of the row as can fit on the home page. As usual, the value of the 4-byte forwarding pointer is a rowid that points to the first remainder piece.</p><p><code>对于超过一页大小的行，用 forwarding pointer 完全替换 home row 上的整行数据并不实际。相反，行的前 4 个字节被用作 forwarding pointer，随后紧跟的是能容纳在主页上的尽可能多的行数据。和往常一样，这 4 字节 forwarding pointer 的值是一个 rowid，它指向 first remainder piece。</code></p><blockquote><p>practical 实际的 英[ˈpræktɪkl] 美[ˈpræktɪkl]</p></blockquote><p><strong>Big remainder pages</strong></p><p>If the first remainder piece is too large to fit on an entire remainder page, a second 4-byte forwarding pointer is written on the remainder page, followed by as much of the remainder piece as possible, and so on until the entire row has been stored. This type of remainder page (one entirely taken up by a remainder piece and a forwarding pointer) is called a <em>b</em>i<em>g</em> <em>remainder page</em>.</p><p><code>如果 first remainder piece  太大，无法完整地存放在一个 remainder page 中，那么会在该 remainder page 上写入第二个 4 字节的 forwarding pointer，随后紧跟的是能容纳在该剩余页上的尽可能多的 remainder piece 数据，以此类推，直到整行数据全部存储完毕。这种完全由一个 remainder piece 数据和一个 forwarding pointer 占据的 remainder page 被称为 big remainder page。</code></p><p>Note that the slide above does <em>not</em> show a big remainder page.</p><p><code>请注意，上面展示的幻灯片并未显示一个 big remainder page。</code></p><p>Also note that the slot table entry for this home row is flagged with the value 0x8000 to indicate that the slot size of 0x7e0 includes a forwarding pointer as the first 4 bytes.</p><p><code>另外还需注意，该 home row（即存储行初始部分数据的页）对应的 slot table 条目会被标记上值 0x8000，以此表明该 slot size 为 0x7e0，且其前 4 个字节包含一个 forwarding pointer。</code></p><p><strong>Home Page With BLOB Descriptor</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232310878.png" alt="image-20250523231039798"></p><p><strong>Notes:</strong></p><p>Informix Dynamic Server supports two different kinds of large objects: <em>simple large objects</em>(<em>blobs</em>) and <em>smart large objects</em> (<em>smart LOs</em>, or <em>smart blobs</em>). Only simple large objects can be stored in partition pages.</p><p><code>IDS 支持两种不同类型的大对象：简单大对象（simple large objects，简称 blobs） 和 智能大对象（smart large objects，简称 smart LOs 或 smart blobs）。只有简单大对象可以存储在 partition page 中。</code></p><p>The data in a blob column is never stored on home data pages with non-blob column data. Blobs are either segregated into different chunks, as when they are configured to reside in a blobspace, or forwarded to special <em>partition blobpages</em> within the tblspace (the default configuration). But because of the complexity of blob management, a lone 4-byte forwarding pointer on the home page describing only the blob’s location does not suffice. Instead, a 56-byte <em>descriptor</em> is stored on the home page in place of the blob data. Even a home row that has a NULL value in its blob column contains an entire 56-byte blob descriptor, albeit a dull one.</p><p><code>BLOB（二进制大对象）列中的数据绝不会与非 BLOB 列的数据一起存储在 home data page 上。BLOB 数据要么被分隔到不同的 chunk 中（例如，当配置为位于blobspace 中时），要么被 forward 到表空间（tblspace，此为默认配置）内的特殊 partition blobpages 中。然而，由于 BLOB 管理的复杂性，仅在主页（home page）上放置一个孤零零的 4 字节 forwarding pointer 来描述 BLOB 的位置是不够的。相反，主页上会存储一个 56 字节的描述符（descriptor）来替代 BLOB 数据。即便某个主页行（home row）的 BLOB 列值为 NULL，它仍然会包含一个完整的 56 字节 BLOB 描述符，只不过这个描述符的内容是“无意义”的。</code></p><p><strong>Partition blob</strong> </p><p>Partition blobpages differ from blobspace blobpages in several important ways. Partition blobpages are more like other Dynamic Server pages; they are the same size (BUFFSIZE), whereas the blobspace blobpage size can be configured to any multiple of BUFFSIZE. Partition blobpages are modified in the shared memory buffer pool; blobspace blobpages are not. Partition blobpages are written to logical logs with their corresponding data row. Blobspace blobpages are not logged.</p><p><code>partition blobpages 与 BLOB 空间 BLOB 页（blobspace blobpages）在几个重要方面存在差异。Partition blobpages 更类似于其他 Dynamic Server 页；它们大小相同（均为 BUFFSIZE），而 BLOB 空间 BLOB 页的大小可以配置为 BUFFSIZE 的任意整数倍。Partition blobpages 在共享内存缓冲池中进行修改；而 BLOB 空间 BLOB 页则不会在此处修改。Partition blobpages 会与其对应的数据行一同写入逻辑日志；而 BLOB 空间 BLOB 页则不会被记录到日志中。</code></p><p><strong>BLOB Descriptor Structure</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232331704.png" alt="image-20250523233146617"></p><p><strong>Notes:</strong></p><p>On the slide above is the layout of the 56-byte blob descriptor. This structure is not only stored on home data pages, but is used throughout the database server for various blob-related reading, writing, and manipulating activities. As a result, there are several elements included in the structure that store fascinating data for fleeting moments, but do not contain anything of interest when the blob descriptor is at rest, as it is on disk.</p><p><code>上面幻灯片展示的是 56 字节 BLOB 描述符的布局结构。这种结构不仅存储在主数据页（home data pages）上，还在整个数据库服务器中用于各种与 BLOB 相关的读取、写入和操作活动。因此，这个结构体中包含若干元素——它们在某些瞬间可能存储着极具价值的数据，但当描述符处于静止状态（如存储在磁盘上时），这些元素就不再包含任何有意义的信息。</code></p><p>The two-byte <strong>flags</strong> element of the descriptor structure contains any <em>one</em> of the following flag values:</p><p><code>描述符结构中的两字节 flags 元素包含以下任意一个标志值：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232337332.png" alt="image-20250523233748283"></p><p>In an upcoming exercise, you will use the <strong>oncheck -pD</strong> command to view and analyze the blob descriptor.</p><p><code>在接下来的练习中，你将使用 oncheck -pD 命令来查看和分析 blob descriptor。</code></p><p><strong>Partition Blobpages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505242215041.png" alt="image-20250524221525914"></p><p><strong>Notes:</strong></p><p>A partition blob consists of one or more blob <em>pieces</em>. Blob data that is too large to fit on one partition blobpage is split into several blob pieces chained together with forwarding pointers. Like a chain of remainder pieces for a very large row, all but the last blob piece in a chain is given its own blobpage so that the fewest possible number of pages are involved.</p><p><code>partition blob 由一个或多个 blob piece 组成。若大对象数据过大，无法容纳于单个partition blobpage 中，则会将其拆分为多个blob piece，并通过forwarding pointers将这些 piece 串联起来。这就好比针对超大行数据所形成的 a chain of remainder pieces，除链中的最后一个 blob piece 外，其余所有 blob piece 都会分配各自独立的 blobpage，以确保涉及的 blobpage 数量尽可能少。</code></p><p>Above is a partition blobpage that contains two blob pieces. By definition, each of these blob pieces must be from a different blob.</p><p><code>上图展示的是一个包含两个 blob piece 的 partition blobpage。根据定义，这两个 blob piece 必定来自不同的 blob。</code></p><p>A blob piece consists of the blob data itself, preceded by 8 bytes of overhead related to forwarding.</p><p><code>一个 blob piece 由 blob 数据本身以及其前面与 forwarding 相关的 8 字节开销（overhead）组成。</code></p><p><strong>bstamp (2 bytes)</strong></p><p>The blobstamp occupies the first two bytes of a blob piece. Blobstamps help Dynamic Server verify the consistency of a chain of blob pieces, which could involve hundreds of pages. Note that the blobstamp does not have to be the same value for all pieces in the chain.</p><p><code>大对象时间戳（blobstamp）占据一个大对象片段（blob piece）的前两个字节。大对象时间戳有助于 Dynamic Server 验证由数百个页可能构成的大对象片段链的一致性。需要注意的是，该链中所有片段的大对象时间戳的值并不一定相同。</code></p><p>A stamp for a particular blob piece simply has to match what was expected by the previous piece (or the descriptor itself, in the case of the first piece). Otherwise, expect this ISAM error:</p><p><code>某个特定大对象片段（blob piece）的时间戳只需与前一个片段（或对于第一个片段而言，是与描述符本身）所预期的时间戳相匹配即可。否则，将会遇到以下 ISAM 错误：</code></p><p>​-164 ISAM error: TEXT or BYTE stamp is incorrect.</p><p><strong>Next blobpage (4 bytes)</strong></p><p>This element looks and functions exactly like the forwarding pointers you have already studied. It contains the rowid of the next blob piece in the chain, if one exists. The last blob piece in the chain has a <em>next blobpage</em> value of 0xffffffff.</p><p><code>这个元素无论是看起来还是功能上都与你之前研究过的 forwarding pointers 完全一致。如果链中存在下一个大对象片段（blob piece），它会包含该片段的 rowid。而链中的最后一个大对象片段，其 next blobpage 的值会被设置为 0xffffffff，以此表示链的结束。</code></p><p><strong>nbstamp (2 bytes)</strong></p><p>This is the expected blobstamp for the next blob piece in the chain.</p><p><code>这是链中下一个大对象片段（blob piece）所预期的大对象时间戳（blobstamp）。</code></p><p><strong>oncheck -pT</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505242245718.png" alt="image-20250524224520621"></p><p><strong>Notes:</strong></p><p>The output from <strong>oncheck -pT</strong> is a super-set of the output from <strong>oncheck -pt</strong>. Information from the partition structure and the extent slot is displayed first, followed by quite a bit of useful information on the complexion of the tblspace, all of which is in decimal.</p><p><code>oncheck -pT 命令的输出是 oncheck -pt 命令输出的超集。它会首先显示 partition structure 和 extent slot 的相关信息，随后会提供大量关于表空间（tblspace）状况的有用信息，所有这些信息均以十进制格式呈现。</code></p><p>The first portion of this extra output for a sample table is shown in the slide above. It is a general usage report for the tblspace that tallies up the number of free pages, bitmap pages, index pages, home data pages, remainder pages and partition blobpages. (This sample table contains both VARCHARS and partition-resident blobs.) The 4-bit bitmap page is used to determine the relative fullness of the remainder pages and partition blobpages.</p><p><code>上述幻灯片中展示了针对一个示例table，这部分额外输出的第一部分内容。它是一份关于表空间（tblspace）的通用使用情况报告，其中汇总了 free pages、bitmap pages、index pages、home data pages、remainder pages 以及 partition blobpages 的数量。（这个示例表中同时包含了 VARCHARS and partition-resident blobs）这里提到的 4-bit bitmap page 用于确定 remainder pages and partition blobpages 的相对填充程度。</code></p><p>The total number of unused bytes on each data-related page type is tallied next.</p><p><code>接下来会对每种与数据相关的页类型上未使用的字节总数进行汇总。</code></p><p>If a table seems to be performing poorly, or using more space than one would expect, this report can be enlightening. For example, if <strong>oncheck -pT</strong> clearly shows that the table is using space inefficiently, a review of the schema might reveal that the row size is just 20 bytes more than the amount of unused space on every full data page, and that a 4 byte reduction in the row size would compact the table by 15%. It has happened.</p><p><code>如果某个表看起来性能不佳，或者占用的空间超出了预期，那么这份报告可能会提供有价值的见解。例如，如果 oncheck -pT 报告清晰地显示出该表的空间使用效率低下，那么对表schema的审查可能会揭示出，row size 仅比每个满数据页上未使用的空间多出 20 字节，而如果将行大小减少 4 字节，就可以使表的占用空间减少 15%。这种情况确实发生过。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 3. Dbspace Layout</title>
      <link href="/2025/05/09/IX9111/3/"/>
      <url>/2025/05/09/IX9111/3/</url>
      
        <content type="html"><![CDATA[<p><strong>A Hypothetical Root Dbspace</strong></p><p>一个假想的root dbspace</p><blockquote><p>hypothetical<br>英[ˌhaɪpəˈθetɪkl]  美[ˌhaɪpəˈθetɪkl]<br>adj.（基于）假设的，假定的;有待证实的;</p></blockquote><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505092150641.png" alt="image-20250509215037499"></p><p><strong>Notes:</strong></p><p>The root dbspace is an Informix database server’s first and most critical dbspace. It contains the system’s first chunk, the <em>root chunk</em>. As with other dbspaces, additional chunks can be added over time. Since the root dbspace as a whole can never be dropped, the initial chunk for the root dbspace should be configured wisely.</p><p><code>root dbspace是 IDS 的第一个也是最关键的数据库空间。它包含系统的第一个数据块，即 root chunk。与其他数据库空间一样，随着时间的推移还可以添加其他块。由于根数据库空间作为一个整体永远不会被删除，因此应明智地配置根数据库空间的初始块。</code></p><blockquote><p>wisely<br>英[ˈwaɪzli] 美[ˈwaɪzli]<br>adv.明智地;</p></blockquote><p>You normally do not keep databases in the root dbspace. Data should be spread across multiple disks, and to do that you should create multiple dbspaces and assign tables to specific dbspaces (or fragment a table across dbspaces).</p><p><code>通常情况下，不会在root dbspace中保存数据库。数据应分布在多个磁盘上，为此应创建多个dbspace，并将表分配到特定的dbspace（或将表分片到不同的dbspace）。</code></p><p>Initially, the physical log and at least three logical logs are located in the root dbspace. During the tuning phase, these are normally recreated in other dbspaces to take advantage of additional disk drives.</p><p><code>最初，物理日志和至少三个逻辑日志位于root dbspace。在调整阶段，通常会在其他dbspace重新创建这些日志，以利用额外的磁盘驱动器。</code></p><blockquote><p>tuning<br>英[ˈtjuːnɪŋ]美[ˈtuːnɪŋ]<br>v.(给收音机、电视等)调谐，调频道;调整，调节(发动机);(为乐器)调音，校音;<br>n.【无线】调谐；收听；【乐】调音[弦];</p></blockquote><p><strong>Layout of a Root Chunk</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505092202432.png" alt="image-20250509220256358"></p><p><strong>Notes:</strong></p><p>After a complete disk initialization and before a system is tuned, the layout of the root chunk looks similar to the one pictured above.</p><p><code>在完成磁盘初始化后和系统调整前，root chunk的布局与上图类似。</code></p><p><strong>Reserved pages</strong></p><p>The first twelve pages of the initial chunk in the root dbspace are the system <em>reserved</em> <em>pages</em>, which are used for system-tracking information and are updated during each checkpoint. Beginning with the third reserved page, the pages are organized into semi-redundant pairs, each of which stores a distinct type of structure, with the pages in each pair taking turns as the more current version.</p><p><code>root dbspace中初始块的前十二页是系统保留页，用于系统跟踪信息，并在每次检查点时更新。从第三个保留页面开始，页面被组织成半冗余对，每个对存储一种不同类型的结构，每个对中的页面轮流作为最新版本。</code></p><blockquote><p>semi<br>英[ˈsemi]  美[ˈsemi]<br>n. 半决赛;半独立式住宅;</p><p>redundant<br>英[rɪˈdʌndənt]  美[rɪˈdʌndənt]<br>adj.冗余的;多余的;不需要的;被裁减的;</p></blockquote><p><strong>Chunk free list</strong></p><p>In every chunk, the page following the reserved pages is a chunk free-list page. A chunk free-list page contains information about free extents (groups of contiguous free pages) in the chunk.</p><p><code>在每个chunk中，保留页之后的页面是chunk free list page。chunk free list page包含分chunk中空闲extents（由连续空闲页组成）的信息。</code></p><p><strong>Tblspace tblspace</strong></p><p>A tblspace tblspace is a collection of pages that describes the location and structure of all tblspaces in a particular dbspace. Most pages in the tblspace tblspace have the same format and contain the following major components:</p><p><code>tblspace tblspace 是描述特定 dbspace 中所有 tblspace 的位置和结构的页面集合。tblspace tblspace 中的大多数页面格式相同，并包含以下主要组件：</code></p><p><strong>•</strong> The number and location of extents</p><p><code>extent的数量和位置</code></p><p><strong>•</strong> Information about special columns (large objects and VARCHAR data)</p><p><code>有关特殊列（大对象和 VARCHAR 数据）的信息</code></p><p><strong>•</strong> An array of index key information</p><p><code>索引键信息数组</code></p><p><strong>•</strong> The database and table name</p><p><code>数据库和表名</code></p><p>You can find out where the tblspace tblspace extents are located by running <strong>oncheck -pe</strong> and looking for <strong>dbspace_name:’informix’.TBLSpace</strong>.</p><p><code>运行oncheck -pe并查找dbspace_name:&#39;gbasedbt&#39;.TBLSpace，即可找出 tblspace tblspace extents 的位置。</code></p><p>实测，oncheck -pe出来一大堆信息，看不懂，截选部分，rootdbs:’gbasedbt’.TBLSpace 有好几个，下边还有。再下边还有其他dbspace的信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">DBspace Usage Report: rootdbs             Owner: gbasedbt  Created: 04/17/2025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Chunk Pathname                             Pagesize(k)  Size(p)  Used(p)  Free(p)</span><br><span class="line">     1 /opt/gbase/storage/rootdbs                     2    78848    13748    65100</span><br><span class="line"></span><br><span class="line"> Description                                                   Offset(p)  Size(p)</span><br><span class="line"> ------------------------------------------------------------- -------- --------</span><br><span class="line"> RESERVED PAGES                                                       0       12</span><br><span class="line"> CHUNK FREELIST PAGE                                                 12        1</span><br><span class="line"> rootdbs:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                         13      250</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.ix_ph_run_03                                   263        4</span><br><span class="line"> tmpsbspace:<span class="string">&#x27;gbasedbt&#x27;</span>.tmpsbspace_desc                              267        4</span><br><span class="line"> RESERVED PAGES                                                     271        2</span><br><span class="line"> RESERVED PAGES                                                     273        2</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.command_history                                275        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.ix_cmd_hist_02                                 283        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_iohist                                     287        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_config                                     295        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage                                 303        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix1                             311        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix2                             315        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix1                             319        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage                                 323        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix2                             331        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_users                                      335        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_table_profile                              343       16</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_checkpoint                                 359        8</span><br><span class="line"> rootdbs:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                        367      200</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.idx_mon_ckpt_1                                 567        4</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>Database tblspace</strong></p><p>The database tblspace is a list of all databases in the Informix Dynamic Server system, and includes the following components:</p><p><code>database tblspace 是 IDS 系统中所有数据库的列表，包括以下组件：</code></p><p><strong>•</strong> Database name</p><p><code>数据库名</code></p><p><strong>•</strong> Database owner</p><p><code>数据库所有者</code></p><p><strong>•</strong> Date and time the database was created</p><p><code>创建数据库的日期和时间</code></p><p><strong>•</strong> The partition number of the <strong>systables</strong> system catalog table for this database</p><p><code>该数据库的 systables 系统表的 partition number</code></p><p><strong>•</strong> Flags that show the logging mode for the database</p><p><code>显示数据库日志记录模式的标志</code></p><p>To find out where the database tblspace is physically located on your server, use the <strong>oncheck -pe</strong> command to generate an extent report and look for the extents allocated to <strong>sysmaster:’informix’.sysdatabases</strong>.</p><p><code>要找出数据库 tblspace 在服务器上的物理位置，请使用 oncheck -pe 命令生成一份扩展报告，并查找分配给 sysmaster:&#39;gbasedbt&#39;.sysdatabases 的extents。</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysmaster:<span class="string">&#x27;gbasedbt&#x27;</span>.sysdatabases                                27447        4</span><br></pre></td></tr></table></figure><p>紫本180页：</p><p>6.4.2.2 tablespace</p><blockquote><p>​tablespace 是一个逻辑概念，指一个表或者索引所占用的空间。GBase 8t 用 tablespace 来描述一个表或者索引信息。一个 tablespace 是多个 extent 的逻辑集合，可以分布在不同的 dbspace 或者 chunk 上。在 GBase 8t 系统表中对表、索引采用 tablespace 进行描述。</p><p>​GBase 8t把分片表、索引的一个分片作为一个tablespace进行管理。每个表、索引在GBase8t 内部都有一个 partnum，在 GBase 8t 内部以该编号进行管理。例如在一个 GBase 8t 实例下有一个 database tblspace，包含所有的数据库 databases 的信息。database tblspace 的 partnum永远是 x00100002，位于 root dbspaces 上，也就是 sysmaster 数据中的 sysdatabases 表。</p><p>​我们可以通过查询 sysmaster 的 systabnames 表得到一个数据库实例下的所有表、索引的 tblspace 信息。</p></blockquote><p>所以，database tblspace有系统表对应sysdatabases，而Tblspace tblspace看着应该是同样有个系统表，叫做Tblspace（描述特定 dbspace 中所有 tblspace），但又不知道在哪</p><p><a href="https://www.ibm.com/support/pages/what-tblspace-tblspace">What is TBLspace TBLspace?</a></p><p>这篇文章提到：You are running IBM® Informix® Dynamic Server (IDS) database server and create a regular Dbspace. This Dbspace contains an internal table called TBLspace TBLspace. You cannot access the table using SQL commands.</p><p>所以，有个内部表叫做TBLspace TBLspace，无法用SQL访问</p><p>deepseek：</p><ul><li>它是Informix内核管理的<strong>元数据表</strong>（metadata table）</li><li><strong>不开放SQL访问</strong>（如文档所述：*”You cannot access the table using SQL commands”*）</li><li>仅通过底层存储引擎直接管理</li></ul><p><strong>Layout of a Non-Root Chunk</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505101345909.png" alt="image-20250510134500787"></p><p><strong>Notes:</strong></p><p>The above slide shows the layout of all other chunks in the system except the root chunk. There are two slightly different types: those that are the first chunks in their respective dbspaces, and those that are subsequent to the first chunk.</p><p><code>上面的幻灯片显示了系统中除root chunk之外的所有其他chunk的布局。有两种略有不同的类型：一种是各自dbspace中的第一个chunk，另一种是第一个chunk之后的chunk。</code></p><p>第一个chunk就是后边提到的所谓<strong>Primary Chunk</strong></p><p><strong>Reserved pages</strong></p><p>The first two pages of any non-root chunk are reserved for nothing. They are not even initialized with a page header. The early Informix Dynamic Server designers thought they might need them someday, but so far, the most sensible suggested uses have been for <em>binary graffiti</em> and <em>credits</em>.</p><p><code>在任何非根区块（non-root chunk）中，前两页是保留不用的。它们甚至没有被初始化为页面头（page header）。早期的 IDS 设计者认为将来可能会用到它们，但到目前为止，最合理的建议用途是用于“二进制涂鸦”（binary graffiti）和“致谢名单”（credits）。</code></p><p><strong>Chunk free list</strong></p><p>In every chunk, the page following the reserved pages is a chunk free-list page.</p><p><code>在每个chunk中，紧跟在保留页之后的那一页是chunk的空闲页列表页（chunk free-list page）。</code></p><p><strong>Tblspace tblspace</strong></p><p>Every dbspace contains a tblspace tblspace, also called a partition table. The first extent of the tblspace tblspace is always allocated in the first chunk of the dbspace. Like any other tblspace, when additional extents are required, they are allocated wherever there is room in the dbspace.</p><p><code>每个 dbspace 都包含一个 tblspace tblspace，也称为分区表(partition table)。tblspace tblspace 的第一个 extent 总是分配在 dbspace 的第一个chunk中。与其他 tblspace 一样，当需要额外的扩展时，它们会被分配到 dbspace 中有空间的地方。</code></p><p>The initial and subsequent extent size for the partition table in non-root dbspaces is 50 pages.</p><p><code>非root dbspace中分区表（partition table）的初始和后续extent大小为 50 页。</code></p><p><strong>Overview of Root Reserved Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505101359231.png" alt="image-20250510135946163"></p><p><strong>Notes:</strong></p><p>The first 12 pages of the root chunk are reserved for system information. Starting with page 2, the pages are grouped in pairs and are alternately updated.</p><p><code>root chunk的前 12 页保留给系统信息。从第 2 页开始，页面成对分组，交替更新。</code></p><p><strong>Page zero</strong></p><p>Page 0 contains the Informix copyright and version information, the minimum page size, and the date and time of the system’s creation.</p><p><code>第 0 页包含 Informix 版权和版本信息、最小页面大小以及系统创建的日期和时间。</code></p><p><strong>Configuration page</strong></p><p>Page 1 contains a copy of all the information stored in the system’s configuration file (<strong>$INFORMIXDIR&#x2F;etc&#x2F;$ONCONFIG</strong>) at the time the server was last brought online.</p><p><code>第 1 页包含服务器上次联机时存储在系统配置文件（$INFORMIXDIR/etc/$ONCONFIG）中的所有信息的副本。</code></p><p><strong>Checkpoint&#x2F;logical log pages</strong></p><p>Page 2 and page 3 are the checkpoint&#x2F;logical log pages. The current checkpoint&#x2F;logical log page gives the location, date and time of the last checkpoint, and the location and current status of each of the logical logs.</p><p><code>第 2 页和第 3 页是检查点/逻辑日志页面。当前检查点/逻辑日志页面显示上次检查点的位置、日期和时间，以及每个逻辑日志的位置和当前状态。</code></p><p><strong>Dbspace pages</strong></p><p>Page 4 and page 5 are the dbspace pages. Each entry on the current dbspace page tracks the status, location, data, and creation time of a dbspace.</p><p><code>第 4 页和第 5 页是 dbspace 页面。当前dbspace页面的每个条目都会跟踪 dbspace 的状态、位置、数据和创建时间。</code></p><p><strong>Primary chunk pages</strong></p><p>Pages 6 and 7 are the reserved pages that contain information about each of the primary chunks on the server. For each chunk, the current primary-chunk page contains information about the pathname, size, offset, and status of the chunk.</p><p><code>第 6 页和第 7 页是保留页，包含server上每个primary chunk的信息。对于每个chunk，当前的primary chunk page包含该chunk的路径名、大小、偏移量和状态信息。</code></p><p><strong>Mirror chunk pages</strong></p><p>Pages 8 and 9 are the mirror chunk pages. The structure of these pages are the same as the primary chunk pages</p><p><code>第 8 页和第 9 页是mirror chunk页面。这些页面的结构与primary chunk pages相同</code></p><p><strong>Archive pages</strong></p><p>Pages 10 and 11 (0xa and 0xb) are the archive pages. These pages contains information on the most recent archives performed on the server.</p><p><code>第 10 页和第 11 页（0xa 和 0xb）是存档页面。这些页面包含在服务器上进行的最新存档信息。</code></p><p><strong>The Copyright Page</strong></p><p>oncheck -pr，下边还有很多内容，与本节无关，不贴出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Validating GBase Database Server reserved pages</span><br><span class="line"></span><br><span class="line">    Validating PAGE_PZERO...</span><br><span class="line"></span><br><span class="line">    Identity                       GBase Database Server Co</span><br><span class="line">                                   pyright 2001, 2021  Gene</span><br><span class="line">                                   ral Data Corporation</span><br><span class="line">    Database system state          0</span><br><span class="line">    Database system flags          0x3</span><br><span class="line">    Page Size                      2048 (b)</span><br><span class="line">    Date/Time created              04/17/2025 08:44:48</span><br><span class="line">    Version number of creator      32</span><br><span class="line">    Last modified time stamp       0</span><br><span class="line">    UID of rootdbs creator         1001</span><br><span class="line">    Index Page Logging             OFF</span><br><span class="line">    HA Disk Owner                  &lt;null&gt;</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The slide above shows a sample <strong>oncheck -pr</strong> output for the copyright page. </p><p><code>上面的幻灯片展示了版权页的oncheck -pr输出示例。</code></p><p>One important use of this page is the identification of the version of the Informix Dynamic Server system. The current version is listed here under <strong>Version number of creator</strong>. If the version number is earlier than the <strong>oninit</strong> version, the database server performs any upgrade steps required to move the Informix Dynamic Server system to the new version. </p><p><code>本页的一个重要用途是识别 IDS 系统的版本。当前版本列于此处的 Version number of creator 下。如果版本号早于 oninit 版本， database server 将执行所有必要的升级步骤，以将 Informix Dynamic Server 系统迁移到新版本。</code></p><p>Upgrading the server is not always required; it is only necessary when the disk architecture or the structure of tables in <strong>sysmaster</strong> or <strong>sysutils</strong> has changed.</p><p><code>并不总是需要升级 server；只有在磁盘架构或 sysmaster 或 sysutils 中的表格结构发生变化时才需要升级。</code></p><p><strong>Hint</strong></p><p>Run the command:</p><p>​oncheck -pP 1 0</p><p>and compare that output to the report generated by <strong>oncheck -pr</strong>.</p><p>1001 -&gt; 3e9    20 - &gt; 32</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@frh gbase]<span class="comment"># oncheck -pP 1 0</span></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:0              157435   66f8   3      1800 ROOTRSV      304   1728  0        0</span><br><span class="line">        slot ptr   len   flg</span><br><span class="line">        1    24    252   0</span><br><span class="line">        3    276   28    0</span><br><span class="line">slot   1:</span><br><span class="line">    0: 47 42 61 73 65 20 44 61 74 61 62 61 73 65 20 53   GBase Database S</span><br><span class="line">   16: 65 72 76 65 72 20 43 6f 70 79 72 69 67 68 74 20   erver Copyright</span><br><span class="line">   32: 32 30 30 31 2c 20 32 30 32 31 20 20 47 65 6e 65   2001, 2021  Gene</span><br><span class="line">   48: 72 61 6c 20 44 61 74 61 20 43 6f 72 70 6f 72 61   ral Data Corpora</span><br><span class="line">   64: 74 69 6f 6e  0  0  0  0  0  0  0  0  0  0  0  0   tion............</span><br><span class="line">   80:  0  0  3  0  0  8  0  0 f0 21  1 68 20  0  0  0   ........p!.h ...</span><br><span class="line">   96:  0  0  0  0 e9  3  0  0 31 32 31 34  1  0  0  0   ....i...1214....</span><br><span class="line">  112:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  128:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  144:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  160:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  176:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  192:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  208:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  224:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  240:  0  0  0  0  0  0  0  0  0  0  0  0               ................</span><br><span class="line">slot   3:</span><br><span class="line">    0:  3  0 10  0 3b 6b  0  0  1  0  0  0  0  0  0  0   ....;k..........</span><br><span class="line">   16:  c 46 22 30 34 2d 32 30 32 35  0  0               .F<span class="string">&quot;04-2025......</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><p><strong>The Configuration Page</strong></p><p>oncheck -pr截取</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    Validating PAGE_CONFIG...</span><br><span class="line"></span><br><span class="line">    ROOTNAME                       rootdbs</span><br><span class="line">    ROOTPATH                       /opt/gbase/storage/rootdbs</span><br><span class="line">    ROOTOFFSET                     0 (k)</span><br><span class="line">    ROOTSIZE                       157696 (k)</span><br><span class="line">    MIRROR                         0</span><br><span class="line">    MIRRORPATH                     /opt/gbase/tmp/demo_on.root_mirror</span><br><span class="line">    MIRROROFFSET                   0 (k)</span><br><span class="line">    DBSERVERNAME                   ol_gbasedbt1210_1</span><br><span class="line">    SERVERNUM                      0</span><br><span class="line">    MSGPATH                        /opt/gbase/ol_gbasedbt1210_1.<span class="built_in">log</span></span><br><span class="line">    TAPEDEV                        /dev/tapedev</span><br><span class="line">    TAPESIZE                       0 (k)</span><br><span class="line">    TAPEBLK                        32 (k)</span><br><span class="line">    LTAPEDEV                       /dev/null</span><br><span class="line">    LTAPESIZE                      0 (k)</span><br><span class="line">    LTAPEBLK                       32 (k)</span><br><span class="line">    PHYSFILE                       71972 (k)</span><br><span class="line">    PHYSBUFF                       512 (k)</span><br><span class="line">    LOGFILES                       19</span><br><span class="line">    LOGSIZE                        6144 (k)</span><br><span class="line">    LOGBUFF                        256 (k)</span><br><span class="line">    DYNAMIC_LOGS                   2</span><br><span class="line">    LTXHWM                         70 (%)</span><br><span class="line">    LTXEHWM                        80 (%)</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The configuration page contains values for all <em>documented</em> parameters in the configuration file ($ONCONFIG). In other words, it is not simply a copy of whatever happens to be in the configuration file; adding additional parameters to the configuration file does not add anything new to the configuration page.</p><p><code>configuration page 包含配置文件 ($ONCONFIG) 中所有已记录参数的值。换句话说，它并非配置文件中内容的简单复制；在配置文件中添加其他参数并不会给 configuration page 添加任何新内容。</code></p><p><strong>Seen and unseen</strong></p><p>The <strong>oncheck -pr</strong> output above shows an example of the contents of the configuration page. Note that on some platforms, many legitimate parameters in the configuration file do not show up in this report, such as NUMCPUVPS, STACKSIZE, and SHMTOTAL.</p><p><code>上面的 oncheck -pr 输出显示了 configuration page 内容的示例。请注意，在某些平台上，configuration page 中的许多合法参数不会显示在此报告中，例如 NUMCPUVPS、STACKSIZE 和 SHMTOTAL。</code></p><blockquote><p>legitimate 合法的 英[lɪˈdʒɪtɪmət]美[lɪˈdʒɪtɪmət]</p></blockquote><p>The <strong>onstat -c</strong> command does not use the information from these pages. This command reads the configuration file instead of the reserved page.</p><p><code>onstat -c 命令不使用这些页面中的信息。此命令读取配置文件，而不是保留页。</code></p><p><strong>Hint</strong></p><p>Run the command:</p><p>​oncheck -pP 1 1</p><p>and compare that output to the report generated by <strong>oncheck -pr</strong>. Notice that <strong>oncheck -pP</strong>, being a more general page-displaying tool, reveals parameters on the configuration page not displayed by <strong>oncheck -pr</strong>.</p><p><code>请注意，oncheck -pP 是一个更通用的页面显示工具，它会显示 oncheck -pr 未显示的配置页面上的参数。</code></p><blockquote><p>reveals<br>英[rɪˈviːlz] 美[rɪˈviːlz]<br>v.揭示;显示;透露;展示;露出;显出;<br>n.揭示（reveal 的复数）;</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">slot   1:</span><br><span class="line">    0: 52 4f 4f 54 4e 41 4d 45 20 72 6f 6f 74 64 62 73   ROOTNAME rootdbs</span><br><span class="line">   16:  0                                                ................</span><br><span class="line">slot   2:</span><br><span class="line">    0: 52 4f 4f 54 50 41 54 48 20 2f 6f 70 74 2f 67 62   ROOTPATH /opt/gb</span><br><span class="line">   16: 61 73 65 2f 73 74 6f 72 61 67 65 2f 72 6f 6f 74   ase/storage/root</span><br><span class="line">   32: 64 62 73  0                                       dbs.............</span><br><span class="line">slot   3:</span><br><span class="line">    0: 52 4f 4f 54 4f 46 46 53 45 54 20 30  0            ROOTOFFSET 0....</span><br><span class="line">slot   4:</span><br><span class="line">    0: 52 4f 4f 54 53 49 5a 45 20 31 35 37 36 39 36  0   ROOTSIZE 157696.</span><br><span class="line">slot   5:</span><br><span class="line">    0: 4d 49 52 52 4f 52 20 30  0                        MIRROR 0........</span><br></pre></td></tr></table></figure><p>上面是 oncheck -pP 1 1 截取部分</p><p><strong>The Checkpoint&#x2F;Logical Log Page</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1CKPT &amp; PAGE_2CKPT...</span><br><span class="line">      Using check point page PAGE_2CKPT.</span><br><span class="line"></span><br><span class="line">Time stamp of checkpoint       0x7f7e6b</span><br><span class="line">Time of checkpoint             05/10/2025 05:17:37</span><br><span class="line">Physical <span class="built_in">log</span> begin address     2:53</span><br><span class="line">Physical <span class="built_in">log</span> size              35986 (p)</span><br><span class="line">Physical <span class="built_in">log</span> position at Ckpt  30148</span><br><span class="line">Logical <span class="built_in">log</span> unique identifier  148</span><br><span class="line">Logical <span class="built_in">log</span> position at Ckpt   0xc510c0 (Page 3153, byte 192)</span><br><span class="line">Checkpoint Interval            98</span><br><span class="line">DBspace descriptor page        1:4</span><br><span class="line">Chunk descriptor page          1:7</span><br><span class="line">Mirror chunk descriptor page   1:8</span><br><span class="line"></span><br><span class="line">Log file number                14</span><br><span class="line">Unique identifier              146</span><br><span class="line">Log file flags                 0x5        Log file <span class="keyword">in</span> use</span><br><span class="line">&amp;                                         Log file has been backed up</span><br><span class="line">Physical location              3:29483</span><br><span class="line">Log size                       3270 (p)</span><br><span class="line">Number pages used              3270</span><br><span class="line">Date/Time file filled          04/17/2025 09:10:15</span><br><span class="line">Time stamp                     0x578dde</span><br><span class="line"><span class="comment"># 下边把剩余的所有 Log file number 都列出来了</span></span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The current checkpoint&#x2F;logical log page gives the location, date, and time of the last checkpoint, and the location and current status of the logical logs.</p><p><code>当前 checkpoint/logical log page 给出了最后一个检查点的位置、日期和时间，以及逻辑日志的位置和当前状态。</code></p><p>Beginning with page 2, the reserved pages are paired. However, only one page out of the pair is current. So when we refer to the primary chunk reserved page, dbspace reserved page, or the checkpoint&#x2F;logical log reserved page, we are talking about the current page of the pair. The current page can be easily found by comparing the timestamps, which is the method used by <strong>oncheck -pr</strong> when deciding which of the pages to display. Notice that at the top of each reserved page output, <strong>oncheck</strong> indicates which page of the pair it has chosen to display.</p><p><code>从第 2 页开始，保留页是成对的。但是，每对页中只有一个是当前页。因此，当我们提到 primary chunk 保留页、dbspace 保留页或检查点/逻辑日志保留页时，我们指的是该对中的当前页。可以通过比较时间戳轻松找到当前页，这也是 oncheck -pr 在决定显示哪些页时使用的方法。请注意，在每个保留页输出的顶部，oncheck 都会指示它选择显示的页对中的哪个页。（说的应该是“Using check point page PAGE_2CKPT.”）</code></p><p><strong>Hint</strong></p><p>Run the commands:</p><p>​oncheck -pP 1 2</p><p>and</p><p>​oncheck -pP 1 3</p><p>First, determine which of the pages is more current by looking at the timestamps. Then compare your observation with the <strong>oncheck -pr</strong> report.</p><p>可能意思是看2和3，哪个stamp数字更大吧</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">oncheck -pP 1 2</span><br><span class="line"></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:2              8343790  5092   20     1800 ROOTRSV      680   1284  0        0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">oncheck -pP 1 3</span><br><span class="line"></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:3              8355443  7e0e   20     1800 ROOTRSV      680   1284  0        0</span><br></pre></td></tr></table></figure><p><strong>A pair of nearly identical pages</strong></p><p>You might still be confused about how the two checkpoint&#x2F;logical log pages are split. It is <strong>not</strong> the case that one page contains checkpoint information while the other page contains logical log information. There is checkpoint and logical log information on both pages, as shown here:</p><p><code>您可能仍然对两个 checkpoint/logical log page 的划分方式感到困惑。一个页面包含检查点信息，而另一个页面包含逻辑日志信息，这种情况并非如此。两个页面上都包含检查点和逻辑日志信息，如下所示：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505102139970.png" alt="image-20250510213923811"></p><p>The difference between the two pages is that one contains up-to-date information, and the other contains information that is one iteration out of date. This is true for all the reserved-page pairs.</p><p><code>这两个页面的区别在于，一个页面包含最新信息，而另一个页面包含的信息已经过期一个迭代。所有保留页对都是如此。</code></p><p>图上，黑横线是page分割线，黑线下边紧邻是页头，上边紧邻右侧是页尾</p><p><strong>The checkpoint structure vs. checkpoint records</strong></p><p>It is important to distinguish between the checkpoint <em>structure</em>, found on the checkpoint&#x2F;logical log page, and checkpoint <em>records</em>.</p><p><code>必须区分检查点/逻辑日志页面上的 checkpoint structure 和 checkpoint records。</code></p><p>Checkpoint records are written to the logical logs. One of the last steps taken by IDS during a checkpoint is to write a checkpoint record to the current logical log file.</p><p><code>Checkpoint records 写入逻辑日志。在检查点过程中，IDS 采取的最后一个步骤是向当前逻辑日志文件写入检查点记录。</code></p><p>At any given time, there can be many checkpoint records scattered throughout the logical logs on disk. But of those records, only the most recently written record is important to fast recovery. The checkpoint structure*,* on the checkpoint&#x2F;logical log page, contains information that, in the event of a system shutdown or crash, guides fast recovery to this most-important, most-recent checkpoint record.</p><p><code>在任意时刻，磁盘上的逻辑日志中可能分布着许多检查点（checkpoint）记录。但在这些记录中，只有最近写入的那条记录对快速恢复最为关键。位于检查点/逻辑日志页上的检查点结构（checkpoint structure）包含了相关信息，在系统关闭或崩溃的情况下，这些信息会引导快速恢复过程定位到这一条最重要、最新的检查点记录。。</code></p><blockquote><p>scatter 分散 英[ˈskætə(r)] 美[ˈskætər]</p><p>throughout 遍及 英[θruːˈaʊt] 美[θruːˈaʊt]</p></blockquote><p><strong>The Checkpoint Structure</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1CKPT &amp; PAGE_2CKPT...</span><br><span class="line">      Using check point page PAGE_2CKPT.</span><br><span class="line"></span><br><span class="line">Time stamp of checkpoint       0x7f7e6b</span><br><span class="line">Time of checkpoint             05/10/2025 05:17:37</span><br><span class="line">Physical <span class="built_in">log</span> begin address     2:53</span><br><span class="line">Physical <span class="built_in">log</span> size              35986 (p)</span><br><span class="line">Physical <span class="built_in">log</span> position at Ckpt  30148</span><br><span class="line">Logical <span class="built_in">log</span> unique identifier  148</span><br><span class="line">Logical <span class="built_in">log</span> position at Ckpt   0xc510c0 (Page 3153, byte 192)</span><br><span class="line">Checkpoint Interval            98</span><br><span class="line">DBspace descriptor page        1:4</span><br><span class="line">Chunk descriptor page          1:7</span><br><span class="line">Mirror chunk descriptor page   1:8</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>What follows is an item-by-item analysis of the checkpoint structure information displayed by <strong>oncheck -pr</strong>. Indicated along with an explanation of each element is its notation (hex or decimal).</p><p><code>下面逐项分析 oncheck -pr 显示的检查点结构信息。每个元素的表示方式（十六进制或十进制）也会一并标出，并附带解释。</code></p><p><strong>Time stamp of checkpoint</strong> (hex) – The global system timestamp that is current during the last moments of the checkpoint. Notice that the timestamp on the current checkpoint&#x2F;logical log page is often just one or two ticks higher than the timestamp value stored in the checkpoint structure.</p><p><code>检查点最后时刻的全局系统时间戳。请注意，当前 checkpoint/logical log page 上的时间戳往往只比存储在 checkpoint structure 中的时间戳值高一两个刻度。</code></p><p>checkpoint&#x2F;logical log page 上的时间戳，指的是页尾的时间戳吧，也就是 oncheck -pP 1 3 的 stamp 值 8355443（0x7F7E73），比0x7f7e6b大一点。</p><p><strong>Time of checkpoint</strong> – The true date and time of the last checkpoint, based on the UNIX host’s <strong>localtime</strong> function.</p><p><code>上次检查点的真实日期和时间，基于 UNIX 主机的 localtime 函数。</code></p><p><strong>Physical log begin address</strong> (decimal:decimal) – This is the location (chunk number and page offset) of the first page in the physical log. You can verify this information using <strong>oncheck -pe</strong>.</p><p><code>这是物理日志中第一页的位置（chunk编号和页偏移量）。您可以使用 oncheck -pe 验证此信息。</code></p><p>oncheck -pe截选，可以看到，chunk 2，offset 53</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DBspace Usage Report: plog                Owner: gbasedbt  Created: 04/17/2025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Chunk Pathname                             Pagesize(k)  Size(p)  Used(p)  Free(p)</span><br><span class="line">     2 /opt/gbase/storage/ol_gbasedbt1210_1_plog_p_1            2    36045    36039        6</span><br><span class="line"></span><br><span class="line"> Description                                                   Offset(p)  Size(p)</span><br><span class="line"> ------------------------------------------------------------- -------- --------</span><br><span class="line"> RESERVED PAGES                                                       0        2</span><br><span class="line"> CHUNK FREELIST PAGE                                                  2        1</span><br><span class="line"> plog:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                             3       50</span><br><span class="line"> PHYSICAL LOG                                                        53    35986</span><br><span class="line"> FREE                                                             36039        6</span><br><span class="line"></span><br><span class="line"> Total Used:    36039</span><br><span class="line"> Total Free:        6</span><br></pre></td></tr></table></figure><p><strong>Physical log size</strong> (decimal) – The size, in pages, of the physical log.</p><p><code>物理日志的大小（以页为单位）。</code></p><p><strong>Physical log position at Ckpt</strong> (decimal) – This is the page offset within the physical log that was current at the time of the last checkpoint, expressed as a number of pages offset from the physical log begin address. The first phase of fast recovery, physical recovery, starts with the page following the one indicated here.</p><p><code>这是上一次检查点时物理日志中的页面偏移量，表示为从物理日志起始地址偏移的页数。快速恢复的第一阶段，即物理恢复，从此处所示页面之后的页面开始。</code></p><p><strong>Logical log unique identifier</strong> (decimal) – This is the unique ID of the logical log that contains the most recently written checkpoint record.</p><p><code>这是包含最近写入的 checkpoint record 的逻辑日志的唯一 ID。</code></p><p><strong>Logical log position at Ckpt</strong> (hex) – This is the position within the logical log indicated by the previous element in the checkpoint structure (logical log unique identifier) where the most-recently-written checkpoint record can actually be found. This is also known as the <em>logpos</em>.</p><p><code>这是 checkpoint structure 中前一个元素 logical log unique identifier(就上边那个) 所指示的逻辑日志中的位置，在该位置可实际找到最近写入的 checkpoint record。这也称为 logpos。</code></p><p><strong>Dbspace descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the dbspace reserved page that was current at the time of the checkpoint. Of course, the timestamps on the two dbspace pages could also be compared to determine which one was more up-to-date.</p><p><code>这是检查点时最新的 dbspace 保留页面的位置（chunk编号和偏移量）。当然，也可以通过比较两个 dbspace 页面上的时间戳来确定哪个页面更新。</code></p><p><strong>Chunk descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the primary chunk reserved page that was current at the time of the last checkpoint. The same redundancy involved with the previous element of the checkpoint structure applies to this one.</p><p><code>这是上次检查点时当前的 primary chunk 保留页的位置（chunk编号和偏移量）。检查点结构的前一个元素所涉及的冗余同样适用于这个元素。</code></p><blockquote><p>redundancy 冗余 英[rɪˈdʌndənsi] 美[rɪˈdʌndənsi]</p></blockquote><p><strong>Mirror chunk descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the mirror chunk reserved page that current at the time of the last checkpoint.</p><p><code>这是上次检查点时当前 mirror chunk 保留页的位置（chunk编号和偏移量）。</code></p><p><strong>The Logical Log File Structure</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Log file number                14</span><br><span class="line">   Unique identifier              146</span><br><span class="line">   Log file flags                 0x5        Log file <span class="keyword">in</span> use</span><br><span class="line">   &amp;                                         Log file has been backed up</span><br><span class="line">   Physical location              3:29483</span><br><span class="line">   Log size                       3270 (p)</span><br><span class="line">   Number pages used              3270</span><br><span class="line">   Date/Time file filled          04/17/2025 09:10:15</span><br><span class="line">   Time stamp                     0x578dde</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>For every logical log file defined in the system, there is one log file structure in the checkpoint&#x2F;logical log reserved page.</p><p><code>对于系统中定义的每个逻辑日志文件，在 checkpoint/logical log 预留页面中有一个日志文件结构。</code></p><p>注意，这是最后一次检查点时的逻辑日志文件结构，不是当前的，onstat -l 时，flags 对不上的</p><p><strong>Log file number</strong> (decimal) – The number of the log file in the Informix Dynamic Server system. Logical log files are generally used in the order of their log file number.</p><p><code>IDS 系统中日志文件的编号。逻辑日志文件通常按其日志文件编号的顺序使用。</code></p><p><strong>Unique identifier</strong> (decimal) – This integer is always associated with the particular set of logical log records currently stored in this log file. A zero value means the log file is free.</p><p><code>该整数总是与当前存储在该日志文件中的特定逻辑日志记录集合相关联。零值表示日志文件空闲。</code></p><p>看不懂说的什么，onstat -l 可以看到这两个数，在同一行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@frh gbase]<span class="comment"># onstat -l</span></span><br><span class="line">……</span><br><span class="line">address          number   flags    uniqid   begin                size     used    %used</span><br><span class="line">4559fa60         14       U-B----  146      3:29483              3270     3270   100.00</span><br><span class="line">4559fac8         13       U-B----  147      3:26213              3270     3270   100.00</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p><strong>Log containing last checkpoint</strong> (decimal) – This indicates the logical log page number and byte offset into that log where the last checkpoint record was recorded.</p><p><code>这表示记录最后一次检查点记录的逻辑日志页码和字节偏移量。</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Log file number                10</span><br><span class="line">Unique identifier              150</span><br><span class="line">Log contains last checkpoint:  Page 1260, byte 192</span><br><span class="line">Log file flags                 0x3        Log file <span class="keyword">in</span> use</span><br><span class="line">&amp;                                         Current <span class="built_in">log</span> file</span><br><span class="line">Physical location              3:16403</span><br><span class="line">Log size                       3270 (p)</span><br><span class="line">Number pages used              1261</span><br><span class="line">Date/Time file filled          04/17/2025 09:12:24</span><br><span class="line">Time stamp                     0x6171d2</span><br><span class="line"></span><br><span class="line">address          number   flags    uniqid   begin                size     used    %used</span><br><span class="line">4559fa60         14       U-B----  146      3:29483              3270     3270   100.00</span><br><span class="line">4559fac8         13       U-B----  147      3:26213              3270     3270   100.00</span><br><span class="line">4559fb30         12       U-B----  148      3:22943              3270     3270   100.00</span><br><span class="line">4559fb98         11       U-B----  149      3:19673              3270     3270   100.00</span><br><span class="line">4559fc00         10       U-B---L  150      3:16403              3270     3270   100.00</span><br><span class="line">4559fc68         9        U-B----  151      3:13133              3270     3270   100.00</span><br></pre></td></tr></table></figure><p>必须有L的逻辑日志文件，才有 Log contains last checkpoint</p><p><strong>Log file flags</strong> (hex) – With the miracle of the logical OR, up to five different logical log flags, like the page flags described in the previous chapter, can be packed into this one short integer. The individual flag values are:</p><p><code>利用逻辑或的神奇功能，可以将最多五个不同的逻辑日志标志（如上一章所述的页面标志）打包到这个短整数中。各个标志值如下</code></p><p>0x01 Log file in use，U</p><p>0x02 Current log file，L</p><p>0x04 Backed up，B</p><p>0x08 Newly added (archive required)</p><p>0x10 Log has been written to an archive tape</p><p>0x20 Log is a temporary log file</p><p>Note that <strong>oncheck -pr</strong> is nice enough to print an English translation of all flag values present in the one value shown.</p><p><code>请注意，oncheck -pr 非常友好，会在显示的一个值中打印所有标志值的英文翻译。(数字右边就是)</code></p><p><strong>Physical location</strong> (decimal:decimal) – This is the physical location (chunk number and offset) of this log file’s first page.</p><p><code>这是日志文件第一页的物理位置（chunk编号和偏移量）。就是当前逻辑日志文件第一页在chunk的物理位置</code></p><p><strong>Log size</strong> (decimal) – This indicates the size of this log file, in pages.</p><p><code>表示该日志文件的大小（以页为单位）。</code></p><p><strong>Number pages used</strong> (decimal) – This element of the log file structure is fairly self-explanatory, though not always very accurate, being updated only during a checkpoint along with the rest of the reserved page information (when wrong, it is low). Informix Dynamic Server’s recovery mechanisms do not rely on this value at all.</p><p><code> 日志文件结构中的这一元素不言自明，但并不总是非常准确，只有在检查点期间才会与其他保留页信息一起更新（错误时，它的值较低）。IDS 的恢复机制完全不依赖这个值。</code></p><p>不懂，先不管</p><blockquote><p>fairly 相当地 英[ˈfeəli] 美[ˈferli]</p><p>self-explanatory 一目了然的 英[ˌself ɪkˈsplænətri] 美[ˌself ɪkˈsplænətɔːri]</p></blockquote><p><strong>Date&#x2F;time file filled</strong> – This is the date and time, based on the UNIX host’s <strong>localtime</strong>function, when this log file was filled. <strong>12&#x2F;31&#x2F;69 16:00</strong> indicates this element’s value is 0, which means the log file is either free or still in use.</p><p><code>根据 UNIX 主机的 localtime 函数，这是日志文件被写满时的日期和时间。&quot;-&quot; 表示此元素的值为 0，这意味着日志文件已空闲或仍在使用中。</code></p><p>原文的12&#x2F;31&#x2F;69 16:00不知道是什么，明明显示的是个”-“</p><p><strong>Time stamp</strong> (decimal) – This is the value of the global system timestamp when this log file was completed (the log file does not have to be filled to capacity to get a timestamp). A 0 here indicates a log file that is either free, or still in use.</p><p><code>这是该日志文件完成时的全局系统时间戳值（日志文件不必写满就可以获得时间戳）。此处的 0 表示日志文件空闲或仍在使用中。</code></p><p>说的是 onmode -l 情况吧</p><p><strong>Log Unique Identifier Versus Log File Number</strong></p><blockquote><p>versus 英[ˈvɜːsəs] 美[ˈvɜːrsəs]<br>prep.(表示两队或双方对阵)对，诉，对抗;(比较两种不同想法、选择等)与…相对，与…相比;</p></blockquote><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505112026087.png" alt="image-20250511202616915"></p><p><strong>Notes:</strong></p><p>A logical log file is an area on disk. It is a chunk extent, LOGSIZE kilobytes large, to which log records are written as they are generated. Each log file has a permanent log file number. In the example above, the log file number is 1 for the first log file, 2 for the second log, and 3 for the third log.</p><p><code>逻辑日志文件是磁盘上的一个区域。它是一个chunk extent，LOGSIZE 为 KB，日志记录生成后会被写入其中。每个日志文件都有一个永久的日志文件编号。在上例中，第一个日志文件的日志文件编号为 1，第二个日志文件的日志文件编号为 2，第三个日志文件的日志文件编号为 3。</code></p><p>In addition, each log file has a unique identifier, which you can think of as a method to uniquely tag the logical log records inside of the log. When a logical log is backed up, it carries its unique identifier with it. The unique identifiers for the logs on disk are incremented, ready for new transaction records.</p><p><code>此外，每个日志文件都有一个唯一标识符，可以将其视为唯一标记日志内逻辑日志记录的方法。备份逻辑日志时，日志会携带这个唯一标识符。磁盘上日志的唯一标识符会递增，为新的事务记录做好准备。</code></p><p>前半段看不懂，感觉按它意思，唯一标识日志里的逻辑日志记录，备份以后唯一标识递增（变了），而此时日志里内容没变吧，也就是内容没变的情况下，却不能唯一标识了，意思里面内容没用了呗，等新的事物记录写入</p><p>In the example above, the newly initialized Informix Dynamic Server system assigns the first log a unique ID of 1, the second log a unique ID of 2, and the third log a unique ID of 3. When these logs are full and you back them up to tape, the unique identifiers for the three logs are changed to 4, 5, and 6. After filling them a second time and backing them up, the unique identifiers are changed to 7, 8, and 9.</p><p><code>在上面的示例中，新初始化的 IDS 系统为第一个日志分配了唯一标识符 1，为第二个日志分配了标识符 2，为第三个日志分配了标识符 3。当这些日志被写满并备份到磁带后，这三个日志的唯一标识符会被更改为 4、5 和 6。在第二次写满并备份之后，唯一标识符会更改为 7、8 和 9。</code></p><p><strong>The Dbspace Page</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1DBSP &amp; PAGE_2DBSP...</span><br><span class="line">      Using DBspace page PAGE_2DBSP.</span><br><span class="line"></span><br><span class="line">DBspace number                 1</span><br><span class="line">DBspace name                   rootdbs</span><br><span class="line">Flags                          0x40001    No mirror chunks</span><br><span class="line">Number of chunks               1</span><br><span class="line">First chunk                    1</span><br><span class="line">Date/Time created              04/17/2025 08:44:48</span><br><span class="line">Partition table page number    14</span><br><span class="line">Pagesize (k)                   2</span><br><span class="line">Logical Log Unique Id          0</span><br><span class="line">Logical Log Position           0x0</span><br><span class="line">Oldest Logical Log Unique Id   155</span><br><span class="line">Last Logical Log Unique Id     0</span><br><span class="line">Expand Size (Chunk Create)     50.0%</span><br><span class="line">Expand size (Chunk Extend)     10.0%</span><br><span class="line">DBspace archive status</span><br><span class="line"></span><br><span class="line">      Archive Level            0</span><br><span class="line">      Real Time Archive Began  05/12/2025 07:25:01</span><br><span class="line">      Time Stamp Archive Began 8590386</span><br><span class="line">      Logical Log Unique Id    155</span><br><span class="line">      Logical Log Position     0x64f018</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The dbspace structure is easier to understand intuitively than either the checkpoint or the log file structure.</p><p><code>与检查点或log file structure相比，dbspace 结构更容易直观地理解。</code></p><blockquote><p>intuitively 英[ɪnˈtjuːɪtɪvli] 美[ɪnˈtuːɪtɪvli]<br>adv.凭直觉;直觉地，直观地；由直觉而得地;</p></blockquote><p><strong>Dbspace number</strong> (decimal) – Dbspace numbers are indexed from 1.</p><p><strong>Dbspace name</strong> – This is the name given the dbspace when it was created, and the name used in all SQL syntax referring to this dbspace.</p><p><code>这是创建 dbspace 时赋予它的名称，也是所有引用该 dbspace 的 SQL 语法中使用的名称。</code></p><p><strong>Flags</strong> (hex) – The possible values for dbspace flags are:</p><p>0x0001 DBspace has no mirror chunks</p><p>0x0002 DBspace uses mirror chunks</p><p>0x0004 DBspace has disabled mirror chunks</p><p>0x0008 Newly mirrored</p><p>Flags specific to blobspaces:</p><p>0x0010 DBspace is a BLOBspace</p><p>0x0020 BLOBspace resides on removable media</p><p>0x0040 BLOBspace resides on optical media</p><p>0x0080 BLOBspace has been dropped</p><p>0x0100 BLOBspace is the optical STAGEBLOB</p><p>Other flags:</p><p>0x0200 Space is being physically recovered</p><p>0x0400 Space has been physically recovered</p><p>0x0800 Space is being logically recovered</p><p>0x1000 A table in the dbspace was dropped</p><p>0x2000 Temp DBspace</p><p>0x4000 Space is being archived</p><p>0x8000 Space is an sbspace</p><p>0x10000 Either the physical or logical log has changed</p><p>按这说的，那应该是0x10001，怎么是0x70001？</p><p><strong>Number of chunks</strong> (decimal) – This indicates the total number of chunks in this dbspace (not counting mirror chunks).</p><p><code>表示该数据库空间中的chunk总数（不包括镜像chunk）。</code></p><p><strong>First chunk</strong> (decimal) – The concept of a <em>first chunk</em> in a dbspace is important internally because a dbspace structure and all its associated primary chunk structures form a linked list. From the <strong>First chunk</strong> element in a dbspace structure, Informix Dynamic Server can quickly find the first primary chunk structure associated with this dbspace. Then, based on the <strong>Next chunk</strong> in dbspace element in each primary chunk structure, Informix Dynamic Server can quickly walk down the rest of the list.</p><p><code>dbspace 中的 first chunk 概念在内部非常重要，因为 dbspace 结构及其所有关联的主 chunk 结构构成了一个链表。IDS 可以通过 dbspace 结构中的 First chunk 元素，快速找到与该数据表空间相关联的 first primary chunk structure。然后，根据每个 primary chunk structure 中 dbspace 的 Next chunk 元素，IDS 可以快速找到列表的其余部分。</code></p><p><strong>Date&#x2F;time created</strong> – This is the date and time, based on the UNIX <strong>localtime</strong> function, when the dbspace was created.</p><p><code>这是创建 dbspace 的日期和时间，基于 UNIX 的 localtime 函数。</code></p><p><strong>Partition table page numbe</strong>r – This indicates the location of the first page of the partition partition as a page offset into the first chunk of the dbspace.</p><p><code>这表示 partition 第一页的位置，作为 dbspace 第一个 chunk 的页面偏移量。</code></p><p>两个连着的partition，多写了一个吧</p><p><strong>Pagesize (k)</strong> – This is the page size defined for this dbspace.</p><p><strong>Logical Log Unique ID</strong> and <strong>Logical Log Position</strong> – These fields indicate the location of the ADDDBS transaction record for this dbspace.</p><p><code>这些字段表示该 dbspace 的 ADDDBS 事务记录的位置。</code></p><p>看不懂</p><p><strong>Oldest Logical Log Unique ID</strong> and <strong>Last Logical Log Unique ID</strong> – These indicate the unique ID numbers of the oldest and most current logical logs.</p><p><code>这表示最旧和最新逻辑日志的唯一 ID 编号。</code></p><p><strong>Dbspace archive status</strong> – This displays information about the last backup that was performed that included this dbspace. Information includes the backup level, the start and end time of the backup, and the location of the backup checkpoint record.</p><p><code>这将显示上一次执行的包含此 dbspace 的备份信息。信息包括备份级别、备份开始和结束时间以及备份 checkpoint record 的位置。</code></p><p>没看出来哪个是结束时间</p><p>最后两个逻辑日志相关参数代表 the location of the backup checkpoint record 吧</p><p><strong>The Primary Chunk Page</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">   Validating PAGE_1PCHUNK &amp; PAGE_2PCHUNK...</span><br><span class="line">         Using primary chunk page PAGE_1PCHUNK.</span><br><span class="line"></span><br><span class="line">   Chunk number                   1</span><br><span class="line">   Flags                          0x30040    Chunk is online</span><br><span class="line">   Chunk path                     /opt/gbase/storage/rootdbs</span><br><span class="line">   Chunk offset                   0 (p)</span><br><span class="line">   Chunk size                     78848 (p)</span><br><span class="line">   Number of free pages           64144</span><br><span class="line">   DBspace number                 1</span><br><span class="line"></span><br><span class="line">   Chunk number                   2</span><br><span class="line">   Flags                          0x32040    Chunk is online</span><br><span class="line">   &amp;                                         Chunk is extendable</span><br><span class="line">   Chunk path                     /opt/gbase/storage/ol_gbasedbt1210_1_plog_p_1</span><br><span class="line">   Chunk offset                   0 (p)</span><br><span class="line">   Chunk size                     36045 (p)</span><br><span class="line">   Number of free pages           6</span><br><span class="line">   DBspace number                 2</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The primary chunk page contains information about each primary chunk created on the database server.</p><p><code>主chunk页面包含在server上创建的每个主chunk的信息。</code></p><p><strong>Chunk number</strong> (decimal) – Chunk numbers are indexed from 1, whereas page offsets begin with 0. The lowest possible value for a page address is therefore 1:0.</p><p><code>chunk编号的索引从 1 开始，而页面偏移量则从 0 开始。 因此，页面地址的最小值可能是 1:0。</code></p><p><strong>Flags</strong> (hex) – Individual chunk flags, ORed together into this one element, have the following values:</p><p><code>各个独立的chunk标志通过按位或操作（OR）组合在一起，形成这个元素，具有以下值：</code></p><p>0x0010 Mirror chunk</p><p>0x0020 Chunk is off-line</p><p>0x0040 Chunk is on-line</p><p>0x0080 Chunk is being recovered</p><p>0x0100 Chunk is newly mirrored</p><p>0x0200 Chunk is belongs to a blobspace</p><p>0x0400 Chunk is being dropped</p><p>0x0800 Chunk is part of an optical stageblob</p><p>0x1000 Chunk is inconsistent with the rest of the system</p><p>0x2000 Chunk has been chained</p><p>0x4000 Chunk belongs to an sbspace</p><p><strong>Chunk path</strong> – This is the full pathname to the chunk device or file. </p><p><code>这是chunk设备或文件的完整路径名。</code></p><p><strong>Chunk offset</strong> (decimal) – This chunk begins at <strong>Chunk offset</strong> <em>pages</em> into <strong>Chunk path</strong>.</p><p><code>该chunk从 Chunk path 中偏移 Chunk offset 页的位置开始。</code></p><p><strong>Chunk size</strong> (decimal) – This indicates the size of the chunk in <em>pages</em>.</p><p><code>这表示数据块的大小，单位为页。</code></p><p><strong>Number of free pages</strong> (decimal) – This indicates the total number of pages currently in the chunk free list.</p><p>·这表示当前chunk free list的页面总数。·</p><p><strong>Dbspace number</strong> (decimal) – This is the unique dbspace number.</p><p><code>这是唯一的dbspace编号。</code></p><p><strong>The Mirror Chunk Page</strong></p><p>没人用 Mirror Chunk 了吧，跳过不看</p><p><strong>The Archive Page</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1ARCH &amp; PAGE_2ARCH...</span><br><span class="line">         Using archive page PAGE_1ARCH.</span><br><span class="line"></span><br><span class="line">   Archive Level                  0</span><br><span class="line">   Real Time Archive Began        05/12/2025 07:25:01</span><br><span class="line">   Time Stamp Archive Began       0x831432</span><br><span class="line">   Logical Log Unique Id          155</span><br><span class="line">   Logical Log Position           0x64f018</span><br><span class="line"></span><br><span class="line">   Archive Level                  1</span><br><span class="line">   Real Time Archive Began        05/12/2025 07:25:52</span><br><span class="line">   Time Stamp Archive Began       0x8314b5</span><br><span class="line">   Logical Log Unique Id          155</span><br><span class="line">   Logical Log Position           0x656018</span><br><span class="line"></span><br><span class="line">   DR has not been initialized.</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The archive reserved page is the last in the set of root reserved pages. Up to three archive structures can be present on the page, depending on the level of archives taken on the system. Once a second or third archive structure comes to exist on the page, it is never deleted because a new level-0 archive does not negate the potential importance of a previous level 1 or level 2 archive.</p><p><code>存档预留页是root预留页中的最后一个。页面上最多可有三个存档结构，具体取决于系统中存档的级别。一旦页面上出现第二个或第三个存档结构，它将永远不会被删除，因为新的 0 级存档不会否定之前的 1 级或 2 级存档的潜在重要性。</code></p><p>看不懂，对应0、1、2级备份吧</p><p>New information is recorded in the archive reserved page only when an archive completes successfully.</p><p><code>只有当存档成功完成时，存档保留页面才会记录新信息。</code></p><p><strong>Archive Level</strong> (decimal) – This can be level 0, 1, or 2.</p><p><strong>Real Time Archive Began</strong> – This indicates the date and time of the archive checkpoint as seen by the localtime function on the UNIX host machine.</p><p><code>这表示存档检查点的日期和时间，由 UNIX 主机上的 localtime 功能显示。</code></p><p>看不懂，什么叫存档检查点？从名字看就是备份时间吧</p><p><strong>Time Stamp Archive Began</strong> (decimal) – This is a timestamp associated with the checkpoint that occurred at the start of the archive.</p><p><code>这是与存档开始时发生的检查点相关联的时间戳。</code></p><p>看不懂</p><p><strong>Logical Log Unique Id</strong> (decimal) – This is the unique ID of the logical log that contains the archive checkpoint record.</p><p><code>这是包含 archive checkpoint record 的逻辑日志的唯一 ID。</code></p><p><strong>Logical Log Position</strong> (hex) – This is the position within the log (logpos) specified by logical log unique ID where the archive checkpoint can be found.</p><p><code>这是在逻辑日志唯一 ID 指定的日志 (logpos) 中可以找到 archive checkpoint 的位置。</code></p><p><strong>Chunk Free List</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505132122121.png" alt="image-20250513212245968"></p><p><strong>Notes:</strong></p><p>Every chunk needs a mechanism to track its own available space. Following the last reserved page in each chunk is a chunk free-list page. This page, which can be one of several depending on the fragmentation in the chunk, contains structures pointing to <em>unused</em> extents. Each structure, or <em>free-list entry</em>, contains two elements: the starting page of an unclaimed extent, and the length of the free extent measured in pages.</p><p><code>每个 chunk 都需要一种机制来跟踪自己的可用空间。在每个chunk的最后一个预留页之后是一个 chunk free-list page。该页面可以是多个页面之一，取决于 chunk 中的碎片情况，包含指向未使用extent的结构。每个结构或free-list条目包含两个元素：空闲extent的起始页和空闲extent的长度（以页为单位）。</code></p><p>“该页面可以是多个页面之一”，多个翻译软件都是这么翻译的，不像人话，意思应该是可能有多个chunk free-list page，如果碎片很多的话，要记录很多的起始和偏移，一页放不下，如果一个碎片都没有，一个起始和偏移就够了。</p><blockquote><p>unclaimed 英[ˌʌnˈkleɪmd] 美[ˌʌnˈkleɪmd]<br>adj.无人认领的;无人索取的;</p></blockquote><p><strong>Allocation of space</strong></p><p>When an extent is allocated in a chunk, the loss of free space is manifested in either the removal of an entry from the chunk free list, or a modification to one or both elements in an entry there.</p><p>当在chunk中分配一个extent时，可用空间的损失表现为从chunk free list中删除一个条目，或修改该条目中的一个或两个元素。</p><blockquote><p>manifest<br>英[ˈmænɪfest] 美[ˈmænɪfest]<br>vt.表明;显示;显现;清楚显示(尤指情感、态度或品质);使人注意到;<br>adj.明显的;<br>n.(船或飞机的)货单;旅客名单;</p><p>以前都按java的<em>MANIFEST</em>.MF理解为：清单</p></blockquote><p><strong>Freeing space</strong></p><p>Informix Dynamic Server frees space when a table is dropped, or in some cases when a table is altered. When free space is reclaimed, a new entry can be added to the chunk free list. If the newly freed space is contiguous with existing free space, only the length element in the associated free-list entry is changed; otherwise, a new entry is created.</p><p><code>IDS 会在删除表或在某些情况下更改表时释放空间。当空闲空间被回收时，可以在chunk free list中添加一个新条目。如果新释放的空间与现有的空闲空间毗连，则只更改相关空闲列表条目中的长度元素；否则，将创建一个新条目。</code></p><blockquote><p>reclaim<br>英[rɪˈkleɪm] 美[rɪˈkleɪm]<br>vt.回收;开垦，利用，改造(荒地);取回;挽救;要求归还;拿回;沙化;荒漠化;重新变为沙漠(或森林等);抛荒;<br>n.开垦;改造;取回;矫正;</p></blockquote><p><strong>Additional chunk free-list pages</strong></p><p>If a chunk becomes so fragmented that the initial chunk free-list page is full of entries, an additional chunk free-list page is allocated. These pages are then chained together in the form of a linked list. Each link in this chain is responsible only for extents between itself and the next chunk free-list page. This design requires a good deal of coordination among the links.</p><p><code>如果一个分块变得非常分散，以至于初始chunk free-list page已经满载条目，那么就会分配一个额外的chunk free-list page。然后，这些页面以链表的形式串联起来。链中的每个链接只负责自身和下一个chunk free-list page之间的扩展。这种设计要求链路之间有很好的协调性。</code></p><p><strong>Tblspace Tblspace (for Root Dbspace)</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505132157873.png" alt="image-20250513215730788"></p><p><strong>Notes:</strong></p><p>In the initial chunk of every dbspace, the page following the chunk free list marks the beginning of the tblspace tblspace (partition table). The tblspace tblspace is a collection of pages that describes the complexion and location of each table in the dbspace. In many ways, the tblspace tblspace itself is considered just another table. For example, one of its pages describes the tblspace tblspace!</p><p><code>在每个 dbspace 的初始chunk中，数据chunk free list之后的页面标志着 tblspace tblspace（分区表）的开始。tblspace tblspace 是描述 dbspace 中每个表的结构和位置的页面集合。在许多方面，tblspace tblspace 本身就被认为是另一个表。例如，其中一个页面描述了 tblspace tblspace！</code></p><blockquote><p>complexion<br>英[kəmˈplekʃn] 美[kəmˈplekʃn]<br>n.肤色;面色;气色;(事物的)性质，特性;</p><ul><li><em>complex</em> 的“复杂性”含义源于“多元素交织”的原始意象。</li><li><em>complexion</em> 的中世纪生理学概念认为体液混合决定面色，故从“混合状态”引申为“肤色”。</li></ul></blockquote><p>You can configure the size of the first and subsequent extents for the tblspace tblspace in by setting the TBLTBLFIRST and TBLTBLNEXT configuration parameters. The default value of 0 directs the database server to determine appropriate extent sizes based on the size of the initial dbspace chunk.</p><p><code>通过设置 TBLTBLFIRST 和 TBLTBLNEXT 配置参数，可以配置 tblspace tblspace 中第一个和后续extent的大小。默认值 0 会指示server根据初始 dbspace chunk 的大小确定适当的extent大小。</code></p><p>Every tblspace in the system has exactly one tblspace tblspace page describing it. For brevity’s sake, we often refer to this special page type as a <em>partition page</em>.</p><p><code>系统中的每个 tblspace 都有且只有一个 tblspace tblspace page 来描述它。为了简洁起见，我们通常将这种特殊类型的页面称为 分区页（partition page）。</code></p><p>上图大方格那一行page</p><p><strong>Partition Number (Partnum)</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505142301023.png" alt="image-20250514230139875"></p><p><strong>Notes:</strong></p><p>The purpose of a table’s partition number, another 4-byte hexadecimal code, is to guide Informix Dynamic Server to that table’s partition page in the tblspace tblspace. The high-order byte-and-a-half (3 nibbles) of a partnum indicates which dbspace contains the table. Using the value of that byte-and-a-half, Informix Dynamic Server locates the tblspace tblspace for the target dbspace. One of the pages in that tblspace tblspace describes the target table. Informix Dynamic Server locates the correct partition page using the low-order five nibbles of the partnum, which contain a logical page number.</p><p><code>表的 partition number 是一个4字节的十六进制代码，其作用是引导 IDS 定位到该表在 tblspace tblspace 中的 partition page。这个 partnum 的高一字节半（3个半字节）用于指示表所在的 dbspace。通过这个高一字节半的值，IDS 可以定位到目标 dbspace 所对应的 tblspace tblspace。该 tblspace tblspace 中的某个页面描述了目标表。IDS 再通过分区号的低五个半字节——即逻辑页码，来定位到正确的 partition page。</code></p><blockquote><p>nibble 英[ˈnɪbl] 美[ˈnɪbl]</p><p>半字节</p><p>v.小口咬;一点点地咬(食物);(对…)略微表现出兴趣;<br>n.一小口;小吃;(餐前或聚会中的)点心;</p></blockquote><p>上上个图，partition number还是3字节，到这边4字节了…</p><p>Let us say the <strong>stores_demo:customer</strong> table has a partition number of 0x001000A5. This code means that logical page 0xA5 (165) within the tblspace tblspace for dbspace 1 is the partition page for <strong>stores_demo:customer</strong>.</p><p><code>例如，stores_demo:customer 表的分区号为 0x001000A5。这段代码表示，dbspace 1 的 tblspace tblspace 中的逻辑页 0xA5 (165) 是 stores_demo:customer 的 partition page。</code></p><p><strong>Partition Page Layout</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505152133530.png" alt="image-20250515213343393"></p><p><strong>Notes:</strong></p><p>Each partition page uses the following 5-slot format to describe the structure, location, and contents of one table in the dbspace:</p><p><code>每个 partition page 使用以下 5 个slot的格式来描述 dbspace 中一个表的结构、位置和内容：</code></p><p><strong>•</strong> The partition structure (slot 1) contains 92 bytes of general table information, including the partition number (see next page).</p><p><code>partition structure（slot 1）包含 92 个字节的常规表信息，包括分区编号（见下页，往后边看有详细解释）。</code></p><p><strong>•</strong> Slot 2 contains information identifying the partition by database name, table owner, table name, and NLS collation sequence (if any).</p><p><code>Slot 2 包含用于标识 partition 的信息，包括数据库名称、表拥有者、表名称，以及 NLS 排序规则（如果有的话）。</code></p><p><strong>•</strong> Slot 3 contains a descriptive entry for each <em>special</em> column in the table, meaning blobs and VARCHAR types.</p><p><code>slot 3 包含表中每个特殊列的描述性条目，即 blobs 和 VARCHAR 类型。</code></p><p><strong>•</strong> Slot 4 contains a <em>key descriptor</em> entry for each index key that exists for this table. Therefore, when accessing a particular tblspace, an error such as <em>Illegal key descriptor:</em> <em>too many parts or too long</em> refers to a problem with slot 4 on that table’s partition page, and not with the index itself. Because dropping an index requires the use of its key descriptor, a bad key descriptor can sometimes require the intervention of IBM Informix Technical Support to fix.</p><p><code>Slot 4 包含该表中每个索引键的“键描述符”（key descriptor）条目。因此，当访问某个特定的表空间（tblspace）时，若出现类似 非法键描述符（Illegal key descriptor）：part过多或过长（too many parts or too long） 的错误，通常说明该表的分区页上的 Slot 4 出现了问题，而不是索引本身存在问题。由于删除索引时需要使用其键描述符（key descriptor），因此损坏的键描述符有时需要 IBM Informix 技术支持介入才能修复。</code></p><p><strong>•</strong> Slot 5 contains extent information. Each 8-byte entry in this slot includes:</p><p><code>slot 5 包含 extent 信息。该 slot 中的每个 8 字节条目包括</code></p><p>​     <strong>-</strong> the logical page number of that extent’s first page within the tblspace (4 bytes)</p><p>​    <code>tblspace 中该 extent 第一页的逻辑页码（4 个字节）</code></p><p>​     <strong>-</strong> the page offset of the extent into the dbspace (4 bytes)</p><p>​    <code>dbspace 中 extent 的页面偏移量（4 个字节）</code></p><p>​    The slot also includes one “on-deck” entry that includes the logical page number for the next extent allocated.</p><p>​    <code>slot还包括一个 “on-deck ”条目，其中包括下一个已分配extent的逻辑页码。</code></p><p>​slot 5 看不懂</p><p>A table could also have a sixth slot, but it does not appear on the main partition page for that table. The sixth slot is used to describe different versions of extents that result from altering a table in-place. This slot appears on a separate page in the tblspace tblspace.</p><p><code>表也可以有第六个slot，但它不会出现在该表的 main partition page 上。第六个 slot 于描述因就地更改表而产生的不同 extent 版本。该 slot 在 tblspace tblspace 中的一个单独页面上。</code></p><p>什么叫 main partition page，第一页？</p><p><strong>Slot 1: The Partition Structure</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">TBLspace Report <span class="keyword">for</span> testdb:root.t1</span><br><span class="line"></span><br><span class="line">    Physical Address               13:570</span><br><span class="line">    Creation <span class="built_in">date</span>                  05/08/2025 05:05:57</span><br><span class="line">    TBLspace Flags                 902        Row Locking</span><br><span class="line">                                              TBLspace contains VARCHARS</span><br><span class="line">                                              TBLspace use 4 bit bit-maps</span><br><span class="line">    Maximum row size               16</span><br><span class="line">    Number of special columns      1</span><br><span class="line">    Number of keys                 0</span><br><span class="line">    Number of extents              1</span><br><span class="line">    Current serial value           1</span><br><span class="line">    Current SERIAL8 value          1</span><br><span class="line">    Current BIGSERIAL value        1</span><br><span class="line">    Current REFID value            1</span><br><span class="line">    Pagesize (k)                   2</span><br><span class="line">    First extent size              8</span><br><span class="line">    Next extent size               8</span><br><span class="line">    Number of pages allocated      8</span><br><span class="line">    Number of pages used           2</span><br><span class="line">    Number of data pages           1</span><br><span class="line">    Number of rows                 4</span><br><span class="line">    Partition partnum              13631559</span><br><span class="line">    Partition lockid               13631559</span><br><span class="line"></span><br><span class="line">    Extents</span><br><span class="line">         Logical Page     Physical Page        Size Physical Pages</span><br><span class="line">                    0           13:2087           8          8</span><br></pre></td></tr></table></figure><p><strong>Notes:</strong></p><p>The partition structure is stored in the first slot on every partition page and holds general information about the corresponding table. You can view the partition structure for any table by running the command:</p><p><code>partition structure 存储在每个 partition page 的第一个 slot 中，包含相应表的一般信息。运行该命令可以查看任何表的 partition structure：</code></p><p>​oncheck -pt <em>database_name</em>:<em>table_name</em></p><p>Instead of a database and table name, you can provide a partition number:</p><p>​oncheck -pt 1048672</p><p>The output of this command consists of slightly-massaged versions of the partition structure (slot 1) and the extent structure (slot 5) for the partition page. An example of <strong>oncheck</strong> output for the partition structure is shown in the slide above.</p><p><code>该命令的输出包括partition structure（slot 1）和 partition page 的 extent structure（slot 5）的略微简化版本（最后3行）。上面的幻灯片显示了 partition structure 的 oncheck 输出示例。</code></p><p>You might recognize some of the general tblspace information stored in the partition structure as table statistics, also stored in system catalogs for use by the optimizer. In fact, during some UPDATE STATISTICS operations, some information from a table’s partition page is copied into system catalogs, while other information must be gathered by reading the tblspace pages themselves. Although the system catalog information can become out of date as the table grows and changes, the information on the partition page should always be accurate. However, the optimizer code is meant to be portable across Informix servers and it, therefore, does not know how to access a partition page. As far as the optimizer is concerned, the only table statistics available are stored in system catalogs.</p><p><code>你可能会注意到，partition structure 中存储的一些通用表空间（tblspace）信息，与存储在系统目录（system catalogs）中的表统计信息相似，这些统计信息被优化器（optimizer）用于优化查询。实际上，在某些 </code>UPDATE STATISTICS<code> 操作中，部分表的分区页（partition page）中的信息会被复制到 system catalogs 中，而其他信息则必须通过读取表空间页（tblspace pages）来收集。尽管系统目录中的信息可能会随着表的增长和变化而变得过时，partition page 中的信息应始终是准确的。然而，优化器的代码是为了在不同的 Informix server 之间具备可移植性，因此它并不了解如何访问 partition page。就优化器而言，唯一可用的表统计信息就是存储在 system catalogs 中的那些。</code></p><blockquote><p>gather 聚集 英[ˈɡæðə(r)] 美[ˈɡæðər]</p></blockquote><p>前边说，为了简洁，把 tblspace tblspace page 叫做 partition page，那 tblspace pages 是什么？先不管它，好像 Unit 4 有讲</p><p><strong>Physical Address</strong> (decimal:decimal) – This is not the partition number, nor is it an address related to any tblspace extent. Unlike the rest of the elements displayed, the physical address is not even part of the partition structure. The oncheck report is simply displaying the physical location (chunk number and page offset) of the partition page from which the rest of the information has been taken.</p><p><code>这不是 partition number，也不是与任何 tblspace extent 相关的地址。与显示的其他元素不同，物理地址甚至不是 partition structure 的一部分。oncheck 只是显示 partition page 的物理位置（chunk number 和 page offset），其他信息都是从该页面获取的。</code></p><p><strong>Creation date</strong> – This is the date and time this table was created.</p><p><code>这是该表的创建日期和时间。</code></p><p><strong>TBLSpace Flags</strong> (decimal) – These flags operate as page flags, dbspace flags, and chunk flags do, coagulating in one integer with the help of the logical OR. Individual tblspace flags have the following values and meanings:</p><p><code>这些 flags 与 page flags, dbspace flags 和 chunk flags 一样，在逻辑 OR 的帮助下合并为一个整数。各个 tblspace 标志的值和含义如下：</code></p><blockquote><p>coagulate 英[kəʊˈæɡjuleɪt] 美[koʊˈæɡjuleɪt]<br>v.(使)凝结，凝固;<br>n.（&#x3D;coagulum）凝结物(如血块);<br>adj.&lt;古&gt;凝结的;</p></blockquote><p>0x0001 Page-level locking</p><p><code>页级锁</code></p><p>0x0002 Row-level locking</p><p><code>行级锁</code></p><p>0x0004 Tblspace is a Bundlespace (OnLine secure)</p><p>看不懂</p><p>0x0008 Partition marked for DDR replication</p><p>和ER有关吧，看不懂</p><p>0x0010 Partition dropped (shared memory only)</p><p>0x0020 System-defined temporary table</p><p>0x0040 User-defined temporary table</p><p>0x0080 Tblspace used for sorting</p><p>0x0100 Contains VARCHAR column(s)</p><p>0x0200 Contains BLOBspace BLOB column(s)</p><p>0x0400 Contains partition-resident BLOB column(s)</p><p>0x0800 Requires 4-bit bitmap</p><p>0x1000 Contains optical BLOB column(s)</p><p>0x2000 Partition required for system to function - do not drop</p><p>0x4000 Temp table being used for special function - do not update</p><p>0x8000 Partition is being appended to</p><p><strong>Maximum row size</strong> (decimal) – For tables with fixed-length rows, this value is simply the row size in bytes. The concept of a <em>maximum</em> row size becomes necessary only when a tblspace contains VARCHAR columns. Recall that a VARCHAR column is defined with a minimum and a maximum size, in units of characters, which is equivalent to bytes. The maximum size of a VARCHAR column, plus one byte of overhead (in which to store the actual size of the VARCHAR data) is added with the sizes of the other columns in the schema to arrive at this <em>maximum row size</em> figure.</p><p><code>对于具有固定长度行的表，该值就是以字节为单位的行大小。只有当 tblspace 包含 VARCHAR 列时，才有必要使用最大行大小的概念。回想一下，VARCHAR 列的最小和最大大小是以字符为单位定义的，相当于字节。VARCHAR 列的最大大小加上一个字节的开销（用于存储 VARCHAR 数据的实际大小），再加上模式中其他列的大小，就得出了最大行大小这个数字。</code></p><blockquote><p>figure 英[ˈfɪɡə(r)] 美[ˈfɪɡjər]<br>n.图形;人物;人，动物;（书中的）图，表;身材;位数;花样;（远处人的）轮廓;（人、动物的）雕像，塑像;算术;数字符号;字码;(代表数量，尤指官方资料中的)数字;<br>v.是…的部分;计算(数量或成本);认为，认定(某事将发生或属实);是重要部分;</p></blockquote><p>知乎这回答应该是oracle里schema的概念。IX9111这段中的schema先理解成包含columns的数据库对象吧，如：表</p><blockquote><p>知乎：</p><p>在学习数据库时，会遇到一个让人迷糊的Schema的概念。实际上，<a href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=schema&zhida_source=entity">schema</a>就是<a href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E8%B1%A1&zhida_source=entity">数据库对象</a>的集合，这个集合包含了各种对象如：表、视图、<a href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B&zhida_source=entity">存储过程</a>、索引等。</p><p>如果把database看作是一个仓库，仓库很多房间（schema），一个schema代表一个房间，table可以看作是每个房间中的储物柜，user是每个schema的主人，有操作数据库中每个房间的权利，就是说每个数据库映射user有每个schema（房间）的钥匙。</p></blockquote><p><strong>Number of special columns</strong> (decimal) – Blob and VARCHAR columns are considered <em>special</em>, Informix Dynamic Server-only column types.</p><p><code>Blob 和 VARCHAR 列被认为是特殊的，仅限 IDS 使用的列类型。</code></p><p><strong>Number of keys</strong> (decimal) – The total number of indexes defined for the table. A composite index can be made from several columns, but still has only one index <em>key</em>.</p><p><code>为表定义的索引总数。复合索引可以由多个列组成，但仍然只有一个索引键。</code></p><p><strong>Number of extents</strong> (decimal) – The number of separate extents allocated to the table. Extent concatenation and doubling, and good tblspace management on the part of the Informix Dynamic Server administrator, tend to keep this number low. As the number of extents for a tblspace grows, not only can data be scattered unpredictably (a performance problem for sequential reads), but the extent slot on the partition page grows. An extent slot can contain only so many entries before it runs out of room. Because other slots on the partition page, such as slot 4, can also grow dynamically, there is no way to publish a maximum number of tblspace extents with any accuracy. Empirical evidence has shown the maximum number of extents on a 2K-page is approximately 190.</p><p><code>分配给表的独立extent的数量。extent的拼接与倍增（机制），以及 IDS 管理员对表空间（tblspace）的良好管理，往往能将这一数量保持在较低水平。随着 tblspace 的extent 数量增加，不仅数据会不可预测地分散（对于顺序读取来说是个性能问题），而且 partition page 上的 extent slot 也会增加。在空间耗尽之前，一个 extent slot 只能容纳这么多条目。由于 partition page 上的其他 slot（如 slot 4）也会动态增长，因此无法准确发布 tblspace extents 的最大数量。经验表明，2K 页面上的最大扩展项数量约为 190 个。</code></p><p>extent slot 是 slot 5 上 extent list 中的元素？</p><blockquote><p>scatter 分散 英[ˈskætə(r)] 美[ˈskætər]</p><p>predictably 可推断 美[prɪˈdɪktəbli]</p><p>empirical 英[ɪmˈpɪrɪkl] 美[ɪmˈpɪrɪkl] adj.经验主义的;以实验(或经验)为依据的;</p><p>approximately 大概 英[əˈprɒksɪmətli] 美[əˈprɑːksɪmətli]</p></blockquote><p><strong>Current serial value</strong> (decimal) – A tblspace can contain only one serial column. If one exists, this is the next value that is used for an insert. If there is no serial column in the table, this value remains 1.</p><p><code>一个 tblspace 只能包含一个 serial 列。如果存在 serial 列，则下一个值将用于插入。如果表中没有 serial 列，该值将保持为 1。</code></p><p><strong>First extent size</strong> (decimal) – This is the configured EXTENT SIZE, in units of Informix Dynamic Server pages. The units here can be a bit confusing because through SQL, one specifies EXTENT SIZE in kilobytes.</p><p><code>这是配置的 EXTENT SIZE，以 IDS page 为单位。这里的单位可能有点令人困惑，因为通过 SQL，我们可以用 KB 来指定 EXTENT SIZE。</code></p><p>The default EXTENT SIZE is 8 pages, regardless of the page size. The minimum extent size is 4 pages.</p><p><code>无论页面大小如何，默认 extent 大小为 8 页。最小 extent 大小为 4 页。</code></p><p><strong>Next extent size</strong> (decimal) – This is the configured NEXT SIZE, also in units of Informix Dynamic Server pages. Note that at the SQL level one specifies NEXT SIZE in units of kilobytes, so like First extent size, the value here is initially either half or one quarter the number used with the NEXT SIZE clause in SQL.</p><p><code>这是配置的 NEXT SIZE，也是以 IDS page 为单位。请注意，在 SQL 级别，NEXT SIZE 是以 KB 为单位指定的，因此与 First extent size 一样，这里的值最初是 SQL 中 NEXT SIZE 子句所用数字的一半或四分之一。</code></p><blockquote><p>chatgpt:</p><h3 id="具体解释如下："><a href="#具体解释如下：" class="headerlink" title="具体解释如下："></a>具体解释如下：</h3><ul><li>在 SQL 中，<code>NEXT SIZE</code> 是以 <strong>KB（千字节）</strong> 为单位指定的。</li><li>在内部，Informix 使用的是 <strong>页（page）</strong> 为单位的存储方式，比如常见的页大小是 <strong>2KB</strong> 或 <strong>4KB</strong>。</li></ul><h4 id="示例说明："><a href="#示例说明：" class="headerlink" title="示例说明："></a>示例说明：</h4><ul><li>如果你的数据库页大小是 <strong>2KB</strong>：<ul><li>你在 SQL 中写 <code>NEXT SIZE 64</code>（表示 64KB）；</li><li>那么转换成页就是：<code>64KB ÷ 2KB = 32 页</code>；</li><li>此时内部记录的 NEXT SIZE 就是 32。</li></ul></li><li>如果页大小是 <strong>4KB</strong>：<ul><li>同样的 SQL 指定 <code>NEXT SIZE 64</code>；</li><li>内部转换成页就是：<code>64KB ÷ 4KB = 16 页</code>；</li><li>所以内部值会是 16。</li></ul></li></ul><p>因此：</p><p>如果页大小是 2KB，则内部值是 SQL 值的一半；<br>如果页大小是 4KB，则内部值是 SQL 值的四分之一。</p></blockquote><p>Next extent size can increase over time due to extent size doubling. The size never decreases unless the table is deliberately altered. The default for the next extent size is 8 pages. The minimum extent size is 4 pages.</p><p><code>由于 extent 大小的倍增机制，Next extent size 可能会随着时间推移而增加。除非对表进行显式修改，否则该大小不会减少。Next extent size 的默认值是 8 页，最小值为 4 页。</code></p><blockquote><p>deliberately 故意 英[dɪˈlɪbərətli] 美[dɪˈlɪbərətli]</p></blockquote><p><strong>Number of pages allocated</strong> (decimal) – This is the total number of pages, whether used or not, contained in the extents allocated to the tblspace.</p><p><code>这是分配给表空间（tblspace）的所有 extent 中包含的页数总和，无论这些页是否已被使用。</code></p><p><strong>Number of pages used</strong> (decimal) – This is the maximum number of pages that have ever been used in the tblspace.</p><p><code>这是 tblspace 中使用过的最大页数。</code></p><p><strong>Number of data pages</strong> (decimal) – This is the number of data pages currently in use in the tblspace. When all rows are deleted from a data page, the page is freed for reuse in the tblspace, and the <strong>Number of data pages</strong> element of the partition structure is decremented.</p><p><code>这是当前在 tblspace 中使用的数据页数。当从数据页中删除所有行时，该页将被释放以供在 tblspace 中重复使用，并且 partition structure 中的“Number of data pages”元素将减少。</code></p><p><strong>Number of rows</strong> (decimal) – This indicates the number of rows in the tblspace.</p><p><code>这表示 tblspace 中的行数。</code></p><p><strong>Partition partnum</strong> (decimal) – This indicates the partition number of the tblspace.</p><p><code>这表示 tblspace 的 partition number。</code></p><p><strong>Partition lockid</strong> – It used to be that when you locked an Informix Dynamic Server table, you were really locking a partition number. This works as long as there is a one-to-one correspondence between database tables and Informix Dynamic Server partition numbers. But fragmentation allows many partitions to be associated with one database table. Rather than associate the partnums of every table fragment with a single table lock, Informix Dynamic Server uses this value, the lockid, to represent all table fragments.</p><p><code>过去，锁定 IDS 表时，实际上是锁定一个 partition number。只要数据库表和 IDS partition number 之间存在一一对应关系，这种方法就能奏效。但分片允许将许多 partition 与一个数据库表关联起来。IDS 不会将每个表片段的分区号与单个表锁相关联，而是使用 lockid 这个值来代表所有表片段。</code></p><p><strong>The Partition Page Location</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171729739.png" alt="image-20250517172857535"></p><p><strong>Notes:</strong></p><p>Dynamic Server determines the location of a table’s partition page based on that table’s partition number, which is stored in <strong>systables.partnum</strong>. Upon reading a partition page, the database server can check that it has found the correct one by scanning the first 4-byte element in the partition structure. This first element contains the partition number. Here is an example:</p><p><code>IDS 根据表的 partition number 确定表的 partition page 位置，partition number 存储在 systables.partnum 中。读取 partition page 时，server 可通过扫描 partition structure 中的第一个 4 字节元素来检查是否找到了正确的 partition page。第一个元素包含 partition number。下面是一个示例：</code></p><ol><li><p>The database server receives a request to access the <strong>items</strong> table.</p><p><code>server 收到访问 items 表的请求。</code></p></li><li><p>In order to find the partition page for the <strong>items</strong> table, the server must determine its partition number. The database server selects the <strong>partnum</strong> value from <strong>systables</strong>.</p><p><code>为了找到 items 表的 partition page，server 必须确定其 partition number。server 从 systables 中查询 partnum 值。</code></p></li><li><p>Based on the partition number, a hex code comprised of a dbspace number and a logical page number, IDS reads a specific partition page from a specific tblspace tblspace.</p><p><code>根据partition number（由 dbspace 编号和逻辑页码组成的十六进制代码），IDS 会从特定的 tblspace tblspace 中读取特定的 partition page。</code></p></li><li><p>To check its work, the Dynamic Server process reads the first element of the partition structure found in slot 1 on the partition page, comparing the value found there against the partition number selected from <strong>systables</strong> during step 2 above.</p><p><code>为检查其工作，server 进程会读取 partition page slot 1 中 partition structure 的第一个元素，并将其中的值与上述第 2 步中从 systables 查询的 partition number 进行比较。</code></p></li><li><p>If the two partition numbers match, the operation has so far been successful. If they differ, the database server writes an assertion failure message to the message log and returns errors 242 and 135 to the client process.</p><p><code>如果两个 partition number 匹配，则操作成功。如果不一致，server 会在消息日志中写入断言失败消息，并向客户进程返回错误 242 和 135。</code></p></li></ol><p><strong>Slot 5: The Extent Slot</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171743215.png" alt="image-20250517174318102"></p><p><strong>Notes:</strong></p><p>The extent slot, slot 5 of a partition page, is an array of 8-byte entries, each of which describes one extent for the table. The information stored in each 8-byte extent entry consists of two 4-byte values: the logical page number (within the tblspace) of the start of the extent, and the offset of that page into the dbspace.</p><p><code>extent slot（partition page 的第 5 slot）是一个 8 字节条目的数组，每个条目描述表的一个 extent。每个 8 字节 extent 条目中存储的信息由两个 4 字节值组成：extent 起始的逻辑页码（在 tblspace 中），以及该页在 dbspace 中的偏移量。</code></p><p>For instance, consider the following entry in the extent slot shown in the slide above (the display format is modified to make interpretation easier):</p><p><code>例如，请看上面幻灯片中显示的 extent slot 中的以下条目（为便于解释，对显示格式进行了修改）：</code></p><p>​0000 0020 0000 0665</p><p>This entry describes an extent whose first page is located on the 1637th (0x665) page of dbspace number 1. With respect to the extent’s tblspace, the extent starts on logical page 32 (0x20).</p><p><code>此条目描述了一个 extent，其首页位于 1 号 dbspace 的第 1637 (0x665) 页。对于该 extent 的 tblspace，该范围从逻辑页 32 (0x20) 开始。</code></p><p>Every extent slot ends with an <em>on-deck</em> or <em>cap</em> extent entry, one poised to accept the dbspace offset of the next allocated extent. Serving as a kind of cap on the array, the last extent entry contains the logical page number for the next extent to be allocated, and a null value to act as placeholder for the dbspace offset for that extent.</p><p><code>每个 extent slot 最后都有一个 on-deck 或 cap  extent条目，准备接受下一个分配 extent 的 dbspace 偏移量。作为数组的一种上限，最后一个 extent 条目包含下一个要分配的 extent 的逻辑页码，以及一个空值，作为该 extent 的 dbspace 偏移量的占位符。</code></p><blockquote><p>poised 英[pɔɪzd] 美[pɔɪzd]<br>adj. 摆好姿势准备行动的</p></blockquote><p><strong>Slot 6: Page Versioning</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171849672.png" alt="image-20250517184920542"></p><p><strong>Notes:</strong></p><p>If a table is altered and the database server is able to alter the table in-place, then an additional slot is required to handle the versioning of extents in the tblspace.</p><p><code>如果更改了表，且 server 能够就地更改表，则需要一个额外的 slot 来处理 tblspace 中 extent 的版本管理。</code></p><p>An <em>in-place alter</em> occurs when an ALTER TABLE command is executed and the changes to the table structure do not require a table rebuild. Instead, the database server simply records the change on an additional page in the tblspace tblspace. This page is an extension of the partition page and the only slot on this page is identified as <em>slot 6</em>. The logical page number of the new page is placed in the <strong>pg_next</strong> field in the header of the original <em>partition</em> page.</p><p><code>当执行 ALTER TABLE 命令，表结构的更改不需要重建表时，就会发生就地更改。此时，server 只需在 tblspace tblspace 中的一个附加页面上记录更改。该页面是 partition page 的扩展，页面上唯一的 slot 被标识为 slot 6。新页面的逻辑页码放在原始 partition 页头的 pg_next 字段中。</code></p><p>chatgpt 和 gemini 都将 Instead 翻译成”此时“，DeelL翻译成”相反“感觉确实不合适</p><p>If a row in the altered table is updated and there is room on the page for all rows to be converted to the new version, then all rows are updated and the new version is recorded on the page. If there is not enough room for all rows on the page to be reversioned, then the updated row is altered and moved to a page that only contains rows of the same version. The version number is recorded in the <strong>pg_next</strong> field in the header of each <em>data</em> page.</p><p><code>如果修改后的表中的某一行被更新，并且页面上有足够的空间将所有行转换为新版本，那么所有行都会被更新，并且新版本信息会被记录在该页面上。如果页面空间不足，无法对所有行进行版本转换，则更新的那一行会被修改并移动到一个仅包含相同版本行的页面中。版本号会被记录在每个数据页（data page）页头的 pg_next 字段中。</code></p><blockquote><p>chagpt</p><h3 id="一、表结构更改会引入“版本”概念"><a href="#一、表结构更改会引入“版本”概念" class="headerlink" title="一、表结构更改会引入“版本”概念"></a>一、表结构更改会引入“版本”概念</h3><p>当你使用 <code>ALTER TABLE</code>（比如增加列、修改字段类型）修改表结构时，如果数据库支持 <strong>in-place alter</strong>，它不会立即重建整张表，而是通过“版本管理”来处理这种变化。</p><p>也就是说：</p><ul><li>表的旧结构是“版本1”；</li><li>修改后生成一个“版本2”的结构；</li><li>原先的旧行仍然保持版本1的格式，直到被访问或更新。</li></ul><hr><h3 id="二、为什么更新一行可能会影响整页？"><a href="#二、为什么更新一行可能会影响整页？" class="headerlink" title="二、为什么更新一行可能会影响整页？"></a>二、为什么更新一行可能会影响整页？</h3><p>Informix 之类的数据库系统出于 <strong>存储和性能优化考虑</strong>，往往会这样设计：</p><blockquote><p><strong>同一个数据页（data page）中尽量只存储相同结构版本的记录。</strong></p></blockquote><p>这就意味着：</p><ol><li>如果一页中原本存储的全是版本1的行；</li><li>你更新了其中的一行（让它变成了版本2）；</li><li>数据库会检查这一页是否有足够空间，把<strong>这整页中的所有行都转换成版本2</strong>；</li><li>如果空间够，就一并转换并更新页面元数据；</li><li>如果空间不够，只更新这一行，并把它迁移到一个专门存放版本2记录的新页中。</li></ol><hr><h3 id="三、这样做的目的是什么？"><a href="#三、这样做的目的是什么？" class="headerlink" title="三、这样做的目的是什么？"></a>三、这样做的目的是什么？</h3><p>主要是为了：</p><ul><li><strong>简化行的读取逻辑</strong>：读取时不需要一行一行地判断是哪个版本；</li><li><strong>提高性能</strong>：相同版本的行可以共享解析逻辑，减少额外开销；</li><li><strong>支持表结构的动态演进</strong>，避免一次性重写整表带来的高成本。</li></ul></blockquote><p>Since a table can be altered several times, the database server uses <em>versioning</em> to keep track of which version of the table is used to describe the pages in an extent that contain updated rows.</p><p><code>由于一张表可能会被多次修改，server 使用版本控制（versioning）来跟踪用于描述包含已更新行的 extent 中各页面所对应的表结构版本。</code></p><p>Slot 6 contains the following information:</p><p> <strong>•</strong> Version number</p><p> <strong>•</strong> Number of columns added in this version</p><p> <strong>•</strong> Number of pages that contain rows that have not been modified</p><p> <strong>•</strong> Logical page number in the tblspace tblspace where descriptor information is stored</p><p> <strong>•</strong> Uncompressed size of a row before the table was altered</p><p> <strong>•</strong> Uncompressed size of a row after the table was altered</p><p><strong>The Physical Log</strong></p><p>Some important facts:</p><p>– The physical log is used during fast recovery.</p><p><code>物理日志用于快速恢复。</code></p><p>– In most customer systems, the physical log is set too small causing checkpoints too occur too frequently.</p><p><code>在大多数客户的系统中，物理日志设置得过小，导致检查点出现得过于频繁。</code></p><p>– It can be moved outside the root dbspace, and usually should be.</p><p><code>它可以移到 root dbspace 之外，通常也应该这样做。</code></p><p><strong>Notes:</strong></p><p>While the physical log might not be of much use in a system that runs perfectly every day of the year, it is crucial to Informix Dynamic Server’s fast recovery mechanism as well as its archiving algorithm, both of which can come in quite handy in the world of power failures and disk crashes that most of us inhabit.</p><p><code>虽然物理日志在全年每天都完美运行的系统中可能用处不大，但它对 IDS 的快速恢复机制及其归档算法却至关重要，而在我们大多数人所处的这个充满断电和磁盘崩溃的现实世界中，这两者往往非常有用。</code></p><blockquote><p>inhabit 英[ɪnˈhæbɪt] 美[ɪnˈhæbɪt]<br>vt.居住在;栖居于;</p></blockquote><p>The initial size of the physical log is usually much too small, which can cause checkpoints to occur much too frequently. Sizing the physical log too small is a common mistake of novice administrators.</p><p><code>物理日志的初始大小通常太小，这可能会导致检查点出现得过于频繁。将物理日志设置得过小是新手管理员常犯的错误。</code></p><p><strong>Physical Log Page Structure</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172010750.png" alt="image-20250517201048659"></p><p><strong>Notes:</strong></p><p>The slide above shows the structure of a physical log page. Pages in the physical log are identical to their pages of origin. The only way to tell that a page came from the physical log is by looking at the page address (offset and chunk). The page contains the address of the original page location and not the physical location within the physical log.</p><p><code>上面的幻灯片展示了一个物理日志页的结构。物理日志中的页面与它们原始来源的页面是完全相同的。判断一个页面是否来自物理日志的唯一方法是查看其页地址（偏移量和chunk号）。该页面记录的是原始页面的位置地址，而不是其在物理日志中的实际物理位置。</code></p><blockquote><p>identical 完全相同的 英[aɪˈdentɪkl] 美[aɪˈdentɪkl]</p></blockquote><p><strong>Logical Log File Structure</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172017022.png" alt="image-20250517201756936"></p><p><strong>Notes:</strong></p><p>Each logical log is a string of contiguous log pages. Each page within an individual log is numbered, beginning with 0. The location of that number on the page is shown in the next slide.</p><p><code>每个逻辑日志由一串连续的日志页组成。每个日志中的页面都从编号 0 开始。该编号在页面中的位置将在下一张幻灯片中展示。</code></p><p>上图就是一个逻辑日志，有一连串的逻辑日志页面，从编号0开始</p><p>Keep in mind that a <em>log file</em> is an extent within a chunk that does not go anywhere and is constantly overwritten. A log file serves as the temporary home of a <em>logical log</em>, which is unique. It is the logical log, not the log file, that is backed up to tape.</p><p><code>请记住，日志文件（log file）是位于某个 chunk 中的一个 extent，它不会被移动，并且会被不断覆盖。日志文件是某个逻辑日志（logical log）的临时存储位置，而每个逻辑日志都是唯一的。被备份到磁带上的，是逻辑日志，而不是日志文件。</code></p><p>A logical log can contain any number of pages from one to the total number available in a log file.</p><p><code>一个逻辑日志可以包含任意数量的页面，从1页到日志文件中可用的总页数。</code></p><p>Logical log pages are manufactured one after another in the logical log buffer, and written out in series each time the buffer is flushed.</p><p><code>逻辑日志页在逻辑日志缓冲区中逐个生成，并在每次刷新缓冲区时按顺序写出。</code></p><blockquote><p>manufacture<br>英[ˌmænjuˈfæktʃə(r)] 美[ˌmænjuˈfæktʃər]<br>vt.制造;产生(一种物质);生成;(用机器)大量生产;捏造;编造;成批制造;<br>n.批量生产;工业品;大量制造;</p></blockquote><p><strong>Logical Log Page Structure</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172036583.png" alt="image-20250517203607494"></p><p><strong>Notes:</strong></p><p>The structure of a logical log page, as pictured above, might suggest the sequential method by which log records are generally accessed. Note for example that the page has no slot table. (The length of each record is stored within the record itself.) Note also that logical log data is very fluid, spilling from one page onto the next without fanfare (though a record must be fully contained within a log file). Even the page header has a few surprises.</p><p><code>如上图所示，逻辑日志页的结构可能暗示了日志记录通常是以顺序方式访问的。比如，请注意该页面没有 slot table，因为每条记录的长度是保存在记录本身中的。还要注意，逻辑日志数据非常灵活，可以自然地从一个页面延伸到下一个页面（不过一条记录必须完整地存储在同一个日志文件中）。甚至页头也有一些惊喜。</code></p><blockquote><p>fluid英[ˈfluːɪd] 美[ˈfluːɪd]<br>n.液体;流体;液;<br>adj.流体的;流动的;不稳定的;易变的;流畅优美的;</p><p>spilling 英[ˈspɪlɪŋ] 美[ˈspɪlɪŋ]<br>v.(使)洒出，泼出，溢出;涌出;蜂拥而出;<br>n.木片，纸捻；洒出量；摔下，跌落;（Spilling）（挪、英、美）施皮林（人名）;</p><p>fanfare 英[ˈfænfeə(r)] 美[ˈfænfer]<br>n.大张旗鼓;号角花彩，号角齐鸣(欢迎仪式等上奏的响亮短曲);(为庆祝而在媒体上的)喧耀;</p></blockquote><p><strong>pg_nslots</strong></p><p>This is unused, since there is no real concept of slots on a log page.</p><p><code>这是未使用的，因为日志页面上没有真正的slot概念。</code></p><p><strong>pg_frcnt</strong></p><p>This is always zero, even for pages that are not full (note that <strong>pg_frptr</strong> is accurate). The reason has more to do with coincidence than design.</p><p><code>即使页面未满，该值也始终为0（请注意，pg_frptr 是准确的）。其原因更多是巧合，而非设计。</code></p><p>下面解释为什么是0</p><blockquote><p>coincidence 巧合 英[kəʊˈɪnsɪdəns] 美[koʊˈɪnsɪdəns]</p></blockquote><p>Log pages within the log buffer are allowed to fill to the last byte, usually continuing the last record on the next page. So a large number of log pages are truly full, especially when buffered logging is used exclusively.</p><p><code>日志缓冲区内的日志页可以填满到其最后一个字节，通常会将最后一条记录延续到下一页。因此，大量的日志页会真正地被完全填满，尤其是在只使用（或：专门采用）缓冲日志记录（buffered logging）的情况下。</code></p><p>However, an early buffer flush, forced by a checkpoint or a commit record for a database with unbuffered logging, for example, tend to come at a time when the last page in the buffer is only partly full. Once flushed to the log file, a log page cannot be changed; additional records cannot be added to it. The reason even these pages have a <strong>pg_frcnt</strong> of 0 is this: just before the log buffer is flushed, the flushing process sets the value of <strong>pg_frcnt</strong> on the last page in the buffer to 0, making the page look artificially full in order to prevent another engine process from writing to the page while the I&#x2F;O is being performed.</p><p><code>然而，例如由检查点 或 采用非缓冲日志记录的数据库的提交记录 所触发的提前缓冲区刷新，往往发生在缓冲区最后一页仅部分填充之时。日志页一旦刷新到日志文件便无法更改，也不能再向其添加额外记录。即便这些页面仅部分填充，其 pg_frcnt 值也为0，原因如下：在日志缓冲区刷新前夕，刷新进程会将缓冲区最后一页的 pg_frcnt 值设为0，从而人为地将该页标记为“已满”，以防止在I/O操作执行期间，其他引擎进程尝试写入该页。</code></p><p><strong>pg_next</strong></p><p>On a logical log page, this element of the page header contains the unique ID of the logical log.</p><p><code>在逻辑日志页面上，页头的这一元素包含逻辑日志的唯一 ID。</code></p><p><strong>pg_prev</strong></p><p>On a logical log page, this element of the page header contains the page offset (similar to a logical page number) of the log page. Note that this is the offset within the log, and as always, page offsets begin with 0.</p><p><code>在逻辑日志页中，页头的这一元素包含日志页的页面偏移量（类似于逻辑页码）。请注意，这是在日志中的偏移量，而页面偏移量总是以 0 开始。</code></p><p><strong>Logical Log Position (Logpos)</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172120865.png" alt="image-20250517212040764"></p><p><strong>Notes:</strong></p><p>Log records are uniquely addressed only within a particular logical log. The address used is called a <em>logical log position</em>, or <em>logpos</em> for short. It is a 4-byte integer code that describes the position of a log record in terms of a page offset and a byte offset. The page offset is with respect to the beginning of the log, and is indexed from 0. The byte offset is with respect to the beginning of the page, and is also indexed from 0, though because of the space taken by the page header, this value should never be less than 0x018.</p><p><code>日志记录只能在特定逻辑日志中唯一寻址。使用的地址称为 logical log position，简称 logpos。它是一个 4 字节整数代码，用页面偏移和字节偏移来描述日志记录的位置。页面偏移量相对于日志的起始位置，索引从 0 开始。 字节偏移量相对于页面的起始位置，索引也从 0 开始，但由于页面头占用了空间，该值不应小于 0x018。</code></p><p><strong>Hint</strong></p><p>Assume you are told a logical log record is located in a logical log with a unique ID of 234 and a logpos of 0x12018. How would you find it? Using the more current of your two checkpoint&#x2F;logical log reserved pages in the root chunk, you could find the physical address of log number 234. Once at that page, you would offset 0x12 pages into the log to find the correct log page, then 0x018 bytes into that page to find the log record.</p><p><code>假设有一条逻辑日志记录位于逻辑日志中，其唯一 ID 为 234，logpos 为 0x12018。你将如何找到它？使用 root chunk 中两个 checkpoint/logical log 保留页面中的最新页面，可以找到日志编号 234 的物理地址。找到该页面后，在日志中偏移 0x12 页，找到正确的日志页，然后在该页中偏移 0x018 字节，找到日志记录。</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 2. The Dynamic Server Page</title>
      <link href="/2025/05/05/IX9111/2/"/>
      <url>/2025/05/05/IX9111/2/</url>
      
        <content type="html"><![CDATA[<p><strong>Page: Smallest Unit of I&#x2F;O</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052201901.png" alt="image-20250505220102809"></p><p><em>Pages</em> are the most basic unit of I&#x2F;O in Informix Dynamic Server; a server process does not read or write to a chunk in an increment smaller than a page. As often as possible, however, I&#x2F;O is performed on more than one page at a time.</p><p><code>在 IDS 中，页是 I/O 的最基本单位；服务进程在访问一个 chunk 时，读取或写入的最小单位就是一个页面。不过，I/O 通常会同时在多个页面上执行。</code></p><p>The default page size for a machine is either 2KB or 4KB depending on the platform. You can configure the page size for each dbspace to be any value from 2KB to 16KB, but the value must be divisible by the default page size.</p><p><code>机器的默认页面大小为 2KB 或 4KB，具体取决于平台。你可以将每个dbspace的page size配置为 2KB 至 16KB 之间的任意值，但该值必须能被默认页面大小整除。</code></p><p>At a binary level, each allocated page in a system contains a unique stream of data. But the structure and meaning of that data is always based on a handful of templates. This module teaches you how to recognize the structural similarities between Dynamic Server pages, and decipher the important parts of those structures. These skills help you understand Dynamic Server architecture and behavior to a degree you never thought possible.</p><p><code>在二进制层面上，系统中分配的每个页面都包含唯一的数据流。但这些数据的结构和含义总是基于一些模板。本模块教你如何识别 Dynamic Server 页面之间的结构相似性，并解读这些结构的重要部分。这些技能将帮助你理解 Dynamic Server 结构和行为，达到你从未想象过的程度。</code>  </p><p><strong>Our Imagined View of a Page</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052211934.png" alt="image-20250505221109866"></p><p><code>Linux中的od命令是一个十六进制和其他进制的转换工具，它可以用于显示二进制文件的内容。-x：以十六进制的形式显示文件内容；</code></p><p>It is rarely convenient to picture a block of bytes as a continuous stream. Our preference is to reorganize the bytes so they can be viewed as if words are seen on a printed page.</p><p><code>将字节块想象成连续的数据流并不方便。我们更倾向于重新组织字节，使它们可以像印刷页面上的文字一样被查看。</code></p><p>In the example above, the <strong>od</strong> (octal dump) utility in UNIX and Linux displays a byte stream from a page. In this output, the numbers on the left represent byte offsets in <em>octal</em> and are not part of the data. The rest of the output is the actual stream of bytes from the <strong>rootchunk</strong>file displayed as hexadecimal values (courtesy of the <strong>-x</strong> option). Note that two hexadecimal digits (<strong>7c</strong>, for instance) represent one byte of data. Therefore, with a little counting, you can see that <strong>od</strong> displays 16 bytes of data on each line. The significance of the number 16 is that it equals 0x10 (hexadecimal 10).</p><p><code>在上面的示例中，UNIX 和 Linux 中的 od（八进制转储）实用程序显示了一个页面的字节流。在该输出中，左边的数字代表八进制的字节偏移量，并不是数据的一部分。输出的其余部分是以十六进制值显示的 rootchunk 文件的实际字节流（由 -x 选项提供）。请注意，两个十六进制数字（例如 7c）代表一个字节的数据。因此，只要稍微数一数，就可以看到 od 每行显示 16 个字节数据。数字 16 的意义在于它等于 0x10（十六进制 10）。</code></p><p>Because most programmers are familiar with this output format, we tend to picture Dynamic Server pages the same way: as a certain number of 16-byte lines. Therefore, this is the standard used in the Informix Dynamic Server course manuals.</p><p><code>由于大多数程序员都熟悉这种输出格式，我们往往会以同样的方式来描绘 Dynamic Server 页面：一定数量的 16 字节行。因此，这是 IDS 课程手册中使用的标准。</code>  </p><p><strong>Page Layout</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052222234.png" alt="image-20250505222202164"></p><p>The layout of a page is shown in the slide above.</p><p><code>页面布局如上图所示。</code></p><p><strong>Page header</strong></p><p>The page header occupies the first 24 bytes on the page. It contains such information as the location, type, and current capacity of the page.</p><p><code>页头占页面的前 24 个字节。它包含页面的位置、类型和当前容量等信息。</code></p><p><strong>Timestamp</strong></p><p>Each time a page is modified, the timestamp field, located in the last 4 bytes of the page, is updated. The timestamp can be used to compare with other pages to determine which was updated most recently.</p><p><code>每次修改页面时，位于页面最后 4 个字节的时间戳字段都会更新。时间戳可用于与其他页面进行比较，以确定哪个页面是最近更新的。</code></p><p><strong>Slot table</strong></p><p>The slot table enables the database server to quickly find data on a page. It is a series of 4-byte entries that begins at the page-ending timestamp and grows toward the beginning of the page. Each entry in the table describes one <em>slot</em> on the page, which can contain a data row, or some other structure. A slot table entry is comprised of two parts: the location of the slot’s first byte and the length of the slot. A slot table entry functions as a kind of pointer, allowing direct, random access to slots on the page.</p><p><code>槽表使数据库服务能够快速查找页面上的数据。它是一系列 4 字节的条目，从页面结束的时间戳开始，向页面的开头延伸。表中的每个条目描述页面上的一个槽，其中可以包含数据行或其他结构。槽表项由两部分组成：槽的第一个字节位置和槽的长度。槽表项作为一种指针，允许直接随机访问页面上的槽。</code></p><p>Page types that tend to be searched sequentially do not utilize a slot table, although they can have one. Logical log pages are an example of a page type that has no slot table at all.</p><p><code>倾向于按顺序搜索的页面类型不使用slot table，尽管它们可以有slot table。逻辑日志页就是完全没有slot table的页面类型。</code></p><p>紫本177页：</p><p><code>slots table：为 slots 描述信息，数据页中有多少 slots，则会对应多少个 slots bitmap，每个占用 4 Byte，记录 slots 在页内的偏移地址和长度，当记录被删除时，只是将其中的占用长度设置为 0，在物理上并没有将记录信息清空。</code></p><p><strong>Page Header Overview</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052238924.png" alt="image-20250505223812841"></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052240740.png" alt="image-20250505224026671"></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052241776.png" alt="image-20250505224107724"></p><p>The <strong>pg_offset</strong> field contains the <em>page offset</em>, which indicates the physical location of the page within the chunk.</p><p><code>pg_offset 字段包含页面偏移量，表示页面在chunk中的物理位置。</code></p><p>The page offset value is incremented by one for each subsequent page in the chunk. The first page in a chunk has a <strong>pg_offset</strong> value of 0. The maximum <strong>pg_offset</strong> value is based on the maximum size of a chunk, which is around 4 terabytes.</p><p><code>页偏移值每增加一页，页面偏移值就递增一次。chunk中的第一个页面的 pg_offset 值为 0。 最大 pg_offset 值基于chunk的最大大小，约为 4 TB。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052245545.png" alt="image-20250505224529492"></p><p><strong>Chunk number</strong></p><p>The <strong>pg_chunk</strong> field contains the number of the chunk where the page is located. Chunk numbering starts at 1. The combination of the <strong>pg_chunk</strong> and <strong>pg_offset</strong> provide all the information needed to identify the <em>page address</em>. The maximum <strong>pg_chunk</strong> value is 32,767.</p><p><code>pg_chunk 字段包含页面所在chunk的编号，chunk编号从 1 开始。pg_chunk 和 pg_offset 的组合提供了识别页面地址所需的全部信息。pg_chunk 的最大值为 32,767。</code></p><p>紫本176页：</p><p>Page Address ： 存 储 页 的 地 址 信 息 ， 占 用 6 Byte ， 由 两 部 分 组 成 ：chunknum+pageoffsize，其中 chunknum 占用 2 Byte，包含了符号位，故支持的最大 chunk 数为 FFFF&#x2F;2&#x3D;32767，也就是说一个 GBase 8t 实例最多可以支持 32767个 chunk。Pageoffzie 占用 4 Byte，故一个 chunk 的最大页数 FFFFFFFF 去掉符号位&#x3D;2 的 31 次方＝2 billion，对于 2k 的 pagesize，最大的空间为 4T&#x3D;22 的 31 次方*2K&#x3D;2 147 483 648*2k。</p><p><strong>Page checksum</strong></p><p>The <strong>pg_cksum</strong> field stores a checksum value that is used to validate the consistency of a page.</p><p><code>pg_cksum 字段存储一个校验和值，用于验证页面的一致性。</code></p><p>紫本：CHKSUM：校验位，占用 2 Byte。</p><p><strong>Number of Slots</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062019861.png" alt="image-20250506201908729"></p><p>You might expect <strong>pg_nslots</strong> to equal the number of active (undeleted) slots on a page. But in fact, <strong>pg_nslots</strong> indicates the <em>highest</em> number of active slots on the page.</p><p><code>你可能会认为 pg_nslots 的值等于页面上活动（未被删除）slot的数量。但实际上，pg_nslots 表示的是页面上曾经出现过的最高活动slot编号。。</code></p><p>The <strong>pg_nslots</strong> field is not decremented, even if slots are deleted. Take the case of a data page, for example. If slots 1 through 4 out of a total of five slots are deleted, slot 5 cannot be made slot 1 in the interest of space efficiency because the rowid for that slot would change. Even though only one slot is active on the page at that point, <strong>pg_nslots</strong> must remain 5 to enable a sequential scan (which does not care about rowids) to search far enough into the slot table.</p><p><code>字段 pg_nslots即使在删除了slot之后也不会减少。以一个数据页为例，假设在总共五个slot中，slot 1到4被删除，那么slot 5也不能为了节省空间而变成slot 1，因为这样会导致该slot的 rowid发生变化。尽管此时这个数据页上只剩下一个有效插槽，pg_nslots 仍必须保持为5，以便顺序扫描（这种扫描方式不关心 rowid）时可以搜索到足够深的位置，访问插槽表中的所有项。</code></p><p><strong>Maximum number of slots</strong></p><p>The maximum number of slots for a data page is 255.</p><p><code>数据页的最大slot数为 255 。</code></p><p><strong>Page Flags (Type)</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062044751.png" alt="image-20250506204451656"></p><p>The <strong>pg_flags</strong> field contains one or more <em>page flags</em>, which are represented by hexadecimal values that are logically <em>OR</em>ed together. The values have the following meanings in Informix Dynamic Server:</p><p><code>pg_flags 字段包含一个或多个页面标志，这些标志由十六进制值表示，并通过逻辑 或 运算组合在一起。这些值在 IDS 中的含义如下：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062048500.png" alt="image-20250506204838394"></p><p><strong>Free Pointer and Free Count</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062052779.png" alt="image-20250506205217703"></p><p>The <strong>pg_frptr</strong> (<em>free pointer</em>) field points to the first free byte <em>after</em> all of the data on a page. If the last slot on a page is occupied, the free pointer points to the position just after that slot.</p><p><code>pg_frptr（空闲指针）字段指向页面上所有数据之后的第一个空闲字节。如果页面上的最后一个slot已被占用，那么空闲指针就会指向该slot之后的位置。</code></p><p>The <strong>pg_frcnt</strong> (<em>free count</em>) field is a sum of all unused bytes on the page.</p><p><code>pg_frcnt（空闲数）字段表示页面上所有未使用字节的总和。</code></p><p>紫本上这两个位置写的是Pfree和Nfree，和IX9111不一致</p><p><strong>Next Pointer and Previous Pointer</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062058207.png" alt="image-20250506205843125"></p><p>The last two 4-byte elements in the page header structure are not always populated. Their main use is as node pointers on index pages. On an index page, also referred to as an index <em>node</em>, these pointers contain the logical page numbers of the two adjacent nodes. The <em>next pointer</em> (<strong>pg_next</strong>) contains the logical page number of the node to the <em>right</em>(containing higher key values), while the <em>previous pointer</em> (<strong>pg_prev</strong>) contains the logical page number of the node to the <em>left</em> (containing lower key values).</p><p><code>页头结构中最后两个 4 字节的元素并不总是被填充。它们的主要用途是在索引页中充当节点指针。在索引页中（也称为索引节点），这些指针包含两个相邻节点的逻辑页号。pg_next 指针包含右侧节点（包含较大键值）的逻辑页号，而 pg_prev 指针则包含左侧节点（包含较小键值）的逻辑页号。</code></p><p>The difference between physical and logical page numbers, and the B+ tree concepts of right and left index nodes, are explained in later modules.</p><p><code>物理页号与逻辑页号之间的区别，以及 B+ 树中右侧和左侧索引节点的概念，将在后续模块中进行解释。</code></p><p>The next and previous-pointer elements were designed into the page-header structure for use in index pages. But instead of wasting eight bytes in the header of all non-index pages, uses have been found for the next and previous pointers in a couple of other page types as well. Their use in logical log pages and tape-header pages, for example, are explained in later modules.</p><p><code>next 和 previous 指针元素最初是为了在索引页中使用而被设计进页头结构的。但为了避免在所有非索引页的页头中浪费这8个字节，这两个指针也被用于其他几种页面类型。例如，它们在逻辑日志页和磁带头页中的用途将在后续模块中进行说明。</code></p><p>紫本：</p><p>Next Page：占用4 Byte，指向下页的地址，对于数据页为0，对于索引页则指向下一个节点。</p><p>Previous Page：占用4 Byte，指向上页的地址，对于数据页为0，对于索引页则存储前页地址。</p><p><strong>Big Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062110830.png" alt="image-20250506211014737"></p><p>The default page size used for your Informix Dynamic Server instance is either 2K or 4K, depending on the platform (machine and operating system) you are using. For example, a 4K page size is the default for Windows and IBM AIX, and a 2K page size is the default for most other platforms. The root dbspace is always created using the default page size.</p><p><code> IDS 实例的默认页面大小是 2K 或 4K，具体取决于所使用的平台（包括机器和操作系统）。例如，Windows 和 IBM AIX 平台的默认页面大小是 4K，而大多数其他平台的默认页面大小是 2K。</code><mark>root dbspace 总是使用默认的页面大小创建。</mark></p><p>When you add dbspaces, you can specify a different page size using a multiple of the default page size with a maximum size of 16 kilobytes. Before you create a dbspace that uses a larger page size, you will want to configure a separate buffer pool for that page size. Configure a new buffer pool by setting the BUFFERPOOL configuration parameter. For example:</p><p><code>当你添加 dbspace 时，可以使用默认页面大小的倍数来指定不同的页面大小，最大支持 16KB。在创建使用较大页面大小的 dbspace 之前，建议先为该页面大小配置一个单独的缓冲池。你可以通过设置 BUFFERPOOL 配置参数来配置新的缓冲池。例如：</code></p><p>BUFFERPOOL <strong>size&#x3D;8k</strong>,buffers&#x3D;2000,lrus&#x3D;8,lru_min_dirty&#x3D;50,lru_max_dirty&#x3D;60</p><p>When the new buffer pool has been created, you can then create a dbspace using the larger page size. For example:</p><p><code>当新的缓冲池创建完成后，你就可以使用更大的页面大小来创建 dbspace。例如：</code></p><p>onspaces -c -d dbsp_bigp <strong>-k 8K</strong> -p &#x2F;opt&#x2F;dbsp3 -o 0 -s 8000</p><p><strong>Displaying a Page</strong></p><ul><li>Oncheck commands</li></ul><p>oncheck -pP chunk_number page_offset</p><p>oncheck -pp partition_number logical_page_number</p><ul><li>Chunk numbers are indexed from 1</li></ul><p><code>chunk号从1开始</code></p><ul><li>Both the page offset into a chunk and the logical page number within a table are indexed from 0</li></ul><p><code>chunk中的页面偏移量和表中的逻辑页面号都是从 0 开始的</code></p><ul><li>To obtain a partition number:</li></ul><p>– Query <strong>systables</strong> (or <strong>sysmaster:systabnames</strong>) if the table is not fragmented</p><p>– Query <strong>sysfragments</strong> if the table is fragmented</p><p>– Run <strong>oncheck -pt</strong> to find all partnums of all fragments</p><ul><li>The <strong>oncheck</strong> utility recognizes both decimal (100) and hexadecimal (0x64) format for its arguments</li></ul><p><code>oncheck 工具支持十进制（100）和十六进制（0x64）格式的参数。</code></p><p>When logged on as either <em>root</em> or <em>informix</em>, you can display most pages within an Informix Dynamic Server chunk using the <strong>oncheck</strong> utility. Based on the type of page it finds, <strong>oncheck</strong> even attempts to print the data on the page in an organized format.</p><p><code>当以 root 用户或 informix 用户登录时，可以使用 oncheck 工具查看 IDS chunk中的大多数页面。根据所找到的页面类型，oncheck 甚至会尝试以结构化的格式打印页面上的数据。</code></p><p><strong>Displaying logical log pages</strong></p><p>The <strong>oncheck</strong> utility does not do much with logical log pages; it treats them as unknown page types. The reason is that logical log pages have no slot table, and when taken as a byte stream, the data on an individual log page is difficult to separate into structures and interpret. The <strong>onlog</strong> utility is a better tool for that task, for reasons that should be clearer a bit later in the course.</p><p><code>oncheck 工具对逻辑日志页（logical log pages）支持较少；它将这些页面视为未知类型。原因在于逻辑日志页没有slot table，而且将其作为字节流来看时，单个日志页上的数据难以划分为结构并进行解释。对于这项任务，onlog 工具更为合适，具体原因将在课程后面进一步解释。</code></p><p><strong>Locating partition numbers</strong></p><p>The <em>partition number</em> (<em>partnum</em>) uniquely identifies a specific tblspace. An unfragmented table has only one data tblspace and, therefore, has only one partition number.</p><p><code>partition number（partnum）用于唯一标识一个特定的 tblspace。一个未分片（unfragmented）的表只有一个数据表空间，因此也只有一个分区号。</code></p><p>Fragmented tables have one tblspace (and one partnum) for each dbspace fragment.</p><p><code>分片表中的每个 dbspace 分片都有一个对应的表空间（tblspace）和一个分区号（partnum）。</code></p><p>Partition numbers for unfragmented tables are stored in the <strong>systables</strong> system catalog table. Here is an example of a query to obtain a partition number in both decimal and hexadecimal format:</p><p><code>未分片表的分区号（partnum）存储在系统目录表 systables 中。下面是一个用于以十进制和十六进制格式获取分区号的查询示例：</code></p><p>deepseek：</p><blockquote><p>在数据库领域中，”catalog” 实际上就是指数据库的元数据（metadata）。</p><p>更具体地讲，数据库的 <strong>catalog</strong> 是由数据库系统维护的一组表或数据结构，用来描述数据库中对象的结构和属性，</p></blockquote><p>SELECT partnum, HEX(partnum) FROM systables WHERE tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072237755.png" alt="image-20250507223709618"></p><p>You can also obtain a partition number for an unfragmented table by querying the <strong>sysmaster</strong> database:</p><p><code>您还可以通过查询 sysmaster 数据库来获取未分区表的分区号：</code></p><p>DATABASE sysmaster;</p><p>SELECT partnum, HEX(partnum) FROM systabnames WHERE tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072238153.png" alt="image-20250507223809100"></p><p>If a table is fragmented, the value in the <strong>partnum</strong> column of <strong>systables</strong> and <strong>systabnames</strong> is zero. To obtain a list of partnums for a fragmented table, it is necessary to query the <strong>sysfragments</strong> system catalog:</p><p><code>如果表是分片的，则 systables 和 systabnames 中 partnum 列的值为零。要获取分片表的 partnum 列表，必须查询 sysfragments ：</code></p><p>SELECT partn, HEX(partn) FROM systables t, sysfragments f WHERE t.tabid &#x3D; f.tabid AND tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p>CREATE TABLE f1 (<br>    id int,<br>    name VARCHAR(10)<br>)<br>FRAGMENT BY EXPRESSION<br>    id &lt; 10 IN datadbs1,<br>    id &gt;&#x3D; 10 AND id &lt; 20 IN datadbs2,<br>    id &gt;&#x3D; 20 IN datadbs3;</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072253021.png" alt="image-20250507225315967"></p><p>Perhaps the easiest way to find a list of all partnums associated with a table (including partition numbers for index partitions) is by using the <strong>oncheck -pt</strong> command:</p><p><code>要查找与表相关的所有分区号列表（包括索引分区的分区号），最简单的方法可能是使用 oncheck -pt 命令：</code></p><p>oncheck -pt <em>database_name</em>:<em>table_name</em></p><p>Partition numbers are displayed under the heading <strong>Partition partnum</strong> in decimal format.</p><p><code>分区编号以十进制格式显示在分区 partnum 标题下。</code></p><p>示例：</p><blockquote><p>[root@frh gbase]# oncheck -pt testdb:f1</p><p>TBLspace Report for testdb:root.f1</p><pre><code>              Table fragment partition datadbs1 in DBspace datadbs1Physical Address               4:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              4194306Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              4:53           8          8              Table fragment partition datadbs2 in DBspace datadbs2Physical Address               5:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              5242882Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              5:53           8          8              Table fragment partition datadbs3 in DBspace datadbs3Physical Address               6:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              6291458Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              6:53           8          8</code></pre></blockquote><p><strong>oncheck -pP&#x2F;pp</strong></p><p>The syntax to use with <strong>oncheck -pP</strong> is shown in the slide above. For example, to display page 0 from chunk 1, type:</p><p><code>使用 oncheck -pP 的语法如上图所示。例如，要显示chunk 1 的第 0 页，请键入</code></p><p>oncheck -pP 1 0</p><p>To display logical page 0 (the first bitmap page) from partition number 0x0100022, type:</p><p><code>要显示 partition number 0x0100022 的逻辑页 0（第一个位图页），请键入</code></p><p>oncheck -pp 0x0100022 0</p><p>这块只是介绍一下这2命令，下面有详细介绍</p><p><strong>Logical page numbers</strong></p><p>Picture all the pages in a table lined up in chronological order and numbered, starting with 0. These would be their <em>logical page numbers</em>. If this is a confusing concept at the moment, do not worry. You will be examining tblspaces further in a later module.</p><p><code>想象一下，所有页面在一个表格中按时间顺序排列，并从0开始编号。这些编号就是它们的逻辑页码。如果你现在对这个概念感到困惑，不用担心——你将在后续的模块中进一步学习表空间（tblspaces）。</code></p><p><strong>Note</strong></p><p>In rare cases, the data on a particular page is formatted differently by <strong>oncheck</strong> depending on the option used. For instance, the <strong>-pP</strong> option displays only the page header for a bitmap page, but the <strong>-pp</strong> option displays the bit values in a more readable format.</p><p><code>在极少数情况下，oncheck 会根据所使用的选项对特定页面上的数据进行不同的格式化处理。例如，-pP 选项只显示位图页面的页头，而 -pp 选项则以更易读的格式显示位值。</code></p><p>应该要到Unit 4才能知道bitmap page是什么，先不用管他</p><p>There is one more variation on the <strong>oncheck -pp</strong> syntax that we have not mentioned because in fact, we do not recommend that you use it. In the spirit of providing you every tool we can think of, here it is:</p><p><code>oncheck -pp 语法还有一个变种，我们没有提及，因为事实上我们</code><mark>不建议你使用它</mark><code>。本着为您提供我们所能想到的所有工具的精神，我们在此介绍它：</code></p><p>oncheck -pp <em>database</em>:<em>table_name rowid</em></p><p>Only rowids above 0x100 work with this syntax; you cannot display the first bitmap page (0x100), but all other used pages in the table are fair game. For example:</p><p><code>只有大于 0x100 的 rowid 才能使用这种语法；你无法显示第一个位图页（0x100），但表中所有其他已使用的页面都可以显示。例如：</code></p><p>oncheck -pp stores_demo:customer 0x201</p><p>Now, you might expect the above command to display only one row from the <strong>stores_demo:customer</strong> table, the first slot on logical page 2. In fact, that command displays all rows on page 2. It is equivalent to the command:</p><p><code>现在，你可能以为上述命令只会显示 stores_demo:customer 表中的一条记录，即逻辑页面 2 的第一个slot。事实上，该命令会显示第 2 页上的所有行。它等同于以下命令</code></p><p>oncheck -pp 0x10001a 0x2</p><p>(assuming the partition number for the <strong>stores_demo:customer</strong> table is 0x10001a).</p><p><code>假设stores_demo:customer表的分区编号为 0x10001a</code></p><p>The advantage, of course, is that you do not need to determine the partnum for a table in order to use <strong>oncheck -pp</strong>.</p><p><code>当然，这样做的好处是，在使用 oncheck -pp 时不需要确定表的partnum。</code></p><p>The disadvantage in using this syntax is that using a rowid with <strong>oncheck</strong> and receiving output for an entire page might slow your efforts to understand the meaning of a rowid.</p><p><code>使用这种语法的一个缺点是，当你在 oncheck 中使用 rowid 并获得整个页面的输出时，可能会降低你理解 rowid 含义的效率。</code></p><p>While it is tempting to avoid working with partition numbers, the relationship between a tblspace and its partnum is extremely important to grasp. Until you have used the recommended syntax long enough to be tired of it, it is a good idea to spend the extra few seconds looking up a table’s partnum.</p><p><code>虽然避免使用分区编号很有诱惑力，但掌握 tblspace 与其 partnum 之间的关系极为重要。在使用推荐语法足够长的时间并对其感到厌倦之前，最好多花几秒钟来查找表的分区号。</code></p><blockquote><p>tempting</p><p>英[ˈtemptɪŋ]    美[ˈtemptɪŋ]<br>adj.诱人的;吸引人的;有吸引力的;v.诱惑;引诱;怂恿;利诱;劝诱;鼓动;</p><p>extremely</p><p>英[ɪkˈstriːmli]   美[ɪkˈstriːmli] </p><p>adv.极其;非常;极端;</p><p>grasp</p><p>英[ɡrɑːsp]    美[ɡræsp]<br>vt.抓住;理解;领会;领悟;抓牢;毫不犹豫地抓住(机会);n.理解(力);控制;领会;紧握;紧抓;能力所及;</p></blockquote><p>实际使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@frh gbase]<span class="comment"># oncheck -pt testdb:t1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">TBLspace Report <span class="keyword">for</span> testdb:root.t1</span><br><span class="line"></span><br><span class="line">    Physical Address               1:525</span><br><span class="line">    Creation <span class="built_in">date</span>                  05/25/2025 05:57:03</span><br><span class="line">    TBLspace Flags                 902        Row Locking</span><br><span class="line">                                              TBLspace contains VARCHARS</span><br><span class="line">                                              TBLspace use 4 bit bit-maps</span><br><span class="line">    Maximum row size               16</span><br><span class="line">    Number of special columns      1</span><br><span class="line">    Number of keys                 0</span><br><span class="line">    Number of extents              1</span><br><span class="line">    Current serial value           1</span><br><span class="line">    Current SERIAL8 value          1</span><br><span class="line">    Current BIGSERIAL value        1</span><br><span class="line">    Current REFID value            1</span><br><span class="line">    Pagesize (k)                   2</span><br><span class="line">    First extent size              8</span><br><span class="line">    Next extent size               8</span><br><span class="line">    Number of pages allocated      8</span><br><span class="line">    Number of pages used           2</span><br><span class="line">    Number of data pages           1</span><br><span class="line">    Number of rows                 2</span><br><span class="line">    Partition partnum              1049134</span><br><span class="line">    Partition lockid               1049134</span><br><span class="line"></span><br><span class="line">    Extents</span><br><span class="line">         Logical Page     Physical Page        Size Physical Pages</span><br><span class="line">                    0            1:6681           8          8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1049134 的十六进制是 0x10022E</span></span><br><span class="line">[root@frh gbase]<span class="comment"># oncheck -pp 0x10022E 1</span></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:6682           8804098  4d9f   2      801  DATA         42    1994  0        0</span><br><span class="line">        slot ptr   len   flg</span><br><span class="line">        1    24    9     0</span><br><span class="line">        2    33    9     0</span><br><span class="line">slot   1:</span><br><span class="line">    0:  0  0  0  1  0  3 61 61 61                        ......aaa.......</span><br><span class="line">slot   2:</span><br><span class="line">    0:  0  0  0  2  0  3 62 62 62                        ......bbb.......</span><br><span class="line"></span><br><span class="line"><span class="comment"># Physical Page 的 6681 加 1</span></span><br><span class="line">[root@frh gbase]<span class="comment"># oncheck -pP 1 6682</span></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:6682           8804098  4d9f   2      801  DATA         42    1994  0        0</span><br><span class="line">        slot ptr   len   flg</span><br><span class="line">        1    24    9     0</span><br><span class="line">        2    33    9     0</span><br><span class="line">slot   1:</span><br><span class="line">    0:  0  0  0  1  0  3 61 61 61                        ......aaa.......</span><br><span class="line">slot   2:</span><br><span class="line">    0:  0  0  0  2  0  3 62 62 62                        ......bbb.......</span><br></pre></td></tr></table></figure><p>本章前边 和 Unit 4 和 《IX9111新讲_第02章_Page_v1.1_韩愈强.mp4》的30分27秒，都有说第 0 页是 bitmap 页</p><p><strong>Displaying a Big Page</strong></p><p>先看下边Notes</p><ul><li>Calculate page offset:</li></ul><p>pg_offset &#x3D; (chunk_pgsize &#x2F; system_pgsize) * page_num</p><ul><li>Example: To dump page 15 of chunk 3 on AIX (default page size &#x3D; 4K) with a configured page size of 16K for chunk 3:</li></ul><p>pg_offset &#x3D; (16 &#x2F; 4) * 15 &#x3D; 60</p><p><strong>oncheck -pP 3 60</strong></p><ul><li>Example: To dump the first partition page (page 3) on Linux (default page size &#x3D; 2) with a configured page size of 8K for chunk 3:</li></ul><p>pg_offset &#x3D; (8 &#x2F; 2) * 3 &#x3D; 12</p><p><strong>oncheck -pP 3 12</strong></p><p><strong>Notes:</strong></p><p>To dump a page that is larger than the default platform page size, the DBA uses the same <strong>oncheck</strong> command: <strong>oncheck -pP</strong> <strong>chunk# pg_offset</strong>, but the <em>pg_offset</em> has to be calculated differently:</p><p><code>要转储大于默认平台页面大小的页面，DBA 使用相同的 oncheck 命令：oncheck -pP chunk# pg_offset，但 pg_offset 的计算方式不同：</code></p><p>pg_offset &#x3D; (<em>chunk_pgsize</em> &#x2F; <em>system_pgsize</em>) * <em>page#</em></p><p>Some example calculations and <strong>oncheck</strong> commands are shown above.</p><p>例子在上边</p><p><strong>Page Header Format</strong></p><p>The formats used for each header element in the display are:</p><p><code>显示中每个标题元素所使用的格式如下：（十进制、十六进制、字符）</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082035860.png" alt="image-20250508203538773"></p><p><strong>Notes:</strong></p><p>A page header displayed by <strong>oncheck</strong> can be frustrating to decipher at first, because the utility does not use a consistent notation for the elements. Some are displayed as hexadecimal values, some as decimals. The slide above indicates the format used for each element.</p><p><code>一开始，oncheck 显示的页眉可能会让人难以理解，因为该工具对元素没有使用统一的符号。有些显示为十六进制值，有些显示为小数。上面的幻灯片显示了每个元素使用的格式。</code></p><blockquote><p>frustrating<br>英[frʌˈstreɪtɪŋ] 美[ˈfrʌstreɪtɪŋ]<br>adj.令人沮丧的;令人懊恼的;  v.使沮丧;挫败;阻止;使懊恼;防止;使懊丧;</p><p>decipher<br>英[dɪˈsaɪfə(r)] 美[dɪˈsaɪfər]<br>vt.破译;辨认(难认、难解的东西);v.破译;n.密电(或密信)的译文;</p><p>notation<br>英[nəʊˈteɪʃn] 美[noʊˈteɪʃn]<br>n.符号;(数学、科学和音乐中的)记号;谱号;</p></blockquote><p>The <strong>addr</strong> column shows the chunk number (<strong>pg_chunk</strong>) and offset (<strong>pg_offset</strong>) for the page.</p><p><code>addr 列显示页面的块号（pg_chunk）和偏移量（pg_offset）。</code></p><p>The <strong>flag</strong> and <strong>type</strong> columns in the output refer to the same element in the structure: <strong>pg_flags</strong>. The <strong>type</strong> column is meant to translate the page flags into something more recognizable, though the chosen terms sometimes add to the confusion. Here are all the <strong>type</strong> values output by <strong>oncheck</strong> followed by yet another translation:</p><p><code>输出中的flag和type指的是结构中的同一个元素：pg_flags。type的目的是将页面标志转换成更容易辨认的内容，尽管所选术语有时会造成混淆。下面是 oncheck 输出的所有类型值，以及另一种翻译：</code></p><p>DATA Tblspace data page</p><p>PARTN Partition (tblspace tblspace) page</p><p>FREE Tblspace bitmap page</p><p>CHUNK Chunk free list page</p><p>REMAIN Remainder page</p><p>PBLOB Partition-resident BLOB page</p><p>BLOB BLOBspace-resident BLOB page</p><p>BBIT BLOB chunk free-list page</p><p>BMAP Blob chunk BLOB map page</p><p>BTREE Index page</p><p>ROOTRSV Root reserved page</p><p>UNKNOWN The default type, which includes logical log pages</p><p><strong>Slot Table Format</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082115460.png" alt="image-20250508211523372"></p><p><strong>Notes:</strong></p><p>For most pages, after displaying the page header, <strong>oncheck</strong> displays the slot table if one exists. All values displayed in the slot table list are in decimal notation.</p><p>对于大多数页面，在显示页头后，<strong>oncheck</strong> 会显示slot table（如果存在）。slot table列表中显示的所有值都是十进制。</p><table><thead><tr><th><strong>slot</strong></th><th>The slot table entry (this value is not actually stored in the slot table).    表条目（该值实际上并不存储在表中）。</th></tr></thead><tbody><tr><td><strong>ptr</strong></td><td><strong>The byte offset into the page where the first byte of the slot is found.    在页面中找到slot第一个字节的字节偏移量。</strong></td></tr><tr><td><strong>len</strong></td><td><strong>The length of the slot in bytes.   slot的长度（字节）。</strong></td></tr><tr><td><strong>flg</strong></td><td><strong>If the slot contains a forward pointer, this value is 2; otherwise, it is 0. 如果slot包含一个前向指针，该值为 2；否则为 0。</strong></td></tr></tbody></table><p>Remember, a slot is not a row, but a <em>container</em>. A slot can contain a data row, a portion of a data row (in the case of a row that has been split across pages), or another structure altogether. A slot table entry consists of a length and a position on a page.</p><p><code>记住，slot不是行，而是容器。slot可以包含一条数据行、数据行的一部分（在数据行被分割到不同页面的情况下）或另一种结构。slot table项由长度和在页面上的位置组成。</code></p><p><strong>Slot Format</strong></p><p>The slots are displayed as streams of individual bytes. Bytes are displayed in hexadecimal format, without leading zeros (this may be a point of confusion at first).</p><p><code>slot显示为单个字节流。字节以十六进制格式显示，不含前导零（起初可能会引起混淆）。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082124609.png" alt="image-20250508212453518"></p><p><strong>Notes:</strong></p><p>After displaying the slot table, <strong>oncheck</strong> displays the slots themselves. Note that <strong>oncheck</strong>displays the bytes in each slot in hexadecimal notation, 16-across. In addition, an ASCII translation of each 16-byte <em>line</em> in the slot, or fraction thereof, is displayed to the right. Dots in the ASCII lines serve as place holders for bytes that cannot be translated into ASCII characters.</p><p><code>显示slot table后，oncheck 显示slot本身。请注意，oncheck 会以十六进制符号显示每个slot中的字节，16-across。此外，右侧还显示slot中每行 16 字节的 ASCII 译文或其部分。ASCII 行中的点是无法转换成 ASCII 字符的字节的占位符。</code></p><p>To the left of each line of bytes is an offset in decimal. This value (0, 16, 32, etc.) is the byte offset of the first byte on the line, relative to the beginning of the slot.</p><p><code>每行字节的左边是一个十进制偏移量。该值（0、16、32 等）是该行第一个字节相对于slot起始位置的字节偏移量。</code></p><p><strong>Page View</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082133156.png" alt="image-20250508213331042"></p><p><strong>Notes:</strong></p><p>The <strong>oncheck</strong> utility attempts to display data in an easy-to read format. To see what a page really looks like, or at least the hexadecimal representation of the page, other utilities are needed. </p><p><code>oncheck 工具试图以易于阅读的格式显示数据。要查看页面的真实情况，或至少查看页面的十六进制表示，还需要其他实用程序。</code></p><p>Above is an example of a page that was extracted from an Informix Dynamic Server chunk and displayed in hexadecimal format. The <strong>dd</strong> and <strong>od</strong> commands, provided by most UNIX operating systems, were used to do this. This view of the page gives a better idea of where the page components are located.</p><p><code>以上是从 IDS chunk 中提取页面并以十六进制格式显示的示例。大多数 UNIX 操作系统都提供了 dd 和 od 命令。通过这种页面视图，可以更好地了解页面组件的位置。</code></p><p>The first column of the <strong>od -x</strong> output indicates the byte offset into the page in <em>octal</em>. Since it is easier to use hexadecimal values to identify the offsets, a hexadecimal translation is provided to the right of the example. An asterisk appears where lines of data repeat.</p><p><code>od -x 输出结果的第一列显示了以八进制表示的页面字节偏移量。由于使用十六进制值更容易识别偏移量，因此示例右侧提供了十六进制转换。数据行重复的地方会出现星号。</code></p><blockquote><h3 id="第一部分：dd-if-dev-chunk1-skip-123-count-1-bs-2k"><a href="#第一部分：dd-if-dev-chunk1-skip-123-count-1-bs-2k" class="headerlink" title="第一部分：dd if=/dev/chunk1 skip=123 count=1 bs=2k"></a>第一部分：<code>dd if=/dev/chunk1 skip=123 count=1 bs=2k</code></h3><p><code>dd</code> 是一个用于按块复制数据的低级工具。各个参数含义如下：</p><ul><li><code>if=/dev/chunk1</code>：<strong>输入文件</strong>（input file），这里是一个设备文件 <code>/dev/chunk1</code>。</li><li><code>skip=123</code>：<strong>跳过前 123 个块</strong>，不读取它们。</li><li><code>count=1</code>：<strong>读取 1 个块</strong>。</li><li><code>bs=2k</code>：<strong>每个块大小为 2KB</strong>（即 2048 字节）。</li></ul><p>➡️ 综合：这个命令会从 <code>/dev/chunk1</code> 中跳过前 123 × 2KB（即 246KB），然后读取接下来的 <strong>2KB 数据</strong>。</p><hr><h3 id="第二部分：-od-x"><a href="#第二部分：-od-x" class="headerlink" title="第二部分：| od -x"></a>第二部分：<code>| od -x</code></h3><ul><li><code>|</code>：管道符，将上一步 <code>dd</code> 的输出传递给下一个命令。</li><li><code>od</code>：<strong>octal dump</strong>（八进制转储）工具，用于以人类可读的方式查看二进制数据。</li><li><code>-x</code>：以 <strong>十六进制</strong>的形式显示输出。</li></ul><p>➡️ 效果：你将看到读取到的 2KB 数据的十六进制表示，通常用于调试、查看原始数据结构、分析二进制文件内容等。</p></blockquote><p><strong>Coming up next</strong></p><p>You now have the tools necessary to display pages based on their location in a chunk or in a tblspace. The trick, of course, is in knowing ahead of time what information is located at specific points in a chunk or tblspace. In the next two chapters, you will learn the architecture of dbspaces and tblspaces at the page level and beyond.</p><p><code>现在你已经拥有了根据页面在chunk或 tblspace 中的位置来显示页面所需的工具。当然，其中的诀窍在于提前知道信息位于chunk或 tblspace 中的特定位置。在接下来的两章中，你将学习 dbspaces 和 tblspaces 在页面级及以上的架构。</code></p><p><strong>Byte Swapping</strong></p><p>In a byte-swapping system, the bytes in a 2-byte and 4-byte value are reversed when saved to disk.</p><p><code>在字节交换系统中，2 字节和 4 字节数值的字节在保存到磁盘时会相反。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082142142.png" alt="image-20250508214227054"></p><p><strong>Notes:</strong></p><p>Some operating systems do not store streams of bytes in the same way that we would normally view them. On these systems, certain values go through a <em>byte-swapping</em> process before the value is written to disk. This is why the values that you may see in a hexadecimal page dump, or even in a slot table entry, may not appear the way you expect. </p><p><code>有些操作系统存储字节流的方式与我们通常查看字节流的方式不同。在这些系统中，某些值在写入磁盘前要经过字节交换过程。这就是为什么你在十六进制页面转储，甚至在slot table项中看到的值可能与你期望的不一样。</code></p><p>When a byte swap occurs, the first byte of a 2-byte value get s “swapped” with the last byte. For a 4-byte value, the first byte is swapped with the fourth byte, and the second byte is swapped with the third. An example is shown above using the octal dump shown on the previous page.</p><p><code>发生字节交换时，2 字节数值的第一个字节会与最后一个字节 “交换”。对于 4 字节值，第一个字节与第四个字节交换，第二个字节与第三个字节交换。上图是一个使用前一页所示八进制转储的示例。</code></p><p>In most cases, oncheck displays output that has been properly converted from the disk format. There are cases where slot information is displayed showing byte-swapped values.</p><p><code>在大多数情况下，oncheck 显示的输出已从磁盘格式正确转换。在某些情况下，显示的slot信息会显示字节交换值。</code></p><p>The Linux operating system, used by the lab image for this course, uses byte-swapping.</p><p><code>本课程实验镜像所使用的 Linux 操作系统采用字节交换（byte-swapping）机制。</code></p><p>补充一些紫本内容：（177页）</p><p>对数据部分的解释如下。</p><ul><li>在数据页中用来存储数据的部分可以存储行记录和索引 key。</li><li>以 slots 的方式分成 <em>n</em> 个存储单元，每个 slots 存放一行记录或者一个 index-key。</li><li>在一个数据页中最多能存储 255 个 slots。</li></ul><p>​一个数据页的页头和页尾占用的总空间为 28 Byte + <em>n**4Byte，其中 <em>n</em> 为 page 中存储的记录数。如总共存储 100 个记录，那么总共占用：28+100</em>4&#x3D;428 Byte，如果为 2k 的 page，那么 100 个记录实际数据占用的空间为：2048－428＝1620 Byte。</p><p>​一个 Page 中能存储多少行记录的计算公式为：28 Byte + <em>n</em> *（4+rowsize） Byte</p><p>​假如表的 rowsize&#x3D;16 Byte，那么一个 pagesize 为 2KB 页刚好可以存储 101 行记录：28+101*（4+16）&#x3D;2048。</p><p>如果采用 pagesize 为 16K 的页来存储 rowsize&#x3D;16 Byte 的表，由于一个 page 最多存储255 行记录，那么实际使用的空间为：28 + 255*（4+16） &#x3D;5128 Byte，那么 16K 的存储Page 将有超过 10K 被浪费，也就说不同的表需要选择合理大小的 pagesize 来存储。</p><p>​表 6.6 列出了采用不同 pagesize 的数据页中最多存储 255 行记录对应的 rowsize 大小。</p><p>​<img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082210927.png" alt="image-20250508221057854"></p><p>如表 6.6 说明了若有一个表的 rowsize 不大于 11 Byte，那么应该采用 2K 的 Pagesize；如果采用 4K 或者更大的 pagesize 那么会有空间浪费。如果一个表的 rowsize 不大于 28，那么不建议采用 8K 的 pagesize；如果表的 rowsize 不大于 60 Byte，那么不建议采用 16K 的 Pagesize。</p><p>假如有表 customer：</p><p>create table customer（cus_id integer,cus_name char（10））;</p><p>该表的 rowsize&#x3D;4+10&#x3D;14 Byte，那么该表建议采用不大于 4K 的 pagesize。为了更好地理解 Page 的存储结构，下面通过表 customer 的实际数据存储情况来展示数据页的内部结构。</p><blockquote><p>Drop table if exists customer;</p><p>Create table customer (cus_id integer,cus_name char(10)) in dbs2k;</p><p>Create index idx_customer on customer(cus_id);</p><p>Insert into customer values(1,’abc’);</p><p>Insert into customer values(2,’def’);</p></blockquote><p>通过 oncheck 及操作系统 od 命令查看 customer 表记录在数据页上的存储情况，如图6.27 所示。</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082212984.png" alt="image-20250508221231802"></p><p>00000043：addr的67，也就是IX9111的pg_offset，4字节</p><p>根据前边可知，0x101是rowid，但为什么是这个数没看到解释，我自己查的：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082234005.png" alt="image-20250508223442940"></p><p>0x101就是257，所以第一条记录的rowid就是0x101</p><p>前边提到，IX9111不推荐这种写法（库名:表名），推荐用partition number</p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 1. Introduction</title>
      <link href="/2025/04/26/IX9111/1/"/>
      <url>/2025/04/26/IX9111/1/</url>
      
        <content type="html"><![CDATA[<p><strong>chunks</strong></p><p>Chunks contain extents; extents contain pages Chunks contain extents; extents contain page</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272252887.png" alt="image-20250427225213804"></p><p>Informix Dynamic Server disk space is allocated in units called chunks.</p><p>To uniquely describe a particular <strong>chunk</strong>, you must specify three things: the chunk <strong>path</strong>, the <strong>offset</strong> (kilobytes) into the device where the chunk begins, and the <strong>size</strong> (kilobytes) of the chunk.</p><br><p><strong>pages</strong></p><p>The <strong>default page size</strong> is either <strong>2</strong> kilobytes or <strong>4</strong> kilobytes, depending on the platform.</p><p><code>默认页大小 2KB 或 4KB (kilobytes是KB)</code></p><p>The <strong>page size</strong> can be configured for each dbspace from <strong>2K</strong> to <strong>16K</strong> and <strong>must be divisible by the default page size</strong>.</p><p><code>页大小可配置为2K - 16K，必须能被默认页面大小整除</code></p><p>The <strong>size of a chunk</strong> must be <strong>a multiple of the page size</strong>.</p><p><code>chunk的大小必须是页大小的倍数</code></p><br><p><strong>extents</strong></p><p>An <em>extent</em> is a <strong>physically contiguous</strong> group of related pages that are <strong>fully contained in a chunk</strong>.</p><p><code>extent是物理上连续的一组相关pages，这些页面完全包含在一个chunk中。</code></p><p>Extents are not exclusively associated with tblspaces.The physical log is made from one extent. The 12 reserved pages in the root dbspace could also be called an extent</p><p><code>extents不只和tblspaces关联。物理日志由一个extent构成。rootdbs的12个保留页也可以被叫做一个extent</code></p><br><p><strong>Tblspaces</strong></p><p>A tblspace is a set of extents allocated to a specific database object.   </p><p><code>tblspace是分配给特定数据库对象的一组extent。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272245936.png" alt="image-20250427224506870"></p><p>A <em>tblspace</em> is a logical collection of extents within a dbspace. A tblspace can represent an entire table or index, or a table or index fragment. Each extent can contain a variety of page types. When a tblspace is created, an initial extent is allocated. Its size is 8 pages by default, but can be set using the EXTENT SIZE clause of the CREATE TABLE statement in SQL. As the table grows, new extents must be allocated. The default size of each <em>next</em>  <em>extent</em> is also 8 pages, but can be set using the NEXT SIZE clause.</p><p><code>tblspace是dbspace内extent的逻辑集合。tblspace可以表示整个表或索引，也可以表示表或索引的片段。每个extent可以包含多种页类型。创建tblspace时，会分配一个初始extent。其大小默认为8页，但可以使用 SQL 中 CREATE TABLE 语句的 EXTENT SIZE 子句进行设置。随着表的增长，必须分配新的extent，下一个extent的默认大小也是 8 页，但可以使用 NEXT SIZE 子句进行设置。</code></p><p>The extent allocation mechanism for tblspaces has a few additional features: </p><p><code>tblspace的extent分配机制有一些额外特性</code></p><ol><li><p>When an extent is allocated adjacent to the extent previously allocated for the same tblspace, the two can be concatenated to form one large extent. </p><p><code>当一个extent分配到与先前为同一tblspace分配的extent相邻的位置时，可以将这两个extent连接起来以形成一个大extent。</code></p></li><li><p>As a tblspace becomes fragmented, the size used for new extent allocations is adjusted upward from its configured value. Specifically, NEXT SIZE is doubled for every 16 extents that are allocated.</p><p><code>当一个tblspace变得碎片化时，用于新extent分配的大小会在其配置值的基础上向上调整。具体来说，每分配16个extent，NEXT SIZE就会翻倍。</code></p></li><li><p>When an extent allocation requires more contiguous space than is available in the dbspace, the server simply allocates the largest amount of contiguous space available.</p><p><code>当extent分配所需的连续空间大于 dbspace 中可用的连续空间时，server会直接分配可用的最大连续空间。</code></p><p>This mechanism helps to avoid reaching extent allocation limits.</p><p><code>此机制有助于避免达到extent分配限制。</code></p></li></ol><br><p><strong>Dbspaces, Blobspaces, and Sbspaces</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272258506.png" alt="image-20250427225802434"></p><p>Dbspaces, blobspaces, and sbspaces are named collections of one or more chunks. These spaces do not define any physical space boundaries, but are <em>logical</em> collections of the <em>physical</em> chunks.</p><p><code>前一句不知道怎么翻译，理解成每个space都有名字，由一个或多个chunk组成吧。这些space没有定义任何物理空间边界，而是物理chunk的逻辑集合。</code></p><p>A <em>dbspace</em> chunk contains data and index pages in the form of tblspaces. The first dbspace in an Informix Dynamic Server system always contains the first chunk, or <em>root chunk</em>. Therefore, dbspace 1 is always the <em>root dbspace</em>.</p><p><code>dbspace chunk以tblspace的形式包含数据页和索引页。IDS的第一个dbspace始终包含第一个chunk，或称为root chunk。因此dbspace 1 始终是 root dbspace</code></p><p>A blobspace chunk contains BYTE and TEXT data.</p><p><code>blobspace chunk包含BYTE和TEXT数据</code></p><p>An sbspace chunk contains smart large object (BLOB and CLOB) data and metadata pages to help manage the data.</p><p><code>sbspace chunk包含智能大对象（BLOB 和 CLOB）数据和元数据页，以帮助管理数据。</code></p><p><strong>Shared Memory</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032211153.png" alt="image-20250503221105036"></p><p>Shared memory in Informix Dynamic Server is divided into three portions:</p><p>IDS中的共享内存分为3个不分：</p><p>The <em>resident portion</em> contains the buffer cache and other system information. These shared memory segments can be configured to remain resident in main memory.  </p><p><code>“常驻部分”包含缓冲区缓存和其他系统信息。这些共享内存段可以配置为驻留在主内存中。</code></p><p>The <em>virtual portion</em> contains information about threads and sessions, data object caching, and temporary data needed for activities such as sorting and parallel data query. This information grows and changes constantly, so the database server must handle the allocation and deallocation of memory.</p><p><code>“虚拟部分”包含有关线程和会话、数据对象缓存以及排序和并行数据查询等活动所需的临时数据的信息。这些信息不断增长和变化，因此数据库服务器必须处理内存的分配和释放。</code></p><p>Clients connecting to the database server by shared memory leave and collect messages in the <em>message portion</em> of shared memory. This portion is created only if you configure shared memory as a communications method for the server.</p><p><code>通过共享内存连接到数据库服务器的客户端会在共享内存的“消息部分”中发送和接收消息。仅当您将共享内存配置为服务器的通信方式时，才会创建此部分。</code></p><p><strong>A Local Delete</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032225865.png" alt="image-20250503222537796"></p><p>The above example assumes that the client is using a shared-memory connection.</p><p><code>上面的例子假设客户端正在使用共享内存连接。</code></p><ol><li><p>When you type <strong>dbaccess</strong>, the UNIX shell spawns a client process.</p><p><code>当你输入dbaccess，UNIX shell 会生成一个客户端进程。</code></p></li><li><p>When you connect to a database, the client process connects to Dynamic Server shared memory. The database server (which is chiefly a collection of processes called <strong>oninit</strong>) detects a new connection and creates a session and an <strong>sqlexec</strong> thread for the session. The <strong>sqlexec</strong> thread waits for further instructions from the client.</p><p><code>连接到数据库时，客户端进程会连接到动态服务器共享内存。数据库服务（主要是一个称为oninit的进程集合）会检测到一个新连接，并为会话创建一个会话和一个sqlexec线程。sqlexec 线程等待客户端将来的指令。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032233662.png" alt="image-20250503223234075"></p></li><li><p>The client connects to the server with the CONNECT or DATABASE statement. Opening the database involves many read and write operations.</p><p><code>客户端通过 CONNECT 或 DATABASE 语句连接服务器。打开数据库涉及许多读写操作。</code></p></li><li><p>Assume that our <strong>sqlexec</strong> thread decides it must scan page 30 in chunk 4. (By the end of this course, you will understand the method by which a thread arrives at this decision in agonizing detail. For now, be thankful for broad assumptions.) First it finds a free <em>buffer</em>, a page-size swath of memory, in the shared memory buffer pool. It locks this buffer, taking temporary ownership of it. The <strong>sqlexec</strong> thread then places a request for page 30 from chunk 4 into the AIO request queue, and then goes to sleep. Again, speaking in broad generalities, the kernel asynchronous I&#x2F;O system (or the Dynamic Server AIO mechanism) puts the page into the buffer, overwriting whatever was there previously. Then the <strong>sqlexec</strong> thread wakes up and scans the buffer for the desired information. The buffer can now be unlocked, (though not freed), so that other processes who require the same page do not have to read it from disk.</p><p><code>假设我们的 sqlexec 线程决定它必须扫描块 4 中的第 30 页。（在本课程结束时，您将理解线程做出此决定的详细过程。现在，请感谢宽泛的假设。）首先，它在共享内存缓冲池中找到一个可用缓冲区，即一个页面大小的内存区域。它锁定此缓冲区，并暂时拥有它。然后，sqlexec 线程将对块 4 中第 30 页的请求放入 AIO 请求队列，然后进入睡眠状态。同样，广义上讲，内核异步 I/O 系统（或 Dynamic Server AIO 机制）将页面放入缓冲区，覆盖先前的内容。然后，sqlexec 线程唤醒并扫描缓冲区以查找所需信息。现在可以解锁缓冲区（但不能释放），以便其他需要同一页面的进程不必从磁盘读取它。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032240217.png" alt="image-20250503224006136"></p></li><li><p>The server process sends an <em>OK</em> message to the client, indicating that the previous operation (database open) was successful. The client then sends the DELETE statement to the server, where it is <em>parsed</em> (the syntax is broken down and interpreted) and optimized (a plan to quickly find the target row(s) is formulated).</p><p><code>服务器进程向客户端发送 OK 消息，表示上一个操作（打开数据库）成功。然后，客户端将 DELETE 语句发送到服务器，服务器对其进行解析（语法分解和解释）和优化（制定快速找到目标行的方案）。</code></p></li><li><p>If transaction logging is turned on for the database about to be modified, by definition, all changes must be logged as part of a transaction. Since the server has received no BEGIN WORK statement to this point, it treats this lone DELETE statement as a singleton transaction, meaning that surrounding the one operation are implicit BEGIN WORK and COMMIT WORK SQL statements. Therefore, before performing the delete operation, the <strong>sqlexec</strong> thread sends a BEGIN WORK log record, a digested form of the BEGIN WORK statement, to the logical log buffer.</p><p><code>如果要修改的数据库启用了事务日志记录，那么根据定义，所有更改都必须作为事务的一部分进行记录。由于服务器目前尚未收到任何 BEGIN WORK 语句，因此它会将此单独的 DELETE 语句视为一个单例事务，这意味着围绕该操作的是隐式的 BEGIN WORK 和 COMMIT WORK SQL 语句。因此，在执行删除操作之前，sqlexec 线程会将 BEGIN WORK 日志记录（BEGIN WORK 语句的摘要形式）发送到逻辑日志缓冲区。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032244997.png" alt="image-20250503224426924"></p><p>The next step is for the server to lock, then modify a particular data page in the <strong>customer</strong>table. There is no reason to read the page from disk if it already exists in shared memory,  so the server first determines whether the page containing the target row is in the buffer pool.</p><p><code>下一步是服务器锁定客户表中的特定数据页，然后进行修改。如果该页已存在于共享内存中，则无需从磁盘读取该页，因此服务器首先会确定包含目标行的页是否位于缓冲池中。</code></p></li><li><p>Let us assume the page had, in fact, been read into a buffer pool by an earlier query, and that this buffer has never been modified. Assuming the buffer is not locked by another thread, the <strong>sqlexec</strong> thread locks it exclusively. Then, prior to changing the data, the server copies the <em>before image</em> of this page to the physical log buffer.</p><p><code>假设该页面实际上已被先前的查询读入缓冲池，并且该缓冲区从未被修改过。假设该缓冲区未被其他线程锁定，则 sqlexec 线程会对其进行独占锁定。然后，在更改数据之前，服务器会将该页面的“前映像”复制到物理日志缓冲区。</code></p></li><li><p>The target row on the page is then deleted.</p><p><code>然后删除页面上的目标行。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032250593.png" alt="image-20250503225034532"></p></li><li><p>After deleting the row, the database server writes a DELETE record of the change row. A record of table and row information is copied to the logical log buffer in memory.</p><p><code>删除行后，数据库服务会写入更改行的 DELETE 记录。表和行信息的记录被复制到内存中的逻辑日志缓冲区。</code></p></li><li><p>The singleton transaction is then committed. All associated locks are freed, and a binary version of a COMMIT WORK record is written to the logical log buffer. At this point, if the affected database uses <em>unbuffered</em> logging*,* the server writes the contents of the logical log buffer to the current log file on disk before returning a <em>success</em>status to the client process. Assume for the sake of this example that our database uses <em>buffered</em> logging, in which case the server does not flush the log buffer unless it is full.</p><p><code>然后提交单事务。所有关联的锁都会被释放，并且 COMMIT WORK 记录的二进制版本会写入逻辑日志缓冲区。此时，如果受影响的数据库使用非缓冲日志记录，则服务器会将逻辑日志缓冲区的内容写入磁盘上的当前日志文件，然后再向客户端进程返回成功状态。为了便于说明，假设我们的数据库使用缓冲日志记录，在这种情况下，除非日志缓冲区已满，否则服务器不会刷新日志缓冲区。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032259197.png" alt="image-20250503225947128"></p></li><li><p>Once the transaction has committed successfully, the server process sends an <em>OK</em>message back to the client. The server then waits on a condition for further instructions. If the client exits at this point, the following events occur:</p><p><code>一旦事务成功提交，服务器进程就会向客户端发送一条 OK 消息。然后，服务器等待进一步的指令。如果客户端在此时退出，则会发生以下事件：</code></p><p><strong>-</strong> The session threads release any resources, such as locks or buffers. </p><p>会话线程会释放所有资源，例如锁或缓冲区。</p><p> <strong>-</strong> The session threads and the session memory disappear.</p><p>会话线程和会话内存会消失。</p><p> <strong>-</strong> The client detaches from shared memory.</p><p>客户端脱离共享内存。</p></li></ol><p><strong>Writing Buffer Pages to Disk</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032304898.png" alt="image-20250503230458815"></p><p>The transaction might be over as far as we are concerned, but nothing our server process did has yet been stored permanently. If shared memory were to vanish suddenly, our changes would be lost.</p><p><code>就我们而言，事务可能已经结束，但我们的服务器进程所做的一切还没有被永久保存（持久化）。如果共享内存突然消失，我们的更改也会丢失。</code></p><ol><li><p>Assuming other sessions continue working after our session disconnected, one of them eventually fills the physical log buffer. The PIO virtual processor flushes the physical log buffer (unless kernel asynchronous I&#x2F;O is used, in which case the kaio thread performs the I&#x2F;O). All before images stored in the buffer are written to the physical log on disk, and the buffer can now be overwritten by new before images.</p><p><code>假设我们的会话断开后其他会话继续工作，其中一个会话最终会填满物理日志缓冲区。PIO 虚拟处理器会刷新物理日志缓冲区（除非使用内核异步 I/O，在这种情况下，kaio 线程会执行 I/O）。所有存储在缓冲区中的前像都会写入磁盘上的物理日志，现在缓冲区可以被新的前映像覆盖。</code></p></li><li><p>Likewise, the LIO virtual processor or the kaio facility flushes the logical log buffer. All transaction log records stored in the buffer, having been packaged there in the form of new logical log pages, are written to the logical log currently in use.</p><p><code>同样，LIO 虚拟处理器或 kaio 工具会刷新逻辑日志缓冲区。所有存储在缓冲区中的事务日志记录，都会以新的逻辑日志页的形式打包，并写入当前正在使用的逻辑日志中。</code></p></li></ol><p>Note that the order of these two operations is random, and is usually dependent on which buffer fills first. However, a page cleaner ensures that the before image of a page is written to the physical log before its modified image is written to disk from the buffer pool.</p><p><code>请注意，这两个操作的顺序是随机的，通常取决于哪个缓冲区先被填满。但是，页面清理器会确保在页面的修改后映像从缓冲池写入磁盘之前，先将页面的修改前映像写入物理日志。  </code></p><p><strong>Performing a Checkpoint</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032316212.png" alt="image-20250503231650138"></p><p>Now that the before image of our page has been written to the physical log and all actions we took on the page have been recorded in the logical log, we can recover the transaction if it became necessary. But replaying transactions using logical logs takes time, and we would rather do as little work as possible during a recovery.At this point, if we were to synchronize the data in shared memory with the data in our chunks—flushing all dirty pages, flushing both log buffers, and marking our current position in the logical log—we would produce a <em>known point of consistency</em>. In the event of a failure, we could return to this synchronization point or <em>checkpoint</em>, replay only the actions taken on the database since then, and the time it would take to get the system back online would be minimized.</p><p><code>现在，页面的“前映像”已写入物理日志，并且我们在页面上执行的所有操作都已记录在逻辑日志中，我们可以在必要时恢复事务。但是，使用逻辑日志重放事务需要时间，我们希望在恢复期间尽可能少地执行工作。此时，如果我们将共享内存中的数据与块中的数据同步（刷新所有脏页，刷新两个日志缓冲区，并标记我们在逻辑日志中的当前位置），我们将产生一个已知的一致性点。如果发生故障，我们可以返回到此同步点或检查点，仅重放自那时以来在数据库上执行的操作，从而最大限度地缩短系统恢复在线所需的时间。</code></p><ol><li><p>First, a checkpoint is <em>requested</em>. There are many conditions or events that trigger a checkpoint request. For example:</p><p><code>触发检查点请求的条件或事件有很多。例如：</code></p><p><strong>-</strong> The checkpoint time-out value has elapsed and pages have been modified</p><p><code>检查点超时值已过且页面已被修改</code></p><p> <strong>-</strong> The physical log becomes 75% full</p><p><code>物理日志已满 75%</code></p><p> <strong>-</strong> The administrator forces a checkpoint</p><p><code>管理员强制检查点</code></p><p>Configuration parameters that could affect when a checkpoint occurs include:</p><p><code>可能影响检查点发生时间的配置参数包括：</code></p><p> <strong>-</strong> CKPTINTVL – Specifies the interval between the completion of one checkpoint and the request for the next checkpoint.</p><p><code>CKPTINTVL – 指定一个检查点完成与下一个检查点请求之间的间隔。</code></p><p> <strong>-</strong> AUTO_CKPTS – If enabled, critical resources are monitored and checkpoint frequency is adjusted to reduce transaction blocking.</p><p><code>AUTO_CKPTS – 如果启用，则会监视关键资源并调整检查点频率以减少事务阻塞。</code></p><p> <strong>-</strong> RTO_SERVER_RESTART – This parameter specifies, in seconds, the recovery time objective for restarting the database server after a server failure. Checkpoint frequency is adjusted to meet the specified objective.</p><p><code>RTO_SERVER_RESTART – 此参数指定服务器故障后重新启动数据库服务器的恢复时间目标（以秒为单位）。检查点频率会进行调整以满足指定的目标。</code></p></li><li><p>To ensure a point of consistency, the database server sets off a global block to suspend all transactions. Once all servers have reached a point where they can safely suspend their work, checkpoint information is recorded (as if it has already occurred) in the physical log reserve page, but <em>not</em> to the checkpoint reserved page. The global block is then released so that server activity can continue.</p><p><code>为了确保一致性点，数据库服务器会触发全局阻塞来暂停所有事务。一旦所有服务器都达到可以安全暂停工作的程度，检查点信息就会被记录在物理日志保留页中（如同已经发生过一样），但不会记录在检查点保留页中。然后全局阻塞会被释放，以便服务器活动可以继续进行。</code></p></li><li><p>Next, the server flushes the physical log buffer contents to the physical log on disk.</p><p><code>接下来，服务器会将物理日志缓冲区中的内容刷新到磁盘上的物理日志中。</code></p></li></ol><p><strong>Non-blocking checkpoints</strong></p><p>In version 11.10 of Informix Dynamic Server, new algorithms make it possible to avoid transaction blocking during most types of checkpoints. Because checkpoint information is saved at the beginning of the checkpoint process, it is no longer necessary to block transactions while pages are flushed to disk. If the server is interrupted during a checkpoint, then fast recovery can restore from the previous checkpoint. Blocking checkpoints are still required to perform a system backup, and when other system events occur, such as the adding of a dbspace.</p><p><code>在 Informix Dynamic Server 11.10 版本中，新算法可以避免大多数类型的检查点期间的事务阻塞。由于检查点信息在检查点过程开始时保存，因此在将页面刷新到磁盘时不再需要阻塞事务。如果服务器在检查点期间中断，则快速恢复可以从上一个检查点恢复。执行系统备份以及发生其他系统事件（例如添加数据库空间）时仍然需要阻塞检查点。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032338289.png" alt="image-20250503233813202"></p><ol start="4"><li>All dirty pages in the shared-memory buffer pool are written to disk by page cleaner threads. Physical and logical log buffers are flushed to disk.</li></ol><p>   <code>共享内存缓冲池中的所有脏页都由页面清理线程写入磁盘。物理和逻辑日志缓冲区均被刷新到磁盘。</code></p><ol start="5"><li><p>A special record called a <em>checkpoint record</em> is written to the logical log buffer. The physical and logical consistency point on disk is updated to the CKPT reserved page.</p><p><code>一个称为检查点记录的特殊记录被写入逻辑日志缓冲区。磁盘上的物理和逻辑一致性点被更新到 CKPT 保留页。</code></p></li></ol><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032341006.png" alt="image-20250503234102938"></p><p><strong>Flushing the Physical Log</strong></p><ol start="6"><li><p>The last step in the checkpoint process is to <em>logically empty</em> the physical log. Logically emptying the log means setting its <em>begin address</em> equal to its current address, an operation that is much less expensive than filling the log with zeros or changing the log in any physical way.</p><p><code>检查点过程的最后一步是逻辑上清空物理日志。逻辑上清空日志意味着将其起始地址设置为其当前地址，这个操作比用零填充日志或以任何物理方式更改日志的开销要小得多。</code></p></li></ol><p><strong>Fast Recovery</strong></p><p> Always occurs during database server startup</p><p><code>总是在数据库服务器启动时发生</code></p><p> Brings the database to a consistent state</p><p><code>使数据库达到一致状态</code></p><p> Consists of two phases</p><p><code>包含两个阶段</code></p><p>– Physical recovery</p><p>物理恢复</p><p>– Logical recovery</p><p>逻辑恢复</p><p>When a database server is brought from Online to Offline mode, the server threads perform a checkpoint to make sure that all data in shared memory gets written to disk. However, events could occur that cause the server to be shut down before it has a chance to complete a checkpoint.</p><p><code>当数据库服务器从在线模式切换到离线模式时，服务器线程会执行检查点操作，以确保共享内存中的所有数据都已写入磁盘。然而，某些事件可能会导致服务在完成检查点操作之前关闭。</code></p><p><em>Fast recovery</em> is the process that Informix Dynamic Server goes through every time a database server is started. If the database server was terminated abnormally, the fast recovery process uses the physical and logical logs to restore the database server to a state of consistency. There are two phases to the fast recovery process: physical recovery and logical recovery.</p><p><code>快速恢复是 IDS 每次启动数据库服务时都会经历的过程。如果数据库服务器异常终止，快速恢复过程将使用物理日志和逻辑日志将数据库服务器恢复到一致性状态。快速恢复过程分为两个阶段：物理恢复和逻辑恢复。</code></p><p><strong>Fast Physical Recovery</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051114478.png" alt="image-20250505111447340"></p><p>During the first stage of fast recovery, called <em>physical recovery</em>, all the before images in the physical log are copied to their proper addresses on disk. We overwrite those pages with their before images for a good reason. During normal operation, page cleaner threads are constantly writing dirty pages out from shared memory to the AIO queue (which gets flushed to disk by the AIO VP or by the <strong>kaio</strong> thread). If we are to reproduce the conditions that existed immediately after the last checkpoint, we must ensure that any pages modified and flushed since that checkpoint are replaced with their original images.</p><p><code>在快速恢复的第一阶段（称为物理恢复）中，物理日志中的所有前映像都会被复制到磁盘上的正确地址。我们用前映像覆盖这些页面是有原因的。在正常运行期间，页面清理线程会不断将脏页从共享内存写入 AIO 队列（该队列由 AIO VP 或 kaio 线程刷新到磁盘）。如果我们要重现上一个检查点之后的情况，必须确保自该检查点以来修改和刷新的所有页面都被替换为其原始映像。</code></p><p>Once this reshelving is done, the physical log is logically emptied (the physical log begin pointer is set to the current pointer).</p><p><code>一旦完成重新搁置，物理日志在逻辑上就被清空（物理日志开始指针设置为当前指针）。</code></p><p><strong>Fast Logical Recovery</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051119920.png" alt="image-20250505111924827"></p><p>The second stage of fast recovery, <em>logical recovery</em>, remodifies the pages restored by physical recovery. Beginning at the last checkpoint record in the logical logs, the <strong>oninit</strong> process rolls forward from there, bringing the system to exactly the state it was in at the time of the crash. The loose ends are tied up after the last log record is applied; <strong>oninit</strong> rolls back any uncommitted transactions, records the rollback by adding CLRs (compensation log records) in the log, deletes temporary tables, performs index builds deferred during the rollforward as an optimization, and brings the system into Quiescent mode.</p><p><code>快速恢复的第二阶段是逻辑恢复，它会重新修改物理恢复所恢复的页面。oninit 进程从逻辑日志中最后一个检查点记录开始前滚，使系统恢复到崩溃时的状态。应用最后一个日志记录后，所有未完成的操作都已完成；oninit 会回滚所有未提交的事务，通过在日志中添加 CLR（补偿日志记录）来记录回滚，删除临时表，执行在前滚过程中作为优化而推迟的索引构建，并将系统置于静默模式。</code></p><p><code>紫本200页Quiescent mode翻译成静默模式</code></p><p>Then the whole cycle begins again. Attached sessions are free to modify shared memory, and the pages on disk become more and more out of date in relation to the buffer pool. If our database server came down unexpectedly at this point, all modified buffers would vanish. We would have to get those pages back somehow. Fast recovery manages to do just that.</p><p><code>然后整个循环再次开始。连接的会话可以自由地修改共享内存，磁盘上的页面相对于缓冲池来说会变得越来越过时。如果我们的数据库服务器此时意外宕机，所有修改过的缓冲区都会消失。我们必须以某种方式恢复这些页面。快速恢复正是这样做的。</code></p><p>After completion of the checkpoint, all pages in the buffer cache are in sync with the pages on disk.</p><p><code>检查点完成后，缓冲区缓存中的所有页面都与磁盘上的页面同步。</code></p><p><strong>Fast Recovery and Checkpoint Messages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051132861.png" alt="image-20250505113201794"></p><p>Above is an example of messages written to the message log during fast recovery. The message log shows the page at which physical recovery began (in the form chunk_number*:<em>page_offset</em>) and how many before-image pages were examined and restored. It also shows the number of transactions that were committed or rolled back during logical recovery. Finally, the message log shows checkpoint information, including where the checkpoint record was written in the logical logs.</p><p><code>以上是快速恢复期间写入消息日志的消息示例。消息日志显示了物理恢复开始的页面（格式为“chunk_number:page_offset”）以及检查和恢复了多少个前映像页面。它还显示了逻辑恢复期间提交或回滚的事务数量。最后，消息日志显示了检查点信息，包括检查点记录在逻辑日志中的写入位置。</code></p><p><code>紫本202页基本是快速恢复这块的翻译，而且有例子</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SQLsmith</title>
      <link href="/2024/04/07/SQLsmith/SQLsmith/"/>
      <url>/2024/04/07/SQLsmith/SQLsmith/</url>
      
        <content type="html"><![CDATA[<p>源码：<a href="https://github.com/anse1/sqlsmith">https://github.com/anse1/sqlsmith</a> tag:v1.4</p><p>在Centos7上用CLion看代码，装了一些东西（顺序不一定），直到项目右键”Reload CMake Project”不报错为止，然后代码点击才能跳转<br>yum install postgresql14<br>yum install gcc-c++<br>yum clean all<br>rm -rf &#x2F;var&#x2F;cache&#x2F;yum&#x2F;*<br>yum install <a href="https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm">https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</a><br>yum install llvm5.0-devel<br>yum install postgresql14-devel<br>yum install libpqxx libpqxx-devel</p><p>目的是看懂执行逻辑，不深入c++语法，只查了一下make_shared的含义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make_shared</span>&lt;query_spec&gt;((<span class="keyword">struct</span> prod *)<span class="number">0</span>, s); <span class="comment">// 它会导致query_spec构造函数的调用，括号里是传入的2个参数</span></span><br></pre></td></tr></table></figure><p>.cc文件，当做.cpp理解即可</p><p>入口：sqlsmith.cc，只看postgres相关逻辑</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main()</span></span><br><span class="line"><span class="comment">// 导致schema_pqxx构造函数调用，见下面postgres.cc</span></span><br><span class="line">schema = <span class="built_in">make_shared</span>&lt;schema_pqxx&gt;(options[<span class="string">&quot;target&quot;</span>], options.<span class="built_in">count</span>(<span class="string">&quot;exclude-catalog&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行sqlsmith时，加--dry-run，会把随机生成的语句写到日志里，不会执行</span></span><br><span class="line"><span class="keyword">if</span> (options.<span class="built_in">count</span>(<span class="string">&quot;dry-run&quot;</span>)) &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        shared_ptr&lt;prod&gt; gen = <span class="built_in">statement_factory</span>(&amp;scope);</span><br><span class="line">        gen-&gt;<span class="built_in">out</span>(cout);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> l : loggers)</span><br><span class="line">            l-&gt;<span class="built_in">generated</span>(*gen);</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;;&quot;</span> &lt;&lt; endl;</span><br><span class="line">        queries_generated++;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (options.<span class="built_in">count</span>(<span class="string">&quot;max-queries&quot;</span>)</span><br><span class="line">            &amp;&amp; (queries_generated &gt;= <span class="built_in">stol</span>(options[<span class="string">&quot;max-queries&quot;</span>])))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>postgres.cc</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">schema_pqxx::<span class="built_in">schema_pqxx</span>(std::string &amp;conninfo, <span class="type">bool</span> no_catalog) : <span class="built_in">c</span>(conninfo)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 使用 libpqxx (PostgreSQL C++ API) 读元数据，包括：</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// types</span></span><br><span class="line">  <span class="comment">// name,oid,typdelim,typrelid,typelem,typarray,typtype</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// tables </span></span><br><span class="line">  <span class="comment">// name，schema，is_insertable，is_base_table（后边，只有是true的表才有机会从中随机）</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// columns and constraints</span></span><br><span class="line">  <span class="comment">// operators</span></span><br><span class="line">  <span class="comment">// routines</span></span><br><span class="line">  <span class="comment">// routine parameters</span></span><br><span class="line">  <span class="comment">// aggregates</span></span><br><span class="line">  <span class="comment">// aggregate parameters</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_LIBPQXX7</span></span><br><span class="line">  c.<span class="built_in">close</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  c.<span class="built_in">disconnect</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  <span class="built_in">generate_indexes</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> SQLsmith </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>物理日志</title>
      <link href="/2023/11/21/gbase8s/%E7%89%A9%E7%90%86%E6%97%A5%E5%BF%97/"/>
      <url>/2023/11/21/gbase8s/%E7%89%A9%E7%90%86%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p><u>数据库原理和实践教程GBase8t剖析与应用.pdf</u></p><h5 id="为什么需要物理日志"><a href="#为什么需要物理日志" class="headerlink" title="为什么需要物理日志"></a>为什么需要物理日志</h5><p>快速恢复时，先用物理日志记录的前映像恢复，再进行逻辑日志恢复</p><h5 id="为什么需要恢复到前映像"><a href="#为什么需要恢复到前映像" class="headerlink" title="为什么需要恢复到前映像"></a>为什么需要恢复到前映像</h5><blockquote><p>发生checkpoint后，由于内存中的脏数据可能在下一次checkpoint之前被写回到磁盘，这就是我们通常所讲的<mark>LRU写</mark>（后台写），所以磁盘上的数据再checkpoint之后发生了变化，就不能用作逻辑恢复</p><p>书 202 页</p></blockquote><h5 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h5><blockquote><p>数据库周期性地将buffer pool的 <mark>脏数据</mark> 刷新到磁盘上，达到磁盘、内存数据一致性的时间点被称为检查点（Checkpoint）</p><p>书 188 页</p></blockquote><h5 id="共享内存缓冲池（Buffer-Pool）"><a href="#共享内存缓冲池（Buffer-Pool）" class="headerlink" title="共享内存缓冲池（Buffer Pool）"></a>共享内存缓冲池（Buffer Pool）</h5><blockquote><p>共享内存缓冲池存储从磁盘读取的数据库空间页的缓冲区，用来缓存数据库表从磁盘读取的数据，数据库在内存中对数据进行访问和修改，当数据发生变化后，将写回磁盘。其中每个缓冲区就是一个数据库服务器页的大小。</p><p>共享内存缓冲池通过 LRU 队列的方式进行集体管理，如图 6.10 所示。LRU 队列由空闲的队列（Free LRU 或 FLRU）和<mark>脏队列</mark>（Modified LRU 或 MLRU）组成。共享内存缓冲池按 LRU 队列对进行管理，一个是 Free，另外一个是 Modify。同一个 Page 只能在 LRU队列对中出现一次，比如：有一行记录被修改了，那么该行记录所在的 Page 将被从 Free队列移动到 Modify 队列。</p><p>书 160 页</p></blockquote><p>脏数据就是脏队列里的数据</p><h5 id="为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）"><a href="#为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）" class="headerlink" title="为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）"></a>为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）</h5><p>书上没写，看官网</p><p><a href="https://www.ibm.com/docs/en/informix-servers/12.10?topic=flushing-lru-write">LRU write - IBM Documentation</a></p><blockquote><p>LRU writes are performed by page cleaners rather than by sqlexec threads. The database server performs LRU writes as background writes that <strong>typically occur when the percentage of dirty buffers exceeds the percent that is specified for lru_max_dirty in the BUFFERPOOL configuration parameter.</strong></p></blockquote><p>就是脏数据的比例超过一个配置的最大脏数据百分比，触发 LRU 写，落盘</p><p>（从 LRU 也能猜出一二，这是一种缓存淘汰算法）</p><p>书 203 页，有个快速恢复的示例</p>]]></content>
      
      
      <categories>
          
          <category> gbase8s </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>PreparedStatement</title>
      <link href="/2023/09/03/jmeter/PreparedStatement/"/>
      <url>/2023/09/03/jmeter/PreparedStatement/</url>
      
        <content type="html"><![CDATA[<p>JDBC Request</p><p>有 2 个 PreparedStatement 相关的选项</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202309031350398.png" alt="image-20230903135037315"></p><p>单纯选择 Prepared Statement（没开启 Pool Prepared Statements）</p><p>如果使用参数化的方式执行 select * from t1 where id&#x3D;? 性能比 Statement 低（2% 左右，粗略测试），Statement 执行的是 select * from t1 where id&#x3D;1（2% 的原因看内部文档）</p><p>如果使用非参数化方式，都执行 select * from t1 where id&#x3D;1，性能没差别</p><p>总之，完全体现不出来 Prepared Statement 一次预编译，多次执行的优势</p><p>因为，每次请求都会重新创建 PreparedStatement 对象预编译，请求结束后 close()</p><p>AbstractJDBCTestElement.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (PREPARED_SELECT.equals(currentQueryType)) &#123;</span><br><span class="line">    <span class="keyword">try</span> (<span class="type">PreparedStatement</span> <span class="variable">pstmt</span> <span class="operator">=</span> getPreparedStatement(conn)) &#123;</span><br><span class="line">        setArguments(pstmt);</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            rs = pstmt.executeQuery();</span><br><span class="line">            sample.latencyEnd();</span><br><span class="line">            <span class="keyword">return</span> getStringFromResultSet(rs).getBytes(ENCODING);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            close(rs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (PREPARED_UPDATE.equals(currentQueryType)) &#123;</span><br><span class="line">    <span class="keyword">try</span> (<span class="type">PreparedStatement</span> <span class="variable">pstmt</span> <span class="operator">=</span> getPreparedStatement(conn)) &#123;</span><br><span class="line">        setArguments(pstmt);</span><br><span class="line">        pstmt.executeUpdate();</span><br><span class="line">        sample.latencyEnd();</span><br><span class="line">        <span class="type">String</span> <span class="variable">sb</span> <span class="operator">=</span> resultSetsToString(pstmt,<span class="literal">false</span>,<span class="literal">null</span>);</span><br><span class="line">        <span class="keyword">return</span> sb.getBytes(ENCODING);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (ROLLBACK.equals(currentQueryType))&#123;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> PreparedStatement <span class="title function_">getPreparedStatement</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">    <span class="keyword">return</span> getPreparedStatement(conn,<span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> PreparedStatement <span class="title function_">getPreparedStatement</span><span class="params">(Connection conn, <span class="type">boolean</span> callable)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">    PreparedStatement pstmt;</span><br><span class="line">    <span class="keyword">if</span> (callable) &#123;</span><br><span class="line">        pstmt = conn.prepareCall(getQuery()); </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pstmt = conn.prepareStatement(getQuery()); <span class="comment">// conn 是 DelegatingConnection，先不用管</span></span><br><span class="line">    &#125;</span><br><span class="line">    setQueryTimeout(pstmt, getIntegerQueryTimeout());</span><br><span class="line">    <span class="keyword">return</span> pstmt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> jmeter </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>blog</title>
      <link href="/2023/08/27/misc/blog/"/>
      <url>/2023/08/27/misc/blog/</url>
      
        <content type="html"><![CDATA[<p><strong>theme: hexo-theme-ayer</strong></p><h4 id="1-分类、标签，访问不了"><a href="#1-分类、标签，访问不了" class="headerlink" title="1. 分类、标签，访问不了"></a>1. 分类、标签，访问不了</h4><h5 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h5><p>hexo new page categories</p><p>source\categories\index.md</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;categories&quot;</span><br><span class="line">layout: &quot;categories&quot;</span><br></pre></td></tr></table></figure><h5 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h5><p>hexo new page tags</p><p>source\tags\index.md</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;tags&quot;</span><br><span class="line">layout: &quot;tags&quot;</span><br></pre></td></tr></table></figure><h4 id="2-打开只有文字"><a href="#2-打开只有文字" class="headerlink" title="2. 打开只有文字"></a>2. 打开只有文字</h4><p>新建仓库的时候，填写的仓库名字为<code>账号名.github.io</code>，这样博客地址默认是根路径</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202308272212419.png" alt="image-20230827221050557"></p><p><a href="https://blog.csdn.net/github_38641765/article/details/100182694?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-100182694-blog-119349705.235%5Ev38%5Epc_relevant_anti_t3_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-100182694-blog-119349705.235%5Ev38%5Epc_relevant_anti_t3_base&utm_relevant_index=2">参考文章</a></p><p>gitee 的话，仓库名和账号名一样即可，frh16&#x2F;frh16</p><h4 id="3-图床图片打不开"><a href="#3-图床图片打不开" class="headerlink" title="3. 图床图片打不开"></a>3. 图床图片打不开</h4><p>raw.githubusercontent.com</p><p>PicGo 设定自定义域名</p><p><a href="https://gcore.jsdelivr.net/gh/%E8%B4%A6%E5%8F%B7%E5%90%8D/%E5%9B%BE%E5%BA%8A%E4%BB%93%E5%BA%93%E5%90%8D">https://gcore.jsdelivr.net/gh/账号名/图床仓库名</a></p><p>如果不用 CDN，需要科学上网 或 Steam++</p><h4 id="4-前端全文搜索"><a href="#4-前端全文搜索" class="headerlink" title="4. 前端全文搜索"></a>4. 前端全文搜索</h4><p>npm install hexo-generator-search –save</p><p>hexo g &amp;&amp; hexo d 可以看到 search.xml</p>]]></content>
      
      
      <categories>
          
          <category> misc </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
