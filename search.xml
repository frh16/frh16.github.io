<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>IX9111 - Unit 2. The Dynamic Server Page</title>
      <link href="/2025/05/05/IX9111/2/"/>
      <url>/2025/05/05/IX9111/2/</url>
      
        <content type="html"><![CDATA[<p><strong>Page: Smallest Unit of I&#x2F;O</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052201901.png" alt="image-20250505220102809"></p><p><em>Pages</em> are the most basic unit of I&#x2F;O in Informix Dynamic Server; a server process does not read or write to a chunk in an increment smaller than a page. As often as possible, however, I&#x2F;O is performed on more than one page at a time.</p><p><code>在 IDS 中，页是 I/O 的最基本单位；服务进程在访问一个 chunk 时，读取或写入的最小单位就是一个页面。不过，I/O 通常会同时在多个页面上执行。</code></p><p>The default page size for a machine is either 2KB or 4KB depending on the platform. You can configure the page size for each dbspace to be any value from 2KB to 16KB, but the value must be divisible by the default page size.</p><p><code>机器的默认页面大小为 2KB 或 4KB，具体取决于平台。你可以将每个dbspace的page size配置为 2KB 至 16KB 之间的任意值，但该值必须能被默认页面大小整除。</code></p><p>At a binary level, each allocated page in a system contains a unique stream of data. But the structure and meaning of that data is always based on a handful of templates. This module teaches you how to recognize the structural similarities between Dynamic Server pages, and decipher the important parts of those structures. These skills help you understand Dynamic Server architecture and behavior to a degree you never thought possible.</p><p><code>在二进制层面上，系统中分配的每个页面都包含唯一的数据流。但这些数据的结构和含义总是基于一些模板。本模块教你如何识别 Dynamic Server 页面之间的结构相似性，并解读这些结构的重要部分。这些技能将帮助你理解 Dynamic Server 结构和行为，达到你从未想象过的程度。</code>  </p><p><strong>Our Imagined View of a Page</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052211934.png" alt="image-20250505221109866"></p><p><code>Linux中的od命令是一个十六进制和其他进制的转换工具，它可以用于显示二进制文件的内容。-x：以十六进制的形式显示文件内容；</code></p><p>It is rarely convenient to picture a block of bytes as a continuous stream. Our preference is to reorganize the bytes so they can be viewed as if words are seen on a printed page.</p><p><code>将字节块想象成连续的数据流并不方便。我们更倾向于重新组织字节，使它们可以像印刷页面上的文字一样被查看。</code></p><p>In the example above, the <strong>od</strong> (octal dump) utility in UNIX and Linux displays a byte stream from a page. In this output, the numbers on the left represent byte offsets in <em>octal</em> and are not part of the data. The rest of the output is the actual stream of bytes from the <strong>rootchunk</strong>file displayed as hexadecimal values (courtesy of the <strong>-x</strong> option). Note that two hexadecimal digits (<strong>7c</strong>, for instance) represent one byte of data. Therefore, with a little counting, you can see that <strong>od</strong> displays 16 bytes of data on each line. The significance of the number 16 is that it equals 0x10 (hexadecimal 10).</p><p><code>在上面的示例中，UNIX 和 Linux 中的 od（八进制转储）实用程序显示了一个页面的字节流。在该输出中，左边的数字代表八进制的字节偏移量，并不是数据的一部分。输出的其余部分是以十六进制值显示的 rootchunk 文件的实际字节流（由 -x 选项提供）。请注意，两个十六进制数字（例如 7c）代表一个字节的数据。因此，只要稍微数一数，就可以看到 od 每行显示 16 个字节数据。数字 16 的意义在于它等于 0x10（十六进制 10）。</code></p><p>Because most programmers are familiar with this output format, we tend to picture Dynamic Server pages the same way: as a certain number of 16-byte lines. Therefore, this is the standard used in the Informix Dynamic Server course manuals.</p><p><code>由于大多数程序员都熟悉这种输出格式，我们往往会以同样的方式来描绘 Dynamic Server 页面：一定数量的 16 字节行。因此，这是 IDS 课程手册中使用的标准。</code>  </p><p><strong>Page Layout</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052222234.png" alt="image-20250505222202164"></p><p>The layout of a page is shown in the slide above.</p><p><code>页面布局如上图所示。</code></p><p><strong>Page header</strong></p><p>The page header occupies the first 24 bytes on the page. It contains such information as the location, type, and current capacity of the page.</p><p><code>页头占页面的前 24 个字节。它包含页面的位置、类型和当前容量等信息。</code></p><p><strong>Timestamp</strong></p><p>Each time a page is modified, the timestamp field, located in the last 4 bytes of the page, is updated. The timestamp can be used to compare with other pages to determine which was updated most recently.</p><p><code>每次修改页面时，位于页面最后 4 个字节的时间戳字段都会更新。时间戳可用于与其他页面进行比较，以确定哪个页面是最近更新的。</code></p><p><strong>Slot table</strong></p><p>The slot table enables the database server to quickly find data on a page. It is a series of 4-byte entries that begins at the page-ending timestamp and grows toward the beginning of the page. Each entry in the table describes one <em>slot</em> on the page, which can contain a data row, or some other structure. A slot table entry is comprised of two parts: the location of the slot’s first byte and the length of the slot. A slot table entry functions as a kind of pointer, allowing direct, random access to slots on the page.</p><p><code>槽表使数据库服务能够快速查找页面上的数据。它是一系列 4 字节的条目，从页面结束的时间戳开始，向页面的开头延伸。表中的每个条目描述页面上的一个槽，其中可以包含数据行或其他结构。槽表项由两部分组成：槽的第一个字节位置和槽的长度。槽表项作为一种指针，允许直接随机访问页面上的槽。</code></p><p>Page types that tend to be searched sequentially do not utilize a slot table, although they can have one. Logical log pages are an example of a page type that has no slot table at all.</p><p><code>倾向于按顺序搜索的页面类型不使用slot table，尽管它们可以有slot table。逻辑日志页就是完全没有slot table的页面类型。</code></p><p>紫本177页：</p><p><code>slots table：为 slots 描述信息，数据页中有多少 slots，则会对应多少个 slots bitmap，每个占用 4 Byte，记录 slots 在页内的偏移地址和长度，当记录被删除时，只是将其中的占用长度设置为 0，在物理上并没有将记录信息清空。</code></p><p><strong>Page Header Overview</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052238924.png" alt="image-20250505223812841"></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052240740.png" alt="image-20250505224026671"></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052241776.png" alt="image-20250505224107724"></p><p>The <strong>pg_offset</strong> field contains the <em>page offset</em>, which indicates the physical location of the page within the chunk.</p><p><code>pg_offset 字段包含页面偏移量，表示页面在chunk中的物理位置。</code></p><p>The page offset value is incremented by one for each subsequent page in the chunk. The first page in a chunk has a <strong>pg_offset</strong> value of 0. The maximum <strong>pg_offset</strong> value is based on the maximum size of a chunk, which is around 4 terabytes.</p><p><code>页偏移值每增加一页，页面偏移值就递增一次。chunk中的第一个页面的 pg_offset 值为 0。 最大 pg_offset 值基于chunk的最大大小，约为 4 TB。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505052245545.png" alt="image-20250505224529492"></p><p><strong>Chunk number</strong></p><p>The <strong>pg_chunk</strong> field contains the number of the chunk where the page is located. Chunk numbering starts at 1. The combination of the <strong>pg_chunk</strong> and <strong>pg_offset</strong> provide all the information needed to identify the <em>page address</em>. The maximum <strong>pg_chunk</strong> value is 32,767.</p><p><code>pg_chunk 字段包含页面所在chunk的编号，chunk编号从 1 开始。pg_chunk 和 pg_offset 的组合提供了识别页面地址所需的全部信息。pg_chunk 的最大值为 32,767。</code></p><p>紫本176页：</p><p>Page Address ： 存 储 页 的 地 址 信 息 ， 占 用 6 Byte ， 由 两 部 分 组 成 ：chunknum+pageoffsize，其中 chunknum 占用 2 Byte，包含了符号位，故支持的最大 chunk 数为 FFFF&#x2F;2&#x3D;32767，也就是说一个 GBase 8t 实例最多可以支持 32767个 chunk。Pageoffzie 占用 4 Byte，故一个 chunk 的最大页数 FFFFFFFF 去掉符号位&#x3D;2 的 31 次方＝2 billion，对于 2k 的 pagesize，最大的空间为 4T&#x3D;22 的 31 次方*2K&#x3D;2 147 483 648*2k。</p><p><strong>Page checksum</strong></p><p>The <strong>pg_cksum</strong> field stores a checksum value that is used to validate the consistency of a page.</p><p><code>pg_cksum 字段存储一个校验和值，用于验证页面的一致性。</code></p><p>紫本：CHKSUM：校验位，占用 2 Byte。</p><p><strong>Number of Slots</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062019861.png" alt="image-20250506201908729"></p><p>You might expect <strong>pg_nslots</strong> to equal the number of active (undeleted) slots on a page. But in fact, <strong>pg_nslots</strong> indicates the <em>highest</em> number of active slots on the page.</p><p><code>你可能会认为 pg_nslots 的值等于页面上活动（未被删除）slot的数量。但实际上，pg_nslots 表示的是页面上曾经出现过的最高活动slot编号。。</code></p><p>The <strong>pg_nslots</strong> field is not decremented, even if slots are deleted. Take the case of a data page, for example. If slots 1 through 4 out of a total of five slots are deleted, slot 5 cannot be made slot 1 in the interest of space efficiency because the rowid for that slot would change. Even though only one slot is active on the page at that point, <strong>pg_nslots</strong> must remain 5 to enable a sequential scan (which does not care about rowids) to search far enough into the slot table.</p><p><code>字段 pg_nslots即使在删除了slot之后也不会减少。以一个数据页为例，假设在总共五个slot中，slot 1到4被删除，那么slot 5也不能为了节省空间而变成slot 1，因为这样会导致该slot的 rowid发生变化。尽管此时这个数据页上只剩下一个有效插槽，pg_nslots 仍必须保持为5，以便顺序扫描（这种扫描方式不关心 rowid）时可以搜索到足够深的位置，访问插槽表中的所有项。</code></p><p><strong>Maximum number of slots</strong></p><p>The maximum number of slots for a data page is 255.</p><p><code>数据页的最大slot数为 255 。</code></p><p><strong>Page Flags (Type)</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062044751.png" alt="image-20250506204451656"></p><p>The <strong>pg_flags</strong> field contains one or more <em>page flags</em>, which are represented by hexadecimal values that are logically <em>OR</em>ed together. The values have the following meanings in Informix Dynamic Server:</p><p><code>pg_flags 字段包含一个或多个页面标志，这些标志由十六进制值表示，并通过逻辑 或 运算组合在一起。这些值在 IDS 中的含义如下：</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062048500.png" alt="image-20250506204838394"></p><p><strong>Free Pointer and Free Count</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062052779.png" alt="image-20250506205217703"></p><p>The <strong>pg_frptr</strong> (<em>free pointer</em>) field points to the first free byte <em>after</em> all of the data on a page. If the last slot on a page is occupied, the free pointer points to the position just after that slot.</p><p><code>pg_frptr（空闲指针）字段指向页面上所有数据之后的第一个空闲字节。如果页面上的最后一个slot已被占用，那么空闲指针就会指向该slot之后的位置。</code></p><p>The <strong>pg_frcnt</strong> (<em>free count</em>) field is a sum of all unused bytes on the page.</p><p><code>pg_frcnt（空闲数）字段表示页面上所有未使用字节的总和。</code></p><p>紫本上这两个位置写的是Pfree和Nfree，和IX9111不一致</p><p><strong>Next Pointer and Previous Pointer</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062058207.png" alt="image-20250506205843125"></p><p>The last two 4-byte elements in the page header structure are not always populated. Their main use is as node pointers on index pages. On an index page, also referred to as an index <em>node</em>, these pointers contain the logical page numbers of the two adjacent nodes. The <em>next pointer</em> (<strong>pg_next</strong>) contains the logical page number of the node to the <em>right</em>(containing higher key values), while the <em>previous pointer</em> (<strong>pg_prev</strong>) contains the logical page number of the node to the <em>left</em> (containing lower key values).</p><p><code>页头结构中最后两个 4 字节的元素并不总是被填充。它们的主要用途是在索引页中充当节点指针。在索引页中（也称为索引节点），这些指针包含两个相邻节点的逻辑页号。pg_next 指针包含右侧节点（包含较大键值）的逻辑页号，而 pg_prev 指针则包含左侧节点（包含较小键值）的逻辑页号。</code></p><p>The difference between physical and logical page numbers, and the B+ tree concepts of right and left index nodes, are explained in later modules.</p><p><code>物理页号与逻辑页号之间的区别，以及 B+ 树中右侧和左侧索引节点的概念，将在后续模块中进行解释。</code></p><p>The next and previous-pointer elements were designed into the page-header structure for use in index pages. But instead of wasting eight bytes in the header of all non-index pages, uses have been found for the next and previous pointers in a couple of other page types as well. Their use in logical log pages and tape-header pages, for example, are explained in later modules.</p><p><code>next 和 previous 指针元素最初是为了在索引页中使用而被设计进页头结构的。但为了避免在所有非索引页的页头中浪费这8个字节，这两个指针也被用于其他几种页面类型。例如，它们在逻辑日志页和磁带头页中的用途将在后续模块中进行说明。</code></p><p>紫本：</p><p>Next Page：占用4 Byte，指向下页的地址，对于数据页为0，对于索引页则指向下一个节点。</p><p>Previous Page：占用4 Byte，指向上页的地址，对于数据页为0，对于索引页则存储前页地址。</p><p><strong>Big Pages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505062110830.png" alt="image-20250506211014737"></p><p>The default page size used for your Informix Dynamic Server instance is either 2K or 4K, depending on the platform (machine and operating system) you are using. For example, a 4K page size is the default for Windows and IBM AIX, and a 2K page size is the default for most other platforms. The root dbspace is always created using the default page size.</p><p><code> IDS 实例的默认页面大小是 2K 或 4K，具体取决于所使用的平台（包括机器和操作系统）。例如，Windows 和 IBM AIX 平台的默认页面大小是 4K，而大多数其他平台的默认页面大小是 2K。</code><mark>root dbspace 总是使用默认的页面大小创建。</mark></p><p>When you add dbspaces, you can specify a different page size using a multiple of the default page size with a maximum size of 16 kilobytes. Before you create a dbspace that uses a larger page size, you will want to configure a separate buffer pool for that page size. Configure a new buffer pool by setting the BUFFERPOOL configuration parameter. For example:</p><p><code>当你添加 dbspace 时，可以使用默认页面大小的倍数来指定不同的页面大小，最大支持 16KB。在创建使用较大页面大小的 dbspace 之前，建议先为该页面大小配置一个单独的缓冲池。你可以通过设置 BUFFERPOOL 配置参数来配置新的缓冲池。例如：</code></p><p>BUFFERPOOL <strong>size&#x3D;8k</strong>,buffers&#x3D;2000,lrus&#x3D;8,lru_min_dirty&#x3D;50,lru_max_dirty&#x3D;60</p><p>When the new buffer pool has been created, you can then create a dbspace using the larger page size. For example:</p><p><code>当新的缓冲池创建完成后，你就可以使用更大的页面大小来创建 dbspace。例如：</code></p><p>onspaces -c -d dbsp_bigp <strong>-k 8K</strong> -p &#x2F;opt&#x2F;dbsp3 -o 0 -s 8000</p><p><strong>Displaying a Page</strong></p><ul><li>Oncheck commands</li></ul><p>oncheck -pP chunk_number page_offset</p><p>oncheck -pp partition_number logical_page_number</p><ul><li>Chunk numbers are indexed from 1</li></ul><p><code>chunk号从1开始</code></p><ul><li>Both the page offset into a chunk and the logical page number within a table are indexed from 0</li></ul><p><code>chunk中的页面偏移量和表中的逻辑页面号都是从 0 开始的</code></p><ul><li>To obtain a partition number:</li></ul><p>– Query <strong>systables</strong> (or <strong>sysmaster:systabnames</strong>) if the table is not fragmented</p><p>– Query <strong>sysfragments</strong> if the table is fragmented</p><p>– Run <strong>oncheck -pt</strong> to find all partnums of all fragments</p><ul><li>The <strong>oncheck</strong> utility recognizes both decimal (100) and hexadecimal (0x64) format for its arguments</li></ul><p><code>oncheck 工具支持十进制（100）和十六进制（0x64）格式的参数。</code></p><p>When logged on as either <em>root</em> or <em>informix</em>, you can display most pages within an Informix Dynamic Server chunk using the <strong>oncheck</strong> utility. Based on the type of page it finds, <strong>oncheck</strong> even attempts to print the data on the page in an organized format.</p><p><code>当以 root 用户或 informix 用户登录时，可以使用 oncheck 工具查看 IDS chunk中的大多数页面。根据所找到的页面类型，oncheck 甚至会尝试以结构化的格式打印页面上的数据。</code></p><p><strong>Displaying logical log pages</strong></p><p>The <strong>oncheck</strong> utility does not do much with logical log pages; it treats them as unknown page types. The reason is that logical log pages have no slot table, and when taken as a byte stream, the data on an individual log page is difficult to separate into structures and interpret. The <strong>onlog</strong> utility is a better tool for that task, for reasons that should be clearer a bit later in the course.</p><p><code>oncheck 工具对逻辑日志页（logical log pages）支持较少；它将这些页面视为未知类型。原因在于逻辑日志页没有slot table，而且将其作为字节流来看时，单个日志页上的数据难以划分为结构并进行解释。对于这项任务，onlog 工具更为合适，具体原因将在课程后面进一步解释。</code></p><p><strong>Locating partition numbers</strong></p><p>The <em>partition number</em> (<em>partnum</em>) uniquely identifies a specific tblspace. An unfragmented table has only one data tblspace and, therefore, has only one partition number.</p><p><code>partition number（partnum）用于唯一标识一个特定的 tblspace。一个未分片（unfragmented）的表只有一个数据表空间，因此也只有一个分区号。</code></p><p>Fragmented tables have one tblspace (and one partnum) for each dbspace fragment.</p><p><code>分片表中的每个 dbspace 分片都有一个对应的表空间（tblspace）和一个分区号（partnum）。</code></p><p>Partition numbers for unfragmented tables are stored in the <strong>systables</strong> system catalog table. Here is an example of a query to obtain a partition number in both decimal and hexadecimal format:</p><p><code>未分片表的分区号（partnum）存储在系统目录表 systables 中。下面是一个用于以十进制和十六进制格式获取分区号的查询示例：</code></p><p>deepseek：</p><blockquote><p>在数据库领域中，”catalog” 实际上就是指数据库的元数据（metadata）。</p><p>更具体地讲，数据库的 <strong>catalog</strong> 是由数据库系统维护的一组表或数据结构，用来描述数据库中对象的结构和属性，</p></blockquote><p>SELECT partnum, HEX(partnum) FROM systables WHERE tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072237755.png" alt="image-20250507223709618"></p><p>You can also obtain a partition number for an unfragmented table by querying the <strong>sysmaster</strong> database:</p><p><code>您还可以通过查询 sysmaster 数据库来获取未分区表的分区号：</code></p><p>DATABASE sysmaster;</p><p>SELECT partnum, HEX(partnum) FROM systabnames WHERE tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072238153.png" alt="image-20250507223809100"></p><p>If a table is fragmented, the value in the <strong>partnum</strong> column of <strong>systables</strong> and <strong>systabnames</strong> is zero. To obtain a list of partnums for a fragmented table, it is necessary to query the <strong>sysfragments</strong> system catalog:</p><p><code>如果表是分片的，则 systables 和 systabnames 中 partnum 列的值为零。要获取分片表的 partnum 列表，必须查询 sysfragments ：</code></p><p>SELECT partn, HEX(partn) FROM systables t, sysfragments f WHERE t.tabid &#x3D; f.tabid AND tabname &#x3D; “<em>table_name</em>“;</p><p>示例：</p><p>CREATE TABLE f1 (<br>    id int,<br>    name VARCHAR(10)<br>)<br>FRAGMENT BY EXPRESSION<br>    id &lt; 10 IN datadbs1,<br>    id &gt;&#x3D; 10 AND id &lt; 20 IN datadbs2,<br>    id &gt;&#x3D; 20 IN datadbs3;</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505072253021.png" alt="image-20250507225315967"></p><p>Perhaps the easiest way to find a list of all partnums associated with a table (including partition numbers for index partitions) is by using the <strong>oncheck -pt</strong> command:</p><p><code>要查找与表相关的所有分区号列表（包括索引分区的分区号），最简单的方法可能是使用 oncheck -pt 命令：</code></p><p>oncheck -pt <em>database_name</em>:<em>table_name</em></p><p>Partition numbers are displayed under the heading <strong>Partition partnum</strong> in decimal format.</p><p><code>分区编号以十进制格式显示在分区 partnum 标题下。</code></p><p>示例：</p><blockquote><p>[root@frh gbase]# oncheck -pt testdb:f1</p><p>TBLspace Report for testdb:root.f1</p><pre><code>              Table fragment partition datadbs1 in DBspace datadbs1Physical Address               4:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              4194306Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              4:53           8          8              Table fragment partition datadbs2 in DBspace datadbs2Physical Address               5:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              5242882Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              5:53           8          8              Table fragment partition datadbs3 in DBspace datadbs3Physical Address               6:5Creation date                  05/07/2025 07:51:07TBLspace Flags                 902        Row Locking                                          TBLspace contains VARCHARS                                          TBLspace use 4 bit bit-mapsMaximum row size               16Number of special columns      1Number of keys                 0Number of extents              1Current serial value           1Current SERIAL8 value          1Current BIGSERIAL value        1Current REFID value            1Pagesize (k)                   2First extent size              8Next extent size               8Number of pages allocated      8Number of pages used           2Number of data pages           1Number of rows                 1Partition partnum              6291458Partition lockid               4194306Extents     Logical Page     Physical Page        Size Physical Pages                0              6:53           8          8</code></pre></blockquote><p><strong>oncheck -pP&#x2F;pp</strong></p><p>The syntax to use with <strong>oncheck -pP</strong> is shown in the slide above. For example, to display page 0 from chunk 1, type:</p><p><code>使用 oncheck -pP 的语法如上图所示。例如，要显示chunk 1 的第 0 页，请键入</code></p><p>oncheck -pP 1 0</p><p>To display logical page 0 (the first bitmap page) from partition number 0x0100022, type:</p><p><code>要显示分区号 0x0100022 的逻辑页 0（第一个位图页），请键入</code></p><p>oncheck -pp 0x0100022 0</p><p>这块只是介绍一下这2命令，下面有详细介绍</p><p><strong>Logical page numbers</strong></p><p>Picture all the pages in a table lined up in chronological order and numbered, starting with 0. These would be their <em>logical page numbers</em>. If this is a confusing concept at the moment, do not worry. You will be examining tblspaces further in a later module.</p><p><code>想象一下，所有页面在一个表格中按时间顺序排列，并从0开始编号。这些编号就是它们的逻辑页码。如果你现在对这个概念感到困惑，不用担心——你将在后续的模块中进一步学习表空间（tblspaces）。</code></p><p><strong>Note</strong></p><p>In rare cases, the data on a particular page is formatted differently by <strong>oncheck</strong> depending on the option used. For instance, the <strong>-pP</strong> option displays only the page header for a bitmap page, but the <strong>-pp</strong> option displays the bit values in a more readable format.</p><p><code>在极少数情况下，oncheck 会根据所使用的选项对特定页面上的数据进行不同的格式化处理。例如，-pP 选项只显示位图页面的页头，而 -pp 选项则以更易读的格式显示位值。</code></p><p>应该要到Unit 4才能知道bitmap page是什么，先不用管他</p><p>There is one more variation on the <strong>oncheck -pp</strong> syntax that we have not mentioned because in fact, we do not recommend that you use it. In the spirit of providing you every tool we can think of, here it is:</p><p><code>oncheck -pp 语法还有一个变种，我们没有提及，因为事实上我们</code><mark>不建议你使用它</mark><code>。本着为您提供我们所能想到的所有工具的精神，我们在此介绍它：</code></p><p>oncheck -pp <em>database</em>:<em>table_name rowid</em></p><p>Only rowids above 0x100 work with this syntax; you cannot display the first bitmap page (0x100), but all other used pages in the table are fair game. For example:</p><p><code>只有大于 0x100 的 rowid 才能使用这种语法；你无法显示第一个位图页（0x100），但表中所有其他已使用的页面都可以显示。例如：</code></p><p>oncheck -pp stores_demo:customer 0x201</p><p>Now, you might expect the above command to display only one row from the <strong>stores_demo:customer</strong> table, the first slot on logical page 2. In fact, that command displays all rows on page 2. It is equivalent to the command:</p><p><code>现在，你可能以为上述命令只会显示 stores_demo:customer 表中的一条记录，即逻辑页面 2 的第一个slot。事实上，该命令会显示第 2 页上的所有行。它等同于以下命令</code></p><p>oncheck -pp 0x10001a 0x2</p><p>(assuming the partition number for the <strong>stores_demo:customer</strong> table is 0x10001a).</p><p><code>假设stores_demo:customer表的分区编号为 0x10001a</code></p><p>The advantage, of course, is that you do not need to determine the partnum for a table in order to use <strong>oncheck -pp</strong>.</p><p><code>当然，这样做的好处是，在使用 oncheck -pp 时不需要确定表的partnum。</code></p><p>The disadvantage in using this syntax is that using a rowid with <strong>oncheck</strong> and receiving output for an entire page might slow your efforts to understand the meaning of a rowid.</p><p><code>使用这种语法的一个缺点是，当你在 oncheck 中使用 rowid 并获得整个页面的输出时，可能会降低你理解 rowid 含义的效率。</code></p><p>While it is tempting to avoid working with partition numbers, the relationship between a tblspace and its partnum is extremely important to grasp. Until you have used the recommended syntax long enough to be tired of it, it is a good idea to spend the extra few seconds looking up a table’s partnum.</p><p><code>虽然避免使用分区编号很有诱惑力，但掌握 tblspace 与其 partnum 之间的关系极为重要。在使用推荐语法足够长的时间并对其感到厌倦之前，最好多花几秒钟来查找表的分区号。</code></p><blockquote><p>tempting</p><p>英[ˈtemptɪŋ]    美[ˈtemptɪŋ]<br>adj.诱人的;吸引人的;有吸引力的;v.诱惑;引诱;怂恿;利诱;劝诱;鼓动;</p><p>extremely</p><p>英[ɪkˈstriːmli]   美[ɪkˈstriːmli] </p><p>adv.极其;非常;极端;</p><p>grasp</p><p>英[ɡrɑːsp]    美[ɡræsp]<br>vt.抓住;理解;领会;领悟;抓牢;毫不犹豫地抓住(机会);n.理解(力);控制;领会;紧握;紧抓;能力所及;</p></blockquote><p>实际使用：</p><blockquote><p>[root@frh gbase]# oncheck -pp 0x00D00047 0<br>addr             stamp    chksum nslots flag type         frptr frcnt next     prev<br>13:2087          8188418  fa54   0      804  FREE         24    2020  0        0<br>   0:8 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</p><p>[root@frh gbase]# oncheck -pp 0x00D00047 1<br>addr             stamp    chksum nslots flag type         frptr frcnt next     prev<br>13:2088          8187311  e5f6   2      801  DATA         42    1994  0        0<br>        slot ptr   len   flg<br>        1    24    9     0<br>        2    33    9     0<br>slot   1:<br>    0:  0  0  0  1  0  3 61 61 61                        ……aaa…….<br>slot   2:<br>    0:  0  0  0  2  0  3 62 62 62                        ……bbb…….</p></blockquote><p>不知道为什么从1开始</p><blockquote><p>chatgpt：</p><p>这是 <strong>Informix 的分区结构（partition）设计</strong>所决定的：</p><h4 id="每个-partition（partnum-对应的分片）中的："><a href="#每个-partition（partnum-对应的分片）中的：" class="headerlink" title="每个 partition（partnum 对应的分片）中的："></a>每个 partition（partnum 对应的分片）中的：</h4><ul><li><strong>逻辑页 0</strong> 是所谓的 <strong>partition header page</strong>（也叫 <code>partn page</code>）；<ul><li>它保存了该分区的元信息，如 extent 列表、分片状态等；</li><li>不是用来存储行数据的；</li></ul></li><li><strong>逻辑页 1 开始</strong> 才是实际存储数据的页（如果有）；<ul><li>数据行通常从逻辑页 1、2、3 开始向后分布；</li><li>这些页才是你期望看到的表行内容页。</li></ul></li></ul></blockquote><p><strong>Displaying a Big Page</strong></p><p>先看下边Notes</p><ul><li>Calculate page offset:</li></ul><p>pg_offset &#x3D; (chunk_pgsize &#x2F; system_pgsize) * page_num</p><ul><li>Example: To dump page 15 of chunk 3 on AIX (default page size &#x3D; 4K) with a configured page size of 16K for chunk 3:</li></ul><p>pg_offset &#x3D; (16 &#x2F; 4) * 15 &#x3D; 60</p><p><strong>oncheck -pP 3 60</strong></p><ul><li>Example: To dump the first partition page (page 3) on Linux (default page size &#x3D; 2) with a configured page size of 8K for chunk 3:</li></ul><p>pg_offset &#x3D; (8 &#x2F; 2) * 3 &#x3D; 12</p><p><strong>oncheck -pP 3 12</strong></p><p><strong>Notes:</strong></p><p>To dump a page that is larger than the default platform page size, the DBA uses the same <strong>oncheck</strong> command: <strong>oncheck -pP</strong> <strong>chunk# pg_offset</strong>, but the <em>pg_offset</em> has to be calculated differently:</p><p><code>要转储大于默认平台页面大小的页面，DBA 使用相同的 oncheck 命令：oncheck -pP chunk# pg_offset，但 pg_offset 的计算方式不同：</code></p><p>pg_offset &#x3D; (<em>chunk_pgsize</em> &#x2F; <em>system_pgsize</em>) * <em>page#</em></p><p>Some example calculations and <strong>oncheck</strong> commands are shown above.</p><p>例子在上边</p><p><strong>Page Header Format</strong></p><p>The formats used for each header element in the display are:</p><p><code>显示中每个标题元素所使用的格式如下：（十进制、十六进制、字符）</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082035860.png" alt="image-20250508203538773"></p><p><strong>Notes:</strong></p><p>A page header displayed by <strong>oncheck</strong> can be frustrating to decipher at first, because the utility does not use a consistent notation for the elements. Some are displayed as hexadecimal values, some as decimals. The slide above indicates the format used for each element.</p><p><code>一开始，oncheck 显示的页眉可能会让人难以理解，因为该工具对元素没有使用统一的符号。有些显示为十六进制值，有些显示为小数。上面的幻灯片显示了每个元素使用的格式。</code></p><blockquote><p>frustrating<br>英[frʌˈstreɪtɪŋ] 美[ˈfrʌstreɪtɪŋ]<br>adj.令人沮丧的;令人懊恼的;  v.使沮丧;挫败;阻止;使懊恼;防止;使懊丧;</p><p>decipher<br>英[dɪˈsaɪfə(r)] 美[dɪˈsaɪfər]<br>vt.破译;辨认(难认、难解的东西);v.破译;n.密电(或密信)的译文;</p><p>notation<br>英[nəʊˈteɪʃn] 美[noʊˈteɪʃn]<br>n.符号;(数学、科学和音乐中的)记号;谱号;</p></blockquote><p>The <strong>addr</strong> column shows the chunk number (<strong>pg_chunk</strong>) and offset (<strong>pg_offset</strong>) for the page.</p><p><code>addr 列显示页面的块号（pg_chunk）和偏移量（pg_offset）。</code></p><p>The <strong>flag</strong> and <strong>type</strong> columns in the output refer to the same element in the structure: <strong>pg_flags</strong>. The <strong>type</strong> column is meant to translate the page flags into something more recognizable, though the chosen terms sometimes add to the confusion. Here are all the <strong>type</strong> values output by <strong>oncheck</strong> followed by yet another translation:</p><p><code>输出中的flag和type指的是结构中的同一个元素：pg_flags。type的目的是将页面标志转换成更容易辨认的内容，尽管所选术语有时会造成混淆。下面是 oncheck 输出的所有类型值，以及另一种翻译：</code></p><p>DATA Tblspace data page</p><p>PARTN Partition (tblspace tblspace) page</p><p>FREE Tblspace bitmap page</p><p>CHUNK Chunk free list page</p><p>REMAIN Remainder page</p><p>PBLOB Partition-resident BLOB page</p><p>BLOB BLOBspace-resident BLOB page</p><p>BBIT BLOB chunk free-list page</p><p>BMAP Blob chunk BLOB map page</p><p>BTREE Index page</p><p>ROOTRSV Root reserved page</p><p>UNKNOWN The default type, which includes logical log pages</p><p><strong>Slot Table Format</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082115460.png" alt="image-20250508211523372"></p><p><strong>Notes:</strong></p><p>For most pages, after displaying the page header, <strong>oncheck</strong> displays the slot table if one exists. All values displayed in the slot table list are in decimal notation.</p><p>对于大多数页面，在显示页头后，<strong>oncheck</strong> 会显示slot table（如果存在）。slot table列表中显示的所有值都是十进制。</p><table><thead><tr><th><strong>slot</strong></th><th>The slot table entry (this value is not actually stored in the slot table).    表条目（该值实际上并不存储在表中）。</th></tr></thead><tbody><tr><td><strong>ptr</strong></td><td><strong>The byte offset into the page where the first byte of the slot is found.    在页面中找到slot第一个字节的字节偏移量。</strong></td></tr><tr><td><strong>len</strong></td><td><strong>The length of the slot in bytes.   slot的长度（字节）。</strong></td></tr><tr><td><strong>flg</strong></td><td><strong>If the slot contains a forward pointer, this value is 2; otherwise, it is 0. 如果slot包含一个前向指针，该值为 2；否则为 0。</strong></td></tr></tbody></table><p>Remember, a slot is not a row, but a <em>container</em>. A slot can contain a data row, a portion of a data row (in the case of a row that has been split across pages), or another structure altogether. A slot table entry consists of a length and a position on a page.</p><p><code>记住，slot不是行，而是容器。slot可以包含一条数据行、数据行的一部分（在数据行被分割到不同页面的情况下）或另一种结构。slot table项由长度和在页面上的位置组成。</code></p><p><strong>Slot Format</strong></p><p>The slots are displayed as streams of individual bytes. Bytes are displayed in hexadecimal format, without leading zeros (this may be a point of confusion at first).</p><p><code>slot显示为单个字节流。字节以十六进制格式显示，不含前导零（起初可能会引起混淆）。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082124609.png" alt="image-20250508212453518"></p><p><strong>Notes:</strong></p><p>After displaying the slot table, <strong>oncheck</strong> displays the slots themselves. Note that <strong>oncheck</strong>displays the bytes in each slot in hexadecimal notation, 16-across. In addition, an ASCII translation of each 16-byte <em>line</em> in the slot, or fraction thereof, is displayed to the right. Dots in the ASCII lines serve as place holders for bytes that cannot be translated into ASCII characters.</p><p><code>显示slot table后，oncheck 显示slot本身。请注意，oncheck 会以十六进制符号显示每个slot中的字节，16-across。此外，右侧还显示slot中每行 16 字节的 ASCII 译文或其部分。ASCII 行中的点是无法转换成 ASCII 字符的字节的占位符。</code></p><p>To the left of each line of bytes is an offset in decimal. This value (0, 16, 32, etc.) is the byte offset of the first byte on the line, relative to the beginning of the slot.</p><p><code>每行字节的左边是一个十进制偏移量。该值（0、16、32 等）是该行第一个字节相对于slot起始位置的字节偏移量。</code></p><p><strong>Page View</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082133156.png" alt="image-20250508213331042"></p><p><strong>Notes:</strong></p><p>The <strong>oncheck</strong> utility attempts to display data in an easy-to read format. To see what a page really looks like, or at least the hexadecimal representation of the page, other utilities are needed. </p><p><code>oncheck 工具试图以易于阅读的格式显示数据。要查看页面的真实情况，或至少查看页面的十六进制表示，还需要其他实用程序。</code></p><p>Above is an example of a page that was extracted from an Informix Dynamic Server chunk and displayed in hexadecimal format. The <strong>dd</strong> and <strong>od</strong> commands, provided by most UNIX operating systems, were used to do this. This view of the page gives a better idea of where the page components are located.</p><p><code>以上是从 IDS chunk 中提取页面并以十六进制格式显示的示例。大多数 UNIX 操作系统都提供了 dd 和 od 命令。通过这种页面视图，可以更好地了解页面组件的位置。</code></p><p>The first column of the <strong>od -x</strong> output indicates the byte offset into the page in <em>octal</em>. Since it is easier to use hexadecimal values to identify the offsets, a hexadecimal translation is provided to the right of the example. An asterisk appears where lines of data repeat.</p><p><code>od -x 输出结果的第一列显示了以八进制表示的页面字节偏移量。由于使用十六进制值更容易识别偏移量，因此示例右侧提供了十六进制转换。数据行重复的地方会出现星号。</code></p><blockquote><h3 id="第一部分：dd-if-dev-chunk1-skip-123-count-1-bs-2k"><a href="#第一部分：dd-if-dev-chunk1-skip-123-count-1-bs-2k" class="headerlink" title="第一部分：dd if=/dev/chunk1 skip=123 count=1 bs=2k"></a>第一部分：<code>dd if=/dev/chunk1 skip=123 count=1 bs=2k</code></h3><p><code>dd</code> 是一个用于按块复制数据的低级工具。各个参数含义如下：</p><ul><li><code>if=/dev/chunk1</code>：<strong>输入文件</strong>（input file），这里是一个设备文件 <code>/dev/chunk1</code>。</li><li><code>skip=123</code>：<strong>跳过前 123 个块</strong>，不读取它们。</li><li><code>count=1</code>：<strong>读取 1 个块</strong>。</li><li><code>bs=2k</code>：<strong>每个块大小为 2KB</strong>（即 2048 字节）。</li></ul><p>➡️ 综合：这个命令会从 <code>/dev/chunk1</code> 中跳过前 123 × 2KB（即 246KB），然后读取接下来的 <strong>2KB 数据</strong>。</p><hr><h3 id="第二部分：-od-x"><a href="#第二部分：-od-x" class="headerlink" title="第二部分：| od -x"></a>第二部分：<code>| od -x</code></h3><ul><li><code>|</code>：管道符，将上一步 <code>dd</code> 的输出传递给下一个命令。</li><li><code>od</code>：<strong>octal dump</strong>（八进制转储）工具，用于以人类可读的方式查看二进制数据。</li><li><code>-x</code>：以 <strong>十六进制</strong>的形式显示输出。</li></ul><p>➡️ 效果：你将看到读取到的 2KB 数据的十六进制表示，通常用于调试、查看原始数据结构、分析二进制文件内容等。</p></blockquote><p><strong>Coming up next</strong></p><p>You now have the tools necessary to display pages based on their location in a chunk or in a tblspace. The trick, of course, is in knowing ahead of time what information is located at specific points in a chunk or tblspace. In the next two chapters, you will learn the architecture of dbspaces and tblspaces at the page level and beyond.</p><p><code>现在你已经拥有了根据页面在chunk或 tblspace 中的位置来显示页面所需的工具。当然，其中的诀窍在于提前知道信息位于chunk或 tblspace 中的特定位置。在接下来的两章中，你将学习 dbspaces 和 tblspaces 在页面级及以上的架构。</code></p><p><strong>Byte Swapping</strong></p><p>In a byte-swapping system, the bytes in a 2-byte and 4-byte value are reversed when saved to disk.</p><p><code>在字节交换系统中，2 字节和 4 字节数值的字节在保存到磁盘时会相反。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082142142.png" alt="image-20250508214227054"></p><p><strong>Notes:</strong></p><p>Some operating systems do not store streams of bytes in the same way that we would normally view them. On these systems, certain values go through a <em>byte-swapping</em> process before the value is written to disk. This is why the values that you may see in a hexadecimal page dump, or even in a slot table entry, may not appear the way you expect. </p><p><code>有些操作系统存储字节流的方式与我们通常查看字节流的方式不同。在这些系统中，某些值在写入磁盘前要经过字节交换过程。这就是为什么你在十六进制页面转储，甚至在slot table项中看到的值可能与你期望的不一样。</code></p><p>When a byte swap occurs, the first byte of a 2-byte value get s “swapped” with the last byte. For a 4-byte value, the first byte is swapped with the fourth byte, and the second byte is swapped with the third. An example is shown above using the octal dump shown on the previous page.</p><p><code>发生字节交换时，2 字节数值的第一个字节会与最后一个字节 “交换”。对于 4 字节值，第一个字节与第四个字节交换，第二个字节与第三个字节交换。上图是一个使用前一页所示八进制转储的示例。</code></p><p>In most cases, oncheck displays output that has been properly converted from the disk format. There are cases where slot information is displayed showing byte-swapped values.</p><p><code>在大多数情况下，oncheck 显示的输出已从磁盘格式正确转换。在某些情况下，显示的slot信息会显示字节交换值。</code></p><p>The Linux operating system, used by the lab image for this course, uses byte-swapping.</p><p><code>本课程实验镜像所使用的 Linux 操作系统采用字节交换（byte-swapping）机制。</code></p><p>补充一些紫本内容：（177页）</p><p>对数据部分的解释如下。</p><ul><li>在数据页中用来存储数据的部分可以存储行记录和索引 key。</li><li>以 slots 的方式分成 <em>n</em> 个存储单元，每个 slots 存放一行记录或者一个 index-key。</li><li>在一个数据页中最多能存储 255 个 slots。</li></ul><p>​一个数据页的页头和页尾占用的总空间为 28 Byte + <em>n**4Byte，其中 <em>n</em> 为 page 中存储的记录数。如总共存储 100 个记录，那么总共占用：28+100</em>4&#x3D;428 Byte，如果为 2k 的 page，那么 100 个记录实际数据占用的空间为：2048－428＝1620 Byte。</p><p>​一个 Page 中能存储多少行记录的计算公式为：28 Byte + <em>n</em> *（4+rowsize） Byte</p><p>​假如表的 rowsize&#x3D;16 Byte，那么一个 pagesize 为 2KB 页刚好可以存储 101 行记录：28+101*（4+16）&#x3D;2048。</p><p>如果采用 pagesize 为 16K 的页来存储 rowsize&#x3D;16 Byte 的表，由于一个 page 最多存储255 行记录，那么实际使用的空间为：28 + 255*（4+16） &#x3D;5128 Byte，那么 16K 的存储Page 将有超过 10K 被浪费，也就说不同的表需要选择合理大小的 pagesize 来存储。</p><p>​表 6.6 列出了采用不同 pagesize 的数据页中最多存储 255 行记录对应的 rowsize 大小。</p><p>​<img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082210927.png" alt="image-20250508221057854"></p><p>如表 6.6 说明了若有一个表的 rowsize 不大于 11 Byte，那么应该采用 2K 的 Pagesize；如果采用 4K 或者更大的 pagesize 那么会有空间浪费。如果一个表的 rowsize 不大于 28，那么不建议采用 8K 的 pagesize；如果表的 rowsize 不大于 60 Byte，那么不建议采用 16K 的 Pagesize。</p><p>假如有表 customer：</p><p>create table customer（cus_id integer,cus_name char（10））;</p><p>该表的 rowsize&#x3D;4+10&#x3D;14 Byte，那么该表建议采用不大于 4K 的 pagesize。为了更好地理解 Page 的存储结构，下面通过表 customer 的实际数据存储情况来展示数据页的内部结构。</p><blockquote><p>Drop table if exists customer;</p><p>Create table customer (cus_id integer,cus_name char(10)) in dbs2k;</p><p>Create index idx_customer on customer(cus_id);</p><p>Insert into customer values(1,’abc’);</p><p>Insert into customer values(2,’def’);</p></blockquote><p>通过 oncheck 及操作系统 od 命令查看 customer 表记录在数据页上的存储情况，如图6.27 所示。</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082212984.png" alt="image-20250508221231802"></p><p>00000043：addr的67，也就是IX9111的pg_offset，4字节</p><p>根据前边可知，0x101是rowid，但为什么是这个数没看到解释，我自己查的：</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505082234005.png" alt="image-20250508223442940"></p><p>0x101就是257，所以第一条记录的rowid就是0x101</p><p>前边提到，IX9111不推荐这种写法（库名:表名），推荐用partition number</p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IX9111 - Unit 1. Introduction</title>
      <link href="/2025/04/26/IX9111/1/"/>
      <url>/2025/04/26/IX9111/1/</url>
      
        <content type="html"><![CDATA[<p><strong>chunks</strong></p><p>Chunks contain extents; extents contain pages Chunks contain extents; extents contain page</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272252887.png" alt="image-20250427225213804"></p><p>Informix Dynamic Server disk space is allocated in units called chunks.</p><p>To uniquely describe a particular <strong>chunk</strong>, you must specify three things: the chunk <strong>path</strong>, the <strong>offset</strong> (kilobytes) into the device where the chunk begins, and the <strong>size</strong> (kilobytes) of the chunk.</p><br><p><strong>pages</strong></p><p>The <strong>default page size</strong> is either <strong>2</strong> kilobytes or <strong>4</strong> kilobytes, depending on the platform.</p><p><code>默认页大小 2KB 或 4KB (kilobytes是KB)</code></p><p>The <strong>page size</strong> can be configured for each dbspace from <strong>2K</strong> to <strong>16K</strong> and <strong>must be divisible by the default page size</strong>.</p><p><code>页大小可配置为2K - 16K，必须能被默认页面大小整除</code></p><p>The <strong>size of a chunk</strong> must be <strong>a multiple of the page size</strong>.</p><p><code>chunk的大小必须是页大小的倍数</code></p><br><p><strong>extents</strong></p><p>An <em>extent</em> is a <strong>physically contiguous</strong> group of related pages that are <strong>fully contained in a chunk</strong>.</p><p><code>extent是物理上连续的一组相关pages，这些页面完全包含在一个chunk中。</code></p><p>Extents are not exclusively associated with tblspaces.The physical log is made from one extent. The 12 reserved pages in the root dbspace could also be called an extent</p><p><code>extents不只和tblspaces关联。物理日志由一个extent构成。rootdbs的12个保留页也可以被叫做一个extent</code></p><br><p><strong>Tblspaces</strong></p><p>A tblspace is a set of extents allocated to a specific database object.   </p><p><code>tblspace是分配给特定数据库对象的一组extent。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272245936.png" alt="image-20250427224506870"></p><p>A <em>tblspace</em> is a logical collection of extents within a dbspace. A tblspace can represent an entire table or index, or a table or index fragment. Each extent can contain a variety of page types. When a tblspace is created, an initial extent is allocated. Its size is 8 pages by default, but can be set using the EXTENT SIZE clause of the CREATE TABLE statement in SQL. As the table grows, new extents must be allocated. The default size of each <em>next</em>  <em>extent</em> is also 8 pages, but can be set using the NEXT SIZE clause.</p><p><code>tblspace是dbspace内extent的逻辑集合。tblspace可以表示整个表或索引，也可以表示表或索引的片段。每个extent可以包含多种页类型。创建tblspace时，会分配一个初始extent。其大小默认为8页，但可以使用 SQL 中 CREATE TABLE 语句的 EXTENT SIZE 子句进行设置。随着表的增长，必须分配新的extent，下一个extent的默认大小也是 8 页，但可以使用 NEXT SIZE 子句进行设置。</code></p><p>The extent allocation mechanism for tblspaces has a few additional features: </p><p><code>tblspace的extent分配机制有一些额外特性</code></p><ol><li><p>When an extent is allocated adjacent to the extent previously allocated for the same tblspace, the two can be concatenated to form one large extent. </p><p><code>当一个extent分配到与先前为同一tblspace分配的extent相邻的位置时，可以将这两个extent连接起来以形成一个大extent。</code></p></li><li><p>As a tblspace becomes fragmented, the size used for new extent allocations is adjusted upward from its configured value. Specifically, NEXT SIZE is doubled for every 16 extents that are allocated.</p><p><code>当一个tblspace变得碎片化时，用于新extent分配的大小会在其配置值的基础上向上调整。具体来说，每分配16个extent，NEXT SIZE就会翻倍。</code></p></li><li><p>When an extent allocation requires more contiguous space than is available in the dbspace, the server simply allocates the largest amount of contiguous space available.</p><p><code>当extent分配所需的连续空间大于 dbspace 中可用的连续空间时，server会直接分配可用的最大连续空间。</code></p><p>This mechanism helps to avoid reaching extent allocation limits.</p><p><code>此机制有助于避免达到extent分配限制。</code></p></li></ol><br><p><strong>Dbspaces, Blobspaces, and Sbspaces</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202504272258506.png" alt="image-20250427225802434"></p><p>Dbspaces, blobspaces, and sbspaces are named collections of one or more chunks. These spaces do not define any physical space boundaries, but are <em>logical</em> collections of the <em>physical</em> chunks.</p><p><code>前一句不知道怎么翻译，理解成每个space都有名字，由一个或多个chunk组成吧。这些space没有定义任何物理空间边界，而是物理chunk的逻辑集合。</code></p><p>A <em>dbspace</em> chunk contains data and index pages in the form of tblspaces. The first dbspace in an Informix Dynamic Server system always contains the first chunk, or <em>root chunk</em>. Therefore, dbspace 1 is always the <em>root dbspace</em>.</p><p><code>dbspace chunk以tblspace的形式包含数据页和索引页。IDS的第一个dbspace始终包含第一个chunk，或称为root chunk。因此dbspace 1 始终是 root dbspace</code></p><p>A blobspace chunk contains BYTE and TEXT data.</p><p><code>blobspace chunk包含BYTE和TEXT数据</code></p><p>An sbspace chunk contains smart large object (BLOB and CLOB) data and metadata pages to help manage the data.</p><p><code>sbspace chunk包含智能大对象（BLOB 和 CLOB）数据和元数据页，以帮助管理数据。</code></p><p><strong>Shared Memory</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032211153.png" alt="image-20250503221105036"></p><p>Shared memory in Informix Dynamic Server is divided into three portions:</p><p>IDS中的共享内存分为3个不分：</p><p>The <em>resident portion</em> contains the buffer cache and other system information. These shared memory segments can be configured to remain resident in main memory.  </p><p><code>“常驻部分”包含缓冲区缓存和其他系统信息。这些共享内存段可以配置为驻留在主内存中。</code></p><p>The <em>virtual portion</em> contains information about threads and sessions, data object caching, and temporary data needed for activities such as sorting and parallel data query. This information grows and changes constantly, so the database server must handle the allocation and deallocation of memory.</p><p><code>“虚拟部分”包含有关线程和会话、数据对象缓存以及排序和并行数据查询等活动所需的临时数据的信息。这些信息不断增长和变化，因此数据库服务器必须处理内存的分配和释放。</code></p><p>Clients connecting to the database server by shared memory leave and collect messages in the <em>message portion</em> of shared memory. This portion is created only if you configure shared memory as a communications method for the server.</p><p><code>通过共享内存连接到数据库服务器的客户端会在共享内存的“消息部分”中发送和接收消息。仅当您将共享内存配置为服务器的通信方式时，才会创建此部分。</code></p><p><strong>A Local Delete</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032225865.png" alt="image-20250503222537796"></p><p>The above example assumes that the client is using a shared-memory connection.</p><p><code>上面的例子假设客户端正在使用共享内存连接。</code></p><ol><li><p>When you type <strong>dbaccess</strong>, the UNIX shell spawns a client process.</p><p><code>当你输入dbaccess，UNIX shell 会生成一个客户端进程。</code></p></li><li><p>When you connect to a database, the client process connects to Dynamic Server shared memory. The database server (which is chiefly a collection of processes called <strong>oninit</strong>) detects a new connection and creates a session and an <strong>sqlexec</strong> thread for the session. The <strong>sqlexec</strong> thread waits for further instructions from the client.</p><p><code>连接到数据库时，客户端进程会连接到动态服务器共享内存。数据库服务（主要是一个称为oninit的进程集合）会检测到一个新连接，并为会话创建一个会话和一个sqlexec线程。sqlexec 线程等待客户端将来的指令。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032233662.png" alt="image-20250503223234075"></p></li><li><p>The client connects to the server with the CONNECT or DATABASE statement. Opening the database involves many read and write operations.</p><p><code>客户端通过 CONNECT 或 DATABASE 语句连接服务器。打开数据库涉及许多读写操作。</code></p></li><li><p>Assume that our <strong>sqlexec</strong> thread decides it must scan page 30 in chunk 4. (By the end of this course, you will understand the method by which a thread arrives at this decision in agonizing detail. For now, be thankful for broad assumptions.) First it finds a free <em>buffer</em>, a page-size swath of memory, in the shared memory buffer pool. It locks this buffer, taking temporary ownership of it. The <strong>sqlexec</strong> thread then places a request for page 30 from chunk 4 into the AIO request queue, and then goes to sleep. Again, speaking in broad generalities, the kernel asynchronous I&#x2F;O system (or the Dynamic Server AIO mechanism) puts the page into the buffer, overwriting whatever was there previously. Then the <strong>sqlexec</strong> thread wakes up and scans the buffer for the desired information. The buffer can now be unlocked, (though not freed), so that other processes who require the same page do not have to read it from disk.</p><p><code>假设我们的 sqlexec 线程决定它必须扫描块 4 中的第 30 页。（在本课程结束时，您将理解线程做出此决定的详细过程。现在，请感谢宽泛的假设。）首先，它在共享内存缓冲池中找到一个可用缓冲区，即一个页面大小的内存区域。它锁定此缓冲区，并暂时拥有它。然后，sqlexec 线程将对块 4 中第 30 页的请求放入 AIO 请求队列，然后进入睡眠状态。同样，广义上讲，内核异步 I/O 系统（或 Dynamic Server AIO 机制）将页面放入缓冲区，覆盖先前的内容。然后，sqlexec 线程唤醒并扫描缓冲区以查找所需信息。现在可以解锁缓冲区（但不能释放），以便其他需要同一页面的进程不必从磁盘读取它。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032240217.png" alt="image-20250503224006136"></p></li><li><p>The server process sends an <em>OK</em> message to the client, indicating that the previous operation (database open) was successful. The client then sends the DELETE statement to the server, where it is <em>parsed</em> (the syntax is broken down and interpreted) and optimized (a plan to quickly find the target row(s) is formulated).</p><p><code>服务器进程向客户端发送 OK 消息，表示上一个操作（打开数据库）成功。然后，客户端将 DELETE 语句发送到服务器，服务器对其进行解析（语法分解和解释）和优化（制定快速找到目标行的方案）。</code></p></li><li><p>If transaction logging is turned on for the database about to be modified, by definition, all changes must be logged as part of a transaction. Since the server has received no BEGIN WORK statement to this point, it treats this lone DELETE statement as a singleton transaction, meaning that surrounding the one operation are implicit BEGIN WORK and COMMIT WORK SQL statements. Therefore, before performing the delete operation, the <strong>sqlexec</strong> thread sends a BEGIN WORK log record, a digested form of the BEGIN WORK statement, to the logical log buffer.</p><p><code>如果要修改的数据库启用了事务日志记录，那么根据定义，所有更改都必须作为事务的一部分进行记录。由于服务器目前尚未收到任何 BEGIN WORK 语句，因此它会将此单独的 DELETE 语句视为一个单例事务，这意味着围绕该操作的是隐式的 BEGIN WORK 和 COMMIT WORK SQL 语句。因此，在执行删除操作之前，sqlexec 线程会将 BEGIN WORK 日志记录（BEGIN WORK 语句的摘要形式）发送到逻辑日志缓冲区。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032244997.png" alt="image-20250503224426924"></p><p>The next step is for the server to lock, then modify a particular data page in the <strong>customer</strong>table. There is no reason to read the page from disk if it already exists in shared memory,  so the server first determines whether the page containing the target row is in the buffer pool.</p><p><code>下一步是服务器锁定客户表中的特定数据页，然后进行修改。如果该页已存在于共享内存中，则无需从磁盘读取该页，因此服务器首先会确定包含目标行的页是否位于缓冲池中。</code></p></li><li><p>Let us assume the page had, in fact, been read into a buffer pool by an earlier query, and that this buffer has never been modified. Assuming the buffer is not locked by another thread, the <strong>sqlexec</strong> thread locks it exclusively. Then, prior to changing the data, the server copies the <em>before image</em> of this page to the physical log buffer.</p><p><code>假设该页面实际上已被先前的查询读入缓冲池，并且该缓冲区从未被修改过。假设该缓冲区未被其他线程锁定，则 sqlexec 线程会对其进行独占锁定。然后，在更改数据之前，服务器会将该页面的“前映像”复制到物理日志缓冲区。</code></p></li><li><p>The target row on the page is then deleted.</p><p><code>然后删除页面上的目标行。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032250593.png" alt="image-20250503225034532"></p></li><li><p>After deleting the row, the database server writes a DELETE record of the change row. A record of table and row information is copied to the logical log buffer in memory.</p><p><code>删除行后，数据库服务会写入更改行的 DELETE 记录。表和行信息的记录被复制到内存中的逻辑日志缓冲区。</code></p></li><li><p>The singleton transaction is then committed. All associated locks are freed, and a binary version of a COMMIT WORK record is written to the logical log buffer. At this point, if the affected database uses <em>unbuffered</em> logging*,* the server writes the contents of the logical log buffer to the current log file on disk before returning a <em>success</em>status to the client process. Assume for the sake of this example that our database uses <em>buffered</em> logging, in which case the server does not flush the log buffer unless it is full.</p><p><code>然后提交单事务。所有关联的锁都会被释放，并且 COMMIT WORK 记录的二进制版本会写入逻辑日志缓冲区。此时，如果受影响的数据库使用非缓冲日志记录，则服务器会将逻辑日志缓冲区的内容写入磁盘上的当前日志文件，然后再向客户端进程返回成功状态。为了便于说明，假设我们的数据库使用缓冲日志记录，在这种情况下，除非日志缓冲区已满，否则服务器不会刷新日志缓冲区。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032259197.png" alt="image-20250503225947128"></p></li><li><p>Once the transaction has committed successfully, the server process sends an <em>OK</em>message back to the client. The server then waits on a condition for further instructions. If the client exits at this point, the following events occur:</p><p><code>一旦事务成功提交，服务器进程就会向客户端发送一条 OK 消息。然后，服务器等待进一步的指令。如果客户端在此时退出，则会发生以下事件：</code></p><p><strong>-</strong> The session threads release any resources, such as locks or buffers. </p><p>会话线程会释放所有资源，例如锁或缓冲区。</p><p> <strong>-</strong> The session threads and the session memory disappear.</p><p>会话线程和会话内存会消失。</p><p> <strong>-</strong> The client detaches from shared memory.</p><p>客户端脱离共享内存。</p></li></ol><p><strong>Writing Buffer Pages to Disk</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032304898.png" alt="image-20250503230458815"></p><p>The transaction might be over as far as we are concerned, but nothing our server process did has yet been stored permanently. If shared memory were to vanish suddenly, our changes would be lost.</p><p><code>就我们而言，事务可能已经结束，但我们的服务器进程所做的一切还没有被永久保存（持久化）。如果共享内存突然消失，我们的更改也会丢失。</code></p><ol><li><p>Assuming other sessions continue working after our session disconnected, one of them eventually fills the physical log buffer. The PIO virtual processor flushes the physical log buffer (unless kernel asynchronous I&#x2F;O is used, in which case the kaio thread performs the I&#x2F;O). All before images stored in the buffer are written to the physical log on disk, and the buffer can now be overwritten by new before images.</p><p><code>假设我们的会话断开后其他会话继续工作，其中一个会话最终会填满物理日志缓冲区。PIO 虚拟处理器会刷新物理日志缓冲区（除非使用内核异步 I/O，在这种情况下，kaio 线程会执行 I/O）。所有存储在缓冲区中的前像都会写入磁盘上的物理日志，现在缓冲区可以被新的前映像覆盖。</code></p></li><li><p>Likewise, the LIO virtual processor or the kaio facility flushes the logical log buffer. All transaction log records stored in the buffer, having been packaged there in the form of new logical log pages, are written to the logical log currently in use.</p><p><code>同样，LIO 虚拟处理器或 kaio 工具会刷新逻辑日志缓冲区。所有存储在缓冲区中的事务日志记录，都会以新的逻辑日志页的形式打包，并写入当前正在使用的逻辑日志中。</code></p></li></ol><p>Note that the order of these two operations is random, and is usually dependent on which buffer fills first. However, a page cleaner ensures that the before image of a page is written to the physical log before its modified image is written to disk from the buffer pool.</p><p><code>请注意，这两个操作的顺序是随机的，通常取决于哪个缓冲区先被填满。但是，页面清理器会确保在页面的修改后映像从缓冲池写入磁盘之前，先将页面的修改前映像写入物理日志。  </code></p><p><strong>Performing a Checkpoint</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032316212.png" alt="image-20250503231650138"></p><p>Now that the before image of our page has been written to the physical log and all actions we took on the page have been recorded in the logical log, we can recover the transaction if it became necessary. But replaying transactions using logical logs takes time, and we would rather do as little work as possible during a recovery.At this point, if we were to synchronize the data in shared memory with the data in our chunks—flushing all dirty pages, flushing both log buffers, and marking our current position in the logical log—we would produce a <em>known point of consistency</em>. In the event of a failure, we could return to this synchronization point or <em>checkpoint</em>, replay only the actions taken on the database since then, and the time it would take to get the system back online would be minimized.</p><p><code>现在，页面的“前映像”已写入物理日志，并且我们在页面上执行的所有操作都已记录在逻辑日志中，我们可以在必要时恢复事务。但是，使用逻辑日志重放事务需要时间，我们希望在恢复期间尽可能少地执行工作。此时，如果我们将共享内存中的数据与块中的数据同步（刷新所有脏页，刷新两个日志缓冲区，并标记我们在逻辑日志中的当前位置），我们将产生一个已知的一致性点。如果发生故障，我们可以返回到此同步点或检查点，仅重放自那时以来在数据库上执行的操作，从而最大限度地缩短系统恢复在线所需的时间。</code></p><ol><li><p>First, a checkpoint is <em>requested</em>. There are many conditions or events that trigger a checkpoint request. For example:</p><p><code>触发检查点请求的条件或事件有很多。例如：</code></p><p><strong>-</strong> The checkpoint time-out value has elapsed and pages have been modified</p><p><code>检查点超时值已过且页面已被修改</code></p><p> <strong>-</strong> The physical log becomes 75% full</p><p><code>物理日志已满 75%</code></p><p> <strong>-</strong> The administrator forces a checkpoint</p><p><code>管理员强制检查点</code></p><p>Configuration parameters that could affect when a checkpoint occurs include:</p><p><code>可能影响检查点发生时间的配置参数包括：</code></p><p> <strong>-</strong> CKPTINTVL – Specifies the interval between the completion of one checkpoint and the request for the next checkpoint.</p><p><code>CKPTINTVL – 指定一个检查点完成与下一个检查点请求之间的间隔。</code></p><p> <strong>-</strong> AUTO_CKPTS – If enabled, critical resources are monitored and checkpoint frequency is adjusted to reduce transaction blocking.</p><p><code>AUTO_CKPTS – 如果启用，则会监视关键资源并调整检查点频率以减少事务阻塞。</code></p><p> <strong>-</strong> RTO_SERVER_RESTART – This parameter specifies, in seconds, the recovery time objective for restarting the database server after a server failure. Checkpoint frequency is adjusted to meet the specified objective.</p><p><code>RTO_SERVER_RESTART – 此参数指定服务器故障后重新启动数据库服务器的恢复时间目标（以秒为单位）。检查点频率会进行调整以满足指定的目标。</code></p></li><li><p>To ensure a point of consistency, the database server sets off a global block to suspend all transactions. Once all servers have reached a point where they can safely suspend their work, checkpoint information is recorded (as if it has already occurred) in the physical log reserve page, but <em>not</em> to the checkpoint reserved page. The global block is then released so that server activity can continue.</p><p><code>为了确保一致性点，数据库服务器会触发全局阻塞来暂停所有事务。一旦所有服务器都达到可以安全暂停工作的程度，检查点信息就会被记录在物理日志保留页中（如同已经发生过一样），但不会记录在检查点保留页中。然后全局阻塞会被释放，以便服务器活动可以继续进行。</code></p></li><li><p>Next, the server flushes the physical log buffer contents to the physical log on disk.</p><p><code>接下来，服务器会将物理日志缓冲区中的内容刷新到磁盘上的物理日志中。</code></p></li></ol><p><strong>Non-blocking checkpoints</strong></p><p>In version 11.10 of Informix Dynamic Server, new algorithms make it possible to avoid transaction blocking during most types of checkpoints. Because checkpoint information is saved at the beginning of the checkpoint process, it is no longer necessary to block transactions while pages are flushed to disk. If the server is interrupted during a checkpoint, then fast recovery can restore from the previous checkpoint. Blocking checkpoints are still required to perform a system backup, and when other system events occur, such as the adding of a dbspace.</p><p><code>在 Informix Dynamic Server 11.10 版本中，新算法可以避免大多数类型的检查点期间的事务阻塞。由于检查点信息在检查点过程开始时保存，因此在将页面刷新到磁盘时不再需要阻塞事务。如果服务器在检查点期间中断，则快速恢复可以从上一个检查点恢复。执行系统备份以及发生其他系统事件（例如添加数据库空间）时仍然需要阻塞检查点。</code></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032338289.png" alt="image-20250503233813202"></p><ol start="4"><li>All dirty pages in the shared-memory buffer pool are written to disk by page cleaner threads. Physical and logical log buffers are flushed to disk.</li></ol><p>   <code>共享内存缓冲池中的所有脏页都由页面清理线程写入磁盘。物理和逻辑日志缓冲区均被刷新到磁盘。</code></p><ol start="5"><li><p>A special record called a <em>checkpoint record</em> is written to the logical log buffer. The physical and logical consistency point on disk is updated to the CKPT reserved page.</p><p><code>一个称为检查点记录的特殊记录被写入逻辑日志缓冲区。磁盘上的物理和逻辑一致性点被更新到 CKPT 保留页。</code></p></li></ol><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505032341006.png" alt="image-20250503234102938"></p><p><strong>Flushing the Physical Log</strong></p><ol start="6"><li><p>The last step in the checkpoint process is to <em>logically empty</em> the physical log. Logically emptying the log means setting its <em>begin address</em> equal to its current address, an operation that is much less expensive than filling the log with zeros or changing the log in any physical way.</p><p><code>检查点过程的最后一步是逻辑上清空物理日志。逻辑上清空日志意味着将其起始地址设置为其当前地址，这个操作比用零填充日志或以任何物理方式更改日志的开销要小得多。</code></p></li></ol><p><strong>Fast Recovery</strong></p><p> Always occurs during database server startup</p><p><code>总是在数据库服务器启动时发生</code></p><p> Brings the database to a consistent state</p><p><code>使数据库达到一致状态</code></p><p> Consists of two phases</p><p><code>包含两个阶段</code></p><p>– Physical recovery</p><p>物理恢复</p><p>– Logical recovery</p><p>逻辑恢复</p><p>When a database server is brought from Online to Offline mode, the server threads perform a checkpoint to make sure that all data in shared memory gets written to disk. However, events could occur that cause the server to be shut down before it has a chance to complete a checkpoint.</p><p><code>当数据库服务器从在线模式切换到离线模式时，服务器线程会执行检查点操作，以确保共享内存中的所有数据都已写入磁盘。然而，某些事件可能会导致服务在完成检查点操作之前关闭。</code></p><p><em>Fast recovery</em> is the process that Informix Dynamic Server goes through every time a database server is started. If the database server was terminated abnormally, the fast recovery process uses the physical and logical logs to restore the database server to a state of consistency. There are two phases to the fast recovery process: physical recovery and logical recovery.</p><p><code>快速恢复是 IDS 每次启动数据库服务时都会经历的过程。如果数据库服务器异常终止，快速恢复过程将使用物理日志和逻辑日志将数据库服务器恢复到一致性状态。快速恢复过程分为两个阶段：物理恢复和逻辑恢复。</code></p><p><strong>Fast Physical Recovery</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051114478.png" alt="image-20250505111447340"></p><p>During the first stage of fast recovery, called <em>physical recovery</em>, all the before images in the physical log are copied to their proper addresses on disk. We overwrite those pages with their before images for a good reason. During normal operation, page cleaner threads are constantly writing dirty pages out from shared memory to the AIO queue (which gets flushed to disk by the AIO VP or by the <strong>kaio</strong> thread). If we are to reproduce the conditions that existed immediately after the last checkpoint, we must ensure that any pages modified and flushed since that checkpoint are replaced with their original images.</p><p><code>在快速恢复的第一阶段（称为物理恢复）中，物理日志中的所有前映像都会被复制到磁盘上的正确地址。我们用前映像覆盖这些页面是有原因的。在正常运行期间，页面清理线程会不断将脏页从共享内存写入 AIO 队列（该队列由 AIO VP 或 kaio 线程刷新到磁盘）。如果我们要重现上一个检查点之后的情况，必须确保自该检查点以来修改和刷新的所有页面都被替换为其原始映像。</code></p><p>Once this reshelving is done, the physical log is logically emptied (the physical log begin pointer is set to the current pointer).</p><p><code>一旦完成重新搁置，物理日志在逻辑上就被清空（物理日志开始指针设置为当前指针）。</code></p><p><strong>Fast Logical Recovery</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051119920.png" alt="image-20250505111924827"></p><p>The second stage of fast recovery, <em>logical recovery</em>, remodifies the pages restored by physical recovery. Beginning at the last checkpoint record in the logical logs, the <strong>oninit</strong> process rolls forward from there, bringing the system to exactly the state it was in at the time of the crash. The loose ends are tied up after the last log record is applied; <strong>oninit</strong> rolls back any uncommitted transactions, records the rollback by adding CLRs (compensation log records) in the log, deletes temporary tables, performs index builds deferred during the rollforward as an optimization, and brings the system into Quiescent mode.</p><p><code>快速恢复的第二阶段是逻辑恢复，它会重新修改物理恢复所恢复的页面。oninit 进程从逻辑日志中最后一个检查点记录开始前滚，使系统恢复到崩溃时的状态。应用最后一个日志记录后，所有未完成的操作都已完成；oninit 会回滚所有未提交的事务，通过在日志中添加 CLR（补偿日志记录）来记录回滚，删除临时表，执行在前滚过程中作为优化而推迟的索引构建，并将系统置于静默模式。</code></p><p><code>紫本200页Quiescent mode翻译成静默模式</code></p><p>Then the whole cycle begins again. Attached sessions are free to modify shared memory, and the pages on disk become more and more out of date in relation to the buffer pool. If our database server came down unexpectedly at this point, all modified buffers would vanish. We would have to get those pages back somehow. Fast recovery manages to do just that.</p><p><code>然后整个循环再次开始。连接的会话可以自由地修改共享内存，磁盘上的页面相对于缓冲池来说会变得越来越过时。如果我们的数据库服务器此时意外宕机，所有修改过的缓冲区都会消失。我们必须以某种方式恢复这些页面。快速恢复正是这样做的。</code></p><p>After completion of the checkpoint, all pages in the buffer cache are in sync with the pages on disk.</p><p><code>检查点完成后，缓冲区缓存中的所有页面都与磁盘上的页面同步。</code></p><p><strong>Fast Recovery and Checkpoint Messages</strong></p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505051132861.png" alt="image-20250505113201794"></p><p>Above is an example of messages written to the message log during fast recovery. The message log shows the page at which physical recovery began (in the form chunk_number*:<em>page_offset</em>) and how many before-image pages were examined and restored. It also shows the number of transactions that were committed or rolled back during logical recovery. Finally, the message log shows checkpoint information, including where the checkpoint record was written in the logical logs.</p><p><code>以上是快速恢复期间写入消息日志的消息示例。消息日志显示了物理恢复开始的页面（格式为“chunk_number:page_offset”）以及检查和恢复了多少个前映像页面。它还显示了逻辑恢复期间提交或回滚的事务数量。最后，消息日志显示了检查点信息，包括检查点记录在逻辑日志中的写入位置。</code></p><p><code>紫本202页基本是快速恢复这块的翻译，而且有例子</code></p>]]></content>
      
      
      <categories>
          
          <category> IX9111 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SQLsmith</title>
      <link href="/2024/04/07/SQLsmith/SQLsmith/"/>
      <url>/2024/04/07/SQLsmith/SQLsmith/</url>
      
        <content type="html"><![CDATA[<p>源码：<a href="https://github.com/anse1/sqlsmith">https://github.com/anse1/sqlsmith</a> tag:v1.4</p><p>在Centos7上用CLion看代码，装了一些东西（顺序不一定），直到项目右键”Reload CMake Project”不报错为止，然后代码点击才能跳转<br>yum install postgresql14<br>yum install gcc-c++<br>yum clean all<br>rm -rf &#x2F;var&#x2F;cache&#x2F;yum&#x2F;*<br>yum install <a href="https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm">https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</a><br>yum install llvm5.0-devel<br>yum install postgresql14-devel<br>yum install libpqxx libpqxx-devel</p><p>目的是看懂执行逻辑，不深入c++语法，只查了一下make_shared的含义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make_shared</span>&lt;query_spec&gt;((<span class="keyword">struct</span> prod *)<span class="number">0</span>, s); <span class="comment">// 它会导致query_spec构造函数的调用，括号里是传入的2个参数</span></span><br></pre></td></tr></table></figure><p>.cc文件，当做.cpp理解即可</p><p>入口：sqlsmith.cc，只看postgres相关逻辑</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main()</span></span><br><span class="line"><span class="comment">// 导致schema_pqxx构造函数调用，见下面postgres.cc</span></span><br><span class="line">schema = <span class="built_in">make_shared</span>&lt;schema_pqxx&gt;(options[<span class="string">&quot;target&quot;</span>], options.<span class="built_in">count</span>(<span class="string">&quot;exclude-catalog&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行sqlsmith时，加--dry-run，会把随机生成的语句写到日志里，不会执行</span></span><br><span class="line"><span class="keyword">if</span> (options.<span class="built_in">count</span>(<span class="string">&quot;dry-run&quot;</span>)) &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        shared_ptr&lt;prod&gt; gen = <span class="built_in">statement_factory</span>(&amp;scope);</span><br><span class="line">        gen-&gt;<span class="built_in">out</span>(cout);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> l : loggers)</span><br><span class="line">            l-&gt;<span class="built_in">generated</span>(*gen);</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;;&quot;</span> &lt;&lt; endl;</span><br><span class="line">        queries_generated++;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (options.<span class="built_in">count</span>(<span class="string">&quot;max-queries&quot;</span>)</span><br><span class="line">            &amp;&amp; (queries_generated &gt;= <span class="built_in">stol</span>(options[<span class="string">&quot;max-queries&quot;</span>])))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>postgres.cc</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">schema_pqxx::<span class="built_in">schema_pqxx</span>(std::string &amp;conninfo, <span class="type">bool</span> no_catalog) : <span class="built_in">c</span>(conninfo)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 使用 libpqxx (PostgreSQL C++ API) 读元数据，包括：</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// types</span></span><br><span class="line">  <span class="comment">// name,oid,typdelim,typrelid,typelem,typarray,typtype</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// tables </span></span><br><span class="line">  <span class="comment">// name，schema，is_insertable，is_base_table（后边，只有是true的表才有机会从中随机）</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">// columns and constraints</span></span><br><span class="line">  <span class="comment">// operators</span></span><br><span class="line">  <span class="comment">// routines</span></span><br><span class="line">  <span class="comment">// routine parameters</span></span><br><span class="line">  <span class="comment">// aggregates</span></span><br><span class="line">  <span class="comment">// aggregate parameters</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_LIBPQXX7</span></span><br><span class="line">  c.<span class="built_in">close</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  c.<span class="built_in">disconnect</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  <span class="built_in">generate_indexes</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> SQLsmith </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>物理日志</title>
      <link href="/2023/11/21/gbase8s/%E7%89%A9%E7%90%86%E6%97%A5%E5%BF%97/"/>
      <url>/2023/11/21/gbase8s/%E7%89%A9%E7%90%86%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p><u>数据库原理和实践教程GBase8t剖析与应用.pdf</u></p><h5 id="为什么需要物理日志"><a href="#为什么需要物理日志" class="headerlink" title="为什么需要物理日志"></a>为什么需要物理日志</h5><p>快速恢复时，先用物理日志记录的前映像恢复，再进行逻辑日志恢复</p><h5 id="为什么需要恢复到前映像"><a href="#为什么需要恢复到前映像" class="headerlink" title="为什么需要恢复到前映像"></a>为什么需要恢复到前映像</h5><blockquote><p>发生checkpoint后，由于内存中的脏数据可能在下一次checkpoint之前被写回到磁盘，这就是我们通常所讲的<mark>LRU写</mark>（后台写），所以磁盘上的数据再checkpoint之后发生了变化，就不能用作逻辑恢复</p><p>书 202 页</p></blockquote><h5 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h5><blockquote><p>数据库周期性地将buffer pool的 <mark>脏数据</mark> 刷新到磁盘上，达到磁盘、内存数据一致性的时间点被称为检查点（Checkpoint）</p><p>书 188 页</p></blockquote><h5 id="共享内存缓冲池（Buffer-Pool）"><a href="#共享内存缓冲池（Buffer-Pool）" class="headerlink" title="共享内存缓冲池（Buffer Pool）"></a>共享内存缓冲池（Buffer Pool）</h5><blockquote><p>共享内存缓冲池存储从磁盘读取的数据库空间页的缓冲区，用来缓存数据库表从磁盘读取的数据，数据库在内存中对数据进行访问和修改，当数据发生变化后，将写回磁盘。其中每个缓冲区就是一个数据库服务器页的大小。</p><p>共享内存缓冲池通过 LRU 队列的方式进行集体管理，如图 6.10 所示。LRU 队列由空闲的队列（Free LRU 或 FLRU）和<mark>脏队列</mark>（Modified LRU 或 MLRU）组成。共享内存缓冲池按 LRU 队列对进行管理，一个是 Free，另外一个是 Modify。同一个 Page 只能在 LRU队列对中出现一次，比如：有一行记录被修改了，那么该行记录所在的 Page 将被从 Free队列移动到 Modify 队列。</p><p>书 160 页</p></blockquote><p>脏数据就是脏队列里的数据</p><h5 id="为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）"><a href="#为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）" class="headerlink" title="为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）"></a>为什么内存中的脏数据可能在下一次checkpoint之前被写回到磁盘（LRU写）</h5><p>书上没写，看官网</p><p><a href="https://www.ibm.com/docs/en/informix-servers/12.10?topic=flushing-lru-write">LRU write - IBM Documentation</a></p><blockquote><p>LRU writes are performed by page cleaners rather than by sqlexec threads. The database server performs LRU writes as background writes that <strong>typically occur when the percentage of dirty buffers exceeds the percent that is specified for lru_max_dirty in the BUFFERPOOL configuration parameter.</strong></p></blockquote><p>就是脏数据的比例超过一个配置的最大脏数据百分比，触发 LRU 写，落盘</p><p>（从 LRU 也能猜出一二，这是一种缓存淘汰算法）</p><p>书 203 页，有个快速恢复的示例</p>]]></content>
      
      
      <categories>
          
          <category> gbase8s </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>PreparedStatement</title>
      <link href="/2023/09/03/jmeter/PreparedStatement/"/>
      <url>/2023/09/03/jmeter/PreparedStatement/</url>
      
        <content type="html"><![CDATA[<p>JDBC Request</p><p>有 2 个 PreparedStatement 相关的选项</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202309031350398.png" alt="image-20230903135037315"></p><p>单纯选择 Prepared Statement（没开启 Pool Prepared Statements）</p><p>如果使用参数化的方式执行 select * from t1 where id&#x3D;? 性能比 Statement 低（2% 左右，粗略测试），Statement 执行的是 select * from t1 where id&#x3D;1（2% 的原因看内部文档）</p><p>如果使用非参数化方式，都执行 select * from t1 where id&#x3D;1，性能没差别</p><p>总之，完全体现不出来 Prepared Statement 一次预编译，多次执行的优势</p><p>因为，每次请求都会重新创建 PreparedStatement 对象预编译，请求结束后 close()</p><p>AbstractJDBCTestElement.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (PREPARED_SELECT.equals(currentQueryType)) &#123;</span><br><span class="line">    <span class="keyword">try</span> (<span class="type">PreparedStatement</span> <span class="variable">pstmt</span> <span class="operator">=</span> getPreparedStatement(conn)) &#123;</span><br><span class="line">        setArguments(pstmt);</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            rs = pstmt.executeQuery();</span><br><span class="line">            sample.latencyEnd();</span><br><span class="line">            <span class="keyword">return</span> getStringFromResultSet(rs).getBytes(ENCODING);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            close(rs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (PREPARED_UPDATE.equals(currentQueryType)) &#123;</span><br><span class="line">    <span class="keyword">try</span> (<span class="type">PreparedStatement</span> <span class="variable">pstmt</span> <span class="operator">=</span> getPreparedStatement(conn)) &#123;</span><br><span class="line">        setArguments(pstmt);</span><br><span class="line">        pstmt.executeUpdate();</span><br><span class="line">        sample.latencyEnd();</span><br><span class="line">        <span class="type">String</span> <span class="variable">sb</span> <span class="operator">=</span> resultSetsToString(pstmt,<span class="literal">false</span>,<span class="literal">null</span>);</span><br><span class="line">        <span class="keyword">return</span> sb.getBytes(ENCODING);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (ROLLBACK.equals(currentQueryType))&#123;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> PreparedStatement <span class="title function_">getPreparedStatement</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">    <span class="keyword">return</span> getPreparedStatement(conn,<span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> PreparedStatement <span class="title function_">getPreparedStatement</span><span class="params">(Connection conn, <span class="type">boolean</span> callable)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">    PreparedStatement pstmt;</span><br><span class="line">    <span class="keyword">if</span> (callable) &#123;</span><br><span class="line">        pstmt = conn.prepareCall(getQuery()); </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pstmt = conn.prepareStatement(getQuery()); <span class="comment">// conn 是 DelegatingConnection，先不用管</span></span><br><span class="line">    &#125;</span><br><span class="line">    setQueryTimeout(pstmt, getIntegerQueryTimeout());</span><br><span class="line">    <span class="keyword">return</span> pstmt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> jmeter </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>blog</title>
      <link href="/2023/08/27/misc/blog/"/>
      <url>/2023/08/27/misc/blog/</url>
      
        <content type="html"><![CDATA[<p><strong>theme: hexo-theme-ayer</strong></p><h4 id="1-分类、标签，访问不了"><a href="#1-分类、标签，访问不了" class="headerlink" title="1. 分类、标签，访问不了"></a>1. 分类、标签，访问不了</h4><h5 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h5><p>hexo new page categories</p><p>source\categories\index.md</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;categories&quot;</span><br><span class="line">layout: &quot;categories&quot;</span><br></pre></td></tr></table></figure><h5 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h5><p>hexo new page tags</p><p>source\tags\index.md</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;tags&quot;</span><br><span class="line">layout: &quot;tags&quot;</span><br></pre></td></tr></table></figure><h4 id="2-打开只有文字"><a href="#2-打开只有文字" class="headerlink" title="2. 打开只有文字"></a>2. 打开只有文字</h4><p>新建仓库的时候，填写的仓库名字为<code>账号名.github.io</code>，这样博客地址默认是根路径</p><p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202308272212419.png" alt="image-20230827221050557"></p><p><a href="https://blog.csdn.net/github_38641765/article/details/100182694?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-100182694-blog-119349705.235%5Ev38%5Epc_relevant_anti_t3_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-100182694-blog-119349705.235%5Ev38%5Epc_relevant_anti_t3_base&utm_relevant_index=2">参考文章</a></p><p>gitee 的话，仓库名和账号名一样即可，frh16&#x2F;frh16</p><h4 id="3-图床图片打不开"><a href="#3-图床图片打不开" class="headerlink" title="3. 图床图片打不开"></a>3. 图床图片打不开</h4><p>raw.githubusercontent.com</p><p>PicGo 设定自定义域名</p><p><a href="https://gcore.jsdelivr.net/gh/%E8%B4%A6%E5%8F%B7%E5%90%8D/%E5%9B%BE%E5%BA%8A%E4%BB%93%E5%BA%93%E5%90%8D">https://gcore.jsdelivr.net/gh/账号名/图床仓库名</a></p><p>如果不用 CDN，需要科学上网 或 Steam++</p><h4 id="4-前端全文搜索"><a href="#4-前端全文搜索" class="headerlink" title="4. 前端全文搜索"></a>4. 前端全文搜索</h4><p>npm install hexo-generator-search –save</p><p>hexo g &amp;&amp; hexo d 可以看到 search.xml</p>]]></content>
      
      
      <categories>
          
          <category> misc </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
