<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      



<!-- Subtitle -->

<div id="main">
  <section class="outer">
  
  
  <article class="articles">
    
    
    
    
    <article
  id="post-IX9111/12"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/07/05/IX9111/12/"
    >IX9111 - Unit 12.Physical and Logical Logs</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/07/05/IX9111/12/" class="article-date">
  <time datetime="2025-07-05T08:16:16.000Z" itemprop="datePublished">2025-07-05</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Physical Log Structure</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507051618788.png" alt="image-20250705161804668"></p>
<p><strong>Notes:</strong></p>
<p>The physical log is a circular file, meaning that when the database server writes to the last physical page of the log, it continues writing from the first page. Although the physical beginning and ending of the log could serve as physical boundaries, they are irrelevant to the way the log functions. What matters are two positions within the log: the current position, and the position that <em>was</em> current just after the last checkpoint. If fast recovery becomes necessary due to a crash, the consistency of the data depends on the string of pages between these two positions in the physical log.</p>
<p><code>物理日志是一个循环文件，这意味着当 database server 写入日志的最后一个物理页时，它会从第一个页开始继续写入。尽管日志的物理起始位置和结束位置可被视为物理边界，但它们与日志的运作方式并无关联。真正重要的是日志中的两个位置：当前位置，以及上一次检查点（checkpoint）刚结束后的“当时”的当前位置。如果由于系统崩溃而需要进行快速恢复，那么数据的一致性就取决于物理日志中这两个位置之间的那串页面。</code></p>
<blockquote>
<p>irrelevant 英[ɪˈreləvənt] 美[ɪˈreləvənt]<br>adj. 无关的;不相关的;无关紧要的;</p>
</blockquote>
<p><strong>New Life at Each Checkpoint</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507051624624.png" alt="image-20250705162406553"></p>
<p><strong>Notes:</strong></p>
<p>Immediately following a checkpoint, all pages within the physical log are free to be reused. However, our current position within the log has not been reset by the checkpoint. It has simply been recorded as the <em>physical log position at last checkpoint</em>. When the time comes to write the next page into the log, we simply start where we left off. </p>
<p><code>在检查点（checkpoint）操作刚完成后，物理日志中的所有页面均可被重新使用。然而，日志中的当前位置并不会因检查点操作而被重置，它只是被记录为“上一次检查点时的物理日志位置”。待到需要将下一页写入日志时，我们只需从上次中断的位置继续写入即可。</code></p>
<p>As the physical log thread starts to write pages into the log, it moves forward from this <em>position at last checkpoint</em>. The <em>head</em> of our stream of used pages moves steadily forward through the file each time the physical log buffer is flushed, while the <em>tail</em> remains fixed.</p>
<p><code>当物理日志线程开始将页面写入日志时，它会从“上一次检查点时的位置”开始向前推进。每当物理日志缓冲区被 flush 时，我们已使用页面流中的头部（即最新写入的位置）会在日志文件中稳步向前移动，而尾部（即上一次检查点时的位置）则保持固定不变。</code></p>
<p>Informix Dynamic Server makes every effort to prevent the head from wrapping to the start of the file and catching the tail. It would spell trouble for fast recovery if pages written since the last checkpoint were overwritten before the physical log could be cleared. Every time a process writes a page to the physical log buffer, it calculates how much space has been used in the physical log as a whole. If the file is 75% full, the process immediately requests a checkpoint, which serves to <em>flush</em> or logically empty the physical log.</p>
<p><code>IDS 会竭尽全力防止日志头部回卷到文件起始位置并追上尾部。如果在物理日志被清空之前，自上次检查点以来写入的页面就被覆盖，那么快速恢复将会陷入困境。每当有进程向物理日志缓冲区写入页面时，它都会计算整个物理日志中已使用的空间量。如果文件已使用75%，该进程会立即请求执行检查点操作，此操作旨在 flush 或从逻辑上清空物理日志。</code></p>
<p><strong>Physical Log Flushing</strong></p>
<p>No extra I&#x2F;O is necessary to logically empty the physical log:</p>
<p><code>无需额外的输入/输出（I/O）操作即可从逻辑上清空物理日志。</code></p>
<p>Step 1: Write a new checkpoint structure to the root reserved pages (a step that is taken anyway).Recall that an element of the checkpoint structure contains the physical log position at checkpoint. With this write to the checkpoint structure, the database server sets the new starting position (or tail) to the current position in the log.</p>
<p><code>将新的检查点结构写入root保留页（这一步骤无论如何都会执行）。需注意，检查点结构的元素之一包含检查点发生时的物理日志位置。通过向检查点结构写入这一信息，数据库服务器将日志的新起始位置（或“尾部”）设置为当前日志位置。</code></p>
<p>Step 2: Set the shared-memory variable representing the number of used physical log pages to 0.</p>
<p><code>将共享内存中表示已用物理日志页数量的变量设置为 0。</code></p>
<p><strong>Notes:</strong></p>
<p>Minimal work is involved with flushing the physical log. In fact, it is really just a side-effect of a late step in the checkpoint algorithm: writing a new checkpoint structure to the checkpoint&#x2F;logical log reserved page. Since one of the elements in the checkpoint structure stores the <em>physical log position at checkpoint</em>, writing a new structure to the reserved pages effectively snips off the tail of the page stream. Both the head and the tail are set to the current position within the file. The final step is to zero out the count of used physical log pages, a value stored in shared memory that is used to calculate the percentage of free log space.</p>
<p><code>刷新（Flush）物理日志所需的工作量极小。实际上，这仅是检查点算法后期步骤的一个附带效果：即向检查点/逻辑日志的保留页写入新的检查点结构。由于检查点结构中有一个元素会存储检查点发生时的物理日志位置，因此向保留页写入新结构会逻辑上截断已用页面流的尾部。此时，日志的头部和尾部均被设置为文件中的当前位置。最后一步是将共享内存中存储的已用物理日志页计数归零，该值用于计算日志空闲空间的百分比。</code></p>
<p><strong>Physical Log Reduction</strong></p>
<p> Uninitialized pages (pages with an invalid address) are no longer physically logged</p>
<p><code>未初始化的页（地址无效的页）不再被物理日志记录。</code></p>
<p> Implications – more physical logging might be performed during rollforward than was done during normal processing</p>
<p><code>影响——在向前恢复（重做日志）过程中，执行的物理日志记录量可能比正常处理期间更多。</code></p>
<p><strong>Notes:</strong></p>
<p>Because the speed with which the physical log fills has an impact on checkpoint frequency, </p>
<p>an effort has been made to limit physical logging to the minimum required for recovering </p>
<p>data consistency.</p>
<p><strong>Do not log garbage</strong></p>
<p>Perhaps the easiest example of physical log reduction, is the case of uninitialized pages. When a page is first used, it usually begins as a random stream of bytes over which the database server page header and <strong>slot</strong> table structures must be written before the data row or index item. This is the process of page initialization, which is different from allocation in that allocation simply reserves the page(s) for later use. Technically, the page is modified during this initialization, but physically logging a useless before image makes no sense.</p>
<p><code>物理日志减少的最典型案例，莫过于未初始化页的处理。当首次使用一个页时，其内容通常是一串随机字节，server 需先在此之上写入 page header 和 slot 表结构，之后才能存储数据行或索引项。这一过程称为页初始化（Page Initialization），它与页分配（Allocation）不同——分配仅是为后续使用预留页空间，而初始化会实际修改页内容。从技术角度看，初始化确实修改了页，但记录无意义的“修改前镜像（before-image）”到物理日志毫无价值。</code></p>
<p>The first rule of physical log reduction is this: uninitialized pages are not physically logged. A page is judged to be uninitialized if its address does not match its physical location.</p>
<p><code>物理日志减少的首要原则是：未初始化的页不会被记录到物理日志中。若一个页的逻辑地址与其物理存储位置不匹配，则判定该页为未初始化状态。</code></p>
<p><strong>Restartable Fast Recovery</strong></p>
<p> To avoid physical log overflow, write physical log pages to the file system during fast recovery</p>
<p><code>为避免物理日志溢出，在快速恢复过程中需将物理日志页实时写入文件系统。</code></p>
<p> If a crash occurs during recovery, fast recovery can resume with the physical restore of pages from the physical log file in the file system</p>
<p><code>若在恢复过程中发生崩溃，系统可通过从文件系统中的物理日志文件中还原数据页，快速重启恢复流程。</code></p>
<p> Meanwhile, new physical log pages continue to be written to the file system</p>
<p><code>与此同时，新的物理日志页仍会持续写入文件系统。</code></p>
<p> At post-recovery checkpoint, physical logging resumes within the database server</p>
<p><code>在恢复后检查点（Post-Recovery Checkpoint）阶段，database server 内重新启用物理日志记录功能。</code></p>
<p> Set the PLOG_OVERFLOW_PATH configuration parameter to the file system path to use during physical recovery</p>
<p><code>将 PLOG_OVERFLOW_PATH 配置参数设置为物理恢复期间使用的文件系统路径。</code></p>
<p><strong>Notes:</strong></p>
<p>To avoid potential problems during fast recovery, new physical log pages are written to a file in the file system instead of to the physical log in the database server. If a crash occurs during recovery, physical recovery can resume from the position in the physical log at last checkpoint, and continue with the pages that were written to the file system. Meanwhile, the database server continues physical logging to the file system.</p>
<p><code>为避免快速恢复期间可能出现的问题，新的物理日志页将写入文件系统中的独立文件，而非 server 内置的物理日志。若恢复过程中发生崩溃，系统可从上一个检查点记录的物理日志位置重新启动物理恢复，并继续处理已写入文件系统的日志页。与此同时，server 仍持续向文件系统写入物理日志。</code></p>
<p>At the completion of fast recovery, a checkpoint is requested, the physical log position is reset, the physical log file in the file system is removed, and logging to the physical log in the database server can resume.</p>
<p><code>快速恢复完成后，系统会触发检查点操作，重置物理日志位置，删除文件系统中的物理日志文件，并恢复向 server 内置的物理日志写入日志。</code></p>
<p><strong>PLOG_OVERFLOW_PATH</strong></p>
<p>The name of the physical log in the file system is <strong>plog_extend.server_num</strong>. By default, this file is located in <strong>$INFORMIXDIR&#x2F;tmp</strong>, but you can specify a location for this file by setting the PLOG_OVERFLOW_PATH configuration parameter. For example:</p>
<p><code>文件系统中物理日志的文件名为 plog_extend.server_num。默认情况下，该文件位于 $INFORMIXDIR/tmp 目录下，但您可以通过设置 PLOG_OVERFLOW_PATH 配置参数来指定该文件的存储路径。例如：</code></p>
<p>​		PLOG_OVERFLOW_PATH &#x2F;home&#x2F;informix&#x2F;temp</p>
<p><strong>A Side-Effect of Unbuffered Logging</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507051828508.png" alt="image-20250705182810410"></p>
<p><strong>Notes:</strong></p>
<p>A database created with logging uses either buffered logging or unbuffered logging.</p>
<p><code>启用日志记录功能的数据库可采用缓冲 Buffered Logging 或 Unbuffered Logging 两种模式。</code></p>
<p> <strong>•</strong> In a database created with unbuffered logging, the logical log buffer is flushed when a transaction on the database is committed.This means that logical log pages are less full when they are written to a logical log file.</p>
<p><code>在启用 Unbuffered Logging 的数据库中，当事务提交时，逻辑日志缓冲区（Logical Log Buffer）中的内容会立即被刷盘（Flushed）到逻辑日志文件。这意味着写入逻辑日志文件时，日志页的填充程度通常较低（即存在较多未使用的空间）。</code></p>
<p> <strong>•</strong> In a database created with buffered logging, the current logical log buffer is flushed only when the log buffer becomes full. Logical log buffer pages are mostly full when they are written to the logical log files.</p>
<p><code>在启用 Buffered Logging 的数据库中，当前逻辑日志缓冲区（Logical Log Buffer）仅在缓冲区满时才会被 flush。写入逻辑日志文件时，日志缓冲区的页（Pages）通常处于接近满载的状态。</code></p>
<p>As illustrated above, one side effect of unbuffered logging, especially in OLTP environments, is that the logging process produces relatively <em>light</em> logical logs. When buffered logging is used, log records are packed more efficiently into each logical log, reducing the frequency of log backups and the likelihood of long transactions as well.</p>
<p><code>如上所述，非缓冲日志记录（尤其在OLTP环境中）的一个副作用是，日志记录过程会生成内容相对“稀疏”（数据量较少）的逻辑日志。而采用缓冲日志记录时，日志记录能更高效地填充到每个逻辑日志页中，从而降低日志备份的频率，并减少长事务发生的可能性。</code></p>
<blockquote>
<p>likelihood 可能性 英[ˈlaɪklihʊd] 美[ˈlaɪklihʊd]</p>
</blockquote>
<p><strong>Long Transactions</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507051835518.png" alt="image-20250705183506446"></p>
<p><strong>Notes:</strong></p>
<p>A database server temporarily grinds to a halt when all logical logs become full, which is why it is important to keep one or more logs free at all times by backing them up promptly. It is by no means a fatal mistake to neglect the logs and let the system freeze; the logs can be backed up any time and the system can be back to normal. There is one scenario, however, in which even a continuous log backup cannot prevent the logs from filling in such a way that the system will permanently halt, and must be restored from an archive. </p>
<p><code>当所有逻辑日志文件被写满时，server 会暂时陷入停滞（完全无法响应），因此必须通过及时备份日志来始终保留一个或多个空闲日志文件。尽管因疏忽未备份日志导致系统冻结并非致命错误——日志可随时备份，系统也能恢复正常——但在特定场景下，即使持续进行日志备份，仍无法避免日志被完全填满，最终导致系统永久性停机，必须通过归档备份进行恢复。</code></p>
<blockquote>
<p>promptly 英[ˈprɒmptli] 美[ˈprɑːmptli]<br>adv.立即;迅速;马上;及时地;准时地;</p>
<p>neglect<br>英[nɪˈɡlekt] 美[nɪˈɡlekt]<br>v.忽视;忽略;疏忽;疏于照顾;疏漏;不予重视;未予看管;<br>n.忽略;忽视;未被重视;</p>
<p>halt<br>英[hɔːlt] 美[hɔːlt]<br>n.暂停，停止，终止，阻止;暂停前进，停住;&lt;古&gt;跛，瘸;小火车站（只有站台）;（口令）站住！立定！;<br>v.使停止前进，使停止，使终止;停止行进，停止，终止;踌躇，犹豫;蹒跚;（诗的格律等）有缺陷; &lt;古&gt;跛行;（论点等）不合逻辑;<br>adj.&lt;古&gt;跛的，瘸的;</p>
</blockquote>
<p>The typical long transaction is not that scenario. In fact, the <em>vast majority</em> of long transactions are successfully rolled back well before they cause a problem. The scenario involves that one long transaction in perhaps a thousand, on a system that is not properly configured to avoid them.</p>
<p><code>典型的长事务（Long Transaction）并非上述危险场景。事实上，绝大多数长事务都会在引发问题前被成功回滚。真正需要警惕的场景是：在未正确配置以规避此类问题的系统中，可能每千次事务中才会出现一次的极端长事务。</code></p>
<p><strong>What are long transactions?</strong></p>
<p>An everyday transaction becomes a <em>long transaction</em> when the percentage of log space used by the transaction reaches a configured high-water-mark value.</p>
<p><code>当某一日常事务占用的日志空间比例达到系统预设的高水位阈值（High-Water Mark）时，该事务即被视为长事务（Long Transaction）。</code></p>
<p><strong>Examples</strong></p>
<p>Here are two specific examples of long transactions. Assume a database server has 10 logs, as pictured in the slide above, and that the long transaction high water mark, LTXHWM, is set to 80.</p>
<p><code>以下是两个长事务（Long Transaction）的具体案例。假设某数据库服务器配置了10个日志文件（如上图幻灯片所示），且长事务高水位阈值（Long Transaction High-Water Mark，简称 LTXHWM）设置为 80（即日志空间使用率达到80%时触发长事务判定）。</code></p>
<p>The system’s solitary user begins a transaction near the end of log file 2, and starts inserting thousands of rows into a table. The records from this transaction fill the latter portion of log file 2, then log file 3, and continue through log file 8. Each log is backed up to tape immediately after it fills.</p>
<p><code>系统的唯一用户在一个事务开始时，日志文件2已接近写满。该用户随即启动了一个向表中插入数千行数据的事务。此事务所生成的日志记录依次填满了日志文件2的剩余空间、整个日志文件3，并持续写入直至占满日志文件8。每个日志文件在写满后立即被备份到磁带。</code></p>
<p>As the transaction crosses into log file 9, only three log files remain available to it: 9, 10 and 1. Log file 2 is not available. Even though the log records it contains are backed up, they cannot be overwritten; they would have to be read and undone if the transaction were ever to roll back. Informix Dynamic Server cannot free a portion of a log file, so until this transaction either commits or rolls back completely, the whole of log file 2 is out of the picture. Summing up, 30% of the total log space—three available log files out of ten—remains available to this transaction.</p>
<p><code>当该事务延伸至日志文件9时，仅剩3个日志文件可供其使用：日志文件9、10和1。日志文件2已不可用。尽管其中包含的日志记录已备份至磁带，但这些记录无法被覆盖；若事务需要回滚，则必须读取并撤销这些记录。IDS 无法释放日志文件的局部空间，因此在该事务完全提交或回滚之前，整个日志文件2均不可用。综上，该事务仅能使用总日志空间的30%（即10个日志文件中的3个可用文件）。</code></p>
<p>The transaction fills log file 9 and begins writing to log file 10. More than 80% of our total log space is now unavailable to the transaction. Having crossed its imaginary <em>high water</em> <em>mark</em>, the transaction is deemed long and forced to begin rolling back. Because undoing log records produces additional log records, the transaction continues writing to the log files. </p>
<p><code>该事务填满日志文件9后，开始向日志文件10写入数据。此时，事务可用的总日志空间已不足20%（超过80%的空间被占用且不可用）。当事务越过预设的虚拟高水位线（high water mark）后，系统判定其为长事务，并强制其开始回滚。由于撤销日志记录的操作本身会产生新的日志记录，该事务仍需持续向日志文件写入数据。</code></p>
<p>As we stated earlier, most of the time this scenario ends with a successful rollback, even in systems with a high water mark configured as poorly as ours. But if all the records necessary to roll back the transaction cannot be written to the log files before the available space is consumed, the logs are not only full, but none of them, no matter how many times they are backed up, can allow themselves to be overwritten. In this case, the database server is truly stuck. Prior to Version 9.3 of Informix Dynamic Server, you cannot simply add another log file to give the rollback some breathing space, because the actions involved with adding a logical log to an Informix Dynamic Server system are, themselves, logged.</p>
<p><code>如前所述，即使在像我们这样高水位线（HWM）配置不合理的情况下，大多数情况下此类场景仍能以成功回滚告终。然而，若在可用日志空间耗尽前，系统无法将回滚所需的所有日志记录写入文件，则日志不仅会完全写满，而且无论已备份多少次，所有日志文件均无法被覆盖。此时，数据库服务器将彻底陷入僵局。在IDS 9.3版本之前，无法通过简单添加新日志文件为回滚操作争取空间，因为向系统添加逻辑日志的操作本身也会被记录到日志中，形成死循环。</code></p>
<p><strong>Another example</strong></p>
<p>In a system with the same configuration, a transaction begins in the same spot near the end of log file 2. It writes a BEGIN record and one INSERT record. The user responsible for the transaction then heads off to lunch without committing the work. Meanwhile, other users in the system continue writing to the logs, performing many average-size operations.</p>
<p><code>在配置相同的系统中，一个事务在日志文件2的末尾附近启动。该事务写入一条</code>BEGIN<code>记录和一条</code>INSERT<code>记录后，负责此事务的用户便丢下工作去吃午饭，未提交事务。与此同时，系统中的其他用户持续向日志文件写入数据，执行大量普通规模的操作。</code></p>
<p>Despite the fact that this transaction involves only two log records, it is deemed long as soon as log file 10 becomes current, and the server is forced to roll back.</p>
<p><code>尽管该事务仅涉及两条日志记录（一条BEGIN和一条INSERT），但一旦日志文件10成为当前活动文件，系统便会立即将其判定为长事务，并强制执行回滚操作。</code></p>
<p>In other words, the amount of log space consumed by a particular transaction is not part of the equation. A transaction is deemed long the minute the amount of log space available to it crosses below a threshold defined by LTXHWM.</p>
<p><code>换句话说，特定事务消耗的日志空间量并不纳入判定标准。一旦该事务可用的日志空间低于由LTXHWM参数定义的阈值，系统会立即将其判定为长事务。</code></p>
<p><strong>Avoiding Fatal Long Transactions</strong></p>
<p>To avoid a fatal long transaction situation:</p>
<p>– Increase your logical log space</p>
<p>– Enable dynamic logging</p>
<p><strong>Notes:</strong></p>
<p>If you allocate plenty of logical log space and enable the dynamic logging feature of IDS, you should never have a fatal long transaction problem on your Informix Dynamic Server system. </p>
<p><code>如果为 IDS 分配充足的逻辑日志空间并启用 IDS 的动态日志功能，则系统绝不会出现致命的长事务问题。</code></p>
<p>You can also avoid a fatal long transaction situation by enabling the dynamic logging feature. This is covered on the next page.</p>
<p><code>您还可以通过启用动态日志功能来避免致命的长事务问题，相关内容将在下一页介绍。</code></p>
<p><strong>Dynamic Allocation of Logs</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507051857540.png" alt="image-20250705185733456"></p>
<p><strong>Notes:</strong></p>
<p>To avoid problems that could occur as a result of long transactions, you can take advantage of an IDS feature that allows logical logs to be added dynamically if a long transaction situation is encountered. You can configure your server to automatically insert one or more logical log files after the current log file when the next logical log in sequence contains a transaction that is still open. The database server determines the size and location (dbspace) of the logical log files added. </p>
<p><code>为避免因长事务引发的问题，您可利用 IDS 的一项功能：当检测到长事务时，系统会自动动态添加逻辑日志文件。您可配置 server 在以下条件满足时，在当前日志文件之后自动插入一个或多个新的逻辑日志文件：当后续待切换的逻辑日志中包含仍处于活动状态的事务时。新增逻辑日志文件的大小和存储位置（dbspace）将由 server 自动确定。</code></p>
<p>You can also configure the server to allow you to manually add logical log files. In this case, you can specify the size and location of the log files when you add them.</p>
<p><code>您还可以将服务器配置为允许手动添加逻辑日志文件。在此情况下，您可在添加时自行指定日志文件的大小和存储位置。</code></p>
<p>To enable dynamic allocation of logical logs, set the DYNAMIC_LOGS configuration parameter to one of these values:</p>
<p><code>要启用逻辑日志的动态分配功能，需将 DYNAMIC_LOGS 配置参数设置为以下任一值：</code></p>
<p><strong>2</strong> Automatically allocate a new logical log file and set off an alarm. This is the default value and is the recommended setting. High-water marks can be set higher because additional log files can be added if a long-transaction rollback causes logs to fill.</p>
<p><code>自动分配新的逻辑日志文件并触发告警。这是默认配置值，也是推荐设置。由于可在长事务回滚导致日志空间耗尽时自动添加额外日志文件，因此可将日志高水位标记（HWM）设置为更高值。</code></p>
<p><strong>1</strong> Pause to allow manual addition of new logical log files and set off an alarm. Use this option if you do not want the database server to choose the size and location of the new log files.</p>
<p><code>暂停操作以允许手动添加新的逻辑日志文件，并触发告警。当您不希望数据库服务器自动决定新日志文件的大小和存储位置时，请使用此选项。</code></p>
<p><strong>0</strong> Do not allocate a new logical log file, but issue a warning message.</p>
<p><code>不分配新的逻辑日志文件，仅发出警告消息。</code></p>
<p><strong>Other Logging and Recovery Features</strong></p>
<p>You may be able to improve checkpoint, logging, and recovery performance by setting the following configuration parameters:</p>
<p><code>通过设置以下配置参数，你或许能够提升检查点（checkpoint）、日志记录（logging）和恢复（recovery）的性能。</code></p>
<p>– Automatic checkpoints: AUTO_CKPTS</p>
<p>– Automatic LRU tuning: AUTO_LRU_TUNING</p>
<p>– Recovery time objective (RTO): RTO_SERVER_RESTART</p>
<p><strong>Notes:</strong></p>
<p>Informix Dynamic Server offers other features that may be helpful in optimizing checkpoint duration, checkpoint frequency, and fast recovery time.</p>
<p><code>IDS 提供了其他一些功能，这些功能可能有助于优化检查点持续时间、检查点频率以及快速恢复时间。</code></p>
<p> <strong>•</strong> Enable the automatic checkpoint feature by setting the AUTO_CKPTS parameter to 1. This enables the database server to monitor checkpoint activity and the state of the logical and physical logs. When the server determines that a checkpoint must occur, it automatically requests the checkpoint to avoid blocking of server activity. This feature is enabled by default.</p>
<p><code>将 AUTO_CKPTS 参数设置为 1，以启用自动检查点功能。这可使 server 监控检查点活动以及逻辑日志和物理日志的状态。当 server 判定必须执行检查点操作时，它会自动请求执行检查点，以避免阻塞服务器活动。此功能默认处于启用状态。</code></p>
<p> <strong>•</strong> Enable automatic LRU tuning by setting the AUTO_LRU_TUNING parameter to 1. When auto LRU tuning is enabled, LRU flushing becomes more “aggressive” when certain events occur in the server.</p>
<p><code>将 AUTO_LRU_TUNING 参数设置为 1，以启用自动 LRU 调优功能。启用自动 LRU 调优后，当服务器中发生特定事件时，LRU 刷新操作会变得更加“积极”。</code></p>
<p>The database server automatically tunes LRU flushing whenever a page replacement occurs. After a checkpoint, if a page-replacement foreground write occurred during the previous checkpoint interval, the database server decreases the LRU settings by 5 percent and continues to increase the LRU flushing at each subsequent checkpoint until page-replacement foreground writes stop or until the <strong>lru_max_dirty</strong> for a given buffer pool falls below 10 percent. For example, if a page-replacement foreground write occurs and the BUFFERPOOL parameter settings for <strong>lru_min_dirty</strong> and <strong>lru_max_dirty</strong> are 80 and 90 percent, the database server adjusts these to 76 and 85.5 percent. This causes an increase in LRU flushing.</p>
<p><code>每当发生页面置换时，server 会自动对 LRU 刷新操作进行调优。在检查点之后，如果上一个检查点间隔期间发生了因页面置换导致的前台写入操作，数据库服务器会将 LRU 设置降低 5%，并在后续每个检查点持续增强 LRU 刷新力度，直到页面置换导致的前台写入操作停止，或者直到给定缓冲池的 lru_max_dirty 值降至 10% 以下。例如，如果发生了因页面置换导致的前台写入操作，且 lru_min_dirty 和 lru_max_dirty 的 BUFFERPOOL 参数设置分别为 80% 和 90%，则数据库服务器会将这些值调整为 76% 和 85.5%。这会导致 LRU 刷新操作增加。</code></p>
<p> <strong>•</strong> The RTO_SERVER_RESTART configuration parameter can be used to set a target time for fast recovery. Based on the parameter setting, the server monitors the workload and adjusts the frequency of checkpoints in order to meet the defined recovery time objective (RTO) policy. Every time the server goes through fast recovery, it is able to better predict what frequency will best meet the policy. The CKPTINTVL parameter is ignored if RTO_SERVER_RESTART is enabled.</p>
<p><code>RTO_SERVER_RESTART 配置参数可用于设定快速恢复的目标时间。根据该参数的设置，server 会监控工作负载情况，并调整检查点的频率，以满足既定的恢复时间目标（RTO）策略要求。每次 server 执行快速恢复时，都能够更准确地预测何种频率最能契合该策略。若启用了 RTO_SERVER_RESTART 参数，则 CKPTINTVL 参数将被忽略。</code></p>
<p><strong>What Goes Into a Logical Log</strong></p>
<p> DDL statements (CREATE, DROP, ALTER)</p>
<p> Index item additions&#x2F;deletions</p>
<p> Home row additions&#x2F;deletions&#x2F;modifications</p>
<p> Blobpage map structures</p>
<p> Checkpoint records</p>
<p> Space allocations (new chunks, extents, logical logs, etc.)</p>
<p> CLRs (compensation log records)</p>
<p><strong>Notes:</strong></p>
<p>Log records are made as concise as possible. They are cryptic representations of actions within the RSAM layer that are not only complex, but proprietary. For these reasons, this course will not attempt to teach you the full meaning of log records at a binary level. It will, however, teach you enough to understand the output of Dynamic Server’s <strong>onlog</strong> utility. This is information that can be quite interesting and useful.</p>
<p><code>日志记录会尽可能做到简洁。它们是对 RSAM 层内操作的晦涩表示，这些操作不仅复杂，而且属于专有技术。鉴于这些原因，本课程不会试图在二进制层面教授日志记录的全部含义。不过，本课程将传授足够的知识，使你能够理解 Dynamic Server 的 onlog 工具所输出的信息。这些信息相当有趣且实用。</code></p>
<p><strong>What Does Not Go Into a Logical Log</strong></p>
<p> SQL statements (log records are at a much lower level)</p>
<p> Modifications to a temp table that is not logged</p>
<p> Blobspace blobs (these are backed up with logical logs, but are kept separate from the log files)</p>
<p> Entire pages (an after-image is just a row)</p>
<p> DML statements that apply to a no-logging database</p>
<p><strong>Notes:</strong></p>
<p>A single logical log record does not necessarily correspond to a single SQL statement, but represents a subtask that is performed as a part of the execution of a statement. Above is a list of other events that occur on a database server that are not recorded in the logical log.</p>
<p><code>单条逻辑日志记录并不一定对应单条 SQL 语句，而是代表作为语句执行部分所执行的一个子任务。上文列出了一些在 server 上发生但未记录在逻辑日志中的其他事件。</code></p>
<p><strong>Note</strong></p>
<p>Simple large objects (TEXT and BYTE data) can be stored within a dbspace partition or in a blobspace. Simple large objects stored in dbspace partitions are logged with their respective data row, while those stored in blobspaces are logged only when logical logs are backed up.</p>
<p><code>简单大对象（TEXT 和 BYTE 数据类型）可存储在 dbspace partition，也可存储在二进制大对象空间（blobspace）中。存储在 dbspace partition 中的简单大对象会与其对应的数据行一同记录到日志中，而存储在二进制大对象空间中的简单大对象仅在备份逻辑日志时才会被记录到日志中。</code></p>
<p>Smart LOs (BLOB and CLOB data) are stored in sbspaces, and logging mode for these objects is configurable. The metadata tables stored in sbspaces are always logged.</p>
<p><code>智能大对象（BLOB 和 CLOB 数据）存储在智能大对象空间（sbspaces）中，且这些对象的日志记录模式是可配置的。存储在智能大对象空间中的元数据表始终会被记录到日志中。</code></p>
<p><strong>Example of a Committed Transaction</strong></p>
<p> At the SQL level:</p>
<p>​		BEGIN WORK;</p>
<p>​		DELETE FROM customer </p>
<p>​		WHERE customer_num &#x3D; 110;</p>
<p>​		COMMIT WORK;</p>
<p> At the logical log level:</p>
<p>​		BEGIN WORK</p>
<p>​		HOME ROW DELETE</p>
<p>​		DELETE INDEX ITEM (first index key)</p>
<p>​		DELETE INDEX ITEM (second index key)</p>
<p>​		COMMIT WORK</p>
<p><strong>Notes:</strong></p>
<p>The following information is recorded in the logical logs for the simple committed transaction shown in the slide above:</p>
<p><code>对于上文幻灯片中所示的简单已提交事务，逻辑日志中会记录以下信息：</code></p>
<p><strong>•</strong> BEGIN (begin the transaction)</p>
<p>​		 <strong>-</strong> Record header (length, type, transaction ID, links to previous record in transaction)</p>
<p>​		 <strong>-</strong> Date and time</p>
<p>​		 <strong>-</strong> Process ID and user ID</p>
<p> <strong>•</strong> HDELETE (delete a home row)</p>
<p>​		 <strong>-</strong> Record header</p>
<p>​		 <strong>-</strong> Partition number</p>
<p>​		 <strong>-</strong> Rowid</p>
<p>​		 <strong>-</strong> Deleted data</p>
<p> <strong>•</strong> DELITEM #1 (delete index item)</p>
<p>​		 <strong>-</strong> Record header</p>
<p>​		 <strong>-</strong> Partition number</p>
<p>​		 <strong>-</strong> Rowid</p>
<p>​		 <strong>-</strong> Node number and key information</p>
<p> <strong>•</strong> DELITEM #2 (same as above)</p>
<p> <strong>•</strong> COMMIT (commit the transaction)</p>
<p>​		 <strong>-</strong> Record header</p>
<p>​		 <strong>-</strong> Date and time</p>
<p><strong>Example of an Aborted Transaction</strong></p>
<p> At the SQL level:</p>
<p>​		BEGIN WORK;</p>
<p>​		DELETE FROM customer WHERE customer_num &#x3D; 109;</p>
<p>​		ROLLBACK WORK;</p>
<p> At the logical log level:</p>
<p>​		BEGIN WORK</p>
<p>​		HOME ROW DELETE</p>
<p>​		DELETE INDEX ITEM (first index key)</p>
<p>​		DELETE INDEX ITEM (second index key)</p>
<p>​		COMPENSATION LOG RECORD (for DELITEM on second index)</p>
<p>​		COMPENSATION LOG RECORD (for DELITEM on first index)</p>
<p>​		COMPENSATION LOG RECORD (for HDELETE)</p>
<p>​		ROLLBACK COMPLETE</p>
<p><strong>Notes:</strong></p>
<p>The following information is recorded in the logical logs for the simple aborted transaction shown in the slide above:</p>
<p><code>对于上文幻灯片中所示的简单中止（回滚）事务，逻辑日志中会记录以下信息：</code></p>
<p><strong>•</strong> BEGIN (begin the transaction)</p>
<p>​		 <strong>-</strong> Record header (length, type, transaction ID, links to previous record in transaction; none in this case)</p>
<p>​		 <strong>-</strong> Date and time</p>
<p>​		 <strong>-</strong> Process ID and user ID</p>
<p> <strong>•</strong> HDELETE (delete a home row)</p>
<p>​		 <strong>-</strong> Record header</p>
<p>​		 <strong>-</strong> Partition number</p>
<p>​		 <strong>-</strong> Rowid</p>
<p>​		 <strong>-</strong> Deleted data</p>
<p> <strong>•</strong> DELITEM #1 (delete index item)</p>
<p>​		 <strong>-</strong> Record header</p>
<p>​		 <strong>-</strong> Partition number</p>
<p>​		 <strong>-</strong> Rowid</p>
<p>​		 <strong>-</strong> Node number </p>
<p>​		 <strong>-</strong> Key information</p>
<p> <strong>•</strong> DELITEM #2 (delete index item)</p>
<p>​		 <strong>-</strong> Same as above</p>
<p> <strong>•</strong> CLR (Compensation Log Record for DELITEM #2)</p>
<pre><code>     **-** Record header (length, type, transaction ID, links to second DELITEM record)
</code></pre>
<p> <strong>•</strong> CLR (Compensation Log Record for DELITEM #1)</p>
<p>​		 <strong>-</strong> Record header (length, type, transaction ID, links to first DELITEM record)</p>
<p> <strong>•</strong> CLR (Compensation Log Record for HDELETE)</p>
<pre><code>     **-** Record header (length, type, transaction ID, links to HDELETE record)
</code></pre>
<p> <strong>•</strong> ROLLBACK</p>
<p>​		 <strong>-</strong> Record header (length, type, transaction ID, links to BEGIN record)</p>
<p>​		 <strong>-</strong> Date and time</p>
<p><strong>The onlog Utility</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507082218490.png" alt="image-20250708221759383"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onlog</strong> utility is used to examine the contents of a logical log that was created using <strong>ontape</strong>. <strong>onlog</strong> can read a logical log file written to disk, or a log backup written to tape. As it reads the entries in the log, it prints out a report listing each entry.</p>
<p><code>onlog 工具用于检查通过 ontape 创建的逻辑日志的内容。onlog 能够读取写入磁盘的逻辑日志文件，或读取写入磁带的日志备份。在读取日志条目时，它会打印出一份报告，逐条列出所有条目。</code></p>
<p><strong>onlog</strong> output is most useful in debugging situations, for example, when you want to track a specific transaction to see what changes have been made to a specific tablespace, or to track what activity a particular user has performed.</p>
<p><code>onlog 的输出结果在调试场景中极为实用，例如，当您想要追踪某笔特定事务，查看其对特定表空间进行了哪些更改时，或者想要追踪某个特定用户执行了哪些操作时。</code></p>
<p>If you use the <strong>onbar</strong> command to back up logs, you can view log contents using <strong>onbar -P</strong>.</p>
<p><code>如果您使用 onbar 命令来备份日志，则可以使用 onbar -P 来查看日志内容。</code></p>
<p><strong>Warning</strong></p>
<p><em>Any time</em> <strong>onlog</strong> <em>is run against a logical log on disk, it acquires a latch to prevent anyone</em> <em>else from reading from or writing to the logical log file. This affects all logs and not just the</em> <em>current log.</em></p>
<p><code>无论何时，当 onlog 针对磁盘上的逻辑日志运行时，它都会获取一个锁（latch），以防止其他任何进程从该逻辑日志文件读取数据或向其写入数据。这一操作会影响所有日志，而不仅仅是当前日志。</code></p>
<p><strong>Log Record Read Filters</strong></p>
<p><strong>-b</strong> Directs <strong>onlog</strong> to display blobspace blobpages stored on the logical log backup tape</p>
<p><code>指示 onlog 显示存储在逻辑日志备份磁带上的二进制大对象空间（blobspace）的二进制大对象页（blobpages）</code></p>
<p><strong>-d device</strong> Names the path name of the tape device where the logical log backup tape is mounted</p>
<p><code>指定已挂载逻辑日志备份磁带的磁带设备的路径名称</code></p>
<p><strong>-n logid</strong> Directs <strong>onlog</strong> to read only the logical log records named in the specified log</p>
<p><code>指示 onlog 仅读取指定日志中列出的逻辑日志记录</code></p>
<p><strong>Notes:</strong></p>
<p>You direct <strong>onlog</strong> to read the following portions of the logical log as it searches for records to include in the output display:</p>
<p><code>你指示 onlog 在搜索要包含在输出显示中的记录时，读取逻辑日志的以下部分：</code></p>
<p> <strong>•</strong> The <strong>-b</strong> option displays blobspace blobpages stored on the logical log backup tape as part of blobspace logging.</p>
<p><code>-b 选项会将作为 blobspace 日志记录一部分而存储在逻辑日志备份磁带上的 blobspace blobpages 显示出来。</code></p>
<p> <strong>•</strong> When the <strong>-d</strong> option is used, it specifies the pathname of the tape device where the logical log backup tape is mounted. If you do not use the <strong>-d</strong> option, <strong>onlog</strong> reads the logical log files stored on disk. </p>
<p><code>当使用 -d 选项时，它用于指定已挂载逻辑日志备份磁带的磁带设备的路径名。如果未使用 -d 选项，onlog 将读取存储在磁盘上的逻辑日志文件。</code></p>
<p> <strong>•</strong> The <strong>-n</strong> option directs <strong>onlog</strong> to read the logical log records in the specified log only. The <em>logid</em> can apply to either a log that has been backed up to tape, or a log currently on disk. When a log from disk is read, read and write access to that log is denied to other users. It is recommended that you do not read the log on disk currently receiving transactions; it could hold up any user processes that need to write to that log.</p>
<p><code>-n 选项指示 onlog 仅读取指定日志中的逻辑日志记录。该 logid 既可适用于已备份到磁带的日志，也可适用于当前存储在磁盘上的日志。当读取磁盘上的日志时，其他用户将被禁止对该日志进行读写访问。建议不要读取当前正在接收事务处理的磁盘日志；因为这可能会阻塞所有需要向该日志写入数据的用户进程。</code></p>
<p><strong>Log Record Display Filters</strong></p>
<p><strong>-l</strong>    Directs <strong>onlog</strong> to display a long listing of the logical log record</p>
<p><code>指示 onlog 显示逻辑日志记录的详细长列表</code></p>
<p><strong>-t tblspace</strong>    Directs <strong>onlog</strong> to display only records associated with the specified tblspace</p>
<p><code>指示 onlog 仅显示与指定表空间（tblspace）相关联的记录</code></p>
<p><strong>-u userid</strong>    Directs <strong>onlog</strong> to display only records associated with activity initiated by the specified user</p>
<p><code>指示 onlog 仅显示与指定用户发起的活动相关联的记录</code></p>
<p><strong>-x xactionnum</strong>    Directs <strong>onlog</strong> to display only records associated with the specified transaction</p>
<p><code>指示 onlog 仅显示与指定事务相关联的记录</code></p>
<p><strong>-n logid</strong>    Directs <strong>onlog</strong> to not print the column headers</p>
<p><code>指示 onlog 不打印列标题</code></p>
<p><strong>Notes:</strong></p>
<p> <strong>•</strong> When the <strong>-l</strong> option is used, <strong>onlog</strong> prints any record images associated with the log record. The record is printed in ASCII and hexadecimal format.</p>
<p><code>当使用 -l 选项时，onlog 会打印出与日志记录相关联的任何记录映像（即记录内容）。该记录会以 ASCII 格式和十六进制格式同时打印出来。</code></p>
<p> <strong>•</strong> The <strong>-t</strong> option is used to specify the tblspace number in either hexadecimal or decimal format. </p>
<p><code>-t 选项用于以十六进制或十进制格式指定表空间（tblspace）编号。</code></p>
<p> <strong>•</strong> Use the <strong>-u</strong> option to specify the <em>userid</em> (UNIX login ID) of the user.</p>
<p><code>使用 -u 选项来指定用户的用户ID（即UNIX登录ID）。</code></p>
<p> <strong>•</strong> The <strong>-x</strong> option is used to specify the transaction number as a decimal value.</p>
<p><code>-x 选项用于以十进制数值的形式指定事务编号。</code></p>
<p> <strong>•</strong> Options can be combined to produce more specific output. For example, you could combine the <strong>-u</strong> and <strong>-t</strong> options to print all of the transaction records for changes made by the specified user to the specified tblspace.</p>
<p><code>选项可以组合使用，以生成更具体的输出结果。例如，你可以将 -u 和 -t 选项组合起来，打印出指定用户对指定表空间所做更改的所有事务记录。</code></p>
<p><strong>Sample onlog Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507091946669.png" alt="image-20250709194639541"></p>
<p><strong>Notes:</strong></p>
<p>Here is an example of <strong>onlog</strong> output.</p>
<p><strong>Log Record Header</strong></p>
<table>
<thead>
<tr>
<th><strong>Header</strong></th>
<th><strong>Contents</strong></th>
<th><strong>Format</strong></th>
</tr>
</thead>
<tbody><tr>
<td>addr</td>
<td>Log record address</td>
<td>hexadecimal</td>
</tr>
<tr>
<td>len</td>
<td>Record length in bytes</td>
<td>decimal</td>
</tr>
<tr>
<td>type</td>
<td>Record type name</td>
<td>char string</td>
</tr>
<tr>
<td>xid</td>
<td>Transaction number</td>
<td>decimal</td>
</tr>
<tr>
<td>id</td>
<td>logical log number</td>
<td>decimal</td>
</tr>
<tr>
<td>link</td>
<td>Address of previous record in transaction</td>
<td>hexadecimal</td>
</tr>
</tbody></table>
<p>This data is printed for every log record. Most records have additional data that is printed. See the appendix for a list of all possible log records, along with an explanation of the additional data printed for each one.</p>
<p><code>每条日志记录都会打印出这些数据。大多数记录还包含额外打印的数据。有关所有可能的日志记录列表，以及针对每条记录所打印额外数据的解释，请参见附录。</code></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onlog</strong> utility displays the header of each logical log record, as well as other information that depends on the type of record. If <strong>-l</strong> is specified, the entire logical log record is also displayed in both character string and hexadecimal format. The above chart outlines the content and format of the columns in the logical log header. These columns are displayed for every type of entry.</p>
<p><code>onlog 工具会显示每条逻辑日志记录的头部信息，以及其他取决于记录类型的信息。如果指定了 -l 选项，则整个逻辑日志记录还会以字符字符串和十六进制格式同时显示。上图概述了逻辑日志头部中各列的内容和格式。这些列会针对每种类型的条目进行显示。</code></p>
<p><strong>Information</strong></p>
<p>For a complete list of all logical log record types and each of the subentry fields for that type that are in the logical log record, refer to the <strong>Interpreting Logical Log Records</strong> chapter in the <em>IBM Informix Dynamic Server Administrator’s Reference</em>.</p>
<p><code>有关逻辑日志记录中所有逻辑日志记录类型及其各类子条目字段的完整列表，请参阅《IBM Informix Dynamic Server 管理员参考指南》中的“解读逻辑日志记录”一章。</code></p>
<p><strong>Checkpoint Record Subentries</strong></p>
<table>
<thead>
<tr>
<th><strong>Contents</strong></th>
<th><strong>Format</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Log begin</td>
<td>decimal</td>
</tr>
<tr>
<td>Transaction ID</td>
<td>decimal</td>
</tr>
<tr>
<td>Unique log number</td>
<td>decimal</td>
</tr>
<tr>
<td>Log position</td>
<td>hexadecimal</td>
</tr>
<tr>
<td>User ID</td>
<td>char string</td>
</tr>
</tbody></table>
<p>The above information is repeated for each transaction that was active at the time of the checkpoint.</p>
<p><code>上述信息会针对检查点发生时处于活动状态的每一笔事务重复显示。</code></p>
<p><strong>Notes:</strong></p>
<p>If there are active transactions at the time of a checkpoint, checkpoint records have subentries that describe each of the active transactions using the columns listed.</p>
<p><code>如果在执行检查点时存在活动事务，则检查点记录会包含子条目，这些子条目会使用所列出的各列信息来描述每一项活动事务。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/10"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/21/IX9111/10/"
    >IX9111 - Unit 10.Shared Memory Architecture</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/21/IX9111/10/" class="article-date">
  <time datetime="2025-06-21T09:08:59.000Z" itemprop="datePublished">2025-06-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Shared Memory</strong></p>
<p>Shared memory is memory that is allocated by one process, yet can be accessed by any process with permission to do so.</p>
<p><code>共享内存是指由一个进程分配的内存空间，但任何获得相应权限的进程均可对其进行访问。</code></p>
<p>– One process creates shared memory by allocating one or more segments. Like regular files, shared memory segments are created with permissions, an owner ID, group ID, even a name.</p>
<p><code>一个进程通过分配一个或多个段(segment)来创建共享内存。与常规文件类似，共享内存段在创建时会设置访问权限、owner ID、group ID，甚至还可以指定 name。</code></p>
<p>– Any process with permission to do so can attach to the memory segments and treat them as its own.</p>
<p><code>任何获得相应权限的进程都可以 attach 到这些内存段，并将其视为自己的内存来使用。</code></p>
<p>– The OS does not let this get out of hand. Shared memory is a kernel resource. There are kernel-defined limits to the size of shared memory as a whole, the size of individual segments, the total number of segments in the system, and the number to which one process can attach.</p>
<p><code>操作系统不会让这种情况失去控制。共享内存是一种内核资源。对于共享内存的整体大小、单个段的大小、系统中段的总数以及一个进程能够 attach 的段数，内核都设定了相应的限制。</code></p>
<p><strong>Notes:</strong></p>
<p>Shared memory is truly one of the finest features of UNIX and Linux. In the past, it has been implemented in very different ways on different platforms, but with the most recent versions of UNIX, most shared memory features have become standardized.</p>
<p><code>共享内存确实是 UNIX 和 Linux 系统中最为出色的特性之一。在过去，不同平台对共享内存的实现方式大相径庭，但在最新版本的 UNIX 系统中，大多数共享内存特性都已实现了标准化。</code></p>
<p>Shared memory is built from separate <em>segments</em>. A shared memory segment is treated much like a regular file. Each is <em>created</em> and owned by a particular user, and can be read or even modified by other users depending on its permissions. A shared memory segment even has a <em>name</em>, a unique identifier chosen by the creating process.</p>
<p><code>共享内存由独立的段（segments）构成。共享内存段的处理方式与常规文件颇为相似。每个共享内存段都由特定用户创建并拥有，其他用户能否对其进行读取甚至修改，取决于该段的权限设置。共享内存段甚至还拥有一个名称，即由创建进程所选定的唯一标识符。</code></p>
<p>In shared memory lingo, a process <em>attaches</em> to a shared memory segment in order to access it. From the perspective of the process itself, the shared memory segment is attached to the memory space of the process. In fact, it looks no different to the process than private memory. Unless the process is programmed to find out, it need never know that other processes are accessing the same memory addresses.</p>
<p><code>在共享内存的专业术语中，一个进程若要访问共享内存段，需要先关联（attaches）到该共享内存段。从进程自身的角度来看，共享内存段会被关联到该进程的内存空间中。实际上，对于进程而言，共享内存段与私有内存看起来并无二致。除非进程被编程以进行特定检测，否则它无需知晓其他进程也在访问相同的内存地址。</code></p>
<p>When a process makes a request of the operating system to attach it to a shared memory segment, it tells the operating system where in its address space to map the memory.</p>
<p><code>当进程向操作系统提出关联（attach）到共享内存段的请求时，它会告知操作系统将该共享内存映射到其地址空间的哪个位置。</code></p>
<p><strong>Shared Memory Portions</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506211752067.png" alt="image-20250621175241975"></p>
<p><strong>Notes:</strong></p>
<p>Informix Dynamic Server shared memory is divided into three portions, the resident portion, the virtual portion, and the message portion. The term <em>portion</em> used in this context is nothing more than a collection of shared memory segments seen as a logical set of memory by the database server. Each portion contains a unique set of information about the server:</p>
<p><code>IDS 的共享内存被划分为三个部分，分别是驻留部分（resident portion）、虚拟部分（virtual portion）和消息部分（message portion）。在此上下文中，“部分（portion）”一词仅指 database server 视为一个逻辑内存集合的一组共享内存段。每个部分都包含关于 server 的独特信息集：</code></p>
<p> <strong>•</strong> The <em>resident portion</em> contains structures that are fixed in size, such as the lock table, the LRU structures, and most significantly, the buffer pool. It is termed <em>resident</em>, because you can set these shared memory segments to stay resident in memory, even if they are not being used. The structure of this portion of shared memory has not changed significantly since early versions of Informix Dynamic Server. </p>
<p><code>驻留部分（resident portion）包含一些大小固定的数据结构，例如 lock table、LRU structures，以及最为关键的 buffer pool。之所以称其为驻留，是因为你可以将这些共享内存段设置为始终驻留在内存中，即使它们当前并未被使用。自 IDS 的早期版本以来，这部分共享内存的结构并未发生显著变化。</code></p>
<p> <strong>•</strong> The <em>virtual portion</em> contains any shared information in the database server that can grow or shrink, or be allocated or de-allocated. The number of segments in the virtual portion can grow as needed during the life of the database server. We’ll discuss how memory is managed in this portion later in the chapter.</p>
<p><code>虚拟部分（virtual portion）包含数据库服务器中所有大小可变、能够动态增长或缩减、或是可被分配与释放的共享信息。在 database server 的运行期间，虚拟部分中的段（segment）数量可以根据需要进行动态增长。我们将在本章稍后部分讨论该部分内存是如何进行管理的。</code></p>
<blockquote>
<p>shrink 收缩 英[ʃrɪŋk]美[ʃrɪŋk]</p>
</blockquote>
<p> <strong>•</strong> The <em>message portion</em> contains message buffers that are used for shared memory communication. The segments in this portion have read&#x2F;write permissions for all users.</p>
<p><code>消息部分（message portion）包含用于共享内存通信的消息缓冲区。该部分中的段对所有用户均设有读写权限。</code></p>
<p><strong>Viewing Shared Memory</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506211803018.png" alt="image-20250621180328956"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat</strong> utility reads the Dynamic Server shared memory structures and report the contents of shared memory the instant it is run. This means the contents of shared memory could be changing as they are being printed (as no memory locking is done by <strong>onstat</strong>). If any strange circumstances are found from one run of <strong>onstat</strong>, you should not assume anything is wrong until several runs report the same situation.</p>
<p><code>onstat 工具会读取 Dynamic Server 的共享内存结构，并在运行该工具的瞬间报告共享内存的内容。这意味着在打印共享内存内容的过程中，这些内容可能会发生变化（因为 onstat 工具不会对内存进行锁定）。如果在使用 onstat 工具进行某次运行时发现了异常情况，你不应立即假定存在问题，而应多次运行该工具，只有在多次运行都报告相同情况时，才应考虑可能存在问题。</code></p>
<p>The <strong>onstat</strong> utility prints out the contents of the structures maintained in shared memory. Since these tables keep track of all activity in the database server, this tool gives a good picture of what is going on in the system at the time it is run. Any user can run <strong>onstat</strong>, but for security purposes, some options may not be available to non-<em>informix</em> users.</p>
<p><code>onstat 工具会输出存储在共享内存中的数据结构内容。由于这些数据结构（通常以表格形式存在）会跟踪 database server 中的所有活动，因此该工具能够清晰地展示在工具运行时刻系统内部正在发生的状况。任何用户都可以运行 onstat 工具，但出于安全考虑，对于非 informix 用户，某些选项可能不可用。</code></p>
<p>Generally, <strong>onstat</strong> does no disk I&#x2F;O of the database server; it reads from shared memory alone (there are a few options that read from disk files). Because it places no locks on shared memory resources, it does not impact the performance of any IDS applications.</p>
<p><code>通常情况下，onstat 工具不会对 database server 执行任何磁盘 I/O 操作；它仅从共享内存中读取数据（不过，有少数选项会从磁盘文件中读取数据）。由于该工具不会对共享内存资源施加任何锁，因此它不会对任何 IDS 应用程序的性能产生影响。</code></p>
<p>Another way to access the same data in shared memory is by querying the tables and views in the <strong>sysmaster</strong> database. Most of the tables in this database are not really tables, but cue the database server to look at shared memory structures instead.</p>
<p><code>另一种访问共享内存中相同数据的方法是查询 sysmaster 数据库中的表和视图。该数据库中的大多数“表”实际上并非传统意义上的存储数据的表，而是作为提示，引导 database server 去查看共享内存中的结构。</code></p>
<p><strong>Process Space: How Shared Memory Fits In</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221319780.png" alt="image-20250622131936662"></p>
<p><strong>Notes:</strong></p>
<p>The arrangement of the various segments within a process is highly dependent on machine architecture, but for the sake of an example, one possible layout is pictured above.</p>
<p><code>进程内各段(segment)的具体排列方式高度依赖于机器架构，不过，为了便于说明，上图展示了一种可能的布局示例。</code></p>
<p>The important point of the illustration to note is that once a process has attached to a particular group of shared memory segments, the memory is made to look and feel just like its own private memory.</p>
<p><code>该示意图需要关注的关键点在于，一旦一个进程附加到一组特定的共享内存段上，这些内存从外观和操作感受上就会如同该进程自身的私有内存一般。</code></p>
<p><strong>Shared memory base address</strong></p>
<p>As is true for each privately allocated block of memory within the heap, the operating system must provide the process with the starting address of the segment group. When attaching to shared memory segments with the <strong>shmat</strong> function, the process requests a particular base address. On success, <strong>shmat</strong> returns the address of the memory, which normally matches the requested address, but might have been adjusted for alignment or other purposes.</p>
<p><code>就如同堆（heap）内每一块私有分配的内存一样，操作系统必须向进程提供该 segment group 的起始地址。当进程使用 shmat 函数附加到共享内存段时，它会请求一个特定的基地址。如果操作成功，shmat 会返回该内存的地址，该地址通常与请求的地址一致，但可能为了对齐或其他目的而进行了调整。</code></p>
<p>Note that depending on its proximity to other process segments, a shared memory base address can have an effect on the amount of private memory and&#x2F;or stack space available. This explains why, on some platforms, raising the SHMBASE configuration parameter can cure o<em>ut of heap space</em> problems for engine processes. On most platforms, however, due to their process space layout, an <strong>oninit</strong> process does not benefit in the same way if SHMBASE is increased.</p>
<p><code>需要注意的是，共享内存基地址与其他进程段之间的邻近关系可能会影响可用的私有内存和/或栈空间的大小。这就解释了为什么在某些平台上，提高 SHMBASE 配置参数可以解决引擎进程出现的“堆空间不足”问题。然而，在大多数平台上，由于进程空间布局的原因，即使增加 SHMBASE 的值，oninit 进程也无法以同样的方式受益。</code></p>
<blockquote>
<p>proximity<br>英[prɒkˈsɪməti] 美[prɑːkˈsɪməti]<br>n.接近;(时间或空间)邻近;靠近;</p>
</blockquote>
<p><strong>Shared Memory Kernel Parameters</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221333022.png" alt="image-20250622133325804"></p>
<p><strong>Notes:</strong></p>
<p>Kernel parameters that impose limits on shared memory usage vary from platform to platform, but the four parameters pictured above are fairly common.</p>
<p><code>对共享内存使用量施加限制的内核参数因平台而异，但上图所示的四个参数相当常见。</code></p>
<blockquote>
<p>impose<br>英[ɪmˈpəʊz] 美[ɪmˈpoʊz]<br>v.把…强加于;使接受，使意识到;推行，采用(规章制度);迫使;强制实行;勉强（某人做某事）;使(别人)接受自己的意见;</p>
</blockquote>
<p><strong>•</strong> SHMMAX (bytes) – This value is the maximum size of a segment.</p>
<p><code>这个值表示段（segment）的最大大小。</code></p>
<p>上图10页，每页1K(1024字节)，所以是10240 bytes</p>
<p><strong>•</strong> SHMSEG (segments) This is the maximum number of segments to which one process can attach.</p>
<p><code>这是一个进程可以附加的共享内存段的最大数量。</code></p>
<p><strong>•</strong> SHMMNI (segments) – This is the maximum number of shared memory segments that can be created system wide.</p>
<p><code>这是整个系统范围内可以创建的共享内存段的最大数量。</code></p>
<p><strong>•</strong> SHMALL (clicks) – This is the maximum number of system pages that can be allocated for shared memory system wide. Remember that system pages have nothing to do with Informix Dynamic Server pages. The size of a system page is usually one kilobyte.</p>
<p><code>这是整个系统范围内可为共享内存分配的系统页面的最大数量。请注意，系统页面与 IDS 页面毫无关系。系统页面的大小通常为一千字节（即 1KB）。</code></p>
<p><strong>Shared Memory Key</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221351519.png" alt="image-20250622135131435"></p>
<p><strong>Notes:</strong></p>
<p>In order for multiple database server instances to run on the same machine without interfering with one another, each instance allocates shared memory segments that have unique key value.</p>
<p><code>为了让多个 database server 实例能够在同一台机器上运行且互不干扰，每个实例都会分配具有唯一键值的共享内存段。</code></p>
<p>Informix Dynamic Server uses a base shared memory key value of 0x52564801. This 4-byte key can be broken down into two parts. The first two bytes reflect a unique value for each database server instance. The last two bytes are incremented for each shared memory segment allocated to an instance.</p>
<p><code>IDS 采用的共享内存基键值为 0x52564801。这个由 4 字节组成的键值可以拆分为两部分。前两个字节反映了每个数据库服务器实例的唯一标识值，而后两个字节则针对分配给每个实例的每个共享内存段进行递增。</code></p>
<p>To produce the shared memory key for a database server, <strong>oninit</strong> simply adds the value of the SERVERNUM configuration parameter to the value of the first two bytes (0x5256). For example, a system with a SERVERNUM value of 3 has a shared memory key of 0x52594801 (0x5256 + 0x3 &#x3D; 0x5259).</p>
<p><code>为了生成 database server 的共享内存键值，oninit 进程只需将 SERVERNUM 配置参数的值加到前两个字节（0x5256）的值上。例如，在一个 SERVERNUM 值为 3 的系统中，其共享内存键值将是 0x52594801（0x5256 + 0x3 = 0x5259）。</code></p>
<p>When <strong>oninit</strong> allocates additional segments, it increments the value of the last two bytes in the shared memory key until all required segments have been allocated. For example, 0x52594801, 0x52594802, 0x525984803, and so forth.</p>
<p><code>当 oninit 分配额外的共享内存段时，它会递增共享内存键值中最后两个字节的值，直到所有需要的共享内存段都分配完毕。例如，键值会依次变为 0x52594801、0x52594802、0x52594803，以此类推。</code></p>
<p><strong>Shared Memory Creation and Initialization</strong></p>
<p><strong>oninit</strong> performs the following steps during Initialization mode:</p>
<p><code>oninit 在初始化模式（Initialization mode）期间执行以下步骤：</code></p>
<p>– Based on configuration values, it calculates the total size of memory required</p>
<p><code>根据配置值，它计算出所需内存的总大小。</code></p>
<p>– It determines the shared memory key based on SERVERNUM</p>
<p><code>它根据 SERVERNUM 确定共享内存键值。</code></p>
<p>– It creates necessary shared memory segments using the <strong>shmget</strong> function</p>
<p><code>它使用 shmget 函数创建必要的共享内存段。</code></p>
<p>– It attaches to new segments using the <strong>shmat</strong> function</p>
<p><code>它使用 shmat 函数附加到新的共享内存段。</code></p>
<p>– It initializes all shared memory structures; if the <strong>-i</strong> option has been used, it also initializes the root chunk</p>
<p><code>它初始化所有共享内存结构；如果使用了 -i 选项，它还会初始化 root chunk。</code></p>
<p>– Shared memory initialization fails unless <strong>shmat</strong> has mapped all segments oninit address space in one contiguous block</p>
<p><code>除非 shmat 将所有共享内存段一次性连续映射到 oninit 进程的地址空间中，否则共享内存初始化将会失败。</code></p>
<p><strong>Notes:</strong></p>
<p>When Informix Dynamic Server shared memory is initialized, more is involved than simply creating the segments. Once the memory has been allocated, the database server attaches to the segments and writes to them, giving the memory a structure. Most of the time required for server initialization is taken by this structure initialization process.</p>
<p><code>在初始化 IDS 的共享内存时，不仅仅是创建共享内存段那么简单。一旦内存分配完成，数据库服务器就会附加到这些段上并向其中写入数据，从而为内存赋予特定的结构。服务器初始化过程中所需的大部分时间都花在了这个结构初始化的步骤上。</code></p>
<blockquote>
<p>involve 涉及 英[ɪnˈvɒlv] 美[ɪnˈvɑːlv]</p>
</blockquote>
<p><strong>Allocating Shared Memory</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506221420687.png" alt="image-20250622142059618"></p>
<p><strong>Notes:</strong></p>
<p>When allocating shared memory for each portion, the <strong>oninit</strong> process first attempts to create one segment that holds all the configured structures. If this attempt fails, <strong>oninit</strong>divides the requested size by two and retries until the allocation either succeeds, or the requested size is less than four kilobytes, in which case, <strong>oninit</strong> exits with an error.</p>
<p><code>在为各个部分分配共享内存时，oninit 进程首先会尝试创建一个能够容纳所有已配置结构的单个共享内存段。如果这一尝试失败，oninit 会将请求的内存大小减半，然后再次尝试分配，直到分配成功，或者请求的内存大小小于四千字节（4KB），在这种情况下，oninit 会以错误状态退出。</code></p>
<p>Once the first request succeeds, more segments might be required depending on how many times the requested size had to be reduced. The requested size is not reduced again, however, until what remains to be allocated is less than this size. In other words, each segment must be the same size as the first except for the last allocated segment.</p>
<p><code>一旦首次分配请求成功，后续可能还需要分配更多的共享内存段，这取决于请求的内存大小需要被减半多少次才能成功分配。然而，在剩余待分配的内存量小于首次成功分配的内存大小之前，不会再对请求的内存大小进行减半操作。换句话说，除了最后一个分配的段之外，每个后续分配的段的大小都必须与首次成功分配的段大小相同。</code></p>
<p>If any of those subsequent allocations fail, <strong>oninit</strong> exits with an error.If all goes well, <strong>oninit</strong> moves onto the next step in Initialization mode, which involves attaching to and writing to the newly-created segments.</p>
<p><code>如果这些后续的共享内存分配操作中有任何一个失败，oninit 进程将以错误状态退出。如果所有分配操作都顺利进行，oninit 将进入初始化模式的下一步，这包括附加到新创建的共享内存段并向其中写入数据。</code></p>
<p><strong>Attaching to Shared Memory</strong></p>
<ol>
<li><p>Calculate SHMKEY based on SERVERNUM.</p>
<p><code>根据 SERVERNUM 计算 SHMKEY。</code></p>
</li>
<li><p>Get the ID for a segment with this SHMKEY using <strong>shmget</strong></p>
<p><code>使用 shmget 获取具有此 SHMKEY 的共享内存段的标识符（ID）。</code></p>
</li>
<li><p>Attach the first segment at SHMBASE using <strong>shmat</strong></p>
<p><code>使用 shmat 将位于 SHMBASE 的首个共享内存段附加到进程的地址空间。</code></p>
</li>
<li><p>If <strong>shmat</strong> does not return SHMBASE, print error and exit</p>
<p><code>如果 shmat 没有返回 SHMBASE，则打印错误信息并退出程序。</code></p>
</li>
<li><p>Attach to additional segments.</p>
<p><code>附加（连接）到额外的共享内存段。</code></p>
</li>
</ol>
<p>​		– The size of each segment is stored in the first segment</p>
<p>​		<code>每个共享内存段的大小存储在首个共享内存段中。</code></p>
<p>​		– Based on these sizes, calculate all desired base addresses</p>
<p>​		<code>基于这些大小，计算所有期望的基地址。</code></p>
<p>​		– By simply incrementing SHMKEY for each segment, obtain each ID from <strong>shmget</strong>, and pass the ID to <strong>shmat</strong></p>
<p>​		<code>通过对每个共享内存段简单地递增 SHMKEY，从 shmget 获取每个段的标识符（ID），然后将该 ID 传递给 shmat。</code></p>
<p><strong>Notes:</strong></p>
<p>When a request is made to attach to shared memory, Informix Dynamic Server performs the following steps:</p>
<ol>
<li><p>The process calculates shared memory key based on SERVERNUM in configuration file.</p>
<p><code>该进程根据配置文件中的 SERVERNUM 计算 shared memory key。</code></p>
</li>
<li><p>Based on the shared memory key, the process uses <strong>shmget</strong> to find the shared memory ID for the first segment.</p>
<p><code>基于 shared memory key，该进程使用 shmget 来查找首个共享内存段的标识符（ID）。</code></p>
</li>
<li><p>Using <strong>shmat</strong>, the process tries to attach the first shared memory segment at SHMBASE.</p>
<p><code>该进程使用 shmat 尝试将首个共享内存段附加到 SHMBASE 地址处。</code></p>
</li>
<li><p>If the segment has been attached at a different address from SHMBASE, the process prints an error and exits.</p>
<p><code>如果该共享内存段已被附加到一个与 SHMBASE 不同的地址上，该进程会打印错误信息并退出。</code></p>
</li>
<li><p>Based on the size of the first attached segment that is stored in the segment itself, the process calculates the next shared memory base address, and continues attaching segments until it is finished.</p>
<p><code>基于首个已附加共享内存段中存储的该段大小信息，该进程会计算下一个共享内存段的基地址，并继续附加共享内存段，直到完成所有操作。</code></p>
</li>
</ol>
<p><strong>Multiple Segments</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251909621.png" alt="image-20250625190940501"></p>
<p><strong>Notes:</strong></p>
<p>When you first initialize a database server, it allocates segments for the resident portion, the virtual portion, and optionally, the message portion. Even though a single portion of shared memory can consist of multiple segments, it is logically viewed (addressed) by the process as if it was one contiguous block of memory. That is why all segments belonging to a shared memory portion must be contiguous when attached to the process. Segments from one <em>portion</em> of shared memory need not be contiguous to segments from other portions.</p>
<p><code>在首次初始化 database server 时，它会为驻留部分（resident portion）、虚拟部分（virtual portion）以及可选的消息部分（message portion）分配共享内存段。尽管共享内存的单个部分可能由多个段组成，但在逻辑上，进程会将其视为一个连续的内存块来进行访问（寻址）。这就是为什么属于同一共享内存部分的所有段在附加到进程时必须是连续的。然而，来自共享内存一个部分的段并不需要与来自其他部分的段保持连续。</code></p>
<p>The resident portion segments are the first segments attached to the <strong>oninit</strong> process. Next are the virtual portion segments, and finally the message segments.</p>
<p><code>驻留部分（resident portion）的段是首先附加到 oninit 进程的。接下来是虚拟部分（virtual portion）的段，最后是消息部分（message）的段。</code></p>
<p><strong>New virtual segments</strong></p>
<p>One exception to this rule is new virtual segments that are added to shared memory dynamically after the database server is initialized. They obviously can be attached in different locations within process memory. In the example above, virtual segment #3 was allocated dynamically.</p>
<p><code>这一规则的一个例外情况是，在 database server 初始化之后，动态添加到共享内存中的新 virtual segments。显然，这些新 segment 可以在进程内存的不同位置进行附加。在上面的例子中，virtual segment #3 就是动态分配的。</code></p>
<p><strong>Client processes</strong></p>
<p>Clients using a shared memory connection attach only to the message portion of shared memory. Instead of attaching at SHMBASE, they attach at a value that is platform-specific. You can modify the location where the client attaches by setting the INFORMIXSHMBASE environment variable.</p>
<p><code>使用共享内存连接的客户端仅附加到共享内存的消息部分。它们并不 attach 到 SHMBASE 地址，而是 attach 到一个与平台相关的特定值上。你可以通过设置 INFORMIXSHMBASE 环境变量来修改客户端 attach 的位置。</code></p>
<p><strong>Shared Memory Usage: onstat -g seg</strong></p>
<p>To monitor shared memory segments:</p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251918133.png" alt="image-20250625191843067"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g seg</strong> command shows how shared memory is used within the Informix Dynamic Server.</p>
<p><code>onstat -g seg 命令用于显示 IDS 中共享内存的使用情况。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251922364.png" alt="image-20250625192241293"></p>
<p>addr: 该段内存附加到 Dynamic Server 可执行文件起始位置的地址</p>
<p>ovhd: 系统开销所需的字节数</p>
<p>The values in the <strong>id</strong> and <strong>key</strong> columns are similar to those columns returned by the <strong>ipcs -m</strong> command. The difference is that <strong>ipcs</strong> returns key values in hexadecimal notation.</p>
<p><code>id 列和 key 列中的值与通过 ipcs -m 命令返回的相应列中的值类似。不同之处在于，ipcs 命令返回的键值（key values）是以十六进制表示法显示的。</code></p>
<p><strong>Shared Memory Addresses</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251926925.png" alt="image-20250625192646856"></p>
<p><strong>Notes:</strong></p>
<p>Each shared memory element is located at a fixed offset into shared memory. In addition to displaying the information held in the shared memory structures themselves, <strong>onstat -k</strong> displays the address of each structure, which is essentially SHMBASE plus the offset.</p>
<p><code>每个共享内存元素都位于共享内存中的一个固定偏移量位置。除了显示共享内存结构本身所包含的信息外，onstat -k 命令还会显示每个结构的地址，这个地址本质上就是 SHMBASE 加上该结构的偏移量。</code></p>
<p>For example, the shared memory address of the first active lock structure in the example above is 0xa031dd4. A process attached to this shared memory would find the structure at that address within its memory space. Since the memory is attached at SHMBASE, which happens to be 0xa00000 in this case, we can tell that the user structure is located at an offset of 0x31dd4 bytes into shared memory.</p>
<p><code>例如，在上述示例中，第一个 active lock 结构的共享内存地址是 0xa031dd4。一个附加到该共享内存的进程会在其内存空间中的该地址处找到该结构。由于内存是附加在 SHMBASE 处的，而在这个例子中 SHMBASE 恰好是 0xa00000，因此我们可以推断出，该用户结构位于共享内存中偏移量为 0x31dd4 字节的位置。</code></p>
<p>The address location can also be used to determine the portion of shared memory in which the structure resides. Compare the address of the structure with the addresses of the shared memory portions shown in the <strong>onstat -g ses</strong> output.</p>
<p><code>该地址位置还可用于确定该结构位于共享内存的哪一部分。可以将该结构的地址与 onstat -g ses 命令输出中显示的共享内存各部分的地址进行比较。</code></p>
<p>The offset value of a particular structure is important to someone analyzing a shared memory dump file, but it is irrelevant to an attached process. Informix Dynamic Server processes access shared memory structures only by using the full shared memory address of the structure.</p>
<p><code>对于分析共享内存转储文件的人来说，特定结构的偏移量值非常重要，但对于已附加的进程而言，该偏移量值并无实际意义。IDS 进程仅通过使用结构的完整共享内存地址来访问共享内存结构。</code></p>
<p><strong>The Resident Portion</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251934017.png" alt="image-20250625193421945"></p>
<p><strong>Notes:</strong></p>
<p>The resident portion of shared memory consists mainly of <em>structure arrays</em>. For convenience, we sometimes refer to these arrays as <em>tables</em>.</p>
<p><code>共享内存的驻留部分主要由 structure arrays 构成。为方便起见，我们有时将这些数组称为 tables。</code></p>
<p><strong>Note</strong></p>
<p>These shared memory <em>tables</em> should not to be confused with database tables.</p>
<p><code>这些共享内存中的表（tables）不应与数据库表（database tables）相混淆。</code></p>
<p><strong>Tracking Shared Memory Segments</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251936937.png" alt="image-20250625193655853"></p>
<p><strong>Notes:</strong></p>
<p>The first segment of resident shared memory contains two structures at fixed addresses that allow access to all other portions of shared memory.</p>
<p><code>驻留共享内存的第一个段包含两个位于固定地址的 structure，这两个 structure 允许访问共享内存的所有其他部分。</code></p>
<p>The first of these structures resides at SHMBASE. This structure describes the first shared memory segment, which means it points to itself.</p>
<p><code>这些 structure 中的第一个位于 SHMBASE（共享内存基地址）。该 structure 描述了第一个共享内存段，这意味着它指向自身。</code></p>
<p>The second structure appears immediately following the first. This structure is the shared memory master control block. Some of the more significant entries in this structure are:</p>
<p><code>第二个 structure 紧接着第一个结构之后出现。这个 structure 是共享内存主控制块（shared memory master control block）。该结构中一些较为重要的条目包括：</code></p>
<p> <strong>•</strong> The size of the first and last shared memory segments</p>
<p><code>第一个和最后一个共享内存段的大小</code></p>
<p> <strong>•</strong> The total size of each shared memory portion</p>
<p><code>每个共享内存部分的总大小</code></p>
<p> <strong>•</strong> A pointer to a linked list that describes each segment</p>
<p><code>指向描述每个段的链表的指针</code></p>
<p> <strong>•</strong> A pointer to the linked list of shared memory pools</p>
<p><code>指向共享内存池链表的指针</code></p>
<p> <strong>•</strong> A pointer to the shared memory header table</p>
<p><code>指向共享内存头表的指针</code></p>
<p><strong>The Header Table</strong></p>
<p>The header table is the starting point for accessing IDS resources. It contains:</p>
<p><code>header table 是访问 IDS 资源的起点。它包含：</code></p>
<p>– Pointers to resources (chunks, dbspaces, rstcb, transactions, dynamic lock tables, etc.)</p>
<p><code>指向资源（如数据块、数据库空间、恢复控制块、事务、动态锁表等）的指针</code></p>
<p>– Pointers to a linked list of sessions and environment variables</p>
<p><code>指向会话和环境变量链表的指针</code></p>
<p>– Parameters and other information, such as boot time, current time, LRU parameters, read-ahead values, archive flags, etc.</p>
<p><code>参数以及其他信息，例如启动时间、当前时间、LRU 参数、预读值、归档标志等。</code></p>
<p><strong>Notes:</strong></p>
<p>The header table is the main source for accessing database server resources. Almost all access starts from here. Some of the information that can be accessed from the header table is shown above.</p>
<p><code>头表是访问数据库服务器资源的主要来源。几乎所有的访问都从这里开始。上面展示了一些可以从头表中访问到的信息。</code></p>
<p><strong>Physical Layout of the Virtual Portion</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251946064.png" alt="image-20250625194611011"></p>
<p><strong>Notes:</strong></p>
<p>The virtual portion is divided into a series of 4K memory <em>blocks</em>. When a thread needs memory for its individual tasks, it takes one or more <em>contiguous</em> blocks.</p>
<p><code>虚拟部分被划分为一系列 4K 大小的 memory blocks。当一个线程需要为其独立任务分配内存时，它会获取一个或多个连续的 memory blocks。</code></p>
<p>A bitmap tracks the usage of each 4K block.</p>
<p><code>位图用于跟踪每个4K内存块的使用情况。</code></p>
<p><strong>Shared Memory Pools</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506251954485.png" alt="image-20250625195428400"></p>
<p><strong>Notes:</strong></p>
<p>A shared memory <em>pool</em> is a collection of memory blocks or <em>fragments</em>. A memory fragment can be any size, but the memory for that fragment must be contiguous. </p>
<p><code>共享内存池是一组内存块(blocks)或片段的集合。内存片段可以是任意大小，但该片段的内存必须是连续的。</code></p>
<p>Each memory fragment consists of:</p>
<p><code>每个内存片段由以下部分组成：</code></p>
<ul>
<li><p>Block header</p>
<p>The header tracks if the memory is used in the fragment, how much memory it contains, the type of data stored in it, and pointers to the next and previous fragment in the pool. Free blocks also contain a pointer to the next and previous free block.</p>
<p><code>该头部（或称为头信息）会跟踪内存片段中的内存是否被使用、该片段包含多少内存、其中存储的数据类型，以及指向内存池中下一个和上一个片段的指针。空闲块还包含指向下一个和上一个空闲块的指针。</code></p>
</li>
<li><p>Data</p>
<p>The data consists of any information appropriate to the pool. For example, a sort pool holds temporary data for a sort operation.</p>
<p><code>这些数据包含与该内存池相关的任何信息。例如，一个排序内存池会存储用于排序操作的临时数据。</code></p>
</li>
</ul>
<p>For new pools, the first fragment (or <em>overhead</em> fragment) contains the pool header. The pool header has a pointer to the first and last memory blocks in the pool. Also, the pool header contains a pointer to the free list in the first free block in the pool.</p>
<p><code>对于新建的内存池，首个内存片段（或称为开销片段）中包含内存池的头部信息。该内存池头部包含指向池中首个和最后一个内存块的指针。此外，内存池头部还包含一个指向池中首个空闲块内空闲链表的指针。</code></p>
<p><strong>Types of Shared Memory Pools</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506252001963.png" alt="image-20250625200157887"></p>
<p><strong>Notes:</strong></p>
<p>Shared memory pools can be classified into one of these three types:</p>
<p><code>共享内存池可以归类为以下三种类型之一：</code></p>
<p> <strong>•</strong> <em>System pools</em> are generally used by and are available to all threads in the database server. Usually these pools are initialized when the database server is started, and remain until the server is brought down.</p>
<p><code>系统内存池通常被 database server 中的所有线程使用，并且对这些线程都可用。通常，这些内存池在 database server 启动时进行初始化，并一直存在，直到服务器关闭。</code></p>
<p> <strong>•</strong> The <em>global pool</em> is used as a general area for threads that do not have a pool allocated for them. For example, network threads that need to allocate memory for internal uses use the global pool.</p>
<p><code>全局内存池被用作那些未分配专用内存池的线程的通用区域。例如，需要为内部用途分配内存的网络线程就会使用全局内存池。</code></p>
<p> <strong>•</strong> Each session has its own <em>session pool</em> that is used for any session-related information. The pool is created when the session is created, and the name of the pool is the same as the session number. The memory is returned to the virtual portion when the session terminates.</p>
<p><code>每个会话（session）都有其专属的会话内存池，用于存储与该会话相关的任何信息。该内存池在会话创建时被创建，且内存池的名称与会话编号相同。当会话结束时，内存会被归还给虚拟内存部分。</code></p>
<p><strong>Common shared memory pools</strong></p>
<p>The following list shows the most commonly used pools and their contents:</p>
<p><code>以下列表展示了最常用的内存池及其内容：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506252005732.png" alt="image-20250625200547618"></p>
<p><strong>Pool Usage: onstat -g mem</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261905744.png" alt="image-20250626190521615"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g mem</strong> command lists all allocated pools.</p>
<p><code>onstat -g mem 命令会列出所有已分配的内存池。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261906902.png" alt="image-20250626190639844"></p>
<p>To see information about the fragments allocated to a pool, you can execute the above command followed by the name of a pool. For example:</p>
<p><code>要查看分配给某个内存池的片段的相关信息，可以在执行上述命令后加上该内存池的名称。例如：</code></p>
<p>​		onstat -g mem global</p>
<p><strong>Shared Memory Caches</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261908933.png" alt="image-20250626190805870"></p>
<p><strong>Notes:</strong></p>
<p>To help in improving database server performance, Informix Dynamic Server allows users to share certain types of objects by providing special pools, or <em>caches</em>, in shared memory.</p>
<p><code>为助力提升 database server 性能，IDS 允许用户通过在共享内存中提供特殊的池（或称为缓存）来共享某些类型的对象。</code></p>
<p><strong>Data Dictionary Cache</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261909297.png" alt="image-20250626190957222"></p>
<p><strong>Notes:</strong></p>
<p>The <em>data dictionary cache</em> is used to store system catalog table information. On an OLTP system, it is common for multiple users to access tables within the same database. Because all queries on tables require a request to a system catalog table (to locate the partition page of a table, for example, the <strong>systables</strong> table must be queried to find the table’s partition number), I&#x2F;O can be reduced by allowing system catalog information to reside in shared memory. </p>
<p><code>data dictionary cache 用于存储 system catalog table 的信息。在 OLTP 系统中，多个用户通常会访问同一数据库中的表。由于对表的所有查询都需要访问 system catalog table（例如，为了定位表的 partition page，必须查询 systables 表以找到该表的 partition number），因此通过允许 system catalog 信息驻留在共享内存中，可以减少 I/O 操作。</code></p>
<p>Unlike the shared memory buffer, the data dictionary cache does not store entire pages from the data dictionary. System catalog rows are stored as <em>entries</em> in one of several <em>lists</em> held within the data dictionary cache. The data dictionary cache has a default of 31 lists with each list having up to 10 entries. You can configure the number of lists by setting the DD_HASHSIZE configuration parameter to any <em>prime</em> number. The maximum number of items in each list is configured by setting the DD_HASHMAX parameter.</p>
<p><code>与共享内存 buffer 不同，data dictionary cache 并不会存储 data dictionary 中的完整页面。System catalog rows 是以条目的形式存储在 data dictionary cache 所持有的若干列表之一中的。data dictionary cache 默认有31个列表，每个列表最多可包含10个条目。你可以通过将 DD_HASHSIZE 配置参数设置为任意质数来配置列表的数量。每个列表中的最大条目数则通过设置 DD_HASHMAX 参数来进行配置。</code></p>
<p>When system catalog rows are modified, the pages that contain these rows are handled through the shared memory buffer like any other pages.</p>
<p><code>当 system catalog rows 被修改时，包含这些行的页面会像其他任何页面一样，通过共享内存 buffer 进行处理。</code></p>
<p>The data dictionary cache, as well as other object caches, are not pre-populated when the server is initialized. Entries are made into the data dictionary cache as requests are received. When the cache is filled, entries are replaced based on a least-recently-used basis.</p>
<p><code>data dictionary cache 以及其他对象缓存，在 server 初始化时并不会预先填充。当接收到请求时，才会将相应的条目存入 data dictionary cache 中。当缓存被填满时，会根据最近最少使用（LRU，Least Recently Used）的原则来替换条目。</code></p>
<p><strong>Stored Procedure Cache</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261918133.png" alt="image-20250626191825059"></p>
<p><strong>Notes:</strong></p>
<p>The <em>stored procedure cache</em> is responsible for maintaining information about user-defined routines from the <strong>sysprocedures</strong> and <strong>sysprocbody</strong> catalogs. This allows users who are sharing routines to access them directly from shared memory without having to read the catalog pages from disk. </p>
<p><code>procedure cache 负责维护来自 sysprocedures 和 sysprocbody 系统目录表(catalogs)的用户自定义例程（存储过程或函数）的相关信息。这使得共享这些例程的用户能够直接从共享内存中访问它们，而无需从磁盘读取目录页。</code></p>
<p>When routines are created or deleted, the pages that contain the routine definitions are handled through the shared memory buffer pool. </p>
<p><code>当创建或删除例程（存储过程或函数）时，包含这些例程定义的页面会通过共享内存 buffer pool 进行处理。</code></p>
<p>Like the data dictionary cache, the stored procedure cache maintains lists of entries; each entry contains the definition for a different user-defined routine. By default, the stored procedure cache can have up to 31 lists that contain a maximum of 127 entries. You can override these defaults by setting, respectively, the PC_HASHSIZE and PC_POOLSIZE configuration parameters. The PC_HASHSIZE must be a prime number.</p>
<p><code>与 data dictionary cache 类似，procedure cache 也会维护条目列表；每个条目都包含一个不同用户自定义例程（存储过程或函数）的定义。默认情况下，存储过程缓存最多可以有31个列表，每个列表最多包含127个条目。你可以分别通过设置 PC_HASHSIZE 和 PC_POOLSIZE 配置参数来覆盖这些默认值。其中，PC_HASHSIZE 必须是一个质数。</code></p>
<p><strong>Global Statement Cache</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261922980.png" alt="image-20250626192249908"></p>
<p><strong>Notes:</strong></p>
<p>The <em>global (SQL) statement cache</em> is a place where frequently executed SQL statements could be stored and shared. </p>
<p><code>global (SQL) statement cache 是一个用于存储和共享频繁执行的SQL语句的地方。</code></p>
<p>Every time an SQL statement is received by the database server, it must be checked for syntax, encoded, and optimized. When enabled, the statement cache receives these preprocessed statements and saves them in a text and encoded form. Repeated statements can then be executed directly from the global statement cache without having to be preprocessed.</p>
<p><code>每当 database server 接收到一条 SQL 语句时，都必须对其进行语法检查、编码和优化。当启用语句缓存功能后，语句缓存会接收这些经过预处理的语句，并以文本和编码的形式将它们保存起来。这样，对于重复执行的语句，就可以直接从全局语句缓存中执行，而无需再次进行预处理。</code></p>
<p>The global statement cache is enabled by setting the STMT_CACHE configuration parameter to either 1 or 2. A value of 1 enables the statement cache, but statement caching is disabled by default for sessions. A value of 2 enables the statement cache and sets the session default to enabled. Statement caching is disabled if STMT_CACHE is set to 0. The total size of the statement cache is configured by setting the STMT_CACHE_SIZE configuration parameter. The default size is 512K.</p>
<p><code>通过将 STMT_CACHE 配置参数设置为 1 或 2，可以启用全局语句缓存(global statement cache)。当该参数值为 1 时， statement cache 功能被启用，但默认情况下，会话级别的 statement caching 是禁用的。当该参数值为 2 时， statement cache 功能被启用，并且会话级别的默认设置也变为启用。如果将 STMT_CACHE 设置为 0，则 statement cache 功能将被禁用。 statement cache 的总大小可通过设置 STMT_CACHE_SIZE 配置参数来进行配置，其默认大小为 512K。</code></p>
<p>You can override the STMT_CACHE configuration parameter either by setting the STMT_CACHE environment variable to either 0 (disabled) or 1 (enabled), or by executing the SQL command:</p>
<p><code>你可以通过以下两种方式之一来覆盖 STMT_CACHE 配置参数：将 STMT_CACHE 环境变量设置为 0（禁用）或 1（启用）；或通过执行以下 SQL 命令：</code></p>
<p>​		SET STATEMENT CACHE {ON|OFF};</p>
<p><strong>Private Memory Cache on CPU VPs</strong></p>
<p> Blocks of cache memory from 1 to 32 blocks in length</p>
<p><code>长度为 1 到 32 个块的缓存内存块</code></p>
<p> 4096 block size</p>
<p> Associated with each CPU virtual processor allocated</p>
<p><code>与每个已分配的 CPU 虚拟处理器相关联</code></p>
<p> Speeds up access to memory and performance of the CPU VPs</p>
<p><code>加快对内存的访问速度并提升 CPU 虚拟处理器（VPs）的性能</code></p>
<p><strong>Notes:</strong></p>
<p>The purpose of the private memory cache is to provide CPU VPs with their own blocks of shared memory that they can use to process their own memory allocation requests. The private cache provides a staging area for memory allocation requests that can be handled much faster than when competing with other CPU VP requests.</p>
<p><code>private memory cache 的目的是为每个 CPU 虚拟处理器（VPs）提供它们各自专用的共享内存块，这些内存块可用于处理它们自身的内存分配请求。私有缓存为内存分配请求提供了一个暂存区域，通过该区域处理内存分配请求的速度要比与其他 CPU 虚拟处理器的请求竞争时快得多。</code></p>
<p><strong>Note</strong></p>
<p>The private memory cache was introduced in version 11.10 of Informix Dynamic Server.</p>
<p><code>private memory cache 是在 IDS 的 11.10 版本中引入的。</code></p>
<p><strong>Private Memory Cache Implementation</strong></p>
<p> Static settings</p>
<p>– Configuration parameter: VP_MEMORY_CACHE_KB</p>
<p>– Default value is 0: feature is turned off </p>
<p>– 800 is the default minimum value (800 KB)</p>
<p>– Maximum value should not exceed 40% of SHMTOTAL</p>
<p> Dynamic tuning</p>
<p>– onmode –wm VP_MEMORY_CACHE_KB&#x3D; value</p>
<p>– onmode –wf VP_MEMORY_CACHE_KB&#x3D; value</p>
<p>– Setting to 0 disables the feature and empties caches</p>
<p><strong>Notes:</strong></p>
<p>To implement support for private memory caching, set the VP_MEMORY_CACHE_KB parameter to the amount of memory to allocate for all private memory caches. 800 kilobytes is the default size and the minimum setting for this parameter.</p>
<p><code>要实现对 private memory caching 的支持，需将 VP_MEMORY_CACHE_KB 参数设置为要为所有 private memory caches 分配的内存量。该参数的默认大小为 800 KB，同时也是其最小设置值。</code></p>
<p>You can also set the VP_MEMORY_CACHE_KB parameter by using the <strong>onmode -wm</strong> or <strong>-wf</strong> command.</p>
<p><code>你也可以通过使用 onmode -wm 或 -wf 命令来设置 VP_MEMORY_CACHE_KB 参数。</code></p>
<p><strong>Note</strong></p>
<p>The <strong>onmode -wm</strong> command changes the parameter for the current session only. Messages are written to the message log file and to the command line.</p>
<p>The <strong>onmode -wf</strong> command changes the value used by the database server and saves the value in the configuration file. A message is written only to the message log file.</p>
<p><strong>Monitoring the VP Memory Cache</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506261938086.png" alt="image-20250626193826002"></p>
<p><strong>Notes:</strong></p>
<p>To view private memory cache statistics, use the <strong>onstat -g vpcache</strong> command. </p>
<p><code>要查看 private memory cache 的统计信息，请使用 onstat -g vpcache 命令。</code></p>
<p>The CPU VP memory block cache statistics report provides the following information:</p>
<p><code>CPU 虚拟处理器（VP）内存块(block)缓存统计信息报告提供以下信息：</code></p>
<p> <strong>• size</strong> – memory block size, based on 4096-byte blocks</p>
<p><code>内存块大小（基于 4096 字节的块）</code></p>
<p> <strong>• cur blks</strong> – current number of blocks—this is a multiple of the <strong>size</strong> field</p>
<p><code>当前 block 数量——这是 size 字段的倍数</code>（我的理解：size是1、2、3……个4096字节大小的块，即: n * 4096，cur blks: m * (n * 4096)）</p>
<p> <strong>• alloc</strong> – number of times a requestor was given a block of this size</p>
<p><code>请求者被分配到此大小内存块的次数</code></p>
<p> <strong>• miss</strong> – number of times a block was requested but none were available</p>
<p><code>请求内存块但无可用块时的次数</code></p>
<p> <strong>• free</strong> – number of times a memory block was placed into the cache</p>
<p><code>内存块被放入缓存的次数</code></p>
<p> <strong>• drain</strong> – number of times an aged block was forced out to make room</p>
<p><code>为腾出空间而强制移除老旧内存块的次数</code></p>
<p> <strong>• release</strong> – number of times the size limit was reached and a block couldn’t be inserted The report repeats for each CPU VP allocated.</p>
<p><code>达到大小限制且无法插入内存块的次数。该报告会针对每个已分配的 CPU 虚拟处理器（VP）重复列出此信息。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/11"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/21/IX9111/11/"
    >IX9111 - Unit 11.Communications</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/21/IX9111/11/" class="article-date">
  <time datetime="2025-06-21T09:08:59.000Z" itemprop="datePublished">2025-06-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Types of Client&#x2F;Server Communications</strong></p>
<p>Choices for client&#x2F;server connections:</p>
<p>– Shared memory</p>
<p>– Stream pipe </p>
<p>– TCP&#x2F;IP using</p>
<p>​		• Sockets</p>
<p>​		• TLI</p>
<p>– IPX&#x2F;SPX</p>
<p>– DRDA</p>
<p><strong>Notes:</strong></p>
<p>Clients can connect to the database server by one of the methods shown above.If clients are on the same machine as the database server, they most likely connect through shared memory or stream pipes. Shared memory is usually faster, but can be a security risk, as the shared memory message segment has read and write permissions for all clients. </p>
<p><code>客户端可通过上述其中一种方法连接到 database server。如果客户端与 database server 位于同一台机器上，那么它们最有可能通过共享内存或流管道进行连接。共享内存的速度通常更快，但可能存在安全风险，因为共享内存消息段对所有客户端均设有读写权限。</code></p>
<p>Remote clients connect using TCP&#x2F;IP or IPX&#x2F;SPX.In this chapter, we will take an in depth look at the shared memory connection, since it is a custom implementation of Informix Dynamic Server. We will also look at TCP&#x2F;IP and streams, but these implementations use generic function calls.</p>
<p><code>远程客户端使用 TCP/IP 或 IPX/SPX 协议进行连接。在本章中，我们将深入探讨共享内存连接方式，因为它是 IDS 的一种自定义实现方式。我们也会探讨 TCP/IP 和流（streams）连接方式，但这些实现方式使用的是通用函数调用。</code></p>
<p><strong>Shared Memory Message Segment</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281450953.png" alt="image-20250628145034847"></p>
<p><strong>Notes:</strong></p>
<p>Clients connect to the database server through the message portion of Informix Dynamic Server shared memory. The size of the message portion is dependent upon the number of users that are allowed to connect to shared memory, set in the NETTYPE parameter. The shared memory message segment has the following components:</p>
<p><code>客户端通过 IDS 共享内存的消息部分与 server 建立连接。消息部分的大小取决于允许连接到共享内存的用户数量，这一数量由 NETTYPE 参数设定。共享内存消息段包含以下组件：</code></p>
<p> <strong>•</strong> Shared memory data – There is one shared memory data structure for each poll thread configured for the IDS server. It contains the bitmap for the message buffers and a bitmap for the message status areas. It also has tables for message buffer addresses and message buffer system status areas.</p>
<p><code>针对为 IDS 服务器配置的每个轮询线程（poll thread），都存在一个共享内存数据结构。该数据结构包含 message buffers 的位图（bitmap）以及 message status areas 的位图。此外，它还包含 message buffer 地址表和 message buffer 系统状态区域表。</code></p>
<p> <strong>•</strong> Status area – The status area contains one structure for each client connection. This structure includes the client ID, the connection state, the semaphore the client sleeps on, and the buffers the client is reading and writing to. In addition, it keeps a list of each buffer owned by the client ID and its status.</p>
<p><code>状态区域为每个客户端连接都包含一个结构体。这个结构体包含客户端ID、连接状态、client sleeps on 时所使用的信号量（semaphore），以及客户端正在读写缓冲区（buffers）的相关信息。此外，它还会维护一个列表，记录客户端ID所拥有的每个缓冲区及其状态。</code></p>
<p> <strong>•</strong> Message buffers – This contains the actual message buffers. The number of message buffers allocated when the system is initialized is: 8 * <em>users</em> * 1.2. The value of <em>users</em> is the number of connections as specified in the NETTYPE configuration parameter times the number of poll threads.</p>
<p><code>这部分包含实际的消息缓冲区。系统初始化时分配的消息缓冲区数量计算公式为：8 * users * 1.2。其中，users 的值等于 NETTYPE 配置参数中指定的连接数乘以轮询线程（poll threads）的数量。</code></p>
<p><strong>How Message Buffers are Used</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281459157.png" alt="image-20250628145953088"></p>
<p><strong>Notes:</strong></p>
<p>The status area for a client contains pointers to buffers it <em>owns</em> in the message buffer pool. Buffers allocated to a client ID can be classified as either client buffers or server buffers.</p>
<p><code>客户端的 status area 包含指向该客户端在消息缓冲区池（message buffer pool）中“拥有”的缓冲区的指针。分配给某个客户端ID的缓冲区可以分为客户端缓冲区（client buffers）或服务器缓冲区（server buffers）。</code></p>
<p> <strong>•</strong> Client buffers are buffers that the client writes to and the server reads from.</p>
<p><code>客户端缓冲区（client buffers）是指客户端向其中写入数据，而服务器从中读取数据的缓冲区。</code></p>
<p> <strong>•</strong> Server buffers are buffers that the server writes to and the client reads from.</p>
<p><code>服务器缓冲区（server buffers）是指服务器向其中写入数据，而客户端从中读取数据的缓冲区。</code></p>
<p>Initially, a client connection is allocated 4 client buffers and 4 server buffers. If the session needs more buffers, the server allocates up to 10 buffers for the client and 10 buffers for the server. If the session needs more than 10 buffers, it waits on a semaphore until one is available.</p>
<p><code>最初，为每个客户端连接分配 4 个客户端缓冲区和 4 个服务器缓冲区。如果会话需要更多缓冲区，server 会为客户端分配最多 10 个缓冲区，为 server 分配最多 10 个缓冲区。如果会话需要的缓冲区数量超过 10 个，那么它会在信号量（semaphore）上等待，直到有可用的缓冲区为止。</code></p>
<p>Periodically, the server assigns buffers with a status of NOTINUSE back to the free list for the buffer pool and removes it from the allocated list for client connection.</p>
<p><code>server 会定期将状态为 NOTINUSE（未使用）的缓冲区重新分配回缓冲区池的空闲列表中，并从客户端连接的已分配列表中移除这些缓冲区。</code></p>
<p><strong>Shared Memory: How Clients Connect</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281503998.png" alt="image-20250628150322929"></p>
<p><strong>Notes:</strong></p>
<p>The following steps detail how the client connects to the database server.</p>
<ol>
<li><p>The client reads the file &#x2F;INFORMIXTMP&#x2F;.inf.servicename to get the number of <strong>poll</strong> threads running. If there is more than one <strong>poll</strong> thread running, it selects one. Each poll thread can take a limited number of connections (specified by NETTYPE). If the <strong>poll</strong> thread has reached the connection limit, the client must try another <strong>poll</strong> thread.</p>
<p><code>客户端会读取文件 /INFORMIXTMP/.inf.servicename 来获取正在运行的 poll（轮询）线程数量。如果存在多个正在运行的 poll 线程，客户端会从中选择一个。每个 poll 线程能够处理的连接数量是有限的（由 NETTYPE 参数指定）。如果某个 poll 线程已达到其连接数量上限，客户端就必须尝试选择另一个 poll 线程。</code></p>
</li>
<li><p>The client attaches to the message portion of shared memory.</p>
<p><code>客户端会附加到共享内存的消息部分。</code></p>
</li>
<li><p>The client looks for a free buffer to send a message and fills it.</p>
<p><code>客户端会寻找一个空闲的缓冲区来发送消息，并将消息填入该缓冲区。</code></p>
</li>
<li><p>The <strong>netscb</strong> (network session control block) is initialized for the connection. </p>
<p><code>netscb（网络会话控制块）会针对该连接进行初始化。</code></p>
</li>
<li><p>The client puts the location of the message buffer on the ready queue.</p>
<p><code>客户端将消息缓冲区的位置放入就绪队列中。</code></p>
</li>
<li><p>The client awakens the <strong>poll</strong> thread using a semaphore operation (<strong>semop)</strong>).</p>
<p><code>客户端使用信号量操作（semop）唤醒 poll 线程。</code></p>
</li>
<li><p>The client sleeps on a semaphore to wait for a response.At this point, the poll thread wakes the listen thread, which creates the <strong>sqlexec</strong> thread for the session. From this point on, the <strong>listen</strong> thread is no longer needed for communication.</p>
<p><code>客户端在信号量上休眠以等待响应。此时，轮询（poll）线程会唤醒监听（listen）线程，该监听线程会为会话创建 sqlexec 线程。从这一刻起，通信过程中就不再需要监听（listen）线程了。</code></p>
</li>
</ol>
<p><strong>Shared Memory: Client Communication</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281511261.png" alt="image-20250628151111193"></p>
<p><strong>Notes:</strong></p>
<p>Once a client connects to the message portion of shared memory, it can now communicate with the server through the message queues.</p>
<p><code>一旦客户端连接到共享内存的消息部分，它现在就可以通过消息队列与服务器进行通信。</code></p>
<ol>
<li><p>The client application places a message (SQL STATEMENT, for example) in a free message buffer in the message portion of shared memory. When it uses a buffer, it marks the buffer as used so that it is not overwritten by another client or by the poll thread.</p>
<p><code>客户端应用程序将一条消息（例如，SQL 语句）放入共享内存消息部分的一个空闲消息缓冲区中。当它使用某个缓冲区时，会将该缓冲区标记为“已使用”，以防止其他客户端或轮询（poll）线程覆盖它。</code></p>
</li>
<li><p>The client puts its ID on the message ready queue.</p>
<p><code>客户端将其标识符（ID）放入消息就绪队列中。</code></p>
</li>
<li><p>The client sleeps on a semaphore.</p>
<p><code>客户端在信号量上休眠（或等待）。</code></p>
</li>
<li><p>The poll thread periodically wakes up and looks through the message ready queue, checking to see if a message has been sent.</p>
<p><code>轮询（poll）线程会定期唤醒，并遍历消息就绪队列，检查是否有消息被发送。</code></p>
<p><strong>Note</strong></p>
<p>The poll thread can potentially have a lot of work to do, handling incoming messages; it checks the message ready queue quite often. Although it is generally more efficient for the poll thread to run on the CPU VP (in-line polling), a very busy poll thread could cause the <strong>sqlexec</strong> threads to wait longer for a free CPU VP.</p>
<p><code>轮询（poll）线程可能面临大量工作，负责处理传入的消息；它会非常频繁地检查消息就绪队列。尽管通常让轮询线程在 CPU 虚拟处理器（VP）上运行（in-line polling，即内联轮询）效率更高，但一个非常繁忙的轮询线程可能会导致 sqlexec 线程需要等待更长时间才能获得一个空闲的 CPU 虚拟处理器（VP）。</code></p>
</li>
<li><p>If there is a message, it takes the message entry off the ready queue, and copies the message from the message buffer to the session pool. It releases the message buffer and, if the <strong>sqlexec</strong> thread is waiting on the <strong>sm_read</strong> condition, it puts the <strong>sqlexec</strong> thread on the ready queue to process the message.</p>
<p><code>如果存在消息，它会从就绪队列中取出该消息条目，并将消息从消息缓冲区复制到会话池中。之后，它会释放该消息缓冲区，并且如果 sqlexec 线程正在等待 sm_read 条件，它会将 sqlexec 线程放入就绪队列中以处理该消息。</code></p>
</li>
</ol>
<p><strong>Shared Memory: Server Communication</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506281520299.png" alt="image-20250628152035225"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>sqlexec</strong> thread leaves the <strong>poll</strong> thread out of operations that write to the client application.</p>
<p><code>sqlexec 线程在执行向客户端应用程序写入数据的操作时，不会让 poll 线程参与其中（即 poll 线程不参与这些写入操作）。</code></p>
<ol>
<li><p>The <strong>sqlexec</strong> thread places the message to be sent to the client (usually SQL results) in the message buffer. </p>
<p><code>sqlexec 线程将待发送给客户端的消息（通常是 SQL 查询结果）放入消息缓冲区中。</code></p>
</li>
<li><p>The <strong>sqlexec</strong> thread wakes the client process.</p>
<p><code>sqlexec 线程唤醒客户端进程。</code></p>
</li>
<li><p>The client reads the message buffer.</p>
<p><code>客户端读取消息缓冲区。</code></p>
</li>
</ol>
<p><strong>How Utilities Communicate</strong></p>
<p>Utilities such as <strong>oncheck</strong> and <strong>ontape</strong> usually do not communicate to the server like other clients. Instead they rely on lower level functions.</p>
<p><code>像 oncheck 和 ontape 这样的工具通常不会像其他客户端那样与服务器进行通信。相反，它们依赖于底层函数。</code></p>
<p>– <strong>onbar</strong> uses stream buffers to move pages</p>
<p><code>onbar 使用 stream buffers 来移动数据页（pages）。</code></p>
<p>– <strong>onmode</strong> attaches directly to the resident segment and modifies structures itself</p>
<p><code>onmode 工具直接连接到常驻内存段（resident segment），并自行修改其中的数据结构。</code></p>
<p>– <strong>oncheck</strong> use lower-level calls to pass messages to its associated server thread</p>
<p><code>oncheck 使用较低级别的调用（lower-level calls）来向其关联的服务器线程传递消息。</code></p>
<p><strong>Notes:</strong></p>
<p>Informix Dynamic Server utilities do not usually connect and send messages like other clients. Instead, they use a variety of techniques, bypassing the high-level communication protocol.</p>
<p><code>IDS 工具通常不会像其他客户端那样进行连接并发送消息。相反，它们采用多种技术，绕过了高级通信协议。</code></p>
<p><strong>Files Used for Shared Memory</strong></p>
<p> &#x2F;INFORMIXTMP&#x2F;.inf.servicename</p>
<p> $INFORMIXDIR&#x2F;etc&#x2F;.infos.dbservername</p>
<p><strong>Notes:</strong></p>
<p>The following files are used in shared memory communications.</p>
<p><code>以下文件用于共享内存通信。</code></p>
<p> <strong>• .inf.servicename</strong> – Informix Dynamic Server creates this file when it initiates a shared memory poll thread and removes the file when you take the database server offline. The name of this file is derived from the <strong>servicename</strong> field of the <strong>sqlhosts</strong> file. IDS keeps information about client&#x2F;server connections in this file. If this file is accidently deleted, you must restart the server. This file includes the following information:</p>
<p><code>IDS 在启动共享内存轮询线程时会创建此文件，并在将数据库服务器置于离线状态时删除该文件。此文件的名称源自 sqlhosts 文件中的 servicename 字段。IDS 会在此文件中保存有关客户端/服务器连接的信息。如果此文件被意外删除，您必须重启服务器。此文件包含以下信息：</code></p>
<p> <strong>-</strong> Shared memory segment ID</p>
<p><code>共享内存段ID</code></p>
<p> <strong>-</strong> Semaphore information for the two semaphores needed by the server.</p>
<p><code>服务器所需的两个信号量的相关信息。</code></p>
<p> <strong>-</strong> Number of poll threads</p>
<p><code>轮询线程的数量</code></p>
<p> <strong>-</strong> Offset and size of bitmap in shared memory segment</p>
<p><code>共享内存段中位图（bitmap）的偏移量和大小。</code></p>
<p> <strong>-</strong> Offset of status area array in message segment</p>
<p><code>消息段中 status area array 的偏移量。</code></p>
<p> <strong>• .infos.dbservername</strong> – IDS creates this file when you initialize shared memory and removes the file when you take the server offline. The name of this file is derived from the DBSERVERNAME configuration parameter. These files allow utilities such as <strong>oncheck</strong>, <strong>onstat</strong>, and <strong>ontape</strong> to attach to the database server.</p>
<p><code>IDS 在初始化共享内存时会创建此文件，而在将服务器置于离线状态时会删除该文件。此文件的名称源自 DBSERVERNAME  配置参数。这些文件允许诸如 oncheck、onstat 和 ontape 之类的实用工具连接到 server。</code></p>
<p><strong>Semaphores Used for Connections</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302342834.png" alt="image-20250630234242729"></p>
<p><strong>Notes:</strong></p>
<p>Informix Dynamic Server uses semaphores for coordinating communication between the client and server when a shared memory connection is used. The semaphore is set to signal if a message is waiting in the message buffer for a client.</p>
<p><code>IDS 在使用共享内存连接时，会利用信号量（semaphores）来协调客户端与服务器之间的通信。当消息缓冲区中有等待客户端接收的消息时，该信号量会被触发（或置位）。</code></p>
<p>The number of semaphores used by a database server depends on the number of connections allocated in the NETTYPE configuration parameter. If NETTYPE is not set, the database server defaults to 50 user connections. The server allocates a semaphore set containing one semaphore for each connection.</p>
<p><code>database server 所使用的信号量数量，取决于在 NETTYPE 配置参数中分配的连接数。若未设置 NETTYPE 参数，database server 将默认采用 50 个用户连接。server 会为每个连接分配一个包含单个信号量的信号量集合。</code></p>
<p>Two additional semaphores are controlled in the <strong>&#x2F;INFORMIXTMP&#x2F;.inf.servicename</strong> file. </p>
<p><code>/INFORMIXTMP/.inf.servicename 文件中还控制着另外两个信号量。</code></p>
<p>Because client processes don’t know anything about mutexes, these semaphores are used by clients to lock the message buffers while connecting. The <strong>sm_discon</strong> thread also uses a semaphore to lock the message buffers when cleaning up after a client that has exited.</p>
<p><code>由于客户端进程对互斥锁（mutexes）一无所知，因此在连接过程中，客户端会使用这些信号量来锁定消息缓冲区。sm_discon 线程在清理已退出的客户端遗留的资源时，也会使用信号量来锁定消息缓冲区。</code></p>
<p><strong>How semaphores are allocated</strong></p>
<p>Semaphores are allocated as a set by the operating system. IDS attempts to allocate the semaphores in groups of 100, however depending upon operating system kernel parameters, you might see fewer semaphores in each set.</p>
<p><code>信号量由操作系统以集合形式进行分配。IDS 会尝试以每组100个的方式分配信号量，但根据操作系统内核参数的不同，每组中实际分配的信号量数量可能会减少。</code></p>
<p><strong>Other semaphores used</strong></p>
<p>Semaphores are used by a database server for other purposes as well. Informix Dynamic Server allocates one semaphore for each VP, and one semaphore in its own set for each VP that is added dynamically. The VP semaphores allow an idle VP to sleep, and allow another VP to wake it up when necessary.</p>
<p><code>database server 还会将信号量用于其他用途。IDS 会为每个虚拟处理器（VP）分配一个信号量，并且会为每个动态添加的虚拟处理器（VP）在其独立的信号量集合中再分配一个信号量。这些针对虚拟处理器（VP）的信号量使得空闲的虚拟处理器能够进入休眠状态，并在必要时允许其他虚拟处理器将其唤醒。</code></p>
<p>In the slide example, two semaphore sets were initially allocated. The first set includes one semaphore for each VP. Since NETTYPE was not set, the second set contains semaphores for 50 connections, plus two semaphores for the <strong>&#x2F;INFORMIXTMP</strong> file. The additional semaphore sets that contain only one semaphore each were likely allocated for dynamically-added VPs.</p>
<p><code>在幻灯片示例中，最初分配了两个信号量集合。第一个集合为每个虚拟处理器（VP）包含一个信号量。由于未设置NETTYPE参数，第二个集合包含为50个连接分配的信号量，再加上为 /INFORMIXTMP 文件分配的两个信号量。那些仅包含一个信号量的额外信号量集合，很可能是为动态添加的虚拟处理器（VP）分配的。</code></p>
<p><strong>Monitoring Shared Memory Connections</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302355128.png" alt="image-20250630235542068"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g nsc</strong> command, without any arguments, summarizes each connection with one line. It lists the following:</p>
<p><code>onstat -g nsc 命令（不带任何参数）会以每行一条记录的形式对各个连接进行汇总。它会列出以下信息：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302357186.png" alt="image-20250630235733128"></p>
<p><strong>Monitoring Individual Connections</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506302358243.png" alt="image-20250630235811169"></p>
<p><strong>Notes:</strong></p>
<p>When you include a client ID, the <strong>onstat -g nsc</strong> command lists more detailed information about shared memory I&#x2F;O. In addition to the summary information (shown on the previous page), this command also shows the following:</p>
<p><code>当指定客户端ID作为参数时，onstat -g nsc 命令会列出有关共享内存I/O的更详细信息。除了（上一页所示的）汇总信息外，该命令还会显示以下内容：</code></p>
<table>
<thead>
<tr>
<th>title</th>
<th>desc</th>
</tr>
</thead>
<tbody><tr>
<td><strong>needbuf</strong></td>
<td>A flag that is set if the server is waiting for a buffer<br><code>若server正在等待缓冲区，则该标志会被置位</code></td>
</tr>
<tr>
<td><strong>segid</strong></td>
<td>The segment ID of the message shared memory segment. See <strong>ipcs</strong> to see the segment ID for each allocated segment.<br><code>消息共享内存段的段ID。可使用 ipcs 命令查看每个已分配内存段的段ID。</code></td>
</tr>
<tr>
<td><strong>semnum</strong></td>
<td>The semaphore number the client waits on<br><code>客户端等待的信号量编号</code></td>
</tr>
<tr>
<td><strong>semid</strong></td>
<td>The semaphore ID of the semaphore the client waits on. See <strong>ipcs</strong> for a list of semaphores and their IDs.<br><code>客户端所等待的信号量对应的信号量标识符ID。可使用 ipcs 命令查看信号量列表及其ID。</code></td>
</tr>
<tr>
<td><strong>be_curread</strong></td>
<td>The buffer ID of the message buffer the server is currently reading<br><code>server当前正在读取的消息缓冲区的 buffer ID</code></td>
</tr>
<tr>
<td><strong>be_curwrite</strong></td>
<td>The buffer ID of the message buffer the server is currently writing to<br><code>server当前正在写入的消息缓冲区的 buffer ID</code></td>
</tr>
<tr>
<td><strong>fe_curread</strong></td>
<td>The buffer ID of the message buffer the client is currently reading<br><code>client当前正在读取的消息缓冲区的 buffer ID</code></td>
</tr>
<tr>
<td><strong>fe_curwrite</strong></td>
<td>The buffer ID of the message buffer the client is currently writing to<br><code>client当前正在写入的消息缓冲区的 buffer ID</code></td>
</tr>
<tr>
<td><strong>next* columns</strong></td>
<td>The buffer IDs that the client and server will process next<br><code>客户端和服务器接下来将处理的 buffer IDs</code></td>
</tr>
<tr>
<td><strong>readyqueue</strong></td>
<td>The message ready queue. A value of <strong>-1</strong> indicates no entry.<br><code>消息就绪队列。值为 -1 表示没有条目（即队列为空）。</code></td>
</tr>
</tbody></table>
<p>The next set of information is a list of the buffers, their status (<strong>avail</strong>, <strong>inuse</strong>, or <strong>free</strong>), and their address.</p>
<p><code>接下来的一组信息是缓冲区列表，包括它们的状态可用（avail）、使用中（inuse）或 空闲（free）及其地址。</code></p>
<p><strong>onstat -g nss</strong></p>
<p>If you know the session ID, you can get the same information as <strong>onstat -g nsc</strong> by running <strong>onstat -g nss</strong> with the session ID.</p>
<p><code>如果你知道会话ID，那么通过将会话ID作为参数运行 onstat -g nss 命令，你可以获取到与 onstat -g nsc 命令相同的信息。</code></p>
<p><strong>Stream Pipes</strong></p>
<p> More secure connection than shared memory</p>
<p><code>比共享内存更安全的连接方式</code></p>
<p> Allows multiple connections from one client</p>
<p><code>允许一个客户端建立多个连接</code></p>
<p> Best for communication between two database servers on the same machine</p>
<p><code>最适合同一台机器上两 database server 之间的通信</code></p>
<p><strong>Notes:</strong></p>
<p>There are two flavors of implementation for the named stream pipe net driver—SVR4 &amp; BSD. The SVR4 stream pipe driver is implemented with a named stream pipe with the <strong>connld</strong> module pushed on the server end. The <strong>connld</strong> module provides unique connections between server and client processes. The BSD stream pipe driver is implemented using UNIX domain socket.</p>
<p><code>命名流管道网络驱动程序有两种实现形式——SVR4 和 BSD。SVR4 流管道驱动程序通过在 server 端加载 connld 模块来实现 named stream pipe。connld 模块为 server 和客户端进程之间提供唯一连接。BSD 流管道驱动程序则是使用 UNIX 域套接字（UNIX domain socket）来实现的。</code></p>
<p>Streams use a file names specified in the <strong>&#x2F;INFORMIXTMP</strong> directory. For both implementations, the name of the stream pipe is a UNIX filename, which is constructed from the service name field of the sqlhosts file, and placed in <strong>&#x2F;INFORMIXTMP</strong>.</p>
<p><code>流（Streams）使用在 /INFORMIXTMP 目录中指定的文件名。对于这两种实现方式，流管道的名称都是一个UNIX文件名，该文件名由 sqlhosts 文件中的服务名（service name）字段构造而成，并放置在 /INFORMIXTMP 目录中。</code></p>
<p>Although shared memory is a faster protocol, there are two areas where shared memory cannot be used and streams is a useful alternative:</p>
<p><code>尽管共享内存是一种速度更快的协议，但在以下两个领域中无法使用共享内存，而流（Streams）则是一种实用的替代方案：</code></p>
<p> <strong>•</strong> Because a stream pipes connection does not read or write to shared memory message buffers, it is considered to be more secure than a shared memory connection.</p>
<p><code>由于流管道连接不会读写共享内存消息缓冲区，因此它被认为比共享内存连接更加安全。</code></p>
<p> <strong>•</strong> A client cannot have multiple connections to the database via shared memory. Our shared memory protocol was never designed to multiplex, and we’ve never got around to changing that. However a front end can have multiple connections to the server via either streams, TLI or sockets.</p>
<p><code>客户端无法通过共享内存与数据库建立多个连接。我们的共享内存协议在设计之初就未考虑多路复用功能，而且我们至今也未着手对其进行修改。不过，前端应用程序可以通过流（Streams）、传输层接口（TLI）或套接字（Sockets）与服务器建立多个连接。</code></p>
<p><strong>•</strong> Two servers on the same machine cannot communicate with each other by shared memory. Streams is a good choice for this type of communication, rather than performing local loopbacks via sockets or TLI.</p>
<p><code>同一台机器上的两个 server 无法通过共享内存进行相互通信。对于此类通信需求，采用流（Streams）是更好的选择，而非通过套接字（Sockets）或传输层接口（TLI）进行本地回环通信。</code></p>
<p><strong>Network User Statistics: onstat -g ntu</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507011947948.png" alt="image-20250701194725824"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g ntu</strong> command displays network information about each user thread.</p>
<p><code>onstat -g ntu 命令显示每个用户线程的网络信息。</code></p>
<p><strong>#netscb</strong></p>
<p>Total current number of network session control blocks &#x2F; number of all network session control blocks ever allocated</p>
<p><code>当前已分配的网络会话控制块总数 / 曾分配过的所有网络会话控制块数量</code></p>
<p><strong>connects</strong></p>
<p>Total connects performed</p>
<p><code>已执行的总连接数</code></p>
<p><strong>read</strong></p>
<p>Total reads performed</p>
<p><code>已执行的总读取次数</code></p>
<p><strong>write</strong></p>
<p>Total writes performed</p>
<p><code>已执行的总写入次数</code></p>
<p><strong>q-free</strong></p>
<p>Number of free buffers currently on the queue &#x2F; greatest number of free buffers simultaneously on the queue since server initialization</p>
<p><code>当前队列中空闲缓冲区的数量 / 自服务器初始化以来队列中同时存在的空闲缓冲区的最大数量</code></p>
<blockquote>
<p>simultaneously 同时 英[ˌsɪməlˈteɪniəsli] 美[ˌsaɪməlˈteɪniəsli]</p>
</blockquote>
<p><strong>q-limits</strong></p>
<p>Maximum number of free buffers that can be on the queue &#x2F; maximum number of buffers that can be on the queue</p>
<p><code>队列中可存在的空闲缓冲区的最大数量 / 队列中可容纳的缓冲区的最大数量</code></p>
<p><strong>q-exceed</strong></p>
<p>Number of times free-buffer limit has been exceeded &#x2F; number of times buffer limit has been exceeded</p>
<p><code>空闲缓冲区限制被突破的次数 / 缓冲区限制被突破的次数</code></p>
<p><strong>alloc&#x2F;max</strong></p>
<p>Number of buffers currently allocated &#x2F; greatest number of buffers allocated simultaneously since server initialization</p>
<p><code>当前已分配的缓冲区数量 / 自服务器初始化以来同时分配的缓冲区最大数量</code></p>
<p><strong>netscb</strong></p>
<p>Address of the network session control block</p>
<p><code>网络会话控制块的地址</code></p>
<p><strong>type</strong> </p>
<p>Identifier of the protocol this thread uses</p>
<p><code>该线程所使用的协议的标识符</code></p>
<p><strong>thread name</strong> </p>
<p>Name of this thread</p>
<p><code>线程名</code></p>
<p><strong>sid</strong> </p>
<p>Session ID associated with this thread</p>
<p><code>与该线程关联的会话ID</code></p>
<p><strong>fd</strong> </p>
<p>File descriptor for the thread </p>
<p><code>该线程的文件描述符</code></p>
<p><strong>poll</strong> </p>
<p>Mail box number of the poll thread that services this network connection</p>
<p><code>服务于该网络连接的轮询线程的 Mail box number</code></p>
<p>Mail box number?</p>
<p><strong>reads</strong> </p>
<p>Number of reads for this thread</p>
<p><code>该线程的读取次数</code></p>
<p><strong>writes</strong> </p>
<p>Number of writes for this thread</p>
<p><code>该线程的写入次数</code></p>
<p><strong>q-nrm</strong> </p>
<p>Number of buffers &#x2F; maximum number of buffers on the normal data queue</p>
<p><code>普通数据队列上的缓冲区数量 / 普通数据队列上的缓冲区最大数量</code></p>
<p><strong>q-pvt</strong> </p>
<p>Number of private buffers&#x2F;maximum number of private buffers on the private data queue</p>
<p><code>私有数据队列上的私有缓冲区数量 / 私有数据队列上的私有缓冲区最大数量</code></p>
<p><strong>q-exp</strong> </p>
<p>Number of expedite buffers &#x2F; maximum number of buffers ever on the expedited data queue</p>
<p><code>加速数据队列上的加速缓冲区数量 / 加速数据队列上曾出现过的缓冲区最大数量</code></p>
<p><strong>Network User Times: onstat -g ntt</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507011959250.png" alt="image-20250701195901170"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g ntt</strong> command prints thread access times.</p>
<p><code>onstat -g ntt 命令会打印线程访问时间。</code></p>
<p><strong>netscb</strong> </p>
<p>Address of the network session control block</p>
<p><code>网络会话控制块的地址</code></p>
<p><strong>thread name</strong> </p>
<p>Name of the thread</p>
<p><code>线程名</code></p>
<p><strong>sid</strong> </p>
<p>Session ID of the thread</p>
<p><code>该线程的会话ID</code></p>
<p>The next three entries show only time if the event occurred today and a time and date if the event occurred prior to today. </p>
<p><code>接下来的三项条目仅显示当天发生事件的时间；若事件发生在当天之前，则同时显示时间和日期。</code></p>
<p><strong>open</strong> </p>
<p>Time of the last open event</p>
<p><code>最后一次开启事件的时间</code></p>
<p><strong>read</strong> </p>
<p>Time of the last close event </p>
<p><code>最后一次关闭事件的时间</code></p>
<p><strong>write</strong> </p>
<p>Time of the last write event</p>
<p><code>最后一次写入事件的时间</code></p>
<p><strong>address</strong> </p>
<p>Address of the server, only valid on listener thread</p>
<p><code>server 地址（仅在监听线程上有效）</code></p>
<p><strong>Network Statistics by Service: onstat -g ntd</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202507012002983.png" alt="image-20250701200256892"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g ntd</strong> command prints network dispatch information.</p>
<p><code>onstat -g ntd 命令会打印网络分发信息。</code></p>
<p><strong>Client Type</strong> </p>
<p>Type of client service</p>
<p><code>客户端服务类型</code></p>
<p><strong>Calls</strong> </p>
<p><strong>yes</strong>: clients of this type are being allowed connections</p>
<p><code>此类客户端被允许建立连接</code></p>
<p><strong>no</strong>: connections of this type are not currently allowed</p>
<p><code>目前不允许此类连接</code></p>
<p><strong>Accepted</strong> </p>
<p>Number of times this client type has had a thread spawned</p>
<p><code>此类客户端类型已触发线程生成的次数</code></p>
<p><strong>Rejected</strong> </p>
<p>Number of times a connection to this client type has been rejected</p>
<p><code>针对此类客户端类型的连接被拒绝的次数</code></p>
<p><strong>Read</strong> </p>
<p>Total number of messages sent from this client type</p>
<p><code>此类客户端类型发送的消息总数</code></p>
<p><strong>Write</strong> </p>
<p>Total number of message sent to this client type</p>
<p><code>发送给此类客户端类型的消息总数</code></p>
<p>All statistics shown in this and other network reports are based on activity since the database server was last initialized.</p>
<p><code>本报告及其他网络报告中显示的所有统计数据均基于自数据库服务器上次初始化以来的活动情况。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/9"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/10/IX9111/9/"
    >IX9111 - Unit 9. Virtual Processors and Threads</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/10/IX9111/9/" class="article-date">
  <time datetime="2025-06-10T13:34:55.000Z" itemprop="datePublished">2025-06-10</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Processors (CPUs) and Processes</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102136917.png" alt="image-20250610213615829"></p>
<p><strong>Notes:</strong></p>
<p>On any computer, all processing of data is handled by one or more <em>processors</em>, sometimes called <em>CPUs</em> (<em>central processing units</em>). Each processor is responsible for handling the requests of many processes that are concurrently active on the system, but can only work on one process at a time. Therefore, a processor must determine when to work on one process, and when that process must yield to another. When a process yields, it copies information about what it was working on, called the process <em>context</em>, into memory. The processor then accepts the context from another process and continues work from where that process was previously interrupted. Moving the context of one process out of the CPU and moving another in is called a <em>context switch</em>.</p>
<p><code>在任何计算机上，所有数据的处理都由一个或多个处理器（有时也称为 CPU，即中央处理器）来完成。每个处理器负责处理系统中同时运行的多个进程的请求，但一次只能处理一个进程。因此，处理器必须决定何时处理某个进程，以及何时该进程需要让位给另一个进程。当一个进程让位时，它会将正在处理的工作相关信息（称为进程的上下文）复制到内存中。随后，处理器会接受另一个进程的上下文，并从该进程之前被中断的地方继续工作。将一个进程的上下文移出 CPU，并将另一个进程的上下文移入 CPU 的过程称为上下文切换。</code></p>
<p><strong>Virtual Processors and Threads</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506112343142.png" alt="image-20250611234339015"></p>
<p><strong>Notes:</strong></p>
<p>A <em>virtual processor (VP)</em> is a process that is designed to do work similar to the processor on a computer. While a processor is responsible for managing processes on the system, VPs are responsible for processing <em>threads</em>. A thread is the portion of a process that is responsible for a particular set of tasks. Like processes, threads compete for the attention of VPs, which can only process one thread at a time. Threads also have contexts associated with them, and <em>thread context switches</em> are performed to allow the virtual processors to interrupt work on one thread so that it can continue work with another. The scheduling of threads is managed by the threads themselves. A running thread is responsible for determining when to yield so that another thread has a chance to run on the VP.</p>
<p><code>虚拟处理器（Virtual Processor，简称 VP）是一种旨在执行与计算机处理器类似工作的进程。处理器负责管理系统中的进程，而VP则负责处理线程。线程是进程中负责特定任务集的部分。与进程类似，线程会竞争VP的关注，因为VP一次只能处理一个线程。线程也有与之关联的上下文，会执行线程上下文切换，以便VP能够中断对一个线程的处理，转而继续处理另一个线程。线程的调度由线程自身管理。正在运行的线程负责决定何时让出（yield），以便其他线程有机会在 VP 上运行。</code></p>
<p>Informix Dynamic Server uses several virtual processors to manage a database server. Each virtual processor is called <strong>oninit</strong>.</p>
<p><code>IDS 使用多个 VP 来管理 server。每个 VP 都称为 oninit。</code></p>
<p><strong>Thread Context Switching</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506122139040.png" alt="image-20250612213923903"></p>
<p><strong>Notes:</strong></p>
<p>Lets look deeper at the Informix Dynamic Server context-switching process. At a specific point of execution, the thread yields control of the virtual processor to another thread. The context switching algorithm consists of the following steps:</p>
<p><code>让我们更深入地探讨一下 IDS 中的上下文切换（context-switching）过程。在执行的某个特定时刻，线程会将其对虚拟处理器（virtual processor）的控制权让渡给另一个线程。上下文切换算法包含以下步骤：</code></p>
<ol>
<li><p>Once the thread decides to yield, it places its <em>state</em> information in a series of control block structures.</p>
<p><code>一旦线程决定让出（控制权），它会将其状态信息存入一系列的控制块结构中。</code></p>
</li>
<li><p>Next, it must put a pointer to itself on one of the wait queues, sleep queue or ready queue, depending on why the thread is yielding.</p>
<p><code>接下来，该线程必须根据让出（控制权）的原因，将其自身的指针放入等待队列（wait queue）、休眠队列（sleep queue）或就绪队列（ready queue）中的一个。</code></p>
</li>
<li><p>The running thread notifies the next thread waiting in the ready queue. (Actually there are multiple ready queues, one for each priority.) Once the thread ID of the waiting thread is determined, the running thread can get the program counter of the waiting thread.</p>
<p><code>正在运行的线程会通知就绪队列中下一个等待的线程。（实际上，存在多个就绪队列，每个优先级对应一个。）一旦确定了等待线程的线程ID，正在运行的线程就可以获取该等待线程的程序计数器（的值）。</code></p>
</li>
<li><p>Finally, the thread performs the actual context switch in the process. Since thread switching must occur quickly and efficiently, the thread switching algorithms are written in the assembly language, ported specifically to the platform the Informix Dynamic Server system runs on. The code in the thread switching functions is straightforward. It must simply:</p>
<p><code>最后，该线程会在进程中执行实际的上下文切换。由于线程切换必须快速且高效地进行，因此线程切换算法是用汇编语言编写的，并专门针对 IDS 系统运行的平台进行了移植。线程切换函数中的代码简洁明了，它只需：</code></p>
<p> <strong>-</strong> Flush the context of the currently running thread to its stack (<em>4a</em>)</p>
<p><code>将当前正在运行的线程的上下文刷到其栈中(4a)</code></p>
<p> <strong>-</strong> Load the context for the next thread to run from its stack (<em>4b</em>)</p>
<p><code>从下一个要运行的线程的栈中加载其上下文(4b)</code></p>
</li>
</ol>
<p><strong>When Threads Yield</strong></p>
<p>Some events that can cause the thread to yield are:</p>
<p><code>可能导致线程让出（控制权）的一些事件包括：</code></p>
<p>– Waiting for a disk read or write operation</p>
<p><code>等待磁盘读写操作完成</code></p>
<p>– Waiting for an SQL request from the client</p>
<p><code>等待来自客户端的 SQL 请求</code></p>
<p>– Waiting for a lock or other resource</p>
<p><code>等待锁或其他资源</code></p>
<p>– There is no more work to do</p>
<p><code>没有更多工作要做</code></p>
<p>But internally, the threads yield when:</p>
<p><code>但在内部，线程会在以下情况下让出（控制权）：</code></p>
<p>– Waiting on a mutex</p>
<p><code>等待互斥锁</code></p>
<p>– Waiting on a condition</p>
<p><code>等待条件变量满足</code></p>
<p>– A yield call is encountered in the Dynamic Server code</p>
<p><code>在 Dynamic Server 代码中遇到了一个 yield 调用</code></p>
<p><strong>Notes:</strong></p>
<p>下面这几行和上面重复</p>
<p>Some common actions that might cause the thread to yield are:</p>
<p> <strong>•</strong> Waiting for a disk read or write operation</p>
<p> <strong>•</strong> Waiting for an SQL request from the client</p>
<p> <strong>•</strong> Waiting for a lock or other resource</p>
<p> <strong>•</strong> There is no more work to do.</p>
<p>A thread also might yield control to another thread for no reason other than to give another thread a chance to run. The Informix Dynamic Server thread management code <em>does not</em> perform a <em>timesharing</em> version of thread scheduling. That is, threads do not yield the virtual processor after a certain period of time has elapsed. Nor can a thread be pre-empted (interrupted). </p>
<p><code>线程也可能仅仅是为了给其他线程一个运行的机会，就将控制权让给另一个线程，而无需其他任何理由。IDS 的线程管理代码并不执行线程调度的分时共享版本。也就是说，线程不会在经过一定时间后自动让出虚拟处理器。同样，线程也不会被抢占（即被中断）。</code></p>
<p>Internally, threads yield on one of the following cases:</p>
<p><code>在内部，线程会在以下情况之一中让出（控制权）:</code></p>
<p><strong>•</strong> The thread is waiting on a mutex. A mutex is a lock on an internal shared memory structure.</p>
<p><code>线程正在等待一个互斥锁（mutex）。互斥锁是一种对内部共享内存结构的锁定机制。</code></p>
<p><strong>•</strong> The thread is waiting on a condition. A condition is a method of waiting for an event to occur.</p>
<p><code>线程正在等待一个条件（变量）。条件（变量）是一种等待事件发生的方法。</code></p>
<p><strong>•</strong> To prevent a thread from using excessive processor time, there are many junctures in the Dynamic Server code at which running threads are required to yield.</p>
<p><code>为了防止线程占用过多的处理器时间，在 Dynamic Server 代码中有许多关键点要求正在运行的线程让出（VP）控制权。</code></p>
<p><strong>The IDS Thread Entity</strong></p>
<p>The physical entity known as a thread consists of:</p>
<p><code>线程这一物理实体由以下部分构成：</code></p>
<p>– A set of structures, or control blocks. The three important control blocks are:</p>
<p><code>一组结构体或控制块。其中三个重要的控制块是：</code></p>
<p>• Session control block (scb)</p>
<p>• Thread control block (tcb)</p>
<p>• RSAM thread control block (rstcb)</p>
<p>– The stack</p>
<p>– The memory pools</p>
<p><strong>Notes:</strong></p>
<p>Many manuals (this one included) explain threads using more humanistic terms—they sleep, they wait, they work. But as humans are able to function because of their brains, the brains of a thread enable it to function within a process.</p>
<p><code>许多手册（包括这本）都使用更具人文色彩的术语来解释线程——它们会sleep、会wait、会work。但正如人类因大脑而能够运作一样，线程的“大脑”也使其能够在进程内发挥作用。</code></p>
<p>The <em>brain</em> of a thread is the physical information stored in shared memory. Major components include:</p>
<p><code>线程的大脑指的是存储在共享内存中的物理信息。其主要组成部分包括：</code></p>
<p><strong>•</strong> Control blocks. A <em>control block</em> is just a fancy name for a structure used as a big scratch pad, or work area. These control blocks store a large amount of information about the thread. The important control blocks include:</p>
<p><code>控制块。所谓“控制块”，其实只是一个花哨的说法，它本质上就是一个被用作大型临时存储区（或工作区）的结构体。这些控制块存储了大量关于线程的信息。重要的控制块包括：</code></p>
<p> <strong>-</strong> Session control block. The <em>session control block</em>, or <em>scb</em>, contains information about the session. When you first connect, the database server creates a session for you, which means it creates a session control block.</p>
<p><code>会话控制块。这个“会话控制块”（Session Control Block），简称“scb”，包含了关于会话的信息。当你首次连接时，数据库服务器会为你创建一个会话，这意味着它会创建一个会话控制块。</code></p>
<p> <strong>-</strong> Thread control block. The <em>thread control block</em>, or <em>tcb</em>, contains information about the thread. There is one thread control block for every thread running in the database server.</p>
<p><code>线程控制块。这个“线程控制块”（Thread Control Block），简称“tcb”，包含了关于线程的信息。在数据库服务器中运行的每一个线程都有一个对应的线程控制块。</code></p>
<p><strong>-</strong> RSAM thread control block. Certain threads running in a database server need access to a layer of Dynamic Server called RSAM, which handles disk I&#x2F;O requests, index management, page management, buffer management, and data replication. Some system threads and all of the user threads (spawned for a session) need an <em>RSAM thread control block</em> (<em>rstcb</em>). </p>
<p><code>RSAM线程控制块。在 server 中运行的某些线程需要访问 Dynamic Server 的一个名为 RSAM 的层，该层负责处理磁盘I/O请求、索引管理、页管理、缓冲区管理以及数据复制。一些系统线程和所有用户线程（为会话而创建的）都需要一个“RSAM线程控制块”（RSAM Thread Control Block），简称“rstcb”。</code></p>
<p>There are other control blocks that hold additional information about the thread, such as the <em>network control block</em> (<em>netscb</em>) and the <em>SQL control block</em> (<em>sqscb</em>).</p>
<p><code>还有其他一些控制块用于存储关于线程的额外信息，例如“网络控制块”（network control block，简称 netscb）和“SQL 控制块”（SQL control block，简称 sqscb）。</code></p>
<p><strong>•</strong> Stack. The <em>stack</em> holds data for the functions that a thread executes. It is similar to the stack concept in a process, but because multiple threads are operating in one process, each thread must have its own stack.</p>
<p><code>栈（Stack）。线程在执行函数时所使用的数据存储在栈中。这与进程中的栈概念类似，但由于一个进程中可能有多个线程在同时运行，因此每个线程都必须拥有自己的栈。</code></p>
<p> <strong>•</strong> Memory pools. <em>Memory pools</em> are not really a separate component of a thread. In fact, all of the information, including the stack and control blocks, are stored in memory pools in the virtual portion of the database server shared memory.</p>
<p><code>内存池（Memory pools）。内存池实际上并非线程的一个独立组成部分。事实上，包括栈和控制块在内的所有信息，都存储在 server 共享内存的虚拟部分中的内存池里。</code></p>
<p><strong>Session (User) Threads</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506150008942.png" alt="image-20250615000841804"></p>
<p><em><strong>Notes:</strong></em></p>
<p>The session control block is created when an application connects to the database server. The scb has information about the session and pointers to the session pool (which holds data used by the threads started for the session) and to the RSAM thread control block. The rstcb has a pointer to the thread control block that stores additional information about the thread.</p>
<p><code>会话控制块（Session Control Block，简称 scb）是在应用程序连接到 server 时创建的。该会话控制块包含有关会话的信息，以及指向会话池（用于存储为该会话启动的线程所使用的数据）和 RSAM 线程控制块（RSAM Thread Control Block，简称 rstcb）的指针。而 RSAM 线程控制块（rstcb）则包含一个指向线程控制块（Thread Control Block）的指针，该线程控制块用于存储有关该线程的额外信息。</code></p>
<p><strong>The Stack</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151116747.png" alt="image-20250615111608624"></p>
<p><strong>Notes:</strong></p>
<p>The stack holds information about functions a thread has called, and the data associated with the functions. It is similar to the stack used in a UNIX process, except that every thread in the Informix Dynamic Server system has its own stack to track functions and data.</p>
<p><code>栈用于存储线程所调用函数的相关信息以及与这些函数关联的数据。它类似于 UNIX 进程中使用的栈，不同之处在于，在 IDS 系统中，每个线程都拥有自己独立的栈，用以跟踪函数调用及相关数据。</code></p>
<p>The <strong>onstat -g stk</strong> command dumps the contents of a stack for the thread ID you specify in the command. It lists:</p>
<p><code>onstat -g stk 命令会转储（显示）你在命令中指定的线程 ID 所对应的栈内容。它会列出：</code></p>
<table>
<thead>
<tr>
<th>Stack ID for thread</th>
<th>The thread ID and name</th>
</tr>
</thead>
<tbody><tr>
<td>base</td>
<td>The memory address of the base of the stack <code>栈底</code></td>
</tr>
<tr>
<td>len</td>
<td>The number of bytes allocated for the stack</td>
</tr>
<tr>
<td>pc</td>
<td>The program counter indicating our current location in the stack. When the thread yields the virtual processor (performs a context switch), this value is updated from the register for the process.<code>程序计数器用于指示我们在栈中的当前位置。当线程让出虚拟处理器（执行上下文切换）时，该值会从进程的寄存器中更新。</code></td>
</tr>
<tr>
<td>tos</td>
<td>The address in memory of the top of the stack. <code>栈顶</code></td>
</tr>
</tbody></table>
<p>In addition, the output lists the functions from which the thread has not returned and the data associated with the thread. The most current function call is shown at the top of the listing.</p>
<p><code>此外，输出还会列出线程尚未返回的函数以及与该线程关联的数据。最新的函数调用会显示在列表的顶部。</code></p>
<p><strong>How a Session is Created</strong></p>
<p>A poll thread picks up an incoming client message. For an existing connection, the request is simply passed to the appropriate sqlexec thread. For a new connection, the listen thread does the following:</p>
<p><code>一个轮询线程（poll thread）会接收传入的客户端消息。对于已存在的连接，请求会直接传递给相应的 sqlexec 线程。而对于新连接，监听线程（listen thread）会执行以下操作：</code></p>
<ol>
<li><p>It allocates a new session control block.</p>
<p><code>它会分配一个新的会话控制块。</code></p>
</li>
<li><p>It creates the session pool in the virtual portion of shared memory, giving it the same name as the session ID.</p>
<p><code>它在共享内存的虚拟部分创建会话池（session pool），并为其赋予与会话 ID 相同的名称。</code></p>
</li>
<li><p>It allocates a new RSAM thread control block.</p>
<p><code>它会分配一个新的 RSAM 线程控制块。</code></p>
</li>
<li><p>It allocates a new thread control block, initializing values such as the pointers to the previous and next tcbs, and the initial function to execute. The thread name specified in the thread control block is <strong>sqlexec</strong>.</p>
<p><code>它会分配一个新的线程控制块（Thread Control Block, TCB），并初始化其中的值，例如指向上一个和下一个线程控制块的指针，以及要执行的初始函数。在线程控制块中指定的线程名称是 sqlexec。</code></p>
</li>
<li><p>It allocates the stack for the thread</p>
<p><code>它会为该线程分配栈空间。</code></p>
</li>
<li><p>It sets the program counter in the stack to the location of the initial function to be executed.</p>
<p><code>它会将栈中的程序计数器（Program Counter）设置为待执行的初始函数的地址位置。</code></p>
</li>
<li><p>It puts the thread control block on the ready queue.When the thread is put on the ready queue, it is ready for work.</p>
<p><code>它将线程控制块（Thread Control Block, TCB）放入就绪队列（ready queue）。当线程被放入就绪队列时，它就已经准备好执行工作了。</code></p>
</li>
</ol>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151143243.png" alt="image-20250615114319182"></p>
<p><code>在 IDS 的后续版本中，会话及其相关结构会进行预分配，以减少客户端连接所需的时间。</code></p>
<p><strong>Monitoring Threads</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151155609.png" alt="image-20250615115542547"></p>
<p><strong>Notes:</strong></p>
<p>You can monitor the information stored in the three major control blocks for a thread in two ways: by using the <strong>onstat</strong> utility, or by querying <strong>sysmaster</strong> tables. The <strong>onstat</strong> utility hold a subset of the information stored in the control block. However, it shows only the information most relevant to administrators. Queries on the <strong>sysmaster</strong> tables can show all of the information in the control blocks.</p>
<p><code>你可以通过两种方式来监控线程的三个主要控制块中存储的信息：一种是使用 onstat 工具，另一种是查询 sysmaster 表。onstat 工具包含控制块中存储的部分信息，但它仅显示对管理员来说最为相关的信息。而对 sysmaster 表的查询则可以展示控制块中的全部信息。</code></p>
<p>If you write applications that include queries to <strong>sysmaster</strong>, it is recommended that you restrict queries to the views in <strong>sysmaster</strong> instead of tables. If there are any changes to the structure of system tables in future releases, your applications are less likely to be affected.</p>
<p><code>如果你编写的应用程序包含对 sysmaster 的查询，建议将查询限制在 sysmaster 的视图上，而不是直接查询表。这样，如果未来版本中系统表的结构发生任何变化，你的应用程序受到的影响将会更小。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151202695.png" alt="image-20250615120200644"></p>
<p>&#96;&#96;systcblst<code>、</code>sysrstcb<code>和</code>sysscblst<code>表中的列定义在</code>$GBASEDBTDIR&#x2F;etc&#x2F;sysmaster.sql 文件中。&#96;</p>
<p><strong>All Threads: onstat -g ath</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151218944.png" alt="image-20250615121852867"></p>
<p><strong>Notes:</strong></p>
<p>An easy way to monitor all threads on a database server is to run <strong>onstat -g ath</strong>. This command lists all system and user threads, the address of the tcb, the address of the rstcb, the priority, the status, the virtual class the thread is running on, and the thread name.</p>
<p><code>监控数据库服务器上所有线程的一个简便方法是运行 onstat -g ath 命令。此命令会列出所有系统线程和用户线程，包括线程控制块（TCB）的地址、RSTCB 的地址、优先级、状态、线程正在运行的虚拟类，以及线程名称。</code></p>
<p>You can easily identify system threads that do not access the RSAM layer because they do not have an rstcb address.</p>
<p><code>你可以轻松识别出那些不访问 RSAM 层的系统线程，因为这些线程没有 rstcb 地址。</code></p>
<p>You can also view lists of threads based on their state by using the following <strong>onstat -g</strong></p>
<p><code>你还可以使用以下 onstat -g 命令（通常需要配合特定选项）来根据线程的状态查看线程列表。</code></p>
<p>options:</p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506151219912.png" alt="image-20250615121958871"></p>
<p><strong>Common Threads</strong></p>
<table>
<thead>
<tr>
<th>Thread name</th>
<th>Virtual processor</th>
<th>Purpose</th>
</tr>
</thead>
<tbody><tr>
<td>sqlexec</td>
<td>CPU</td>
<td>Primary session thread that services SQL requests<br><code>服务于 SQL 请求的主会话线程</code></td>
</tr>
<tr>
<td>main_loop</td>
<td>CPU</td>
<td>Wakes up every second to see if certain tasks need to be performed, such as checkpoints, LRU cleaning, etc.<br><code>每秒唤醒一次，以检查是否需要执行某些任务，例如检查点（checkpoints）、最近最少使用（LRU）清理等。</code></td>
</tr>
<tr>
<td>flush_sub#</td>
<td>CPU</td>
<td>Page cleaning</td>
</tr>
<tr>
<td>kaio</td>
<td>CPU</td>
<td>Performs administrative tasks for kernel asynchronous I&#x2F;O<br><code>为内核异步 I/O 执行管理任务</code></td>
</tr>
<tr>
<td>btscanner</td>
<td>CPU</td>
<td>Cleans the b-tree scanner pool</td>
</tr>
<tr>
<td>onmode_mon</td>
<td>CPU</td>
<td>onmode servicing thread</td>
</tr>
<tr>
<td>lio vp #</td>
<td>LIO</td>
<td>Handles I&#x2F;O to the logical log</td>
</tr>
<tr>
<td>pio vp #</td>
<td>PIO</td>
<td>Handles I&#x2F;O to the physical log</td>
</tr>
<tr>
<td>aio vp #</td>
<td>AIO</td>
<td>Handles database I&#x2F;O; if kernel asynchronous I&#x2F;O is used, this thread handles I&#x2F;O to any file system files (e.g. sqlhosts)<br><code>处理数据库的 I/O 操作；如果使用了内核异步 I/O，则此线程负责处理与任何文件系统文件（例如 sqlhosts 文件）之间的 I/O 操作。</code></td>
</tr>
</tbody></table>
<p><strong>Notes:</strong></p>
<p>The table above and the one on the next page show some of the most commonly used threads. The threads used in communication between client and server are shown in the unit titled, <strong>Communications</strong>.</p>
<p><code>上表展示了一些最常用的线程。在标题为“Communications”的 Unit 中展示了在客户端与服务器之间通信时所使用的线程。</code></p>
<p><strong>Conditions</strong></p>
<p><strong>Notes:</strong></p>
<p>Conditions are mechanisms used in the database server that block threads from proceeding so that events can occur without interruption. Conditions, therefore, actually protect events. Conditions are structures that are created and destroyed dynamically in the virtual portion of shared memory.</p>
<p><code>条件（Conditions）是数据库服务器中使用的一种机制，用于阻塞线程的继续执行，以便事件能够在不被中断的情况下发生。因此，条件实际上起到了保护事件的作用。条件是在共享内存的虚拟部分中动态创建和销毁的结构。</code></p>
<p>“以便事件能够在不被中断的情况下发生” ，看不太懂，AI回答是：这线程wait，被唤醒后，安全的消费数据，不被中断。就像java的condition在lock和unlock之间。</p>
<p>A thread that is waiting on a condition is waiting for something to happen, such as the completion of a checkpoint, or for a user to send an SQL statement from the client. The condition structure is kept in shared memory and is created and destroyed dynamically. You can view a list of active conditions by running the command <strong>onstat -g con</strong>.</p>
<p><code>一个在条件（condition）上等待的线程，是在等待某件事情的发生，比如检查点（checkpoint）的完成，或者等待用户从客户端发送一条 SQL 语句。条件结构存储在共享内存中，并且是动态创建和销毁的。你可以通过运行命令 onstat -g con 来查看活动条件的列表。</code></p>
<p>A blocking checkpoint is one example of an event that is handled by a condition. To prevent threads from entering critical sections while transactions are blocked during a checkpoint, a condition called <strong>cp</strong> is used. Before a thread enters a critical section, it determines if a checkpoint has been requested. If so, it calls a function called <strong>mt_wait</strong> (passing a pointer to the <strong>cp</strong> condition). The <strong>mt_wait</strong> function modifies the condition structure, adding the thread to the wait queue.</p>
<p><code>阻塞式检查点（blocking checkpoint）就是由条件（condition）处理的事件的一个例子。为了防止在检查点执行期间事务被阻塞时，线程进入关键代码段（critical section），会使用一个名为 cp 的条件。在线程进入关键代码段之前，它会判断是否已请求执行检查点。如果是，线程会调用一个名为 mt_wait 的函数（并向该函数传递指向 cp 条件的指针）。mt_wait 函数会修改条件结构，将该线程添加到等待队列中。</code></p>
<p>新事务，由于检测到检查点已请求，就放进等待队列，所以这防止了阻塞</p>
<p>After the <strong>main_loop</strong> thread has released the global transaction block, it moves all threads waiting for the checkpoint condition from the wait queue to the ready queue.As each waiter runs again, it double-checks the status of the condition. If the condition is not satisfied, it waits again. This extra step is necessary because the state of the condition could have changed since the thread was moved from the wait queue to the ready queue.</p>
<p><code>在 main_loop 线程释放全局事务块（global transaction block）之后，它会将所有正在等待检查点条件（checkpoint condition）的线程从等待队列（wait queue）移动到就绪队列（ready queue）。当每个等待线程再次运行时，它会再次检查条件的当前状态。如果条件仍未满足，线程会再次进入等待状态。这一额外步骤是必要的，因为从线程被从等待队列移动到就绪队列的这段时间内，条件的状态可能已经发生了变化。</code></p>
<p><strong>Note</strong></p>
<p>With the introduction of non-blocking checkpoints in IDS 11, threads rarely have to wait on a <strong>cp</strong> condition.</p>
<p><code>在 IDS 11 中引入了非阻塞式检查点（non-blocking checkpoints）后，线程很少需要再在 cp 条件（condition）上等待。</code></p>
<p>Although the checkpoint condition is a good example of the value of condition structures, their most common use is as a simple communication mechanism between two threads. For instance, in a parallel database query (PDQ) operation, a producer thread, whose job is to feed data to a consumer thread, uses an <strong>awaitMC%d</strong> condition to notify the waiting consumer when data is available. Also, the shared memory poll thread, <strong>sm_poll</strong> uses a condition to notify an <strong>sqlexec</strong> thread that a front-end message has arrived for it.</p>
<p><code>虽然检查点条件很好地展示了条件结构的价值，但条件结构最常见的用途是作为两个线程之间的一种简单通信机制。例如，在并行数据库查询（PDQ）操作中，负责向消费者线程提供数据的生产者线程，会使用一个名为 awaitMC%d 的条件，在数据可用时通知正在等待的消费者线程。此外，共享内存轮询线程 sm_poll 也会利用一个条件来通知 sqlexec 线程，有前端发送的消息已到达，供其处理。</code></p>
<p><strong>Internal Locking Through Mutexes</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172210348.png" alt="image-20250617221021215"></p>
<p><strong>Notes:</strong></p>
<p>A <em>mutex</em> (short for mutually exclusive) is a fancy name for a method that protects a memory structure from other threads. Dynamic Server uses mutexes to protect many memory structures, such as the lock list, or the session control block.</p>
<p><code>互斥量（mutex，是mutually exclusive（互斥）的缩写）是一种用于保护内存结构免受其他线程干扰的方法，这一称谓听起来颇为专业。Dynamic Server 使用互斥量来保护许多内存结构，例如 lock list 或 session control block。</code></p>
<p><strong>Locking a mutex</strong></p>
<p>Locking a mutex is a multi-step process:</p>
<p><code>锁定一个互斥量是一个多步骤的过程：</code></p>
<ol>
<li><p>First the thread must lock the mutex lock just to see if the mutex itself is locked. A mutex is a structure like any other and needs to be protected from multiple threads attempting to obtain the mutex at the same time.</p>
<p><code>首先，线程必须先尝试锁定互斥量（即获取互斥锁），以此判断该互斥量本身是否已被锁定。互斥量和其他任何结构一样，需要防止多个线程同时尝试获取它。</code></p>
</li>
<li><p>Once the thread obtains the mutex lock, it checks to see if any thread holds the mutex. </p>
<p><code>一旦线程获取了互斥锁，它就会检查是否有其他线程持有该互斥量。</code></p>
</li>
<li><p>If there is no holder, the thread can designate itself as the holder.</p>
<p><code>如果没有持有者，该线程就可以将自己指定为持有者。</code></p>
</li>
<li><p>If there is a holder, the thread can put itself on the wait queue for the mutex.</p>
<p><code>如果已经有持有者，该线程可以把自己加入到该互斥量的等待队列中。</code></p>
</li>
<li><p>The thread unlocks the mutex lock.</p>
<p><code>该线程释放（或解开）互斥锁。</code></p>
</li>
</ol>
<p><strong>How long do mutexes stay around?</strong></p>
<p><code>互斥量会保留（或存在）多久？</code></p>
<p>Mutex structures are generally embedded in the structures they’re meant to protect. Those structures are constantly being allocated and freed as threads are spawned, perform work, and exit. An example of a fairly volatile mutex is the one embedded in a thread control block. Each instance of that mutex only lives as long as the thread lives. Some mutexes, such as the one protecting the buffer header structure, are allocated for the life of the database server.</p>
<p><code>互斥量结构通常嵌入在它们旨在保护的那些结构中。随着线程的创建、执行任务和退出，这些结构会不断地被分配和释放。一个相当“易变”（即频繁创建和销毁）的互斥量示例是嵌入在 thread control block 中的那个互斥量。该互斥量的每个实例仅在其所属线程的生命周期内存在。而有些互斥量，例如用于保护缓冲区头结构的互斥量，则会在数据库服务器的整个生命周期内被分配并持续存在。</code></p>
<p>There are other cases in which the mutex is not part of another structure; the mutex memory is allocated when the mutex is needed and removed when it is no longer used.</p>
<p><code>在其他情况下，互斥量并不是另一个结构的一部分；当需要互斥量时，会为其分配内存，而当不再需要它时，则会释放该内存。</code></p>
<p><strong>The example diagram</strong></p>
<p>In the example shown in the slide, Thread 1 holds the mutex, while Thread 2, Thread 3, and Thread 4 are waiting.</p>
<p><code>在幻灯片所示的示例中，线程 1 持有互斥量，而线程 2、线程 3 和线程 4 正在等待。</code></p>
<p><strong>Monitoring Mutexes and Conditions</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172228820.png" alt="image-20250617222837748"></p>
<p><strong>Notes:</strong></p>
<p>The chart above shows the <strong>onstat</strong> options and <strong>sysmaster</strong> tables you can use to view mutexes and conditions.</p>
<p><code>上图展示了可用于查看互斥量和条件变量的 onstat options 以及 sysmaster tables。</code></p>
<p><strong>Monitoring Locked Mutexes: onstat –g lmx</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172237476.png" alt="image-20250617223745406"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g lmx</strong> command shows all locked mutexes.</p>
<p>The <strong>onstat -g wmx</strong> command shows only locked mutexes that have waiting threads.</p>
<p><code>onstat -g wmx 命令仅显示有线程等待的已锁定互斥量。</code></p>
<p><strong>All Mutexes</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506172240553.png" alt="image-20250617224002494"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g amx</strong> command shows all mutexes, even if they are not held by any thread. If a mutex is not held, the value in the holder column is <strong>-1</strong>.</p>
<p><code>onstat -g amx 命令会显示所有的互斥量，即使它们当前没有被任何线程持有。如果一个互斥量未被持有，那么在持有者（holder）列中显示的值将是 -1。</code></p>
<p><strong>Configuration Parameters Affecting Mutexes</strong></p>
<p> QSTATS – collects mutex statistics</p>
<p> SINGLE_CPU_VP – If set to &gt;0, fewer mutexes are acquired</p>
<p><strong>Notes:</strong></p>
<p>The QSTATS parameter is a configuration parameter that causes mutex statistics to be collected. Set the QSTATS parameter to any value. For example:</p>
<p><code>QSTATS 参数是一个配置参数，用于触发互斥量（mutex）统计信息的收集。可将 QSTATS 参数设置为任意值。例如：</code></p>
<p>​		QSTATS 1</p>
<p>QSTATS should not be set in a production system, because it can slow performance.If the SINGLE_CPU_VP configuration parameter is set to 1, the need to acquire many mutexes is not necessary because there is no contention with other CPU VP threads.This is true for the following reasons:</p>
<p><code>在生产系统中不应设置 QSTATS 参数，因为它可能会降低系统性能。如果将 SINGLE_CPU_VP 配置参数设置为 1，那么由于不存在与其他 CPU 虚拟处理器（VP）线程的竞争，也就无需获取多个互斥量。原因如下：</code></p>
<p> <strong>•</strong> A thread never yields while holding a mutex </p>
<p><code>线程在持有互斥量（mutex）期间永远不会让出（CPU）执行权</code></p>
<p> <strong>•</strong> With only one CPU VP only one thread (of the CPU VP class) can be running</p>
<p><code>在只有一个 CPU 虚拟处理器（CPU VP）的情况下，同一时间只能有一个属于该 CPU VP 类的线程在运行。</code></p>
<p><strong>Mutex Queue Statistics: onstat –g qst</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192213146.png" alt="image-20250619221343021"></p>
<p><strong>Notes:</strong></p>
<p>The mutex structure contains a number of statistics that can give developers an idea of which mutexes might be causing a bottleneck in the server. Normally, these statistics fields are not populated, but turning on queuing statistics for mutexes is as simple as setting QSTATS.</p>
<p><code>互斥量（mutex）结构中包含多个统计信息字段，这些字段能够帮助开发者识别出 server 中可能导致瓶颈的互斥量。通常情况下，这些统计信息字段是空的，但开启互斥量的排队统计信息非常简单，只需设置 QSTATS 参数即可。</code></p>
<p><strong>Warning</strong></p>
<p><em>Setting QSTATS might cause some degradation in performance. As a rule, you should not</em> <em>set QSTATS on servers in which performance is critical.</em></p>
<p><code>设置 QSTATS 可能会导致性能有所下降。一般来说，在性能至关重要的 server 上，不应设置 QSTATS。</code></p>
<p>Once you have set this configuration parameter and restarted the database server, you can execute the following command to show statistics for any mutex that is currently allocated in memory.</p>
<p><code>一旦你设置了该配置参数并重新启动了 database server，你就可以执行以下命令来显示当前在内存中分配的任何互斥量的统计信息。</code></p>
<p>​		onstat -g qst</p>
<p>Statistics include the following information:</p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192219161.png" alt="image-20250619221951093"></p>
<p><strong>Mutex queue statistics and tuning</strong></p>
<p>Mutex queue statistics don’t offer much information to an administrator, except to show which shared memory structures are being accessed the most. The mutex wait queues increase when the database server is heavily used. This isn’t a bad thing—just an indication of a busy database server. </p>
<p><code>互斥量队列统计信息对管理员来说提供的信息并不多，除了能显示哪些共享内存结构被访问得最频繁之外。当 database server 使用繁忙时，互斥量等待队列的长度会增加。这并不是一件坏事——它只是表明 database server 处于繁忙状态。</code></p>
<p>Developers can use mutex statistics to make sure that threads are not locking shared memory structures too long.</p>
<p><strong>Why Are Threads Waiting?</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506192223296.png" alt="image-20250619222338229"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g wst</strong> command displays statistics about the time a thread is waiting and the reason why it is waiting.</p>
<p><code>onstat -g wst 命令会显示线程等待的时间以及线程等待原因的相关统计信息。</code></p>
<p>Statistics on thread waits are not normally collected because of the overhead required to calculate and store them. To collect statistics for this report, you must add a line in the configuration file to set the WSTATS parameter to a non-zero value. For example:</p>
<p><code>通常情况下，由于计算和存储线程等待统计信息会产生额外的开销，因此不会收集这些统计信息。若要为这份报告收集统计信息，你必须在配置文件中添加一行，将 </code>WSTATS<code> 参数设置为非零值。例如：</code></p>
<p>​		WSTATS 1</p>
<p><strong>Warning</strong></p>
<p><em>Setting the WSTATS parameter might cause performance degradation. You should not set</em> <em>this parameter on servers in which performance is critical.</em></p>
<p><code>设置 WSTATS 参数可能会导致性能下降。你不应在性能至关重要的 server 上设置此参数。</code></p>
<p>Each thread is listed once per <em>state</em>, such as <strong>yield</strong>, <strong>ready</strong>, or <strong>run</strong>. The average and maximum times are usually listed in millionths of a second. If an <strong>s</strong> follows the number, the unit is seconds.</p>
<p><code>每个线程会按照其状态（如 yield、ready 或 run）分别列出一次。平均时间和最大时间通常以百万分之一秒为单位列出。如果数字后面跟着一个 s，则单位是秒。</code></p>
<p>The <strong>onstat -g wst</strong> report is useful for troubleshooting. It’s the only way, for example, that you can tell if the thread had a chance to run, and how often it runs compared to other threads. Also, if a thread’s maximum or average run time really stands out as high, it could be an indication of a runaway thread.</p>
<p><code>onstat -g wst 报告对于故障排查非常有用。例如，这是你唯一能够判断线程是否有机会运行，以及与其他线程相比其运行频率的方法。此外，如果某个线程的最大或平均运行时间显著偏高，这可能表明该线程是一个失控线程（runaway thread）。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/8"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/07/IX9111/8/"
    >IX9111 - Unit 8. Sbspaces</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/07/IX9111/8/" class="article-date">
  <time datetime="2025-06-07T12:50:00.000Z" itemprop="datePublished">2025-06-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Unit 8. Sbspaces</strong></p>
<p><strong>Sbspace Chunk Layout</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072051497.png" alt="image-20250607205138379"></p>
<p><strong>Notes:</strong></p>
<p>A <em>smart blobspace</em>, or <em>sbspace</em>, is a logical collection of chunks that is used to store <em>smart</em> <em>large objects</em> (also called <em>smart LOs</em> or <em>smart blobs</em>).</p>
<p><code>智能大对象空间（smart blobspace，简称 sbspace）是一个由多个 chunk 构成的逻辑集合，用于存储智能大对象。</code></p>
<p>When an sbspace is initially created, it assigns space for header data, <em>metadata</em>, and user data. The first chunk of an sbspace always contains a 53-page header, also known as the sbspace reserved pages. Subsequent chunks require only 3 reserved pages.</p>
<p><code>在最初创建 sbspace 时，它会为 header data、metadata 以及 user data 分配空间。sbspace 的第一个 chunk 始终包含一个由 53 页组成的 header，也称为sbspace 的保留页。而后续的 chunk 则仅需 3 页保留页。</code></p>
<p>There is always a metadata area stored within the first chunk of an sbspace. The default location is near the middle of the chunk to optimize access time. The location and size can be determined during the creation of the sbspace. A metadata area can contain information for one or more chunks within the sbspace. Once it is allocated, the metadata area cannot be changed in size or location.</p>
<p><code>sbspace 的第一个 chunk 中，始终会存储一个 metadata 区域。默认情况下，该 metadata 区域位于 chunk 接近中间的位置，以优化访问时间。其具体位置和大小可在创建 sbspace 时确定。一个 metadata 区域可以包含 sbspace 内一个或多个 chunk 的相关信息。一旦 metadata 区域被分配，其大小和位置便无法再更改。</code></p>
<p>Any space remaining after the header pages and the metadata are allocated is used for storing user data, that is, the smart large objects.</p>
<p><code>在分配完 header pages 和 metadata 之后所剩余的空间，均用于存储 user data，即智能大对象（smart large objects）。</code></p>
<p><strong>Sbspace Reserved Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072101662.png" alt="image-20250607210141608"></p>
<p><strong>Notes:</strong></p>
<p>The first few pages of an sbspace are laid out much like other spaces in the server. There are 3 header pages at the beginning of every chunk in an sbspace. These include two unused reserved pages and one chunk free-list page. This page doesn’t track all pages used in the chunk. It only tracks the pages in the chunk that are not allocated for metadata or preassigned user data. This is the first of two levels of free-space tracking. The second level is within the metadata itself where smart LO subsystem tracking is handled.</p>
<p><code>sbspace 的前几页布局与 server 中的其他空间颇为相似。在 sbspace 的每个 chunk 开头，都设有3个 header pages。这其中包括两个 unused reserved pages 和一个 chunk free-list page。需要注意的是，这个 chunk free-list page 并不追踪 chunk 中使用的所有页面，它仅追踪那些未被分配给 metadata 或预先分配的 user data 的页面。这是空闲空间追踪的第一级机制。而第二级追踪机制则位于 metadata 内部，由智能大对象（smart LO）子系统负责处理。</code></p>
<p>A tblspace tblspace is found only in the first chunk of each sbspace. It is used to track information about tables within the metadata area. Information about archives taken for this sbspace are also stored here.</p>
<p><code>在每个 sbspace 的第一个 chunk 中，会存在一个 tblspace tblspace。该结构用于在 metadata 区域内追踪与 tables 相关的信息。此外，针对该 sbspace 所进行的归档（archives）信息也会被存储在此处。</code></p>
<p><strong>Types of Sbspace Pages</strong></p>
<p> Standard pages</p>
<p> Metadata partitions</p>
<p> Smart LO pages</p>
<p> Smart LO data stored in rows</p>
<p><strong>Notes:</strong></p>
<p>There are four different types of pages used to store and manage large objects in an sbspace. These are discussed in the following pages.</p>
<p><code>sbspace 中，用于存储和管理 large objects 的页面共有四种不同类型。以下页面将对这些类型进行讨论。</code></p>
<p><strong>Standard Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072118900.png" alt="image-20250607211850828"></p>
<p><strong>Notes:</strong></p>
<p>The pages in an sbspace that are considered <em>standard</em> are those that look like and are handled similarly to the pages in a dbspace. These pages contain page headers, timestamps, and slot tables. There are data pages, partition pages, and index pages found in various sbspace structures.</p>
<p><code>sbspace 中，被视为标准页面的，是那些在外观和处理方式上与数据库空间（dbspace）中的页面相似的页面。这些标准页面包含页头（page headers）、时间戳（timestamps）以及 slot tables。在 sbspace 的各种结构中，可以找到数据页（data pages）、分区页（partition pages）以及索引页（index pages）。</code></p>
<p><strong>Metadata Area</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072123110.png" alt="image-20250607212332036"></p>
<p><strong>Notes:</strong></p>
<p>The <em>metadata area</em> is preallocated at the time the sbspace is created. It cannot be enlarged by allocating more unused user-data space; another chunk with a new metadata area must be allocated. The metadata for the sbspace contains tables for handling four types of information. These tables are stored in the sbspace as regular tblspaces (partitions).</p>
<p><code>元数据区域（metadata area）在创建 sbspace 时即被预先分配。它无法通过分配更多未使用的用户数据空间来扩大；若需扩展，必须分配一个包含新 metadata area 的新 chunk。sbspace 的 metadata 包含用于处理四种类型信息的表。这些表以常规 tblspaces (partitions) 的形式存储在 sbspace 中。</code></p>
<p><strong>•</strong> Sbspace description partition (<strong>sbspace_desc</strong>) – This partition contains a single structure that describes the smart blobspace. It includes special attributes for the sbspace (the <strong>onspaces -Df</strong> attributes used when the sbspace was created), the location of the chunk adjunct partition, and sbspace flags. This partition uses only one page and is stored in the first chunk of the sbspace.</p>
<p><code>此分区包含一个单一结构，用于描述 smart blobspace。它包 space 的特殊属性（即创建智能块空间时使用的 onspaces -Df 属性）、数据块附属分区（chunk adjunct partition）的位置，以及 sbspace 的标志位（flags）。该 partition 仅占用一页，并存储在 sbspace 的第一个 chunk 中。</code></p>
<p> <strong>•</strong> Chunk adjunct partition (<strong>chunk_adjunc</strong>) – This partition stores information about each chunk in the sbspace. It includes the location and size of the user-data metadata areas, and the location of the LO header partition for the chunk. The chunk adjunct partition contains one row for each chunk and is stored in the first chunk of the sbspace.</p>
<p><code>该 partition 用于存储 sbspace 中每个 chunk 的相关信息。这些信息包括 user-data metadata areas 的位置和大小，以及每个 chunk 中 LO header partition 的位置。chunk adjunct partition 为每个 chunk 包含一行记录，并且该分区存储在 sbspace 的第一个 chunk 中。</code></p>
<p> <strong>•</strong> LO header partition (<strong>LO_hdr_partn</strong>) – For each smart LO in the chunk, this table describes the time and date the LO was created, the size of the LO, and other attributes. It also includes an extent list that is allocated to the smart LO. There is one LO header partition allocated for each chunk in the sbspace.</p>
<p><code>对于 sbspace 中的每个智能大对象（smart LO），此表均会描述该大对象的创建时间和日期、大小以及其他属性。此外，它还包含一个分配给该智能大对象的 extent list。在 sbspace 的每个 chunk 中，都会分配一个这样的 LO header partition。</code></p>
<p><strong>•</strong> UD free-list partition (<strong>LO_ud_free</strong>) – This partition tracks free extents in the user-data areas of a chunk; it is very similar to the chunk free list. There is one UD free-list partition for each chunk in the sbspace.</p>
<p><code>该 partition 负责追踪 chunk 的 user-data areas 中的 free extents；其功能与 chunk free list 非常相似。在 sbspace 的每个 chunk 中，都会分配一个这样的 UD free-list partition。</code></p>
<p>Use the <strong>oncheck -cS</strong> command to display the partition numbers and space usage for these partitions.</p>
<p><code>使用 oncheck -cS 命令可以显示这些 partition 的 partition numbers 以及空间使用情况（space usage）。</code></p>
<p><strong>Smart LO Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072204946.png" alt="image-20250607220400881"></p>
<p><strong>Notes:</strong></p>
<p>Smart LO pages have the same format as a dbspace data page that contains rows of data. It has a twenty-four-byte header and a four-byte timestamp trailer. The page size is specified when the sbspace is created. A smart LO can span multiple pages within the sbspace. The LO is simply stored in pieces that fit on a page. The pages are read and written by the smart LO subsystem via the dynamic buffer manager. I&#x2F;O for the metadata subsystem, on the other hand, is handled by the regular RSAM I&#x2F;O subsystem.</p>
<p><code>智能大对象（smart LO）页面的格式与包含数据行的 dbspace 数据页面相同。它具有一个 24 字节的页头（header）和一个 4 字节的时间戳尾记（timestamp trailer）。页面大小在创建 sbspace 时指定。一个智能大对象可以跨越 sbspace 内的多个页面。该大对象只是被拆分成适合存储在单个页面上的片段进行存储。智能大对象子系统通过动态缓冲区管理器（dynamic buffer manager）来读写这些页面。另一方面，metadata 子系统的输入/输出（I/O）操作则由常规的 RSAM 输入/输出子系统来处理。</code></p>
<p><strong>Large Object Data Stored on Data Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506072207241.png" alt="image-20250607220742169"></p>
<p><strong>Notes:</strong></p>
<p>Both simple LOs (data of type BYTE or TEXT) and smart LOs (types BLOB and CLOB) contain information in the data row to locate the large object data. For simple large objects, there is a 56-byte descriptor that is stored in the data row. Smart large objects have a 72-byte descriptor structure. Depending on byte-alignment requirements, the descriptor could be preceded with up to 4 bytes of padding.</p>
<p><code>无论是简单大对象（数据类型为 BYTE 或 TEXT）还是智能大对象（数据类型为 BLOB 和 CLOB），其数据行中均包含用于定位大对象数据的信息。对于简单大对象，数据行中存储有一个 56 字节的描述符（descriptor）。而智能大对象则具有一个 72 字节的描述符结构。根据字节对齐（byte-alignment）的要求，描述符前面可能会添加最多 4 字节的填充（padding）。</code></p>
<p>The LO descriptor contains a 12-byte structure called the <em>smart LO handle</em>. This handle consists of three integer values: an sbspace number, a chunk number, and a sequence number. These values indicate the location (sbspace and chunk) of the LO header partition that describes the smart LO, and the <em>logical sequence number</em>, which is assigned based on the logical position within the partition.</p>
<p><code>大对象（LO）描述符中包含一个 12 字节的结构，称为智能大对象句柄（smart LO handle）。该句柄由三个整数值组成：一个 sbspace number、chunk number 以及一个序列号（sequence number）。这些值用于指示描述该智能大对象的 LO header partition 的位置（sbspace and chunk），以及逻辑序列号（logical sequence number），该序列号是根据该智能大对象在分区内的逻辑位置分配的。</code></p>
<p><strong>Locating a Smart Large Object</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506092035208.png" alt="image-20250609203539067"></p>
<p><strong>Notes:</strong></p>
<p>The figure above shows how the smart LO handle is used to locate and retrieve a smart large object from a table.</p>
<p><code>上图展示了智能大对象句柄如何用于从表上定位并取回智能大对象。</code></p>
<ol>
<li><p>When a row containing a smart LO is requested, the database server reads the page containing the row into shared memory. </p>
<p><code>当请求包含智能大对象的某一行数据时，server 会将包含该行数据的页面读入共享内存。</code></p>
</li>
<li><p>The server locates the smart LO descriptor and extracts the LO handle. The handle is used to look up the entry for the smart large object in the LO header partition. </p>
<p><code>server 定位智能大对象描述符，并提取出大对象句柄。该句柄用于在 LO header partition 中查找智能大型对象的条目。</code></p>
</li>
<li><p>This partition contains the location of each extent of the large object. With this information, the smart LO can be retrieved from the sbspace.</p>
<p><code>该 partition 包含大对象的每个 extent 的位置信息。借助这些信息，即可从 sbspace 中检索出智能大对象。</code></p>
</li>
</ol>
<p><strong>Inserting a Smart Large Object</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506092043588.png" alt="image-20250609204313509"></p>
<p><strong>Notes:</strong></p>
<p>When a request is received to insert a new row into a table that contains a smart LO, an insert is required in both a page in the tblspace as well as an insert to the sbspace. The figure above shows how smart LOs are inserted.</p>
<p><code>当收到向包含智能大对象的表中插入新行的请求时，不仅需要在 tblspace中的一个页面进行插入操作，还需要在 sbspace 中进行插入操作。上图展示了智能大对象是如何被插入的。</code></p>
<ol>
<li><p>When the INSERT request is received, a data page with available space is read into shared memory and a slot is allocated for the new row. </p>
<p><code>当接收到 INSERT 请求时，会将一个有可用空间的数据页读入共享内存，并为新行分配一个 slot。</code></p>
</li>
<li><p>To insert the smart LO into the sbspace, the database server examines the UD free-list partition to locate available space for the large object. </p>
<p><code>为了将智能大对象插入到 sbspace 中，server 会检查 UD free-list partition，以定位该大对象可用的空间。</code></p>
</li>
<li><p>If a single free extent cannot be found that is large enough for the object, then multiple extents are allocated. The smart LO is inserted into the free extents, and the free-extent information is updated in the UD free-list partition. </p>
<p><code>如果找不到一个足够大的单个空闲 extent 来容纳该对象，那么就会分配多个 extent。智能大对象会被插入到这些空闲 extent 中，并且 UD free-list partition 中的 free-extent 信息也会随之更新。</code></p>
</li>
<li><p>Extent information for the new LO are added to a new row in the LO header partition.</p>
<p><code>该新大对象的 extent 信息会被添加到 LO header partition 中的一个新行中。</code></p>
</li>
<li><p>Finally, the smart LO descriptor on the data page is updated with information about the smart LO, including the smart LO handle.</p>
<p><code>最后，数据页上的 smart LO descriptor 会被更新，添加关于该智能大对象的信息，包括智能大对象句柄。</code></p>
</li>
</ol>
<p><strong>Sbspace Example</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102052633.png" alt="image-20250610205239507"></p>
<p><strong>Notes:</strong></p>
<p>Above is a sample of output from an <strong>onstat -d</strong> command. An <strong>oncheck -pe</strong> report for the sbspace in this system is shown on the following page. The information for the user data free list was obtained right after the sbspace was created and appears as FREE USER DATA in an <strong>oncheck -pe</strong> report. </p>
<p><code>以上是 onstat -d 命令输出的一个示例。该系统 sbspace 的 oncheck -pe 报告内容展示在下一页。user data free list 的相关信息是在创建该 sbspace 后立即获取的，并以 oncheck -pe 报告中的“FREE USER DATA”形式呈现。</code></p>
<p>The database server reserves 40 percent of the user-data area as a RESERVED USER DATA area. This space can be used for either the metadata or user data. Space in the metadata area gets used up as smart large objects are added to that sbspace. When the database server runs out of metadata or user-data space, it moves a block of the reserved space to the corresponding area.</p>
<p><code>server 会将用户数据区的 40% 预留为“RESERVED USER DATA”区域。该空间既可用于 metadata，也可用于 user data。随着向该 sbspace 添加智能大对象（smart large objects），metadata 区的空间会逐渐被占用。当 server 的 metadata 区或 user data 区空间耗尽时，它会将预留空间中的一块区域移动到相应的区域（元metadata 区或 user data 区）以供使用。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102101138.png" alt="image-20250610210106034"></p>
<p>The three values in brackets after each LO listing together represent the smart LO handle, which is used to uniquely identify every large object on the database server. In the example above, you can see smart LOs that have a <em>physical</em> order that is different from their <em>logical</em>order. The database server tries to balance the load of the sbspace by inserting into both user-data areas on a chunk.</p>
<p><code>每个大对象条目后方括号内的三个值共同构成了智能大对象句柄，该句柄用于在 server 上唯一标识每一个大对象。在上述示例中，你可以看到智能大对象的物理顺序与其逻辑顺序并不相同。server 会尝试通过在 chunk 的两个 user-data 区中插入数据来平衡 sbspace 的负载。</code></p>
<p><strong>Monitoring Sbspaces: oncheck</strong></p>
<p>Use oncheck to view:</p>
<p>– Metadata information</p>
<p>– Pages on disk</p>
<p>– General chunk layout</p>
<p><strong>Notes:</strong></p>
<p>The <strong>oncheck</strong> utility provides options to generate reports on sbspaces and elements within sbspaces.</p>
<p><code>oncheck utility 提供了生成有关 sbspace 以及 sbspace 内元素的报告的选项。</code></p>
<table>
<thead>
<tr>
<th><strong>-cs sbspace</strong></th>
<th align="left">Checks metadata information</th>
</tr>
</thead>
<tbody><tr>
<td><strong>-cS sbspace</strong></td>
<td align="left">Checks metadata and extent information</td>
</tr>
<tr>
<td><strong>-ps&#x2F;-pS sbspace</strong></td>
<td align="left">Prints metadata information</td>
</tr>
<tr>
<td><strong>-pp partnum logical_offset</strong></td>
<td align="left">View a page on disk</td>
</tr>
<tr>
<td><strong>-pP chunk page_offset</strong></td>
<td align="left">View a page on disk</td>
</tr>
<tr>
<td><strong>-pd&#x2F;-pD partnum</strong></td>
<td align="left">View contents of metadata tables. The partnum for the LO partition header is needed and can be obtained from -cs options. For example: oncheck -pD 0x200004</td>
</tr>
<tr>
<td><strong>-ce&#x2F;-pe sbspace</strong></td>
<td align="left">General chunk layout</td>
</tr>
</tbody></table>
<p>The <strong>oncheck -pS</strong> command is used to display tblspace information for metadata tables (like <strong>oncheck -pt</strong>) and displays additional information about smart LO extents. Here is an example:</p>
<p><code>oncheck -pS 命令用于显示 metadata tables 的 tblspace 信息（类似于 oncheck -pt 命令），同时还会显示有关智能大对象 extent 的额外信息。以下是一个示例：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102128798.png" alt="image-20250610212815669"></p>
<p><strong>oncheck –g smb</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102129908.png" alt="image-20250610212957842"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>onstat -g smb</strong> command can be used with any of the above options to obtain statistical information about sbspaces. The <strong>e</strong> and <strong>lod</strong> options provide a list of the entries in the LO header table. These represent the smart LOs that have been stored in sbspaces. An example is shown on the next page.</p>
<p><code>onstat -g smb 命令可与上述任意选项配合使用，以获取有关 sbspace 的统计信息。其中，e 和 lod 选项会提供 LO header table 中的条目列表。这些条目代表存储在 sbspace 中的智能大对象。示例将在下一页展示。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506102131931.png" alt="image-20250610213146849"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/7"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/02/IX9111/7/"
    >IX9111 - Unit 7. Blobspaces</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/02/IX9111/7/" class="article-date">
  <time datetime="2025-06-02T14:35:55.000Z" itemprop="datePublished">2025-06-02</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>Blobspace Architecture</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022236155.png" alt="image-20250602223600067"></p>
<p><strong>Notes:</strong></p>
<p>Every blob chunk has the same basic layout, yet it still manages to baffle the best of us because of similar terms for its relatively few elements. A blob chunk begins with a <em>blobpage map</em>, followed by a blob <em>bitmap</em>, followed by the actual <em>blobpages</em>. The blobpage map (1) tracks blobpages (3). The blob bitmap (2) tracks pages in the blobspace map (1). The blobpages store blob data.</p>
<p><code>每个 blob chunk 都具有相同的基本布局，但由于其元素数量相对较少且术语相似，仍会让我们感到困惑。blob chunk 以 blobpage map 开头，接着是一个 BLOB bitmap，最后是实际的 blobpages。blobpage map（1）用于跟踪 blobpages（3）。blob bitmap（2）用于跟踪 blobspace map（1） 里的页 。blobpages 则用于存储 blob 数据。</code></p>
<p>Clear as mud? It is best to divide and conquer.</p>
<p><code>还是一头雾水吗？最好的办法就是分而治之（逐个击破、逐一理解）。</code></p>
<p><strong>Blob chunk overhead pages</strong></p>
<p>When a blob chunk is created, all overhead pages are allocated up front. These are regular-sized Dynamic Server pages. Only blobpages, which come after the blob chunk overhead pages, are potentially larger than the database server page size.</p>
<p><code>在创建 blob chunk 时，会预先分配所有开销页（overhead pages）。这些开销页都是常规大小的 Dynamic Server 页。只有位于 blob chunk overhead pages 之后的 blobpages，其大小才可能超过 database server 页的大小。</code></p>
<p><strong>The blobpage map</strong></p>
<p>The first of the two overhead elements is the blobpage map. It is an extent of pages that tracks all blobpages in the chunk, essentially describing each one as either used or free. The number of separate pages allocated for the blobpage map depends on the number of blobpages that must be tracked, of course, and the size of each tracking page in the map, which is the server page size.</p>
<p><code>两个 overhead elements 中的第一个是 blobpage map。它是一组连续的页面，用于跟踪 chunk 中的所有 blobpage，实质上会记录每个 blobpage 是处于“已使用”还是“空闲”状态。当然，为 blobpage map 分配的独立页面数量，取决于需要跟踪的 blobpage 数量，以及 map 中每个跟踪页面的大小（该大小即 server 页面大小）。</code></p>
<p><strong>The blob bitmap</strong></p>
<p>Picture a large blob chunk. It would begin with a fairly large blobpage map, consisting of possibly hundreds of pages. As the chunk began to get full, it would be a pain to search every page of the blobpage map looking for those scarce references to free blobpages. So the blobpage map itself has a bitmap describing each of its pages as either 0, which means it contains at least one reference to a free blobpage, or 1, which means it is worthless to search through, containing no reference to a free spot.</p>
<p><code>设想一个大的 blob chunk。它会以一个相当庞大的 blobpage map 作为起始，可能由数百个页面组成。当这个 chunk 逐渐被填满时，若要搜索 blobpage map 的每一页以寻找那些稀少的指向空闲 blobpage 的引用，将会是一件非常繁琐的事情。因此，blobpage map 本身设有一个位图（bitmap），用于描述其每一页的状态：若某页标记为 0，则表示该页至少包含一个指向空闲 blobpage 的引用；若标记为 1，则意味着搜索该页毫无价值，因为它不包含任何指向空闲位置的引用。</code></p>
<blockquote>
<p>scarce 英[skeəs] 美[skers]<br>adj.稀少的;缺乏的;不足的;<br>adv.几乎不;刚;简直不;勉强;</p>
</blockquote>
<p><strong>Blobpages</strong></p>
<p>Blobpages are what the fighting is all about. They store blobspace blob data. We will get to lower-level blobpage details in a few minutes. In the meantime, here are a few tidbits to tide you over:</p>
<p><code>Blobpages（二进制大对象页）正是这场“存储之战”的核心所在。它们用于存储 blobspace（二进制大对象空间）中的 blob 数据（二进制大对象数据）。几分钟后，我们将深入探讨 blobpage 更底层的细节。在此期间，先分享几个小知识点，让你先睹为快：</code></p>
<p> <strong>•</strong> Their size is configurable, but only to intervals of the system page size and only at the blobspace level. </p>
<p><code>它们（指 blobpages）的大小是可配置的，但只能按照系统页面大小的间隔进行配置，并且这种配置只能在 blobspace（二进制大对象空间）级别进行。</code></p>
<p> <strong>•</strong> Their size is not trivial; unlike blobs stored with the data, a blobspace blobpage can store data from only one blob.</p>
<p><code>它们的大小并非微不足道；与和数据一起存储的二进制大对象（blobs）不同，一个二进制大对象空间（blobspace）中的 blobpage 只能存储来自一个二进制大对象（blob）的数据。</code></p>
<p> <strong>•</strong> They are never found in the shared memory buffer pool. Blobs stored in a blobspace are read and written there directly.</p>
<p><code>它们永远不会出现在共享内存缓冲区池（shared memory buffer pool）中。存储在二进制大对象空间（blobspace）中的二进制大对象（blobs）是直接在那里（即 blobspace 中）进行读写操作的。</code></p>
<p><strong>A Typical Blobpage Map Page</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032123759.png" alt="image-20250603212316620"></p>
<p><strong>Notes:</strong></p>
<p>Every blobpage in the chunk is represented by one 8-byte blob <em>free-map structure</em> in the blobpage map. Not surprisingly, the first blobpage is tracked by the first blob free-map structure in the first page of the blobpage map. The second structure tracks the second blobpage, and so on.</p>
<p><code>chunk 中的每一个 blobpage，都会在 blobpage map 中由一个 8 字节的 blob free-map structure 来表示。不出所料，blobpage map 第一页中的第一个 blob free-map structure 会负责跟踪第一个 blobpage。第二个 structure 则负责跟踪第二个 blobpage，依此类推。</code></p>
<p><strong>The blob free-map structure</strong></p>
<p>Each blob free-map structure, which consists of two 4-byte integers, contains three pieces of information about the blobpage it represents; it is meant to convey the <em>state</em> of the blobpage.</p>
<p><code>每个由两个 4 字节整数构成的 blob free-map structure 都包含关于其所代表的 blobpage 的三部分信息；该 structure 旨在传达该 blobpage 的状态。</code></p>
<p><strong>Blobpage state</strong></p>
<p>Blobspace blob data is never actually <em>modified</em>. An update of blob data involves inserting new data into a new chain of blobpages, then freeing the old blobpages. Think of blob data as having a state that toggles back and forth between used and free.</p>
<p><code>blobspace 中的 blob 数据实际上从未被真正修改过。对 blob 数据的更新操作涉及将新数据插入到一个新的 blobpage 链中，然后释放旧的 blobpage。可以将 blob 数据的状态想象为在“已使用”和“空闲”之间来回切换。</code></p>
<p><strong>Used bit</strong></p>
<p>The most significant bit of the first integer in the blob free-map structure indicates whether the blobpage is used (1) or free (0). Recall that a 4-byte integer with only the most significant bit set has a hex value of 0x80000000.</p>
<p><code>blob free-map structure 中第一个 4 字节整数的最高有效位（most significant bit）用于指示该 blobpage 是否正在被使用（值为 1）或处于空闲状态（值为 0）。回想一下，一个仅最高有效位被置为 1 的 4 字节整数，其十六进制值为 0x80000000。</code></p>
<p><strong>Loguniq</strong></p>
<p>Even with the sign bit unavailable, there is plenty of room in the first integer of the structure to store a logical log unique ID. This ID, stored only for blobs in databases being logged, represents the logical log that was current when the state of the blobpage last changed.</p>
<p><code>即便符号位（sign bit）不可用，该结构中第一个整数的剩余空间也足以存储一个 logical log unique ID。这个 ID 仅针对处于被记录日志状态的数据库中的二进制大对象（blobs）进行存储，它表示在该 blobpage 状态最后一次发生变更时，当前处于活动状态的逻辑日志。</code></p>
<blockquote>
<p>plenty 大量 英[ˈplenti] 美[ˈplenti]</p>
</blockquote>
<p><strong>Why store a loguniq?</strong></p>
<p>Blobspace blob data, because its size is practically unlimited, is never written to the logical log files. When a blobspace blob is inserted, deleted, or updated in a database created with logging, the record of the operation that is written to the current log file contains only a miniature representation of the blob data: the home row’s 56-byte descriptor. </p>
<p><code>blobspace 中的 blob 数据大小实际上不受限制，因此这些数据从不会被写入到逻辑日志文件中。当在一个启用了日志记录功能的数据库中对 blobspace 中的 blob 进行插入、删除或更新操作时，写入到当前日志文件中的操作记录仅包含该 blob 数据的一个微型表示：即其所在行的 56 字节描述符（56-byte descriptor）。</code></p>
<p>Meanwhile, in the blobspace, the operation has changed the state of a number of blobpages. The blob free-map structures tracking those blobpages are updated to include the current logical log unique ID. Thus, the blob data is not included in, but <em>associated with</em> the log containing its descriptor. Then, when that logical log file is backed up, the appropriate blobpages tag along. (They are actually written to tape before the log is.) The mechanism that determines which blobpages are appropriate for a particular logical log hinges on the <strong>loguniq</strong> values stored in the blob free-map structures.</p>
<p><code>与此同时，在 blobspace 中，这些操作已改变了多个 blobpage 的状态。跟踪这些 blobpage 的 blob free-map structures 会被更新，以包含当前的 logical log unique ID。因此，虽然 blob 数据本身并未被包含在日志文件中，但它却与包含其描述符（descriptor）的日志文件相关联。随后，当该逻辑日志文件被备份时，相应的 blobpage 也会随之一起备份（实际上，它们会在日志文件之前被写入到磁带中）。确定哪些 blobpage 适用于特定逻辑日志的机制，依赖于存储在 blob free-map structures 中的 loguniq（逻辑日志唯一标识符）值。</code></p>
<p><strong>Partition number</strong></p>
<p>This is the partition number of the tblspace that contains the blob data. The purpose of storing this information is to speed the freeing of blobpages when a tblspace is dropped.</p>
<p><code>这是包含 blob 数据的 tblspace 的 partition number。存储此信息的目的是在表空间被删除时，能够加速释放（freeing）相关的 blobpage。</code></p>
<p><strong>Blobpage Addressing</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032147823.png" alt="image-20250603214703763"></p>
<p><strong>Notes:</strong></p>
<p>A blobpage is referred to mainly by its <em>blobpage address</em>, which is close to, but never quite the same as its physical address. For instance, imagine an Informix Dynamic Server system’s third chunk is a blob chunk beginning with five overhead pages. The first blobpage in the chunk has a physical address of 0x00300005 and a blobpage address of 0x00300000. Assume the size of a blobpage in this chunk is 6 x BUFFSIZE. The second blobpage in the chunk has a physical address of 0x0030000b, and a blobpage address of 0x00300001.</p>
<p><code>一个 blobpage 主要通过其 blobpage address 来引用，该地址与它的物理地址相近，但并不完全相同。例如，假设一个 IDS 系统的第3个 chunk 是一个 blob chunk，该 chunk 以五个 overhead pages 开头。该 chunk 中的第一个 blobpage 的物理地址是 0x00300005，而其 blobpage address 是 0x00300000。假设该数据块中一个 blobpage 的大小为 6 倍的 BUFFSIZE（缓冲区大小）。那么，该数据块中的第二个 blobpage 的物理地址是 0x0030000b，而其 blobpage address 是 0x00300001。</code></p>
<p>Like a physical address, a blobpage address is a 4-byte code. The most significant one and a half bytes (3 nibbles) contain the chunk number, and the low order two and a half bytes (5 nibbles) contain the blobpage number.</p>
<p><code>与物理地址类似，一个 blobpage 地址是一个 4 字节（32 位）的编码。其中，最高有效的 1.5 字节（即 3 个半字节，nibble，每个 nibble 为 4 位）包含 chunk 的编号，而最低有效的 2.5 字节（即 5 个半字节）则包含 blobpage 的编号。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506032153800.png" alt="image-20250603215341754"></p>
<p><strong>Viewing a Blobpage</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042159319.png" alt="image-20250604215910188"></p>
<p><strong>Notes:</strong></p>
<p>Unfortunately there is no supported method by which you can display an entire blobspace blobpage, as we have been displaying all other types of pages. The output from <strong>oncheck</strong> <strong>-pP</strong> is more confusing than helpful; it prints only header information, most of which is inaccurate because the header structure on a blobpage is not the one expected by <strong>oncheck -pP</strong>. The only <strong>oncheck</strong> command that displays any blobpage information of value is <strong>oncheck -pD</strong>.</p>
<p><code>遗憾的是，目前并没有受支持的方法能像展示其他所有类型的页面那样，完整显示一个 blobspace 中的 blobpage。oncheck -pP 命令的输出结果不仅没有起到多大帮助，反而令人困惑；它仅打印页头信息，而且其中大部分信息都不准确，这是因为 blobpage 的页头结构并非 oncheck -pP 命令所预期的结构。在所有 oncheck 命令中，唯一能显示有价值 blobpage 信息的命令是 oncheck -pD。</code></p>
<p>Run <strong>oncheck -pD</strong> on your <strong>stores_demo:bsblob</strong> tblspace and pipe the output to <strong>tail -16</strong>. These last 16 lines should be the information for the last home row in your table. Below the hex dump of the blob descriptor, your output should resemble the slide above.</p>
<p><code>对你的 stores_demo:bsblob tblspace 运行 oncheck -pD 命令，并将输出结果通过管道传输给 tail -16。最后这 16 行应该是你表中 home row 的信息。在 blob 描述符的十六进制转储（hex dump）下方，你的输出结果应该与上面的幻灯片内容相似。</code></p>
<p><strong>TBLOB</strong></p>
<p>TBLOB stands for the blob descriptor structure. Here are some useful fields in the TBLOB section.</p>
<p><code>TBLOB 代表的是 blob 描述符结构。以下是 TBLOB 部分中一些有用的字段。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042206692.png" alt="image-20250604220608650"></p>
<p><strong>BLOBPAGE</strong></p>
<p>These fields can be found in the BLOBPAGE section.</p>
<p><code>这些字段可以在 BLOBPAGE 部分中找到。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042209829.png" alt="image-20250604220908771"></p>
<p><strong>Blobspace Behavior: Logging and Backup</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506042210740.png" alt="image-20250604221040674"></p>
<p><strong>Notes:</strong></p>
<p>Blobspace blob data is never written to the logical log files. Instead, Informix Dynamic Server writes minimal reference information about the blobspace blob to the logical log files: the blob descriptor structure from the home row, and any associated blob free-map structures from the blobspace. However, blob data does manage to sneak its way onto the appropriate logical log tape while nobody is watching.</p>
<p><code>Blobspace 中的 blob 数据从来不会被写入逻辑日志文件。相反，IDS 仅将关于 blobspace 中 blob 的最少引用信息写入逻辑日志文件：这些信息包括 home row 中的 blob descriptor structure，以及 blobspace 中与之相关的任何 blob free-map structures。然而，在无人察觉的情况下，blob 数据还是会设法“潜入”到相应的逻辑日志磁带上。</code></p>
<blockquote>
<p>sneak 英[sniːk] 美[sniːk]<br>v.溜;偷走(不重要的或小的东西);偷拿;偷偷地走;偷带;（儿童向成人）打小报告，告状;偷偷地做;<br>n.打小报告的人，告状者(尤指儿童);<br>adj.突然的;出其不意的;</p>
</blockquote>
<p>You might assume that at log backup time, <strong>ontape</strong> determines which blobpages belong with a particular logical log by scanning the log records for descriptor structures, tracking down their blobpages and whisking them off to the tape. But there is a much faster way to do this. </p>
<p><code>你可能会认为，在进行日志备份时，ontape 工具会通过扫描日志记录中的 descriptor structures，来确定哪些 blobpage 属于某个特定的逻辑日志，然后追踪这些 blobpage 并将它们快速传输到磁带上。但实际上，有一种更快的方法可以实现这一目的。</code></p>
<p>Before backing up each log, <strong>ontape</strong> searches the blobpage map for any blobpages, whether used or free, whose <strong>loguniq</strong> (logical log unique ID) matches the log waiting to go to tape. Any blobpages that fit the criteria are sent first, followed by the logical log that presumably contains all the associated blob descriptor structures.</p>
<p><code>在备份每个日志之前，ontape 工具会在 blobpage map 中搜索任何其 loguniq（逻辑日志唯一标识符）与等待写入磁带的日志相匹配的 blobpage，无论这些 blobpage 是已使用状态还是空闲状态。任何符合条件的 blobpage 都会被优先发送，随后才会发送可能包含所有相关 blob descriptor structures 的逻辑日志。</code></p>
<p>This should explain why blobpages that are freed during a delete operation cannot be reused until the current logical log is backed up to tape.</p>
<p><code>这应该能解释为什么在执行删除操作后被释放的 blobpages，在当前逻辑日志备份到磁带之前无法被重新使用。</code></p>
<p>This should also explain why you must switch to the next logical log before writing blob data to a brand new blobspace. Can you make the connection?</p>
<p><code>这也应该能解释为什么在向一个全新的 blobspace 写入 blob 数据之前，必须切换到下一个逻辑日志。你能理清其中的关联吗？</code></p>
<p>When you create a blobspace, a record of the event is written to the current logical log. </p>
<p><code>当你创建一个 blobspace 时，该事件的一个记录会被写入当前的逻辑日志。</code></p>
<p>Now imagine a scenario in which you are allowed to immediately write blob data to the new blobspace.</p>
<p><code>现在设想这样一个场景：你被允许立即向这个全新的 blobspace 写入 blob 数据。</code></p>
<p>When that logical log is backed up, a number of blobpages are written to the tape ahead of the log.</p>
<p><code>当那个逻辑日志被备份时，会有多个 blobpage 在日志之前被写入磁带。</code></p>
<p>If that logical log is applied after the restore of an archive, the blobpages appear on the tape long before the blobspace creation record is applied. As the archive API reads blobpages, it expects to put them somewhere. The current design guarantees that there is always a blobspace in which to put them.</p>
<p><code>如果在恢复一个归档文件之后应用该逻辑日志，那么在 blobspace 创建记录被应用之前很久，blobpage 就已经出现在磁带上了。由于归档文件接口在读取 blobpage 时，期望能将它们放置到某个位置，而当前的设计确保了总有一个 blobspace 可以用来放置这些 blobpage。</code></p>
<p>大概这个意思，按之前说的，备份每个逻辑日志之前，先备 blobpage，所以，即使在这同一逻辑日志里，刚刚新建的 blobspace 这个操作，要在备份 blobspace 之后才备份，所以恢复时，先恢复 blobpage，但此时 blobspace 创建的这个操作还没重做呢。这解释了上边第二个问题。</p>
<p>至于第一个问题 ：“执行删除操作后被释放的 blobpages，在当前逻辑日志备份到磁带之前无法被重新使用”  ，不理解，如果全删了，一直不备份，岂不是所有 blobpage 都用不了了</p>
<p><strong>Advantages of Partition Storage</strong></p>
<p><code>分区存储的优点</code></p>
<p> Small blobs are usually best stored in the tblspace:</p>
<p><code>小的 blob 通常最好存储在 tblspace 中：</code></p>
<p>– PNBLOB pages take advantage of the data cache, traveling through the buffer pool like any other dbspace page.</p>
<p><code>PNBLOB 页会利用数据缓存，像其他任何 dbspace page 一样在缓冲池中传递。</code></p>
<p>– PNBLOB pages can store more than one blob piece.</p>
<p><code>PNBLOB 页可以存储多个 blob 片段。</code></p>
<p> PNBLOB pages are physically logged, so there are no special archiving issues</p>
<p><code>PNBLOB 页会进行物理日志记录，因此不存在特殊的归档问题</code></p>
<p> PNBLOB pages are truly updated. It is not necessary to have double the space available for a blob that is being modified</p>
<p><code>PNBLOB 页确实会被真正更新。对于正在修改的 blob，无需预留双倍的空间。</code></p>
<p>突然蹦出来个 PNBLOB 莫名其妙，看不懂</p>
<p><strong>Notes:</strong></p>
<p>Some of the advantages of storing blobs in a tblspace as opposed to a blobspace are listed above.</p>
<p><code>上述内容列出了将 blobs 存储在 tblspace 而非 blobspace 中的一些优势。</code></p>
<p><strong>Advantages of Blobspace Storage</strong></p>
<p>Large blobs are usually best stored in a blobspace when:</p>
<p><code>以下情况通常最好将 blobs 存储在 blobspace 中：</code></p>
<p>– The unit of storage is configurable, at the blobspace level, in multiples of the server page size. A properly configured blob page size could mean more efficient I&#x2F;O and far fewer locks per blob operation.</p>
<p><code>存储单元在 blobspace 级别是可配置的，其大小以 server page size 的整数倍为单位。适当配置 blob page size 可能意味着更高效的输入/输出（I/O）操作，以及每个 blob 操作所需的锁数量大幅减少。</code></p>
<p>– Blobspace blob data is written directly to disk, which can be more efficient for large blobs.</p>
<p><code>blobspace 中的 blob 数据会直接写入磁盘，这对于大型二进制大对象而言可能更为高效。</code></p>
<p>– Only blob free-map pages and blob descriptors are logged, so logs do not fill up as quickly as they might with PNBLOBs.</p>
<p><code>只有 blob 的 free-map pages 和 blob descriptors 会被记录到日志中，因此与使用 PNBLOBs 的情况相比，日志不会那么快被填满。</code></p>
<p>– The same goes for physical logging. PNBLOBs can cause so much physical logging that checkpoints are triggered prematurely.</p>
<p><code>物理日志记录的情况也是如此。PNBLOBs 可能会导致大量的物理日志记录，从而过早触发检查点（checkpoints）。</code></p>
<p><strong>Notes:</strong></p>
<p>A good rule for deciding whether a blob should be stored in a blobspace or in with the tblspace is this: if the average blob size for a table is greater than two pages, store it in a blobspace. If the average blob size is less than one-half of a page, store it in the tblspace. Blobs that are generally in between these sizes, or blobs that are highly variable in size pose a more difficult decision and might require benchmark tests to determine the more efficient storage method.</p>
<p><code>以下是一个用于决定 blob 应存储在 blobspace 还是 tblspace 中的良好准则：如果表中 blob 的平均大小超过两页，则将其存储在 blobspace 中；如果平均大小小于半页，则将其存储在 tblspace 中。对于大小通常介于这两者之间的二进制 blob，或者大小高度可变的二进制大对象，做出决定则更为困难，可能需要进行基准测试以确定更高效的存储方法。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/6"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/01/IX9111/6/"
    >IX9111 - Unit 6. Fragmented Tables and Indexes</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/01/IX9111/6/" class="article-date">
  <time datetime="2025-06-01T15:25:44.000Z" itemprop="datePublished">2025-06-01</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>System Catalog</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506012328374.png" alt="image-20250601232814236"></p>
<p><strong>Notes:</strong></p>
<p>A table or index that is not fragmented is confined to a single dbspace and has only one partition page in the tblspace tblspace for that dbspace. In a <em>fragmented</em> table, the physical data for the table is distributed across multiple dbspaces. Each dbspace contains a fragment of that table, and each fragment has its own partition page. The partnum for each fragment is stored in the <strong>partn</strong> column of the <strong>sysfragments</strong> system catalog. Because it uniquely identifies each fragment, the <strong>sysfragments.partn</strong> value is sometimes known as the <em>fragid</em>. The <strong>partnum</strong> column in <strong>systables</strong> is zero (0) for tables and indexes that are fragmented.</p>
<p><code>未分片的表或索引仅局限于单个 dbspace，且在该 dbspace 对应的 tblspace 中仅有一个分区页。而在分片表中，表的物理数据会分布在多个 dbspace 中。每个 dbspace 包含该表的一个分片，且每个分片都有自己独立的分区页（partition page）。每个分片的分片号（partnum）存储在系统目录表 sysfragments 的 partn 列中。由于该值能唯一标识每个分片，因此 sysfragments.partn 的值有时也被称为分片标识符（fragid）。对于已分片的表和索引，systables 表中的 partnum 列值为零（0）。</code></p>
<p><strong>Checking Tblspaces: oncheck -pt&#x2F;-pT</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022044772.png" alt="image-20250602204354649"></p>
<p><strong>Notes:</strong></p>
<p>The <strong>oncheck -pT</strong> command (or <strong>oncheck -pt</strong>) lists each fragment separately. The information about pages allocated, pages used, data pages, rows, and the partition partnum is for the fragment currently listed. The <strong>oncheck -pT</strong> command is an excellent way to monitor the size and use of an individual fragment.</p>
<p><code>oncheck -pT 命令（或 oncheck -pt）会单独列出每个片段（fragment）。对于当前列出的片段，它会显示已分配页数（pages allocated）、已使用页数（pages used）、数据页数（data pages）、行数（rows）以及分区标识号（partition partnum）等信息。oncheck -pT 命令是监控单个片段大小和使用情况的绝佳工具。</code></p>
<p>Notice in the example that the <strong>partition lockid</strong> is now different from the <strong>Partition</strong> <strong>partnum</strong>. The oncheck report shows that each fragment of a table or index has a different partnum value, but they all have the same lockid value.</p>
<p><code>请注意，在示例中，分区锁标识号（partition lockid）现在与分区标识号（Partition partnum）不同。oncheck 报告显示，表或索引的每个片段都有不同的 partnum 值，但它们的 lockid 值都相同。</code></p>
<p><strong>Partition Layout</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022151315.png" alt="image-20250602215113216"></p>
<p><strong>Notes:</strong></p>
<p>Each fragment has its own bitmap page on logical page 0. The rest of the pages (except for additional bitmap pages) contain data for the fragment.</p>
<p><code>每个片段在逻辑页 0 上都有其自己的位图页（bitmap page）。其余的页（除了额外的位图页）都包含该片段的数据。</code></p>
<p><strong>Indexes in a Fragmented Table</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022153517.png" alt="image-20250602215300455"></p>
<p><strong>Notes:</strong></p>
<p>Any indexes built on a fragmented table are stored in their own separate partitions. There is no case in which a table fragment has data pages and index pages intermingled.</p>
<p><code>在分片表上创建的任何索引都存储在它们各自独立的分区（partition）中。不存在表片段的数据页和索引页相互混杂的情况。</code></p>
<p>The number of index fragments built depends on how the administrator created the index with the CREATE INDEX statement. If the CREATE INDEX statement does not include the FRAGMENT clause, the index is fragmented in the same way as the table and there is one index partition for every data partition (as shown in the example above). You can also specify a unique fragmentation strategy for the index, or you can store the entire index in a separate dbspace.</p>
<p><code>所构建的索引片段数量取决于管理员如何使用 </code>CREATE INDEX<code> 语句来创建索引。如果 CREATE INDEX 语句中未包含 FRAGMENT 子句，那么索引将按照与表相同的方式进行分区，即每个数据分区对应一个索引分区（如上例所示）。此外，你也可以为索引指定一种独特的分区策略，或者将整个索引存储在一个单独的数据库空间（dbspace）中。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022157326.png" alt="image-20250602215758277"></p>
<p><code>在 IDS 的早期版本中，非分片表（non-fragmented tables）的索引页和数据页位于同一个表空间（tblspace）中。</code></p>
<p><strong>The Index Entry</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202506022200964.png" alt="image-20250602220001908"></p>
<p><strong>Notes:</strong></p>
<p>If a table is fragmented and the index is not fragmented the same way as the table, the rowid is no longer sufficient to locate a row. Why? Because the rowid describes a logical page and slot number within a partition, but not the partition. In a non-fragmented table, there is only one partition per table; a fragmented table has multiple partitions.</p>
<p><code>如果表被分片了，而索引却没有按照与表相同的方式进行分区，那么 rowid 就不再足以定位一行数据了。这是为什么呢？因为 rowid 描述的是 partition 内的一个逻辑页和槽位号，但它并不包含 partition 信息。在非分片表中，每个表只有一个 partition；而在分区表中，一个表会有多个 partition。</code></p>
<p>As you might have guessed, the additional piece of information that must be included in the index entry is the partition number. This is why an index for a fragmented table could be much larger than an index for a non-fragmented table.</p>
<p><code>正如你可能已经猜到的，索引条目中必须包含的额外信息就是分区号（partition number）。这就是为什么分片表的索引可能比非分片表的索引大得多的原因。</code></p>
<p>When an index and a table are fragmented identically, the index does not require the partition number to locate a row because the server knows that rowids referenced in an index partition refer to rows in corresponding table partitions on the same dbspace.</p>
<p><code>当索引和表以相同的方式进行分片时，索引不需要使用分区号（partition number）来定位一行数据，因为 server 知道索引分区中引用的 rowid 指的是与该索引分区（index partition）位于同一数据库空间（dbspace）的对应表分区（partition）中的行。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/5"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/05/25/IX9111/5/"
    >IX9111 - Unit 5. Index Architecture</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/05/25/IX9111/5/" class="article-date">
  <time datetime="2025-05-25T13:12:33.000Z" itemprop="datePublished">2025-05-25</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>163 - 167 页讲 <strong>B-Tree</strong>，跳过</p>
<p><strong>B+ Trees</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505252131910.png" alt="image-20250525213144822"></p>
<p><strong>Notes:</strong></p>
<p>The ability to move right or left from a node to its adjacent node puts the <em>plus</em> in B+ tree. All Informix Dynamic Server indexes are B+ trees.</p>
<p><code>从某个节点能够向左或向右移动到其相邻节点的能力，为B+树赋予了其特有的优势（这里的“plus”即指B+树相较于B树等结构的增强特性）。所有 IDS 的索引都是采用B+树结构实现的。</code></p>
<p><strong>Node contents</strong></p>
<p>A node page consists of slots, just as data pages do. A slot table is necessary on an index page because slots can vary in size, <em>not</em> because slots are accessed randomly. Unlike data rows, the slots on an index page are always read sequentially. Therefore, there is no rowid-type address that refers to a particular slot on a particular index node. This means an index page is not limited to 255 slots; it can contain as many slots as will fit. </p>
<p><code>node page 由 slots 组成，这一点与数据页（data pages）相同。索引页（index page）上需要一个 slot table，这是因为 slot 的大小可能各不相同，并非因为槽是随机访问的。与数据行（data rows）不同，索引页上的槽总是按顺序读取的。因此，不存在指向特定索引节点上特定 slot 的 rowid 类型的地址。这意味着索引页并不局限于255个 slot；它可以包含尽可能多的 slot，只要这些 slot 能够容纳得下。</code></p>
<p>Though they can vary greatly in size, every slot in a node page is essentially the same structure: a key value followed by a series of references. (A unique index has only one reference per key.) Each reference <em>points down</em> to another part of the tree. The type of reference depends on the index level occupied by the node.</p>
<p><code>尽管 node page 中的每个 slot 在大小上可能存在很大差异，但它们本质上具有相同的结构：一个键值（key value）后面跟着一系列引用（references）。（唯一索引（unique index）中，每个键值仅对应一个引用。）每个引用都指向树中的另一部分。引用的类型取决于节点在索引层级中所处的位置。</code></p>
<p><strong>Questions</strong></p>
<p>How do Dynamic Server nodes point down? </p>
<p><code>Dynamic Server节点是如何向下指向的？</code></p>
<p>A node points down either to data rows that are referenced by rowid, or to nodes that are referenced by logical page number.</p>
<p><code>一个节点要么向下指向通过 rowid 引用的数据行，要么向下指向通过逻辑页号（logical page number）引用的其他节点。</code></p>
<p>How do Dynamic Server nodes point across?</p>
<p><code>Dynamic Server节点是如何横向指向（或相互连接）的？</code></p>
<p>Here is where those omnipresent <strong>pg_next</strong> and <strong>pg_prev</strong> elements in the Dynamic Server page header come in. Picture an index node whose logical page number is 0x9, and whose adjacent node to the right is logical page 0x4a. In the header of node 0x9, <strong>pg_next</strong> is 0x4a. In the header of node 0x4a, <strong>pg_prev</strong> is 0x9. (An index page’s <em>node</em> <em>number</em> is simply its logical page number.)</p>
<p><code>这时，Dynamic Server页头中无处不在的 pg_next 和 pg_prev 元素就派上用场了。想象一下，有一个索引节点，其逻辑页号为0x9，而其右侧的相邻节点的逻辑页号为0x4a。在节点0x9的页头中，pg_next 的值就是0x4a。同样，在节点0x4a的页头中，pg_prev 的值就是0x9。（索引页的 node number 实际上就是其逻辑页号。）</code></p>
<p><strong>The Tree After Clustering the Index</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505252154178.png" alt="image-20250525215457105"></p>
<p><strong>Notes:</strong></p>
<p>Although index nodes might in reality be scattered haphazardly throughout the table, they are always drawn in their idealized B+ tree arrangement. The data pages to which they refer, however, have been drawn in previous slides as they would likely be arranged physically on disk, in an order unrelated to the index.</p>
<p><code>尽管索引节点在实际存储中可能零散分布在表的各处，但在图示中，它们始终以理想的B+树结构呈现。而它们所指向的数据页（如前几页幻灯片所示），则更接近磁盘上的物理存储排列方式，其顺序与索引逻辑无关。</code></p>
<p>Clustering the index temporarily changes the picture as shown. Although the index nodes could have shifted around physically in the rewritten table, by definition the B+ tree picture stays the same. But the data pages are now physically rearranged such that their true order is the ideal order.</p>
<p><code>聚簇索引会暂时改变图示的存储布局。尽管在表重写后，索引节点的物理位置可能已发生变动，但根据定义，其B+树的逻辑结构保持不变。而此时，数据页会按索引的理想顺序重新物理排列，使得实际存储顺序与逻辑顺序完全一致。</code></p>
<p>Of course, forcing the data pages to fit nicely into this picture does more than make the slide easier to read. It can improve the efficiency of the index&#x2F;data combination by reducing the amount of I&#x2F;O when scanning for a range of values, and reducing the expense of the I&#x2F;O that is performed.</p>
<p><code>当然，将数据页强制对齐到这种理想布局的作用远不止让幻灯片更易读。它还能通过减少范围扫描时的I/O操作量，以及降低所执行I/O操作的开销，来提高索引与数据组合的效率。</code></p>
<p><strong>A One-Level Index</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262025860.png" alt="image-20250526202545746"></p>
<p><strong>Notes:</strong></p>
<p>An Informix Dynamic Server index that refers to a small number of data rows requires only one node, and therefore only one node level: the root. The root node alters the structure of its contents to point directly to data rows instead of to nodes.</p>
<p><code>对于一个引用少量数据行的 IDS 索引而言，它仅需一个节点，因此也只有一个节点层级，即根节点。该根节点会调整其内容结构，使其直接指向数据行，而非指向其他节点。</code></p>
<p><strong>A Two-Level Index</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262028127.png" alt="image-20250526202809034"></p>
<p><strong>Notes:</strong></p>
<p>In order to show all the named levels of a B+ tree (root, branch, leaf), we have been picturing 3-level indexes all along. But an Informix Dynamic Server index that refers to a moderate number of data rows (roughly between 300 and 100,000) requires only two node levels: root and leaf.</p>
<p><code>为了展示 B+ 树中所有命名的层级（根节点、分支节点、叶子节点），我们一直以来都以三层索引为例进行说明。然而，对于一个引用中等数量数据行（大约在 300 行到 100,000 行之间）的 IDS 索引而言，它仅需要两个节点层级：根节点和叶子节点。</code></p>
<p><strong>The Generic Index Node</strong></p>
<p><img src="C:\Users\49491\AppData\Roaming\Typora\typora-user-images\image-20250526203330803.png" alt="image-20250526203330803"></p>
<p><strong>Notes:</strong></p>
<p>Index nodes come in several different flavors, but there are many things that can be said about them in general. </p>
<p><code>索引节点有几种不同的类型，但总体而言，关于它们有很多可以阐述的共性内容。</code></p>
<p>Perhaps you can see from the slide above that an Informix Dynamic Server index node is structured similarly to a data page. Each slot on the page is described by one 4-byte slot table entry, which, as usual, contains a byte offset into the page and a length. But where each slot on a data page stores a row of data, each slot on an index node contains an <em>index entry</em>. </p>
<p><code>或许你可以从上面的幻灯片中看到，IDS 的索引节点结构与数据页的结构类似。页上的每个 slot 都由一个 4 字节的 slot table 条目来描述，该条目像往常一样，包含指向页内的字节偏移量和长度信息。不过，数据页上的每个 slot 存储的是一行数据，而索引节点上的每个 slot 则包含一个索引条目。</code></p>
<p>There are two types of index entries: <em>leaf-type entries</em> and <em>twig-type entries</em>, but they do not mix; all nodes on a particular level of the index have either leaf-type or twig-type entries. We will describe the structure of each entry type on the next few pages.</p>
<p><code>索引条目有两种类型：叶子类型条目（leaf-type entries）和枝节点类型条目（twig-type entries），但它们不会混合存在；索引中特定层级的所有节点要么只包含叶子类型条目，要么只包含枝节点类型条目。在接下来的几页中，我们将分别描述每种条目类型的结构。</code></p>
<blockquote>
<p>twig 英[twɪɡ] 美[twɪɡ]<br>n.细枝;嫩枝;小枝;<br>v.(突然地)懂得，理解，明白，意识到;</p>
</blockquote>
<p><strong>Page Flags for Index Pages</strong></p>
<p>Index page flags:</p>
<p>– 0x10 – B-tree node (on for all B-tree node types)</p>
<p>– 0x20 – Root node</p>
<p>– 0x40 – Branch (or twig) node</p>
<p>– 0x80 – Leaf node</p>
<p>And here is how they combine on real nodes:</p>
<p>– 0x30 – Root node</p>
<p>– 0x50 – Branch node</p>
<p>– 0x70 – Root node; also acting as a twig (two-level index)</p>
<p>– 0x90 – Leaf node</p>
<p>– 0xb0 – Root node; also acting as a leaf (one-level index)</p>
<p><strong>Notes:</strong></p>
<p>The page flags on a node reveal the index level it occupies. The flags shown above are specific to index pages.</p>
<p><code>节点上的页标志（page flags）揭示了该节点在索引中所处的层级。上述所示的标志是专门针对索引页的。</code></p>
<blockquote>
<p>occupy 占据 英[ˈɒkjupaɪ] 美[ˈɑːkjupaɪ]</p>
<p>reveal 揭示 英[rɪˈviːl] 美[rɪˈviːl]</p>
</blockquote>
<p>Every index page has the first flag (0x10) set. And, depending upon the role the node plays in the index, it has one or more additional flags. For example, in a small index, the root node can also be a leaf node (giving it a flag setting of 0xb0, or 0x10 + 0x20 + 0x80).</p>
<p><code>每个索引页都会设置第一个标志位（0x10）。此外，根据节点在索引中所扮演的角色，它还会设置一个或多个额外的标志位。例如，在一个小型索引中，根节点也可以同时是叶子节点（此时其标志位设置为 0xb0，即 0x10 + 0x20 + 0x80）。</code></p>
<p><strong>The Root-Leaf Node</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262050829.png" alt="image-20250526204942852"></p>
<p><strong>Notes:</strong></p>
<p>Let us look closely at the root node of a one-level index.</p>
<p><code>让我们仔细研究一下单层索引的根节点。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262201528.png" alt="image-20250526220154376"></p>
<p><code>除了页类型为 0xb0（表示该页既是节点页，又是根节点页，还是叶子节点页）且没有相邻的兄弟节点之外，它的结构与叶子节点完全相同，每个 slot 中都包含一个叶子类型的条目。</code></p>
<p>Each leaf-type entry, also known as an <em>index item</em>, contains the following components:</p>
<p><code>每个叶子类型的条目，也称为索引项（index item），包含以下组成部分：</code></p>
<p> <strong>•</strong> A key value.</p>
<p> <strong>•</strong> One or more rowids. A duplicate index can have multiple rowids in a leaf-type entry. A unique index can have only one rowid per entry. The index page shown in the example above must be a duplicate index, because the third index item has two rowids.</p>
<p><code>一个或多个rowid。在重复索引（duplicate index）中，一个叶子类型的条目可以包含多个 rowid；而在唯一索引（unique index）中，每个条目只能包含一个 rowid。上述示例中展示的索引页必定是一个重复索引，因为第三个索引项中包含两个行标识符。</code></p>
<blockquote>
<p>gemini</p>
<p>“duplicate index”（或者更准确地说，是 “允许重复值的索引” 或 “非唯一索引”）指的是<strong>索引列中允许存在重复值</strong>的索引。</p>
</blockquote>
<p><strong>•</strong> A delete flag (<strong>df</strong>) for each rowid listed. Rather than deleting a key value immediately, Informix Dynamic Server marks it as deleted by setting the delete flag to 1. The delete flag is only operational if the database is logged and the table is not locked in EXCLUSIVE MODE.</p>
<p><code>对于列出的每个rowid，都有一个删除标志(df）。IDS 不会立即删除键值，而是通过将删除标志设置为 1 来标记该键值为已删除。不过，删除标志仅在数据库处于日志记录模式（logged）且表未以独占模式（EXCLUSIVE MODE）锁定的情况下才会生效。</code></p>
<p>Except for data rows whose indexed column is null, each row in the tblspace has exactly one corresponding item in the index. Add another index to the tblspace, and the same rule applies to that index.</p>
<p><code>除了那些索引列值为 NULL 的数据行之外，表空间（tblspace）中的每一行在索引中都有且仅有一个对应的条目。如果再为该表空间添加一个索引，那么同样的规则也适用于这个新索引。</code></p>
<p><strong>Term review</strong></p>
<p>These many similar index terms have probably begun to get confusing. An Informix Dynamic Server index is made of index pages, called <em>nodes</em>. Index nodes contain <em>index</em> <em>entries</em>: one per slot. There are two types of index entries. The entry type found on the last level of an index is called a <em>leaf-type entry</em>. Leaf-type entries have a slightly different structure than do <em>twig-type entries</em>, which are found on all non-leaf levels of an index. We will describe the structure of twig-type entries in a few pages.</p>
<p><code>如此众多的相似索引术语可能已开始让人感到困惑。IDS 的索引由索引页构成，这些索引页被称为 节点。索引节点包含 索引条目，每个 slot 对应一个索引条目。索引条目分为两种类型。位于索引最后一层的条目类型称为 叶型条目。叶型条目的结构与位于索引所有非叶层的 枝型条目 略有不同。我们将在后续几页中介绍枝型条目的结构。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505262247826.png" alt="image-20250526224716736"></p>
<p><code>尽管上面准确描绘了每个 4 字节 rowid 的大小，但所显示的 key 值大小（3 字节）是随意选定的。</code></p>
<p><strong>The Root-Leaf Node: oncheck –pp Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272039907.png" alt="image-20250527203900751"></p>
<p><strong>Notes:</strong></p>
<p>Above is a real output from <strong>oncheck -pp</strong>, which is equivalent to the picture on the previous slide. The meaning of each slot on this particular root node should be clear. In this case, the indexed column is apparently a CHAR(3). Each key is stored in a separate slot in order of its value. A series of rowids is included in the same slot as the key value.</p>
<p><code>以上是 oncheck -pp 的实际输出结果，其内容与上一张幻灯片中的图片等效。对于这个特定根节点上的每个 slot，其含义应当十分清晰。在此例中，被索引的列显然是一个 CHAR(3) 类型。每个键值都按其数值顺序存储在单独的slot中。而与键值处于同一 slot 的，还有一系列的 rowid。</code></p>
<p>The first index entry in the output indicates that rowid 0x201 (the data row on logical page 2, slot 1) contains the character <strong>A</strong> in the indexed column.</p>
<p><code>输出结果中的第一条索引条目表明，rowid 为 0x201（位于逻辑页 2 的 slot 1 的数据行）在被索引列中包含字符 A。</code>(0x41 -&gt; 97 -&gt; A)</p>
<p>The third index entry indicates that two rows in the table contain the character <strong>C</strong> in the indexed column: one in slot 3 on page 2, and one in slot 4 on the same page.</p>
<p><code>第三条索引条目表明，表中有两行数据在被索引列中包含字符 C：一行位于第 2 页的 slot 3，另一行位于同一页的 slot 4。</code></p>
<p><strong>Key Value Storage</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272049916.png" alt="image-20250527204923813"></p>
<p><strong>Notes:</strong></p>
<p>Key values in indexes are compared as binary entities, which makes the key comparison algorithm much quicker and more versatile. For example, key values that you and I happen to know are integers are not compared as integers, but as a series of 4 bytes:</p>
<p><code>索引中的键值是以二进制实体的形式进行比较的，这使得键值比较算法更为迅速且通用。例如，你我恰好都知道是整数的那些键值，在比较时并不会被当作整数处理，而是被当作一系列的 4 字节数据来进行比较：</code></p>
<p>Steps required to compare 0x12345678 with 0x12345679:</p>
<ol>
<li><p>0x12 vs. 0x12 (No winner. We will have to keep comparing.)</p>
</li>
<li><p>0x34 vs. 0x34 (Still no winner. Maybe next time.)</p>
</li>
<li><p>0x56 vs. 0x56 (Will this ever end?)</p>
</li>
<li><p>0x78 vs. 0x79 (Aha! The second stream of bytes is greater.)</p>
</li>
</ol>
<p>The byte comparisons stop as soon as one of the two byte streams wins a comparison.</p>
<p><code>一旦两个字节流中的某一个在比较中胜出，字节比较就会立即停止。</code></p>
<p>Now, without some intervention, this algorithm would not work at all when comparing negative integers with positive ones, because of the way signed integers are normally stored in computer memory.</p>
<p><code>现在，如果不进行某种干预，在比较负整数与正整数时，这个算法将完全无法正常工作，这是因为有符号整数在计算机内存中通常的存储方式所致。</code></p>
<p><strong>Storing Integers in Columns: The Sign Bit</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272058161.png" alt="image-20250527205856071"></p>
<p><strong>Notes:</strong></p>
<p>At the binary level, all integer values look positive. Bits are either on (1) or off (0). It is impossible to make a bit less than off, though no doubt someone has tried. For now, at least, negative values are represented using software tricks and storage conventions.</p>
<p><code>在二进制层面上，所有的整数值看起来都是正数。比特位要么是 1，要么是 0。要让一个比特位处于比 0 更小是不可能的。至少在目前，负值是通过软件技巧和存储约定来表示的。</code></p>
<p>Early on it was decided that in order to represent signed numbers in binary, the most significant bit would be used as a flag called the <em>sign bit</em>.</p>
<p><code>早期人们就决定，为了在二进制中表示有符号数，将使用最高有效位作为标志位，称为符号位。</code></p>
<p>For negative numbers, the sign bit is <em>on</em>. For positive numbers, the sign bit is <em>off</em>. The price of this trick is paid in storage capacity. For example, sacrificing the most significant bit for use as a sign bit reduces the highest possible positive value of a 4-byte integer from 0xffffffff (4,294,967,295) to 0x7fffffff (2,147,483,647).</p>
<p><code>对于负数，符号位是1。对于正数，符号位是0。这种技巧的代价体现在存储容量上。例如，将最高有效位牺牲用作符号位后，一个4字节整数的最大可能正数值就从0xffffffff（即4,294,967,295）减少到了0x7fffffff（即2,147,483,647）。</code></p>
<p>There is still more to this storage method than you might think, however. Although intuition might tell you that -2147483647 is the sign bit turned <em>on</em> for the value 2147483647, and would therefore be stored as 0xffffffff, in fact 0xffffffff is the value -1. To most computer chips, signed arithmetic is a much cleaner operation if the <em>odometer flips over</em> when you add 1 to -1:</p>
<p><code>然而，这种存储方法背后的细节比你想象的要更多。尽管直觉可能会告诉你，-2147483647 是将 2147483647 的符号位开启后得到的值，因此可能会被存储为 0xffffffff，但实际上 0xffffffff 表示的是 -1。后边略。</code></p>
<p>Getting back to the problem this storage method would cause our comparison algorithm, let us say we were trying to determine whether -1 was greater than 1. Obviously it is not. But as shown above, the integer value 1 is stored in computer memory as 0x00000001, whereas the integer value -1 is stored as 0xffffffff. If we stored these values the same way in our index, a comparison would come out heavily on the side of -1.</p>
<p><code>回到这种存储方法给我们比较算法带来的问题上，假设我们试图判断 -1 是否大于 1。显然，它并不大于 1。但如上所述，整数值 1 在计算机内存中是以 0x00000001 的形式存储的，而整数值 -1 则是以 0xffffffff 的形式存储的。如果我们在索引中以同样的方式存储这些值，那么在进行比较时，结果会严重偏向于认为 -1 更大。</code></p>
<p><strong>So what goes into our index?</strong></p>
<p>The problem is solved by simply toggling the sign bit before we store the value in the key. A negative integer is stored in an index key with its sign bit turned <em>off</em>, and a positive integer has its sign bit turned <em>on</em>. For example the value -1, stored in the data row as 0xffffffff, is stored in the index as 0x7fffffff. The value 1, stored in the data row as 0x00000001, is stored in the index as 0x80000001. Now, as a byte stream, 1 beats -1 every time, and translating the key value back into an integer is just a matter of toggling the sign bit again.</p>
<p><code>这个问题可以通过在将值存入键之前简单翻转符号位来解决。在索引键中，负整数以其符号位0的形式存储，而正整数则以其符号位1的形式存储。例如，在数据行中以 0xffffffff 形式存储的值 -1，在索引中则以 0x7fffffff 的形式存储。同样，在数据行中以 0x00000001 形式存储的值 1，在索引中则以 0x80000001 的形式存储。现在，作为字节流来看，1 在每次比较中都会胜过 -1，而将键值转换回整数，也只需再次翻转符号位即可。</code></p>
<p><strong>The Root Node</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272119410.png" alt="image-20250527211936330"></p>
<p><strong>Notes:</strong></p>
<p>The vast majority of root nodes do not lead double lives as leaves. Most real indexes have more than one level, which means that a root node normally points down to other nodes, not to data rows. The page flags on the index node pictured above indicate this is simply a root node.</p>
<p><code>绝大多数根节点并不会同时作为叶子节点存在。大多数真实的索引结构都不止一层，这意味着根节点通常会指向其他节点，而不是直接指向数据行。上图所示索引节点上的页面标志表明，这仅仅是一个根节点(30)。</code></p>
<p>The structure of each slot on this page, also called a t<em>wig-type entry</em>, is similar to the structure of a leaf-type entry; a key value is followed by a 4-byte reference. But there are important differences. For instance, in this case the reference is to a node number, which is simply the logical page number of another index node. (One cannot tell from the data on this page whether the node numbers refer to branch nodes or leaf nodes.) </p>
<p><code>此页面上每个slot（也称为枝型条目）的结构与叶型条目的结构相似；一个键值后面跟着一个 4 字节的引用。但二者之间存在重要差异。例如，在这种情况下，该引用指向一个节点编号，而这个节点编号仅仅是另一个索引节点的逻辑页号。（仅凭此页面上的数据，无法判断这些节点编号指的是分支节点还是叶节点。）</code></p>
<p>An odd variety of the twig-type entry is shown on this slide: a key-less last slot, a.k.a. the <em>mini-slot</em> or <em>infinity slot</em>. The node number contained in the infinity slot leads to key values that are not infinite, but are nonetheless greater than any key value on this index level. The last slot on each non-leaf level of an index is a mini-slot.</p>
<p><code>本幻灯片展示了一种特殊的枝型条目变体：无键值的最后一个 slot，也被称为 mini slot 或 infinity slot。infinity slot 中包含的节点编号指向的键值并非无穷大，但这些键值仍大于本索引层级上的任何其他键值。索引结构中每个非叶层级的最后一个 slot 都是 mini-slot。</code></p>
<p><strong>The Root Node: oncheck -pp Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505272138164.png" alt="image-20250527213817050"></p>
<p><strong>Notes:</strong></p>
<p>Above is the <strong>oncheck -pp</strong> output for a real root node. Translating what we find here, we know that:</p>
<p><code>以上是针对一个真实根节点的 oncheck -pp 命令输出结果。解读我们在这里发现的信息，我们可以得知：</code></p>
<ol>
<li><p>Node 0x6 leads to all keys with a value less than or equal to <strong>LLLLLLLL</strong>.</p>
<p><code>节点 0x6 指向所有键值小于或等于 LLLLLLLL 的条目。</code></p>
</li>
<li><p>Node 0xb leads to all keys with a value greater than <strong>LLLLLLLL</strong>, and less than or equal to <strong>aaaaaaaa</strong>.</p>
<p><code>节点 0xb 指向所有键值大于 LLLLLLLL 且小于或等于 aaaaaaaa 的条目。</code></p>
</li>
<li><p>Node 0x5 leads to keys that are greater than <strong>aaaaaaaa</strong>, and less than or equal to <strong>mmmmmmmm</strong>.</p>
<p><code>节点 0x5 指向所有键值大于 aaaaaaaa 且小于或等于 mmmmmmmm 的条目。</code></p>
</li>
<li><p>Node 0x9 leads to keys greater than <strong>mmmmmmmm</strong>, and less than or equal to <strong>ssssssss</strong>.</p>
<p>略</p>
</li>
<li><p>Since this is the right-most node in level 0 (being the only node in level 0), its last slot contains a node number without a key, whose value is assumed to be infinite. The node number specified in the level-0 mini-slot leads to real key values, all of which are greater than <strong>ssssssss</strong>.</p>
<p><code>由于这是第 0 层（也是唯一一层节点所在的层级）中最右边的节点，因此其最后一个 slot 包含一个不带键值的节点编号，该编号的值被假定为无穷大。第 0 层 mini-slot 中指定的节点编号指向实际的键值，这些键值均大于 ssssssss。</code></p>
</li>
</ol>
<p><strong>The Branch Node</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282107467.png" alt="image-20250528210710325"></p>
<p><strong>Notes:</strong></p>
<p>By definition, a branch node always points down to other nodes. Branch nodes have a page flag value of 0x50, and contain twig-type index entries.</p>
<p><code>根据定义，分支节点（branch node）始终向下指向其他节点。分支节点的页标志（page flag）值为 0x50，并且包含枝状（twig-type）类型的索引条目。</code></p>
<p>The basic twig-type entry is structured as follows:</p>
<p><code>基本的枝状（twig-type）类型条目的结构如下：</code></p>
<p>​		<em>key_value</em> <em>node_number</em></p>
<p>The <em>key_value</em> is the same size as the key column value. The node number is 4 bytes.</p>
<p><code>key_value 的大小与 key column value 相同。节点编号（node number）为 4 字节。</code></p>
<p><strong>The Branch Node With Duplicates</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282113914.png" alt="image-20250528211344798"></p>
<p><strong>Notes:</strong></p>
<p>A duplicate index that contains many items (rowids) per key might contain several leaf nodes per key. In this case, the twig-type entries in the branch nodes above those leaves have to contain more than one reference to a node number. A twig-type entry referencing three leaf nodes, all of which contain items (rowids) for the same key value, looks like this:</p>
<p><code>对于每个 key 包含多个 rowid 的 duplicate index 而言，每个 key 可能包含多个叶子节点。在这种情况下，位于这些叶子节点上方的分支节点中的枝状类型条目必须包含对多个节点编号的引用。一个引用三个叶子节点的枝状类型条目（这三个叶子节点都包含针对同一键值的条目（rowids）如下所示：</code></p>
<p>​		key value|<strong>rowid</strong>|<strong>node number</strong>|rowid|node number|node number</p>
<p>This is the last rowid stored on this node number.</p>
<p><code>这是存储在该节点编号上的最后一个 rowid。</code></p>
<p>Note that at the leaf level, all rowids associated with a particular key value are sorted. The rowids mentioned in a twig-type entry like the one shown above, therefore, increase in value as you scan right, and Informix Dynamic Server can assume that the last node number in the entry contains rowids that are all greater than the last rowid in the entry.</p>
<p><code>需要注意的是，在叶子层级，与特定键值相关联的所有 rowid 都是经过排序的。因此，在像上面所示的那种枝状类型条目中提及的 rowid，在从左到右扫描时会呈现递增趋势。IDS 可以据此假定，条目中的最后一个节点编号所包含的 rowid，其值均大于该条目（先前部分）中最后一个 rowid 的值。</code></p>
<p><strong>The Branch Node: oncheck -pp Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282132688.png" alt="image-20250528213209595"></p>
<p><strong>Notes:</strong></p>
<p>Above is the <strong>oncheck -pp</strong> output for a branch node. Analyzing what we find in the first slot, we can tell that:</p>
<p><code>以上是针对一个分支节点执行 oncheck -pp 命令后输出的结果。通过分析第一个 slot 中的信息，我们可以得出以下结论（或可判断出以下情况） 。</code></p>
<ol>
<li><p>Key value <strong>a</strong> can be found in quite a few data rows. A total of 5 nodes below this one are filled with rowids associated with the key value <strong>a</strong>.</p>
<p><code>键值 a 出现在许多数据行中。与该键值 a 相关联的 rowids 填满了其下方的总共 5 个节点。</code></p>
</li>
<li><p>Node 0x5 contains the lowest-valued rowids for the key. The last and greatest-valued rowid on that node is 0x8421.</p>
<p><code>节点 0x5 包含该键值对应的最小 rowids。该节点上的最后一个（也是值最大的）rowid 是 0x8421。</code></p>
</li>
<li><p>Node 0x85 contains rowids for the key that are all greater than 0x8421. The last rowid on that node is 0x10642.</p>
<p><code>节点 0x85 包含的该键值对应的所有 rowids 均大于 0x8421。该节点上的最后一个 rowid 是 0x10642。</code></p>
</li>
<li><p>Node 0x17 contains rowids that are all greater than 0x10642. The last rowid on that node is 0x1c98c.</p>
<p><code>节点 0x17 包含的该键值对应的所有 rowids 均大于 0x10642。该节点上的最后一个 rowid 是 0x1c98c。</code></p>
</li>
<li><p>Node 0x1ca contains rowids greater than 0x1c98c. The last one on the node is 0x1cc84.</p>
<p><code>节点 0x1ca 包含的该键值对应的所有 rowids 均大于 0x1c98c。该节点上的最后一个 rowid 是 0x1cc84。</code></p>
</li>
<li><p>Node 0x1cd contains all rowids for the key value that are greater than 0x1cc84.</p>
<p><code>节点 0x1cd 包含的所有 rowids 均对应于键值且这些 rowid 的值均大于 0x1cc84。</code></p>
</li>
</ol>
<p>不明白 branch node 为什么存 rowid？</p>
<p><strong>The Leaf Node</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282208212.png" alt="image-20250528220857112"></p>
<p><strong>Notes:</strong></p>
<p>By definition, leaf nodes point to data rows. The example of a root-leaf node presented earlier demonstrates references to the rowids of data rows.</p>
<p><code>根据定义，叶节点指向数据行。之前展示的 root-leaf 节点示例就演示了对数据行 rowids 的引用。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282210187.png" alt="image-20250528221034107"></p>
<p><code>上图所示的叶节点与之前分析的 root-leaf 节点之间存在两个差异。首先，这个叶节点有兄弟节点，因此 </code>pg_next<code>和</code>pg_prev<code> 分别包含指向右侧和左侧兄弟节点的节点编号。其次，页标志（0x90）表明这只是一个普通的叶节点，而不是 root-leaf 组合节点（页标志为 0xb0）。</code></p>
<p><strong>The Leaf Node: oncheck -pp Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505282212001.png" alt="image-20250528221212843"></p>
<p><strong>Notes:</strong></p>
<p>Above is the <strong>oncheck -pp</strong> output for a leaf node. Analyzing what we find here, we can tell that:</p>
<ol>
<li><p>This is a duplicate index. Note that the index entry in slot 3 contains two rowids.</p>
<p><code>这是一个 duplicate index。请注意，slot 3 中的索引条目包含两个 rowid。</code></p>
<p>写错了，应该是 slot 4</p>
</li>
<li><p>The keys appear to be character data, and we could make an educated guess that the indexed column was a CHAR(5). Of course, Informix Dynamic Server does not need to guess. Based on the appropriate key descriptor on slot 4 of this table’s partition page, the database server knows what column type(s) make up this index key.</p>
<p><code>这些键值看起来像是字符数据，我们可以合理推测被索引的列是 CHAR(5) 类型。当然，IDS 并不需要靠猜测来确定。根据该表 partition page 上 slot 4 的适当键描述符，server 能够确切知道构成该索引键的列类型。</code></p>
</li>
<li><p>The index entry in slot 1 indicates that we could find the key value <strong>AAACi</strong> in slot 0x9b on logical page 2.</p>
<p><code>slot 1 中的索引条目表明，我们可以在逻辑页 2 的 slot 0x9b 处找到键值 AAACi。</code></p>
</li>
</ol>
<p><strong>The Root Node: oncheck -pK Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292201666.png" alt="image-20250529220135558"></p>
<p><strong>Notes:</strong></p>
<p>You can use <strong>oncheck -pK</strong> to produce what should now be a fairly readable report on all index nodes in a tblspace. Only the portion of a sample output that relates to the root node is shown above. The output for each node is topped with the following information.</p>
<p><code>你可以使用 oncheck -pK 命令生成一份如今应相当易读的报告，该报告会展示 tblspace 中所有索引节点的相关信息。上面仅展示了与根节点相关的样本输出片段。每个节点的输出内容开头都会包含以下信息。</code></p>
<p><strong>Level</strong></p>
<p>(Decimal) The index level of the node. Index levels begin with 0.</p>
<p><code>（十进制表示）该节点的索引层级。索引层级从 0 开始。</code></p>
<p><strong>Node</strong></p>
<p>(Hex) The node number (logical page number) of the node.</p>
<p><code>（十六进制表示）该节点的节点编号（逻辑页号）。</code></p>
<p><strong>Prev</strong></p>
<p>(Hex) The value of <strong>pg_prev</strong> in the header of this node, which, if it is not 0, is the node number of the adjacent node to the <em>left</em>.</p>
<p><code>（十六进制表示）该节点头信息中 pg_prev 的值，若此值不为 0，则表示相邻左侧节点的节点编号（逻辑页号）。</code></p>
<p><strong>Next</strong></p>
<p>(Hex) The value of <strong>pg_next</strong> in the header of this node, which, if it is not 0, is the node number of the adjacent node to the <em>right</em>.</p>
<p><code>（十六进制表示）该节点头信息中 pg_next 的值，若此值不为 0，则表示相邻右侧节点的节点编号（逻辑页号）。</code></p>
<p>After displaying this information, <strong>oncheck</strong> then sets up to display either twig-type entries, or leaf-type entries, in a very generic format. In the slide above, based on the page flags for the node, <strong>oncheck</strong> could sense the node contained twig-type entries. Neither entry is very long or complex, however. The first entry evidently contains the key value <strong>N</strong>, followed by the node number 0x2cd. Notice that the mini-slot is indicated by <strong>oncheck</strong>, and understood to contain no key value.</p>
<p><code>在显示完这些信息后，oncheck 会接着以一种非常通用的格式准备显示分支类型条目（twig-type entries）或叶子类型条目（leaf-type entries）。在上面的幻灯片中，根据该节点的页标志（page flags），oncheck 能够感知到该节点包含分支类型条目。不过，这两个条目都不算很长或很复杂。第一个条目显然包含键值 N，后面跟着节点编号 0x2cd。请注意，oncheck 指出了 mini-slot 的存在，并理解它不包含任何键值。</code></p>
<p><strong>The Branch Node: oncheck -pK Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292211708.png" alt="image-20250529221129639"></p>
<p><strong>Notes:</strong></p>
<p>More output from the same <strong>oncheck -pK</strong> report is shown above. We can see from the heading information that node 0x2cd is on level 1 of the index, with no sibling to its left, and an adjacent sibling to the right with node number 0x2cc.</p>
<p><code>上面展示的是同一份 oncheck -pK 报告的更多输出内容。从标题信息中我们可以看出，节点 0x2cd 位于索引的第 1 层，其左侧没有兄弟节点，而右侧有一个相邻的兄弟节点，节点编号为 0x2cc。</code></p>
<p>The twig-type entries on this level of the index reference multiple nodes for each key, so we can tell our index it contains duplicates.</p>
<p><code>在该索引层级的分支类型条目（twig-type entries）中，每个键值都对应多个节点的引用，因此我们可以判断出该索引中包含重复键值（即索引包含重复项）。</code></p>
<p>The first entry on the node points to node 0x1da. From the information here, we can tell that node 0x1da contains one index entry, whose key value is 0, and whose last rowid is 0x498d.</p>
<p><code>该节点上的第一个条目指向节点 0x1da。根据此处提供的信息，我们可以得知节点 0x1da 包含一个索引条目，该条目的键值为 0，且其最后一个 rowid 为 0x498d。</code></p>
<p><strong>The Leaf Node: oncheck -pK Output</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292216282.png" alt="image-20250529221632214"></p>
<p><strong>Notes:</strong></p>
<p>Yet more output from the <strong>oncheck -pK</strong> report is shown in the slide. The mid-portion of the entry has been removed from this output in order to show the last line, which does, indeed, end with 0x498d, the value promised by the branch node on the previous page.</p>
<p><code>幻灯片中展示了 oncheck -pK 报告的更多输出内容。为了显示最后一行（该行确实以 0x498d 结尾，这一值正是上一页分支节点所承诺的值），输出内容中删除了条目的中间部分。</code></p>
<p>Note, too, that node number 0x1d9, the adjacent sibling to the right of this node, is also referred to by the branch node shown on the previous page. Before you look, can you guess where the value 0x1d9 occurs on that branch node?</p>
<p><code>另外还需注意，节点编号 0x1d9（即该节点右侧的相邻兄弟节点）也在上一页所显示的分支节点中被提及。在你查看之前，能否猜猜看 0x1d9 这个值在该分支节点的哪里出现呢？</code></p>
<p><strong>Oncheck -pT</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505292222440.png" alt="image-20250529222227383"></p>
<p><strong>Notes:</strong></p>
<p>The second portion of the extra output generated by <strong>oncheck -pT</strong> concentrates on the indexes. Again, all numbers here are in decimal.</p>
<p><code>oncheck -pT 命令生成的额外输出内容的第二部分主要聚焦于索引。同样，此处列出的所有数字均为十进制形式。</code></p>
<p>The first section you see above is for the ALTER TABLE statement. While the alter is going on, a page that has been altered has a later <em>version</em> than a page Informix Dynamic Server has not altered yet.</p>
<p><code>你上面看到的第一部分内容是关于 ALTER TABLE 语句的。在执行 ALTER 操作的过程中，已被修改的页面的“版本”（version）会比 IDS 尚未修改的页面的版本要新（即版本号更高）。</code></p>
<p><strong>Level</strong> – Unfortunately, <strong>oncheck -pT</strong> refers to the root level of an index as level 1, instead of level 0 as it is known practically everywhere else. It is not too confusing here, but be sure to avoid thinking the same way or you will make mistakes interpreting other index-related <strong>oncheck</strong> output.</p>
<p><code>遗憾的是，oncheck -pT 命令将索引的根层级称为第 1 层，而在其他几乎所有地方，根层级都被称为第 0 层。在这里，这种命名方式或许不会造成太大的混淆，但务必注意避免形成这样的思维定式，否则在解读其他与索引相关的 oncheck 输出时，你很可能会犯错误。</code></p>
<p><strong>Total</strong> – The total number of nodes on this particular level.</p>
<p><code>这一特定层级上的节点总数。</code></p>
<p><strong>Average No. Keys</strong> – This column is a bit misleading. Even if your index contains one key value, the <em>Average Number of Keys</em> on each level depends more on the number of rows in the table than the number of keys on that level. To arrive at the number for the leaf level, for instance, <strong>oncheck</strong> divides the total number of rows in the tblspace by the total number of leaf nodes. For non-leaf levels, the total number of node references is divided by the number of nodes on the level.</p>
<p><code>这一列的数据可能会让人产生误解。即便你的索引中只包含一个键值，但每一层上的“平均键数”（Average Number of Keys）更多地还是取决于表中记录的数量，而非该层上键的实际数量。举例来说，为了得出叶子层（leaf level）的平均 key 数，oncheck 命令会将 tblspace 中的总记录数除以叶子节点的总数。而对于非叶子层（non-leaf levels），则是将该层上的节点引用总数除以该层的节点数。</code></p>
<p><strong>Average Free Bytes</strong> – This title is accurate. The total number of free bytes in all the nodes on an index level is divided by the number of nodes on that level.</p>
<p><code>这个标题表述准确。它是将索引某一层级上所有节点中空闲字节（free bytes）的总数，除以该层级的节点数所得出的结果。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/4"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/05/18/IX9111/4/"
    >IX9111 - Unit 4. Tblspaces</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/05/18/IX9111/4/" class="article-date">
  <time datetime="2025-05-18T08:31:08.000Z" itemprop="datePublished">2025-05-18</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>The Physical Elements in a Tblspace</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505181632526.png" alt="image-20250518163231397"></p>
<p><strong>Notes:</strong></p>
<p>For the Informix Dynamic Server user who never has a reason to manage a database table below the SQL level, it might be useful to picture a table as simply as a series of data rows. But an IDS administrator must understand tables at the RSAM (Relational Sequential Access Method) level.</p>
<p><code>对于那些从不需要在 SQL 层面之下管理数据库表的 IDS 用户而言，将表简单地看作是一系列数据行可能就足够了。但是，IDS 管理员必须在 RSAM（关系型顺序访问方法）级别上理解表。</code></p>
<p>An Informix Dynamic Server database table is actually a logical combination of several physical elements:</p>
<p><code>IDS 数据库表实际上是多个物理元素的逻辑组合：</code></p>
<ol>
<li><p>SQL level: any system catalog data related to the table (none, in the case of temp tables)</p>
<p><code>与该表相关的任何系统 catalog 数据（对于临时表而言，则没有）。</code></p>
</li>
<li><p>RSAM level: one or more partition pages</p>
<p><code>一个或多个 partition page</code></p>
</li>
<li><p>RSAM level: a number of extents</p>
<p><code>若干 extent</code></p>
</li>
</ol>
<p>A <em>tblspace</em> (or <em>partition</em>) is the logical collection of RSAM-level elements located in a single dbspace. A table can consist of one or more tblspaces, depending on if the table is fragmented.</p>
<p><code>一个 tblspace（或 partition）是位于单个 dbspace 中的 RSAM 级元素的逻辑集合。一个表可以由一个或多个 tblspace 组成，具体取决于表是否分片。</code></p>
<p><strong>How do these elements work together?</strong></p>
<p>An <strong>sqlexec</strong> thread intent on accessing tblspace data must first read the system catalog information related to the table. For each table in a database, there is a corresponding row in <strong>systables</strong>. The row contains information such as the name of the table, various statistics, and a partition number (partnum). </p>
<p><code>一个打算访问 tblspace 数据的 sqlexec 线程，首先必须读取与该表相关的系统目录（system catalog）信息。对于数据库中的每个表，systables 中都有一条对应的记录。该记录包含表名、各种统计信息以及一个分区号（partnum）等信息。</code></p>
<p>The partnum describes the location of that table’s partition page. Among other information on that page are the physical locations of each extent in the table. From those addresses, the thread can easily find the tblspace extents.</p>
<p><code>partnum 描述了该表 partition page 的位置。在该页所包含的其他信息中，还记录了表中每个 extent 的物理位置。通过这些地址，线程就可以轻松地找到 tblspace 的各个 extent。</code></p>
<p><strong>The Database Tblspace</strong></p>
<ul>
<li><p>There is only one database tblspace in the system. It contains information about all databases</p>
<p><code>系统中只有一个 database tblspace。它包含所有 database 的信息</code></p>
</li>
<li><p>The database tblspace partnum is always <strong>0x0100002</strong></p>
<p><code>database tblspace partnum 始终为 0x100002</code></p>
</li>
<li><p>It resides in the root dbspace</p>
<p><code>它位于 root dbspace</code></p>
</li>
<li><p>It can be viewed as a <strong>sysmaster</strong> table called <strong>sysdatabases</strong></p>
<p><code>可将其视为一个 sysmaster 的表，叫做 sysdatabases</code></p>
</li>
</ul>
<p><strong>Notes:</strong></p>
<p>In the root dbspace, partition number 0x0100002 is a special tblspace that is used for tracking all the databases created in a database server. This is known as the <em>database</em> <em>tblspace</em>. It can be thought of as a special, internal database table that can grow just like any other table can. A <strong>sysmaster</strong> table called <strong>sysdatabases</strong> allows users to view the contents of this table, but the table cannot be modified.</p>
<p><code>在 root dbspace 中，partnum 0x0100002 是一个特殊的 tblspace，用于跟踪 server 中创建的所有数据库。这就是 database tblspace。可以将其视为一个特殊的内部数据库表，它可以像其他表一样增长。sysdatabases 表允许用户查看该表的内容，但不能修改该表。</code></p>
<p>The database tblspace is initially four pages in size, but additional extents can be allocated (as with any tblspace) as the need arises.</p>
<p><code>数据库表空间（tablespace）初始大小为四页，但随着需求增长，可（如同任意 tblspace 一样）动态分配额外的 extents。</code></p>
<blockquote>
<p>arise 英[əˈraɪz] 美[əˈraɪz]<br>vi.发生;出现;(由…)引起;(因…)产生;发展;起床;（随着人走近而）逐渐显现;群起反对;</p>
</blockquote>
<p>The database tblspace contains all the information needed to identify any database created in the database server. Each row tracks the name of one database, its owner, the date and time of creation, flags related to its logging mode, and the partition number of <strong>systables</strong>. Once the server has found <strong>systables</strong>, all other tables in the database can be located.</p>
<p><code>数据库 tblspace 包含识别 server 中创建的任何数据库所需的所有信息。每一行都跟踪一个数据库的名称、所有者、创建日期和时间、与日志模式相关的标志以及 systables 的 partition number。一旦 server 找到 systables，就能找到数据库中的所有其他表。</code></p>
<p>The schema of the database tblspace includes a unique index on the database name.</p>
<p><code>database tblspace 的模式（schema）中包含一个基于数据库名称的唯一索引。</code></p>
<blockquote>
<p>gemini 2.5 pro</p>
<ul>
<li><strong>“模式 (schema)”</strong> 在这里指的就是这个<strong>特殊的系统级表空间（或其内部的系统表）的结构</strong>。这个结构定义了它有哪些列（比如数据库名称、所有者、创建日期等）。</li>
<li>句子强调了这个结构的一部分：<strong>“包含一个基于数据库名称的唯一索引”</strong>。这意味着在这个系统表空间（或其内部的系统表）的“数据库名称”这一列上，建立了一个唯一索引，以确保每个数据库的名称都是独一无二的。</li>
</ul>
</blockquote>
<p><strong>Tblspace Extent Allocation</strong></p>
<p>Speaking generally, when a tblspace requires more space, another extent of size NEXT SIZE is allocated. There are, however, three variations on this basic theme:</p>
<p><code>一般而言，当表空间（tblspace）需要更多空间时，会分配一个大小为 NEXT SIZE 的 extent。不过，这一基本机制存在三种变体情况：</code></p>
<p>– Extent size doubling</p>
<p><code>extent size 翻倍</code></p>
<p>– Extent size compliance – Not enough contiguous space for NEXT SIZE? The database server allocates what it can (but not less than 4 pages).</p>
<p><code>extent 大小合规性检查 —— 若没有足够连续空间来分配 NEXT SIZE (所指定的 extent)？ server会分配其所能分配的空间量（但不少于 4 页）。</code></p>
<p>– Extent concatenation</p>
<p><code>extent 连接</code></p>
<p><strong>Notes:</strong></p>
<p>After the first extent allocated to a tblspace fills, the database server attempts to allocate another extent. The amount of space it allocates is normally equal to the size configured for subsequent extents (NEXT SIZE). However, the allocation mechanism is affected by these factors:</p>
<p><code>在分配给 tblspace 的第一个 extent 填满后，server 会尝试分配另一个 extent。分配的空间大小通常等于为后续 extent 配置的大小（NEXT SIZE）。但是，分配机制会受到这些因素的影响：</code></p>
<p><strong>•</strong> The number of existing extents</p>
<p><code>现有 extent 的数量</code></p>
<p><strong>•</strong> The availability of contiguous space</p>
<p><code>连续空间的可用性</code></p>
<p><strong>•</strong> The location of existing TBLspace extents</p>
<p><code>现有表空间（TBLspace）中extents的位置</code></p>
<p><strong>Extent size doubling</strong></p>
<p>When the number of extents within a tblspace becomes large, Informix Dynamic Server attempts to compensate by doubling the value on the partition page. It doubles the next extent size after every 16 extents.</p>
<p><code>当表空间（tblspace）内的 extents 数量变得庞大时，IDS 会尝试通过在分区页（partition page）上将相关值加倍来进行补偿。具体来说，在每分配完 16 个 extent 之后，它会将下一个 extent 的大小加倍。。</code></p>
<blockquote>
<p>compensate 补偿 英[ˈkɒmpenseɪt] 美[ˈkɑːmpenseɪt]</p>
</blockquote>
<p><strong>Not enough space for full extent</strong></p>
<p>If the database server is unable to find the space requested for the extent in the first chunk of the dbspace, it searches the next chunk, and so on. If the server is unable to come up with enough space after searching the chunk free lists for all chunks in the dbspace, it settles for the largest available amount of contiguous space. If this is less than 4 pages, however, the allocation fails with an error indicating there is no free disk space available.</p>
<p><code>如果 server 在数据库空间（dbspace）的第一个 chunk 中无法找到为该 extent 请求的所需空间，它会继续搜索下一个 chunk，依此类推。如果服务器在遍历数据库空间中所有chunk的 chunk free lists 后，仍无法找到足够大的空间，那么它会选择当前可用的最大连续空间进行分配。然而，如果这个最大连续空间的大小小于 4 页，那么分配操作将失败，并返回一个错误，指示没有可用的空闲磁盘空间。</code></p>
<blockquote>
<p>settle<br>英[ˈsetl]<br>美[ˈsetl]<br>v.解决(分歧、纠纷等);定居;（使）沉降，下陷，变得密实;(最终)决定，确定，安排好;结束(争论、争端等);付清（欠款）;（使）平静下来，安静下来，定下心来;殖民;降落;把…放好;使处于舒适的位置;<br>n.高背长椅(老式木家具，有扶手，座下多带柜);</p>
</blockquote>
<p><strong>Existing extent locations</strong></p>
<p>When the database server allocates a new extent that is contiguous to the previously allocated extent, it does not create a new extent. Rather, it extends the size of the last one.</p>
<p><code>当 server 分配一个与先前已分配 extent 相邻的新 extent 时，它并不会创建一个全新的 extent。相反，它会扩展最后一个 extent 的大小。</code></p>
<p><strong>Extent Allocation Question</strong></p>
<p>Suppose a tblspace has 5 extents. What do you think would happen if the next allocated extent were contiguous to the thirdextent? Is this a situation in which extent concatenation can beused?</p>
<p><code>假设某个表空间（tblspace）已包含5个 extent。若接下来分配的extent与第三个 extent 在物理存储上直接相邻（contiguous），您认为会发生什么？这种场景是否属于可应用 extent concatenation 技术的情况？</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192105922.png" alt="image-20250519210524805"></p>
<p><strong>Notes:</strong></p>
<p>Here is an example showing a tblspace with five extents. The server determines that the next extent can be allocated in the pages that immediately follow the third extent.</p>
<p><code>以下示例展示了一个包含五个 extent 的表空间（tblspace）。server 判定，下一个 extent 可分配在与第三个 extent 物理地址直接相邻的后续存储页中。</code></p>
<p><strong>Index Tblspaces</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192109867.png" alt="image-20250519210937792"></p>
<p><strong>Notes:</strong></p>
<p>Indexes on tables created by users are stored in tblspaces that are separate from their base tables. An index tblspace can be stored in the same dbspace(s) as a data tblspace, or it can be created in a different dbspace. Indexes can also be fragmented into tblspaces located in different dbspaces.</p>
<p><code>用户创建的表上的索引会存储在与基表相互独立的表空间（tblspace）中。索引表空间（index tblspace）可以与数据表空间（data tblspace）共享同一dbspace，也可以单独创建于其他dbspace。此外，索引还支持跨dbspace分片，即索引的不同部分可分布于多个tblspace（这些表空间可位于不同dbspace内）。</code></p>
<p>Since indexes are stored in their own tblspaces, they also can be identified by a partition number. To find a partition number for an index, you can either run <strong>oncheck -pT</strong> on the table on which the index was created, or you can query the <strong>sysfragments</strong> database, as shown here:</p>
<p><code>由于索引存储在独立的表空间（tblspace）中，因此它们也可通过**分区号（partition number）**进行标识。若要查询某个索引的分区号，您可通过以下两种方式实现：对索引所基于的表运行 oncheck -pT 命令 或 查询数据库的系统目录表 sysfragments（具体方法见下文示例）。</code></p>
<p>​	SELECT HEX(partn) FROM sysfragments WHERE indexname &#x3D; “index_name”;</p>
<p>Index extent sizes are not configurable; the size calculated for the index first and next extent sizes are based on the proportion of the key size in relation to the entire table. Index tblspaces use the same rules for adding extents as data tblspaces.</p>
<p><code>索引的 extent 大小不可配置；系统为索引计算的首个 extent 和 next extent）的大小，是基于索引键（key）大小与整表数据规模的比例关系动态确定的。索引表空间（index tblspace）在分配新 extent 时，遵循与数据表空间（data tblspace）完全相同的规则。</code></p>
<blockquote>
<p>proportion 比例 英[prəˈpɔːʃn] 美[prəˈpɔːrʃn]</p>
</blockquote>
<p>Indexes created on system catalog tables are stored in the same tblspace as their base tables. Extents allocated to system catalog tables contain both data and index pages.</p>
<p><code>在系统目录表（system catalog tables）上创建的索引会存储在与基表相同的表空间（tblspace）中。分配给系统目录表的 extents 会同时包含数据页（data pages）和索引页（index pages），即数据与索引共享同一存储单元。</code></p>
<p><strong>Bitmap Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192223826.png" alt="image-20250519222314760"></p>
<p><strong>Notes:</strong></p>
<p>An Informix Dynamic Server thread searching for a place to insert data within a tblspace uses that table’s <em>bitmap</em> pages to quickly identify a page with sufficient space. Along with inserts, actions that require bitmap searches include:</p>
<p><code>IDS 一个线程在表空间（tblspace）内搜索可插入数据的位置时，会利用该表的位图页（bitmap pages）快速定位具有足够空间的页。除插入操作外，需要执行位图搜索的其他操作还包括：</code></p>
<p><strong>•</strong> Updates whose resulting <em>tuple</em> (the internal term for a row) no longer fits into the existing slot.</p>
<p><code>更新操作导致生成的元组（tuple，即数据库内部对行的术语）无法再存入其原有的 slot。</code></p>
<p><strong>•</strong> Index operations that allocate new&#x2F;free tblspace pages, such as B-tree splits and index creations.</p>
<p><code>索引操作中需要分配新页或释放页的场景包括：B树分裂（B-tree splits）以及索引创建（index creations）等。</code></p>
<p><strong>•</strong> Tblspace usage reports.</p>
<p><code>Tblspace 使用报告。</code></p>
<p><strong>•</strong> Index and data checkers (<strong>oncheck</strong>).</p>
<p><code>索引与数据校验工具（oncheck）</code></p>
<p><strong>Myth buster</strong></p>
<p><code>误区澄清者</code></p>
<p>Every tblspace extent does not begin with a bitmap page. That would be a considerable waste of space, since each bitmap page can describe thousands of pages. So where do second and third bitmap pages appear in a tblspace, if they exist?</p>
<p><code>并不是每个表空间（tblspace）的 extent 都以一个位图页（bitmap page）开始。那样会造成相当大的空间浪费，因为每个位图页可以描述成千上万个页面。那么，如果存在第二个和第三个位图页，它们会出现在表空间的什么位置呢？</code></p>
<p><strong>Displaying Data Tblspace Bitmap Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192247198.png" alt="image-20250519224746044"></p>
<p><strong>Notes:</strong></p>
<p>You can view the contents of a bitmap page by running <strong>oncheck -pp</strong>. The syntax for this command is:</p>
<p><code>通过运行 oncheck -pp，可以查看位图页面的内容。该命令的语法为</code></p>
<p>​		oncheck -pp <em>partnum</em> <em>logical_page_num</em></p>
<p>In every tblspace, logical page 0 is the first bitmap page. For smaller tables, it is probably the only bitmap page. In the case of larger tables, there could be several others. To display the first bitmap page for a particular tblspace, determine the partition number for the table, then run the command:</p>
<p><code>在每个 tblspace 中，逻辑页 0 是第一个位图页面。对于较小的表，它可能是唯一的位图页面。对于较大的表，可能还有其他几个页。要显示特定 tblspace 的第一个位图页面，请确定表的 partition number，然后运行该命令：</code></p>
<p>​		oncheck -pp <em>partnum</em> 0</p>
<p>As usual, the first two lines displayed by <strong>oncheck</strong> show the page header. Next, <strong>oncheck</strong>displays one or more rows containing 32 values, each bit value representing one page in the table. The row(s) of 32 values are always complete—padded with several 0 values if necessary—whether the table contains 4 pages or exactly 64.</p>
<p><code>与往常一样，</code>oncheck<code> 输出的前两行会显示页头（page header）信息。 随后，</code>oncheck<code> 会输出一行或多行，每行包含 32 个位值（bit value），每个位值代表表中的一个页。 无论表包含 4 个页还是恰好 64 个页，这行（或多行）32 个位值始终是完整的——若不足 32 位，则会用若干个 0 值填充补齐。</code></p>
<p>To the left of each row of bit values is a <em>page offset</em>, akin to the byte offset you have seen in the slot output from <strong>oncheck</strong>. This decimal number indicates which logical page number is represented by the first bit value in the row, as shown here:</p>
<p><code>在每一行位值（bit value）的左侧，有一个页偏移量（page offset），类似于你在 oncheck 的 slot 输出中见过的字节偏移量（byte offset）。 这个十进制数表示该行中第一个位值所对应的逻辑页号（logical page number），具体示例如下：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505192255582.png" alt="image-20250519225526534"></p>
<p><strong>Displaying Index Tblspace Bitmap Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202219055.png" alt="image-20250520221930894"></p>
<p><strong>Notes:</strong></p>
<p>Index tblspaces can contain bitmap pages, index pages, and free pages. Since the same bitmap value (8) is used to indicate both index pages and bitmap pages, the bitmap context is important. Page 0 is always a bitmap page, but all other pages with a bitmap value of 8 are index pages. If the table becomes so large that bitmap entries for index nodes fill the bitmap page, then another bitmap page is created.</p>
<p><code>索引表空间（index tablespace）可以包含位图页（bitmap pages）、索引页（index pages）和空闲页（free pages）。由于使用相同的位图值（8）来同时表示索引页和位图页，因此位图上下文（即页面所处的具体情境或类别）就显得尤为重要。具体而言，页面0始终是位图页，而所有其他位图值为8的页面则均为索引页。如果表变得非常大，以至于用于索引节点的位图条目填满了当前的位图页，那么就会创建另一个位图页。</code></p>
<p>To display the bitmap page for an index tblspace, you must first determine the partnum for the index. You can find this by either running <strong>oncheck -pT</strong> on the source table, or by querying the <strong>sysfragments</strong> system catalog.</p>
<p><code>要显示某个索引表空间（index tblspace）的位图页，首先必须确定该索引的分区号（partnum）。你可以通过在源表上运行 oncheck -pT 命令来查找该分区号，或者通过查询系统目录表 sysfragments 来获取。</code></p>
<p>The <strong>oncheck -pT</strong> command includes tblspace information for each index created on the table. An example is shown on the next page.</p>
<p><code>oncheck -pT 命令会包含在表上创建的每个索引的表空间（tblspace）信息。下一页将展示一个示例。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202225828.png" alt="image-20250520222526762"></p>
<p><strong>Displaying System Catalog Bitmap Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202226010.png" alt="image-20250520222622935"></p>
<p><strong>Notes:</strong></p>
<p>Unlike user-defined tables and indexes, each system catalog table and the indexes for the catalog are created in the same tblspace. The example above shows a bitmap page of a <strong>sysindexes</strong> table. Notice that data pages and index pages appear in the same bitmap. Indexes that share the same tblspace as their parent table are said to be <em>attached indexes</em>.</p>
<p><code>与用户自定义的表和索引不同，每个系统目录表及其对应的索引都是在同一个表空间（tblspace）中创建的。上面的示例展示了 sysindexes 表的一个位图页。请注意，数据页和索引页会出现在同一个位图中。那些与其父表共享同一个表空间的索引被称为附属索引（attached indexes）。</code></p>
<p>Indexes created by users are, by default, <em>detached</em> from their parent table. That is, they are created in separate tblspaces, as shown in previous examples. However, you can create indexes that are attached by using the IN TABLE option of the CREATE INDEX command.</p>
<p><code>用户创建的索引在默认情况下是与其父表分离（detached）的，也就是说，它们是在单独的表空间（tblspaces）中创建的，正如之前的示例所示。然而，你可以通过使用 CREATE INDEX 命令的 IN TABLE 选项来创建与父表关联（即附属）的索引。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505202230431.png" alt="image-20250520223030371"></p>
<p><code>IDS 的第 11 版继续支持 DEFAULT_ATTACH 环境变量。当该变量设置为 1 时，所有创建的索引都会成为附属索引（即与父表关联）。不过，该变量在文档中已被标记为“已弃用”，未来版本可能不再支持。</code></p>
<p><strong>Home Data Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212138685.png" alt="image-20250521213844555"></p>
<p><strong>Notes:</strong></p>
<p>Remainder pages and blobpages are types of data pages because they contain portions of rows. But the data in these types of pages is second-tier. Without <em>home rows</em> pointing to them, remainder pieces and blobs would be orphaned. The rowids used by an index refer only to home rows, and never to remainder pieces or blobs.</p>
<p><code>剩余页（remainder pages）和大对象页（blobpages）均属于数据页类型，因为它们包含行数据的部分内容。不过，这些页面中的数据属于次级（非核心）数据。若没有“主行（home rows）”指向它们，剩余数据片段和大对象数据便会成为“无主（孤儿）”数据，无处可依。索引所使用的 rowid 仅指向主行，而绝不会指向剩余数据片段或大对象数据。</code></p>
<p>The <em>data</em> pages we have been talking about are known internally as <em>home data pages</em>, in an effort to distinguish between home rows, and the second-tier data to which home rows can refer.</p>
<p><code>我们一直在讨论的这些数据页在内部被称为主数据页（home data pages），这样做的目的是为了区分主行（home rows）以及主行可能引用的那些次级（第二层级）数据。</code></p>
<p>这一节莫名其妙，基本不懂</p>
<p><strong>Rowids</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212145897.png" alt="image-20250521214559846"></p>
<p><strong>Notes:</strong></p>
<p>A <em>rowid</em> is a 4-byte code, decipherable only when displayed in hexadecimal notation. The format for a rowid is <strong>0xPPPPPPSS</strong> where the <strong>PPPPPP</strong>, the most significant 3 bytes, contain the logical page number of the row, and the <strong>SS</strong>, the least significant byte, contains the slot number that the row occupies on the page.</p>
<p><code>rowid 是一个 4 字节的编码，只有在以十六进制格式显示时才能被解读。行标识符的格式为 0xPPPPPPSS，其中 PPPPPP（高 3 字节）表示该行所在的逻辑页号，而 SS（低 1 字节）则表示该行在页中所占用的 slot number。</code></p>
<p>A home data page consists of a page header, a slot table, and slots containing data rows. To access a specific slot on a specific data page, one must either stumble upon it during a sequential scan, or pass RSAM the correct rowid.</p>
<p><code>home data page 由页头（page header）、slot table 以及包含数据行的 slots 组成。若要访问特定数据页上的某个特定 slot，要么需在顺序扫描过程中偶然发现它，要么需向随机存储访问方法（RSAM，Random Storage Access Method）传递正确的 rowid。</code></p>
<blockquote>
<p>stumble upon 偶然发现 英[ˈstʌmbl əˈpɒn] 美[ˈstʌmbl əˈpɑːn]</p>
</blockquote>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212153391.png" alt="image-20250521215319325"></p>
<p><code>上一张幻灯片展示了一个 home data page 的示例。该页是来自一个未命名 tblspace 的逻辑页 3。slot table 中的第 2 个条目指向了一个被高亮显示的 slot。因此，这个 home row 的 rowid 为 0x00000302，简化表示即为 0x302。</code></p>
<p>别往上找，找不到对应</p>
<p><strong>The Data Row: Just a Byte Stream</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505212209654.png" alt="image-20250521220956573"></p>
<p><strong>Notes:</strong></p>
<p>As you have had the opportunity to view Informix Dynamic Server data rows at the binary level, you may have noticed that columns are not aligned on any particular address boundaries. To a C programmer whose assumption is that rows in a tblspace are stored as C structures, this might come as a surprise.</p>
<p><code>既然你已有机会从二进制层面查看 IDS 的数据行，那么你可能已经注意到，列数据并没有对齐到任何特定的地址边界。对于那些原本假设 tblspace 中的行是以 C 语言结构体形式存储的 C 语言程序员来说，这可能会让他们感到意外。</code></p>
<p><strong>Structure alignment</strong></p>
<p>On most computer architectures, the needs of the data bus dictate that an instance of the 11-byte C structure defined in the slide above be stored in memory, as shown on the right. The 1-byte element beginning the structure (<strong>a</strong>) is <em>aligned</em> on an integer boundary, meaning that the memory address of that byte is evenly divisible by 4. The next element (<strong>b</strong>), a 4-byte long integer, must also be aligned on an integer boundary. Therefore, <strong>b</strong> cannot be stored immediately following <strong>c</strong>, and 3 bytes of wasted space separate the two elements. Short integers like the next element must be aligned on short-integer boundaries. Luckily, the address directly following the previous element suffices for <strong>c</strong>. However, the next element (<strong>d</strong>) has to be separated from <strong>c</strong> by 2 bytes, in order to be aligned on an integer boundary. Thus, in this particular case, 16 bytes are used in memory to store 11 bytes of real data.</p>
<p><code>在大多数计算机架构中，数据总线的需求决定了上一张幻灯片中定义的 11 字节 C 语言结构体实例在内存中的存储方式，就如同右侧所示的那样。结构体中以 1 字节元素开头的部分（a）是按整数边界对齐的，这意味着该字节的内存地址能够被 4 整除。接下来的元素（b）是一个 4 字节的长整型，它也必须按整数边界对齐。因此，b 不能紧跟在 a 之后存储，这两个元素之间需要浪费 3 字节的内存空间。像下一个元素这样的短整型（short integer）必须按短整型边界对齐。幸运的是，上一个元素之后的内存地址刚好满足 c 的对齐要求。然而，下一个元素（d）为了按整数边界对齐，必须与 c 间隔 2 字节。因此，在这个特定例子中，为了存储 11 字节的实际数据，内存中实际使用了 16 字节的空间。</code></p>
<p><strong>Data row storage</strong></p>
<p>In most cases, a Dynamic Server data row is not written, stored, or read as a C structure, but as a stream of bytes. Once read, the database server parses the bytes into separate columns based primarily on its knowledge of the schema. This binary method of storage not only saves space, but it puts total control of the data layout in the hands of the engine, making the Dynamic Server source code, and the data itself, more portable.</p>
<p><code>在大多数情况下，server 的数据行并非以 C 语言结构体的形式进行写入、存储或读取，而是以字节流（stream of bytes）的形式来处理。server 在读取数据后，会主要依据对模式（schema）的了解，将这些字节解析为独立的列。这种二进制存储方式不仅节省了空间，还将数据布局的完全控制权交给了数据库引擎，从而使得 server 的源代码以及数据本身具有更高的可移植性。</code></p>
<p><strong>VARCHAR Column Storage</strong></p>
<ul>
<li><p>Extra byte at beginning that contains data length</p>
<p><code>在开头有一个额外的字节，用于存储数据长度</code></p>
</li>
<li><p>Maximum size: 255 characters (maximum length value is <strong>0xff</strong>)</p>
<p><code>最大大小：255 个字符（最大长度值为 0xff）</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222154583.png" alt="image-20250522215405444"></p>
</li>
</ul>
<p><strong>Notes:</strong></p>
<p>VARCHAR storage is easier to understand than it might look. The first rule to remember is that, because the length of the column data is variable, an extra byte is added to the head of the column to store that length. This might explain why the maximum size of a VARCHAR column is 255 characters. The <em>length</em> byte can store a maximum value of 0xFF, or 255. The second rule relates to the minimum size and the padding required when a column contains less than the minimum configured number of characters. Note that the <em>row</em> is padded, not the VARCHAR column.</p>
<p><code>VARCHAR 类型的存储理解起来可能比看起来要简单。需要记住的第一条规则是，由于列数据的长度是可变的，因此在列的开头会额外添加一个字节来存储该长度。这或许可以解释为什么 VARCHAR 列的最大大小是 255 个字符。这个用于存储长度的字节最大可以存储的值是 0xFF，即 255。第二条规则与最小大小以及当列中包含的字符数少于配置的最小字符数时所需的填充有关。需要注意的是，进行填充的是 row（下段解释），而不是 VARCHAR 列本身。</code></p>
<p>For example, pictured above are three rows of data from the same table, which consists of an INTEGER column (4 bytes), followed by a VARCHAR column configured with a maximum size of 20 bytes and a minimum of 5 bytes, followed by a SMALLINT column (2 bytes). In the first row, the VARCHAR column contains only 3 characters, reflected in the value of the length byte. The configured minimum is 5, however, so while the column data is compressed together into only 10 bytes, a total slot length of 12 is stored in the slot table, effectively <em>padding</em> the row by simply including whatever 2 bytes happen to be out beyond the data.</p>
<p><code>例如，上图展示了来自同一张表的三行数据，这张表包含一个 INTEGER 列（占 4 字节），紧接着是一个配置了最大长度为 20 字节、最小长度为 5 字节的 VARCHAR 列，再接着是一个 SMALLINT 列（占 2 字节）。在第一行中，VARCHAR 列仅包含 3 个字符，这一点在长度字节的值中得到了体现。然而，由于配置的最小长度是 5 字节，所以尽管列数据被压缩到了仅 10 字节，但在 slot table 中存储的总 slot 长度却是 12 字节。这实际上是通过简单地包含超出数据部分的任意 2 字节来对行进行“填充”（padding）的。</code></p>
<p>The data in the padding bytes does not matter because as Informix Dynamic Server reads the row, it can easily tell, based on the length byte preceding each VARCHAR column and the known sizes of all other columns, how many bytes to consider.</p>
<p><code>填充字节中的数据并不重要，因为当 IDS 读取这行数据时，它能够很容易地根据每个 VARCHAR 列前面的长度字节以及所有其他列的已知大小，判断出需要考虑多少个字节。</code></p>
<p>Note that no padding is required for row 2 or 3 because, in each case, the number of characters in the VARCHAR column meets or exceeds the configured minimum of 5.</p>
<p><code>需要注意的是，对于第 2 行或第 3 行数据，并不需要进行填充，因为在每一种情况下，VARCHAR 列中的字符数都达到或超过了所配置的最小长度 5 字节。</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222229057.png" alt="image-20250522222905998"></p>
<p>The bytes added for padding can contain any values. The server knows they do not contain any meaningful information and does not bother to initialize the bytes.</p>
<p><code>为填充而添加的字节可以包含任何值。服务器知道这些字节不包含任何有意义的信息，因此不会费心去初始化这些字节。</code></p>
<p><strong>Forward Pointers for VARCHAR Rows</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505222250645.png" alt="image-20250522225020556"></p>
<p><strong>Notes:</strong></p>
<p>When a row containing a VARCHAR column is updated such that the VARCHAR column grows, as long as the page has room for the row’s expansion, no remainder page or forwarding pointer are needed. However, in the case of a home data page that is almost full, an expanding row is not able to remain intact on the home page.</p>
<p><code>当包含 VARCHAR 列的一行数据被更新，导致该 VARCHAR 列的内容增长时，只要数据页还有足够的空间容纳这行数据的扩展，就不需要使用剩余页（remainder page）或 forwarding pointer。然而，如果该行数据所在的主数据页（home data page）几乎已满，那么扩展后的行数据就无法完整地保留在主数据页上。</code></p>
<p>In this case, the <em>entire row</em> moves to a remainder page. All that is left in the original slot on the home data page is a 4-byte forwarding pointer.</p>
<p><code>在这种情况下，整行数据会移动到一个剩余页（remainder page）上。而在主数据页（home data page）上原来的 slot 中，仅留下一个 4 字节的 forwarding pointer。</code></p>
<p>Once a row has been forwarded to a remainder page like this, accessing the row of data involves 4 pointers.</p>
<p><code>一旦一行数据像这样被转发到剩余页（remainder page）上，访问该行数据就需要涉及 4 个指针。</code></p>
<ol>
<li><p>The rowid addresses the original slot table entry on the home page.</p>
<p><code>该 rowid 指向主数据页（home page）上原始 slot table 中的条目。</code></p>
</li>
<li><p>The slot table entry points to a forwarding pointer that has replaced the data row on the home page.</p>
<p><code>该 slot table 条目指向一个 forwarding pointer，这个 forwarding pointer 已经替换了主数据页（home page）上原来的数据行。</code></p>
</li>
<li><p>The forwarding pointer is yet another rowid, which points to a slot table entry on the relevant remainder page.</p>
<p><code>这个 forwarding pointer 实际上是另一个 rowid，它指向相关剩余页（remainder page）上的一个 slot table 条目。</code></p>
</li>
<li><p>The slot table entry on the remainder page points to the actual data row.</p>
<p><code>remainder page 上的 slot table 条目指向实际的数据行。</code></p>
</li>
</ol>
<p>根据之前讲的，前3个字节代表逻辑页号，最后1个字节代表 slot number</p>
<p>0x603，逻辑页6，第3个slot</p>
<p>0x701，逻辑页7，第1个slot</p>
<p>下面解释 8004 的 8</p>
<p>Note that a slot table entry that points to a slot containing a forwarding pointer is <em>flagged</em>with a special value: 0x8000 (however, the flag value shown for the slot in <strong>oncheck -pp</strong> is 2).</p>
<p><code>需要注意的是，指向包含 forwarding pointer 的 slot 的 slot table 条目会被标记上一个特殊值：0x8000（然而，在 oncheck -pp 命令中显示该槽的标记值时为 2）。</code></p>
<p>Also note that a deleted slot is indicated by a 0 length in its slot table entry.</p>
<p><code>另外还需注意，slot table 条目中若长度为 0，则表示该 slot 已被删除。</code></p>
<p><strong>Forward Pointers for Large Rows</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232238710.png" alt="image-20250523223814560"></p>
<p><strong>Notes:</strong></p>
<p>For rows larger than a page, it is not practical to replace the entire home row with a forwarding pointer. Instead, the first 4 bytes are devoted to the forwarding pointer, followed by as much of the row as can fit on the home page. As usual, the value of the 4-byte forwarding pointer is a rowid that points to the first remainder piece.</p>
<p><code>对于超过一页大小的行，用 forwarding pointer 完全替换 home row 上的整行数据并不实际。相反，行的前 4 个字节被用作 forwarding pointer，随后紧跟的是能容纳在主页上的尽可能多的行数据。和往常一样，这 4 字节 forwarding pointer 的值是一个 rowid，它指向 first remainder piece。</code></p>
<blockquote>
<p>practical 实际的 英[ˈpræktɪkl] 美[ˈpræktɪkl]</p>
</blockquote>
<p><strong>Big remainder pages</strong></p>
<p>If the first remainder piece is too large to fit on an entire remainder page, a second 4-byte forwarding pointer is written on the remainder page, followed by as much of the remainder piece as possible, and so on until the entire row has been stored. This type of remainder page (one entirely taken up by a remainder piece and a forwarding pointer) is called a <em>b</em>i<em>g</em> <em>remainder page</em>.</p>
<p><code>如果 first remainder piece  太大，无法完整地存放在一个 remainder page 中，那么会在该 remainder page 上写入第二个 4 字节的 forwarding pointer，随后紧跟的是能容纳在该剩余页上的尽可能多的 remainder piece 数据，以此类推，直到整行数据全部存储完毕。这种完全由一个 remainder piece 数据和一个 forwarding pointer 占据的 remainder page 被称为 big remainder page。</code></p>
<p>Note that the slide above does <em>not</em> show a big remainder page.</p>
<p><code>请注意，上面展示的幻灯片并未显示一个 big remainder page。</code></p>
<p>Also note that the slot table entry for this home row is flagged with the value 0x8000 to indicate that the slot size of 0x7e0 includes a forwarding pointer as the first 4 bytes.</p>
<p><code>另外还需注意，该 home row（即存储行初始部分数据的页）对应的 slot table 条目会被标记上值 0x8000，以此表明该 slot size 为 0x7e0，且其前 4 个字节包含一个 forwarding pointer。</code></p>
<p><strong>Home Page With BLOB Descriptor</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232310878.png" alt="image-20250523231039798"></p>
<p><strong>Notes:</strong></p>
<p>Informix Dynamic Server supports two different kinds of large objects: <em>simple large objects</em>(<em>blobs</em>) and <em>smart large objects</em> (<em>smart LOs</em>, or <em>smart blobs</em>). Only simple large objects can be stored in partition pages.</p>
<p><code>IDS 支持两种不同类型的大对象：简单大对象（simple large objects，简称 blobs） 和 智能大对象（smart large objects，简称 smart LOs 或 smart blobs）。只有简单大对象可以存储在 partition page 中。</code></p>
<p>The data in a blob column is never stored on home data pages with non-blob column data. Blobs are either segregated into different chunks, as when they are configured to reside in a blobspace, or forwarded to special <em>partition blobpages</em> within the tblspace (the default configuration). But because of the complexity of blob management, a lone 4-byte forwarding pointer on the home page describing only the blob’s location does not suffice. Instead, a 56-byte <em>descriptor</em> is stored on the home page in place of the blob data. Even a home row that has a NULL value in its blob column contains an entire 56-byte blob descriptor, albeit a dull one.</p>
<p><code>BLOB（二进制大对象）列中的数据绝不会与非 BLOB 列的数据一起存储在 home data page 上。BLOB 数据要么被分隔到不同的 chunk 中（例如，当配置为位于blobspace 中时），要么被 forward 到表空间（tblspace，此为默认配置）内的特殊 partition blobpages 中。然而，由于 BLOB 管理的复杂性，仅在主页（home page）上放置一个孤零零的 4 字节 forwarding pointer 来描述 BLOB 的位置是不够的。相反，主页上会存储一个 56 字节的描述符（descriptor）来替代 BLOB 数据。即便某个主页行（home row）的 BLOB 列值为 NULL，它仍然会包含一个完整的 56 字节 BLOB 描述符，只不过这个描述符的内容是“无意义”的。</code></p>
<p><strong>Partition blob</strong> </p>
<p>Partition blobpages differ from blobspace blobpages in several important ways. Partition blobpages are more like other Dynamic Server pages; they are the same size (BUFFSIZE), whereas the blobspace blobpage size can be configured to any multiple of BUFFSIZE. Partition blobpages are modified in the shared memory buffer pool; blobspace blobpages are not. Partition blobpages are written to logical logs with their corresponding data row. Blobspace blobpages are not logged.</p>
<p><code>partition blobpages 与 BLOB 空间 BLOB 页（blobspace blobpages）在几个重要方面存在差异。Partition blobpages 更类似于其他 Dynamic Server 页；它们大小相同（均为 BUFFSIZE），而 BLOB 空间 BLOB 页的大小可以配置为 BUFFSIZE 的任意整数倍。Partition blobpages 在共享内存缓冲池中进行修改；而 BLOB 空间 BLOB 页则不会在此处修改。Partition blobpages 会与其对应的数据行一同写入逻辑日志；而 BLOB 空间 BLOB 页则不会被记录到日志中。</code></p>
<p><strong>BLOB Descriptor Structure</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232331704.png" alt="image-20250523233146617"></p>
<p><strong>Notes:</strong></p>
<p>On the slide above is the layout of the 56-byte blob descriptor. This structure is not only stored on home data pages, but is used throughout the database server for various blob-related reading, writing, and manipulating activities. As a result, there are several elements included in the structure that store fascinating data for fleeting moments, but do not contain anything of interest when the blob descriptor is at rest, as it is on disk.</p>
<p><code>上面幻灯片展示的是 56 字节 BLOB 描述符的布局结构。这种结构不仅存储在主数据页（home data pages）上，还在整个数据库服务器中用于各种与 BLOB 相关的读取、写入和操作活动。因此，这个结构体中包含若干元素——它们在某些瞬间可能存储着极具价值的数据，但当描述符处于静止状态（如存储在磁盘上时），这些元素就不再包含任何有意义的信息。</code></p>
<p>The two-byte <strong>flags</strong> element of the descriptor structure contains any <em>one</em> of the following flag values:</p>
<p><code>描述符结构中的两字节 flags 元素包含以下任意一个标志值：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505232337332.png" alt="image-20250523233748283"></p>
<p>In an upcoming exercise, you will use the <strong>oncheck -pD</strong> command to view and analyze the blob descriptor.</p>
<p><code>在接下来的练习中，你将使用 oncheck -pD 命令来查看和分析 blob descriptor。</code></p>
<p><strong>Partition Blobpages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505242215041.png" alt="image-20250524221525914"></p>
<p><strong>Notes:</strong></p>
<p>A partition blob consists of one or more blob <em>pieces</em>. Blob data that is too large to fit on one partition blobpage is split into several blob pieces chained together with forwarding pointers. Like a chain of remainder pieces for a very large row, all but the last blob piece in a chain is given its own blobpage so that the fewest possible number of pages are involved.</p>
<p><code>partition blob 由一个或多个 blob piece 组成。若大对象数据过大，无法容纳于单个partition blobpage 中，则会将其拆分为多个blob piece，并通过forwarding pointers将这些 piece 串联起来。这就好比针对超大行数据所形成的 a chain of remainder pieces，除链中的最后一个 blob piece 外，其余所有 blob piece 都会分配各自独立的 blobpage，以确保涉及的 blobpage 数量尽可能少。</code></p>
<p>Above is a partition blobpage that contains two blob pieces. By definition, each of these blob pieces must be from a different blob.</p>
<p><code>上图展示的是一个包含两个 blob piece 的 partition blobpage。根据定义，这两个 blob piece 必定来自不同的 blob。</code></p>
<p>A blob piece consists of the blob data itself, preceded by 8 bytes of overhead related to forwarding.</p>
<p><code>一个 blob piece 由 blob 数据本身以及其前面与 forwarding 相关的 8 字节开销（overhead）组成。</code></p>
<p><strong>bstamp (2 bytes)</strong></p>
<p>The blobstamp occupies the first two bytes of a blob piece. Blobstamps help Dynamic Server verify the consistency of a chain of blob pieces, which could involve hundreds of pages. Note that the blobstamp does not have to be the same value for all pieces in the chain.</p>
<p><code>大对象时间戳（blobstamp）占据一个大对象片段（blob piece）的前两个字节。大对象时间戳有助于 Dynamic Server 验证由数百个页可能构成的大对象片段链的一致性。需要注意的是，该链中所有片段的大对象时间戳的值并不一定相同。</code></p>
<p>A stamp for a particular blob piece simply has to match what was expected by the previous piece (or the descriptor itself, in the case of the first piece). Otherwise, expect this ISAM error:</p>
<p><code>某个特定大对象片段（blob piece）的时间戳只需与前一个片段（或对于第一个片段而言，是与描述符本身）所预期的时间戳相匹配即可。否则，将会遇到以下 ISAM 错误：</code></p>
<p>​		-164 ISAM error: TEXT or BYTE stamp is incorrect.</p>
<p><strong>Next blobpage (4 bytes)</strong></p>
<p>This element looks and functions exactly like the forwarding pointers you have already studied. It contains the rowid of the next blob piece in the chain, if one exists. The last blob piece in the chain has a <em>next blobpage</em> value of 0xffffffff.</p>
<p><code>这个元素无论是看起来还是功能上都与你之前研究过的 forwarding pointers 完全一致。如果链中存在下一个大对象片段（blob piece），它会包含该片段的 rowid。而链中的最后一个大对象片段，其 next blobpage 的值会被设置为 0xffffffff，以此表示链的结束。</code></p>
<p><strong>nbstamp (2 bytes)</strong></p>
<p>This is the expected blobstamp for the next blob piece in the chain.</p>
<p><code>这是链中下一个大对象片段（blob piece）所预期的大对象时间戳（blobstamp）。</code></p>
<p><strong>oncheck -pT</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505242245718.png" alt="image-20250524224520621"></p>
<p><strong>Notes:</strong></p>
<p>The output from <strong>oncheck -pT</strong> is a super-set of the output from <strong>oncheck -pt</strong>. Information from the partition structure and the extent slot is displayed first, followed by quite a bit of useful information on the complexion of the tblspace, all of which is in decimal.</p>
<p><code>oncheck -pT 命令的输出是 oncheck -pt 命令输出的超集。它会首先显示 partition structure 和 extent slot 的相关信息，随后会提供大量关于表空间（tblspace）状况的有用信息，所有这些信息均以十进制格式呈现。</code></p>
<p>The first portion of this extra output for a sample table is shown in the slide above. It is a general usage report for the tblspace that tallies up the number of free pages, bitmap pages, index pages, home data pages, remainder pages and partition blobpages. (This sample table contains both VARCHARS and partition-resident blobs.) The 4-bit bitmap page is used to determine the relative fullness of the remainder pages and partition blobpages.</p>
<p><code>上述幻灯片中展示了针对一个示例table，这部分额外输出的第一部分内容。它是一份关于表空间（tblspace）的通用使用情况报告，其中汇总了 free pages、bitmap pages、index pages、home data pages、remainder pages 以及 partition blobpages 的数量。（这个示例表中同时包含了 VARCHARS and partition-resident blobs）这里提到的 4-bit bitmap page 用于确定 remainder pages and partition blobpages 的相对填充程度。</code></p>
<p>The total number of unused bytes on each data-related page type is tallied next.</p>
<p><code>接下来会对每种与数据相关的页类型上未使用的字节总数进行汇总。</code></p>
<p>If a table seems to be performing poorly, or using more space than one would expect, this report can be enlightening. For example, if <strong>oncheck -pT</strong> clearly shows that the table is using space inefficiently, a review of the schema might reveal that the row size is just 20 bytes more than the amount of unused space on every full data page, and that a 4 byte reduction in the row size would compact the table by 15%. It has happened.</p>
<p><code>如果某个表看起来性能不佳，或者占用的空间超出了预期，那么这份报告可能会提供有价值的见解。例如，如果 oncheck -pT 报告清晰地显示出该表的空间使用效率低下，那么对表schema的审查可能会揭示出，row size 仅比每个满数据页上未使用的空间多出 20 字节，而如果将行大小减少 4 字节，就可以使表的占用空间减少 15%。这种情况确实发生过。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-IX9111/3"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/05/09/IX9111/3/"
    >IX9111 - Unit 3. Dbspace Layout</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/05/09/IX9111/3/" class="article-date">
  <time datetime="2025-05-09T13:44:05.000Z" itemprop="datePublished">2025-05-09</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/IX9111/">IX9111</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>A Hypothetical Root Dbspace</strong></p>
<p>一个假想的root dbspace</p>
<blockquote>
<p>hypothetical<br>英[ˌhaɪpəˈθetɪkl]  美[ˌhaɪpəˈθetɪkl]<br>adj.（基于）假设的，假定的;有待证实的;</p>
</blockquote>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505092150641.png" alt="image-20250509215037499"></p>
<p><strong>Notes:</strong></p>
<p>The root dbspace is an Informix database server’s first and most critical dbspace. It contains the system’s first chunk, the <em>root chunk</em>. As with other dbspaces, additional chunks can be added over time. Since the root dbspace as a whole can never be dropped, the initial chunk for the root dbspace should be configured wisely.</p>
<p><code>root dbspace是 IDS 的第一个也是最关键的数据库空间。它包含系统的第一个数据块，即 root chunk。与其他数据库空间一样，随着时间的推移还可以添加其他块。由于根数据库空间作为一个整体永远不会被删除，因此应明智地配置根数据库空间的初始块。</code></p>
<blockquote>
<p>wisely<br>英[ˈwaɪzli] 美[ˈwaɪzli]<br>adv.明智地;</p>
</blockquote>
<p>You normally do not keep databases in the root dbspace. Data should be spread across multiple disks, and to do that you should create multiple dbspaces and assign tables to specific dbspaces (or fragment a table across dbspaces).</p>
<p><code>通常情况下，不会在root dbspace中保存数据库。数据应分布在多个磁盘上，为此应创建多个dbspace，并将表分配到特定的dbspace（或将表分片到不同的dbspace）。</code></p>
<p>Initially, the physical log and at least three logical logs are located in the root dbspace. During the tuning phase, these are normally recreated in other dbspaces to take advantage of additional disk drives.</p>
<p><code>最初，物理日志和至少三个逻辑日志位于root dbspace。在调整阶段，通常会在其他dbspace重新创建这些日志，以利用额外的磁盘驱动器。</code></p>
<blockquote>
<p>tuning<br>英[ˈtjuːnɪŋ]美[ˈtuːnɪŋ]<br>v.(给收音机、电视等)调谐，调频道;调整，调节(发动机);(为乐器)调音，校音;<br>n.【无线】调谐；收听；【乐】调音[弦];</p>
</blockquote>
<p><strong>Layout of a Root Chunk</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505092202432.png" alt="image-20250509220256358"></p>
<p><strong>Notes:</strong></p>
<p>After a complete disk initialization and before a system is tuned, the layout of the root chunk looks similar to the one pictured above.</p>
<p><code>在完成磁盘初始化后和系统调整前，root chunk的布局与上图类似。</code></p>
<p><strong>Reserved pages</strong></p>
<p>The first twelve pages of the initial chunk in the root dbspace are the system <em>reserved</em> <em>pages</em>, which are used for system-tracking information and are updated during each checkpoint. Beginning with the third reserved page, the pages are organized into semi-redundant pairs, each of which stores a distinct type of structure, with the pages in each pair taking turns as the more current version.</p>
<p><code>root dbspace中初始块的前十二页是系统保留页，用于系统跟踪信息，并在每次检查点时更新。从第三个保留页面开始，页面被组织成半冗余对，每个对存储一种不同类型的结构，每个对中的页面轮流作为最新版本。</code></p>
<blockquote>
<p>semi<br>英[ˈsemi]  美[ˈsemi]<br>n. 半决赛;半独立式住宅;</p>
<p>redundant<br>英[rɪˈdʌndənt]  美[rɪˈdʌndənt]<br>adj.冗余的;多余的;不需要的;被裁减的;</p>
</blockquote>
<p><strong>Chunk free list</strong></p>
<p>In every chunk, the page following the reserved pages is a chunk free-list page. A chunk free-list page contains information about free extents (groups of contiguous free pages) in the chunk.</p>
<p><code>在每个chunk中，保留页之后的页面是chunk free list page。chunk free list page包含分chunk中空闲extents（由连续空闲页组成）的信息。</code></p>
<p><strong>Tblspace tblspace</strong></p>
<p>A tblspace tblspace is a collection of pages that describes the location and structure of all tblspaces in a particular dbspace. Most pages in the tblspace tblspace have the same format and contain the following major components:</p>
<p><code>tblspace tblspace 是描述特定 dbspace 中所有 tblspace 的位置和结构的页面集合。tblspace tblspace 中的大多数页面格式相同，并包含以下主要组件：</code></p>
<p><strong>•</strong> The number and location of extents</p>
<p><code>extent的数量和位置</code></p>
<p><strong>•</strong> Information about special columns (large objects and VARCHAR data)</p>
<p><code>有关特殊列（大对象和 VARCHAR 数据）的信息</code></p>
<p><strong>•</strong> An array of index key information</p>
<p><code>索引键信息数组</code></p>
<p><strong>•</strong> The database and table name</p>
<p><code>数据库和表名</code></p>
<p>You can find out where the tblspace tblspace extents are located by running <strong>oncheck -pe</strong> and looking for <strong>dbspace_name:’informix’.TBLSpace</strong>.</p>
<p><code>运行oncheck -pe并查找dbspace_name:&#39;gbasedbt&#39;.TBLSpace，即可找出 tblspace tblspace extents 的位置。</code></p>
<p>实测，oncheck -pe出来一大堆信息，看不懂，截选部分，rootdbs:’gbasedbt’.TBLSpace 有好几个，下边还有。再下边还有其他dbspace的信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">DBspace Usage Report: rootdbs             Owner: gbasedbt  Created: 04/17/2025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Chunk Pathname                             Pagesize(k)  Size(p)  Used(p)  Free(p)</span><br><span class="line">     1 /opt/gbase/storage/rootdbs                     2    78848    13748    65100</span><br><span class="line"></span><br><span class="line"> Description                                                   Offset(p)  Size(p)</span><br><span class="line"> ------------------------------------------------------------- -------- --------</span><br><span class="line"> RESERVED PAGES                                                       0       12</span><br><span class="line"> CHUNK FREELIST PAGE                                                 12        1</span><br><span class="line"> rootdbs:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                         13      250</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.ix_ph_run_03                                   263        4</span><br><span class="line"> tmpsbspace:<span class="string">&#x27;gbasedbt&#x27;</span>.tmpsbspace_desc                              267        4</span><br><span class="line"> RESERVED PAGES                                                     271        2</span><br><span class="line"> RESERVED PAGES                                                     273        2</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.command_history                                275        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.ix_cmd_hist_02                                 283        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_iohist                                     287        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_config                                     295        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage                                 303        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix1                             311        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix2                             315        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix1                             319        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage                                 323        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_page_usage_ix2                             331        4</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_users                                      335        8</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_table_profile                              343       16</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.mon_checkpoint                                 359        8</span><br><span class="line"> rootdbs:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                        367      200</span><br><span class="line"> sysadmin:<span class="string">&#x27;gbasedbt&#x27;</span>.idx_mon_ckpt_1                                 567        4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>Database tblspace</strong></p>
<p>The database tblspace is a list of all databases in the Informix Dynamic Server system, and includes the following components:</p>
<p><code>database tblspace 是 IDS 系统中所有数据库的列表，包括以下组件：</code></p>
<p><strong>•</strong> Database name</p>
<p><code>数据库名</code></p>
<p><strong>•</strong> Database owner</p>
<p><code>数据库所有者</code></p>
<p><strong>•</strong> Date and time the database was created</p>
<p><code>创建数据库的日期和时间</code></p>
<p><strong>•</strong> The partition number of the <strong>systables</strong> system catalog table for this database</p>
<p><code>该数据库的 systables 系统表的 partition number</code></p>
<p><strong>•</strong> Flags that show the logging mode for the database</p>
<p><code>显示数据库日志记录模式的标志</code></p>
<p>To find out where the database tblspace is physically located on your server, use the <strong>oncheck -pe</strong> command to generate an extent report and look for the extents allocated to <strong>sysmaster:’informix’.sysdatabases</strong>.</p>
<p><code>要找出数据库 tblspace 在服务器上的物理位置，请使用 oncheck -pe 命令生成一份扩展报告，并查找分配给 sysmaster:&#39;gbasedbt&#39;.sysdatabases 的extents。</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysmaster:<span class="string">&#x27;gbasedbt&#x27;</span>.sysdatabases                                27447        4</span><br></pre></td></tr></table></figure>

<p>紫本180页：</p>
<p>6.4.2.2 tablespace</p>
<blockquote>
<p>​		tablespace 是一个逻辑概念，指一个表或者索引所占用的空间。GBase 8t 用 tablespace 来描述一个表或者索引信息。一个 tablespace 是多个 extent 的逻辑集合，可以分布在不同的 dbspace 或者 chunk 上。在 GBase 8t 系统表中对表、索引采用 tablespace 进行描述。</p>
<p>​		GBase 8t把分片表、索引的一个分片作为一个tablespace进行管理。每个表、索引在GBase8t 内部都有一个 partnum，在 GBase 8t 内部以该编号进行管理。例如在一个 GBase 8t 实例下有一个 database tblspace，包含所有的数据库 databases 的信息。database tblspace 的 partnum永远是 x00100002，位于 root dbspaces 上，也就是 sysmaster 数据中的 sysdatabases 表。</p>
<p>​		我们可以通过查询 sysmaster 的 systabnames 表得到一个数据库实例下的所有表、索引的 tblspace 信息。</p>
</blockquote>
<p>所以，database tblspace有系统表对应sysdatabases，而Tblspace tblspace看着应该是同样有个系统表，叫做Tblspace（描述特定 dbspace 中所有 tblspace），但又不知道在哪</p>
<p><a target="_blank" rel="noopener" href="https://www.ibm.com/support/pages/what-tblspace-tblspace">What is TBLspace TBLspace?</a></p>
<p>这篇文章提到：You are running IBM® Informix® Dynamic Server (IDS) database server and create a regular Dbspace. This Dbspace contains an internal table called TBLspace TBLspace. You cannot access the table using SQL commands.</p>
<p>所以，有个内部表叫做TBLspace TBLspace，无法用SQL访问</p>
<p>deepseek：</p>
<ul>
<li>它是Informix内核管理的<strong>元数据表</strong>（metadata table）</li>
<li><strong>不开放SQL访问</strong>（如文档所述：*”You cannot access the table using SQL commands”*）</li>
<li>仅通过底层存储引擎直接管理</li>
</ul>
<p><strong>Layout of a Non-Root Chunk</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505101345909.png" alt="image-20250510134500787"></p>
<p><strong>Notes:</strong></p>
<p>The above slide shows the layout of all other chunks in the system except the root chunk. There are two slightly different types: those that are the first chunks in their respective dbspaces, and those that are subsequent to the first chunk.</p>
<p><code>上面的幻灯片显示了系统中除root chunk之外的所有其他chunk的布局。有两种略有不同的类型：一种是各自dbspace中的第一个chunk，另一种是第一个chunk之后的chunk。</code></p>
<p>第一个chunk就是后边提到的所谓<strong>Primary Chunk</strong></p>
<p><strong>Reserved pages</strong></p>
<p>The first two pages of any non-root chunk are reserved for nothing. They are not even initialized with a page header. The early Informix Dynamic Server designers thought they might need them someday, but so far, the most sensible suggested uses have been for <em>binary graffiti</em> and <em>credits</em>.</p>
<p><code>在任何非根区块（non-root chunk）中，前两页是保留不用的。它们甚至没有被初始化为页面头（page header）。早期的 IDS 设计者认为将来可能会用到它们，但到目前为止，最合理的建议用途是用于“二进制涂鸦”（binary graffiti）和“致谢名单”（credits）。</code></p>
<p><strong>Chunk free list</strong></p>
<p>In every chunk, the page following the reserved pages is a chunk free-list page.</p>
<p><code>在每个chunk中，紧跟在保留页之后的那一页是chunk的空闲页列表页（chunk free-list page）。</code></p>
<p><strong>Tblspace tblspace</strong></p>
<p>Every dbspace contains a tblspace tblspace, also called a partition table. The first extent of the tblspace tblspace is always allocated in the first chunk of the dbspace. Like any other tblspace, when additional extents are required, they are allocated wherever there is room in the dbspace.</p>
<p><code>每个 dbspace 都包含一个 tblspace tblspace，也称为分区表(partition table)。tblspace tblspace 的第一个 extent 总是分配在 dbspace 的第一个chunk中。与其他 tblspace 一样，当需要额外的扩展时，它们会被分配到 dbspace 中有空间的地方。</code></p>
<p>The initial and subsequent extent size for the partition table in non-root dbspaces is 50 pages.</p>
<p><code>非root dbspace中分区表（partition table）的初始和后续extent大小为 50 页。</code></p>
<p><strong>Overview of Root Reserved Pages</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505101359231.png" alt="image-20250510135946163"></p>
<p><strong>Notes:</strong></p>
<p>The first 12 pages of the root chunk are reserved for system information. Starting with page 2, the pages are grouped in pairs and are alternately updated.</p>
<p><code>root chunk的前 12 页保留给系统信息。从第 2 页开始，页面成对分组，交替更新。</code></p>
<p><strong>Page zero</strong></p>
<p>Page 0 contains the Informix copyright and version information, the minimum page size, and the date and time of the system’s creation.</p>
<p><code>第 0 页包含 Informix 版权和版本信息、最小页面大小以及系统创建的日期和时间。</code></p>
<p><strong>Configuration page</strong></p>
<p>Page 1 contains a copy of all the information stored in the system’s configuration file (<strong>$INFORMIXDIR&#x2F;etc&#x2F;$ONCONFIG</strong>) at the time the server was last brought online.</p>
<p><code>第 1 页包含服务器上次联机时存储在系统配置文件（$INFORMIXDIR/etc/$ONCONFIG）中的所有信息的副本。</code></p>
<p><strong>Checkpoint&#x2F;logical log pages</strong></p>
<p>Page 2 and page 3 are the checkpoint&#x2F;logical log pages. The current checkpoint&#x2F;logical log page gives the location, date and time of the last checkpoint, and the location and current status of each of the logical logs.</p>
<p><code>第 2 页和第 3 页是检查点/逻辑日志页面。当前检查点/逻辑日志页面显示上次检查点的位置、日期和时间，以及每个逻辑日志的位置和当前状态。</code></p>
<p><strong>Dbspace pages</strong></p>
<p>Page 4 and page 5 are the dbspace pages. Each entry on the current dbspace page tracks the status, location, data, and creation time of a dbspace.</p>
<p><code>第 4 页和第 5 页是 dbspace 页面。当前dbspace页面的每个条目都会跟踪 dbspace 的状态、位置、数据和创建时间。</code></p>
<p><strong>Primary chunk pages</strong></p>
<p>Pages 6 and 7 are the reserved pages that contain information about each of the primary chunks on the server. For each chunk, the current primary-chunk page contains information about the pathname, size, offset, and status of the chunk.</p>
<p><code>第 6 页和第 7 页是保留页，包含server上每个primary chunk的信息。对于每个chunk，当前的primary chunk page包含该chunk的路径名、大小、偏移量和状态信息。</code></p>
<p><strong>Mirror chunk pages</strong></p>
<p>Pages 8 and 9 are the mirror chunk pages. The structure of these pages are the same as the primary chunk pages</p>
<p><code>第 8 页和第 9 页是mirror chunk页面。这些页面的结构与primary chunk pages相同</code></p>
<p><strong>Archive pages</strong></p>
<p>Pages 10 and 11 (0xa and 0xb) are the archive pages. These pages contains information on the most recent archives performed on the server.</p>
<p><code>第 10 页和第 11 页（0xa 和 0xb）是存档页面。这些页面包含在服务器上进行的最新存档信息。</code></p>
<p><strong>The Copyright Page</strong></p>
<p>oncheck -pr，下边还有很多内容，与本节无关，不贴出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Validating GBase Database Server reserved pages</span><br><span class="line"></span><br><span class="line">    Validating PAGE_PZERO...</span><br><span class="line"></span><br><span class="line">    Identity                       GBase Database Server Co</span><br><span class="line">                                   pyright 2001, 2021  Gene</span><br><span class="line">                                   ral Data Corporation</span><br><span class="line">    Database system state          0</span><br><span class="line">    Database system flags          0x3</span><br><span class="line">    Page Size                      2048 (b)</span><br><span class="line">    Date/Time created              04/17/2025 08:44:48</span><br><span class="line">    Version number of creator      32</span><br><span class="line">    Last modified time stamp       0</span><br><span class="line">    UID of rootdbs creator         1001</span><br><span class="line">    Index Page Logging             OFF</span><br><span class="line">    HA Disk Owner                  &lt;null&gt;</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The slide above shows a sample <strong>oncheck -pr</strong> output for the copyright page. </p>
<p><code>上面的幻灯片展示了版权页的oncheck -pr输出示例。</code></p>
<p>One important use of this page is the identification of the version of the Informix Dynamic Server system. The current version is listed here under <strong>Version number of creator</strong>. If the version number is earlier than the <strong>oninit</strong> version, the database server performs any upgrade steps required to move the Informix Dynamic Server system to the new version. </p>
<p><code>本页的一个重要用途是识别 IDS 系统的版本。当前版本列于此处的 Version number of creator 下。如果版本号早于 oninit 版本， database server 将执行所有必要的升级步骤，以将 Informix Dynamic Server 系统迁移到新版本。</code></p>
<p>Upgrading the server is not always required; it is only necessary when the disk architecture or the structure of tables in <strong>sysmaster</strong> or <strong>sysutils</strong> has changed.</p>
<p><code>并不总是需要升级 server；只有在磁盘架构或 sysmaster 或 sysutils 中的表格结构发生变化时才需要升级。</code></p>
<p><strong>Hint</strong></p>
<p>Run the command:</p>
<p>​		oncheck -pP 1 0</p>
<p>and compare that output to the report generated by <strong>oncheck -pr</strong>.</p>
<p>1001 -&gt; 3e9    20 - &gt; 32</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@frh gbase]<span class="comment"># oncheck -pP 1 0</span></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:0              157435   66f8   3      1800 ROOTRSV      304   1728  0        0</span><br><span class="line">        slot ptr   len   flg</span><br><span class="line">        1    24    252   0</span><br><span class="line">        3    276   28    0</span><br><span class="line">slot   1:</span><br><span class="line">    0: 47 42 61 73 65 20 44 61 74 61 62 61 73 65 20 53   GBase Database S</span><br><span class="line">   16: 65 72 76 65 72 20 43 6f 70 79 72 69 67 68 74 20   erver Copyright</span><br><span class="line">   32: 32 30 30 31 2c 20 32 30 32 31 20 20 47 65 6e 65   2001, 2021  Gene</span><br><span class="line">   48: 72 61 6c 20 44 61 74 61 20 43 6f 72 70 6f 72 61   ral Data Corpora</span><br><span class="line">   64: 74 69 6f 6e  0  0  0  0  0  0  0  0  0  0  0  0   tion............</span><br><span class="line">   80:  0  0  3  0  0  8  0  0 f0 21  1 68 20  0  0  0   ........p!.h ...</span><br><span class="line">   96:  0  0  0  0 e9  3  0  0 31 32 31 34  1  0  0  0   ....i...1214....</span><br><span class="line">  112:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  128:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  144:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  160:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  176:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  192:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  208:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  224:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0   ................</span><br><span class="line">  240:  0  0  0  0  0  0  0  0  0  0  0  0               ................</span><br><span class="line">slot   3:</span><br><span class="line">    0:  3  0 10  0 3b 6b  0  0  1  0  0  0  0  0  0  0   ....;k..........</span><br><span class="line">   16:  c 46 22 30 34 2d 32 30 32 35  0  0               .F<span class="string">&quot;04-2025......</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>



<p><strong>The Configuration Page</strong></p>
<p>oncheck -pr截取</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    Validating PAGE_CONFIG...</span><br><span class="line"></span><br><span class="line">    ROOTNAME                       rootdbs</span><br><span class="line">    ROOTPATH                       /opt/gbase/storage/rootdbs</span><br><span class="line">    ROOTOFFSET                     0 (k)</span><br><span class="line">    ROOTSIZE                       157696 (k)</span><br><span class="line">    MIRROR                         0</span><br><span class="line">    MIRRORPATH                     /opt/gbase/tmp/demo_on.root_mirror</span><br><span class="line">    MIRROROFFSET                   0 (k)</span><br><span class="line">    DBSERVERNAME                   ol_gbasedbt1210_1</span><br><span class="line">    SERVERNUM                      0</span><br><span class="line">    MSGPATH                        /opt/gbase/ol_gbasedbt1210_1.<span class="built_in">log</span></span><br><span class="line">    TAPEDEV                        /dev/tapedev</span><br><span class="line">    TAPESIZE                       0 (k)</span><br><span class="line">    TAPEBLK                        32 (k)</span><br><span class="line">    LTAPEDEV                       /dev/null</span><br><span class="line">    LTAPESIZE                      0 (k)</span><br><span class="line">    LTAPEBLK                       32 (k)</span><br><span class="line">    PHYSFILE                       71972 (k)</span><br><span class="line">    PHYSBUFF                       512 (k)</span><br><span class="line">    LOGFILES                       19</span><br><span class="line">    LOGSIZE                        6144 (k)</span><br><span class="line">    LOGBUFF                        256 (k)</span><br><span class="line">    DYNAMIC_LOGS                   2</span><br><span class="line">    LTXHWM                         70 (%)</span><br><span class="line">    LTXEHWM                        80 (%)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The configuration page contains values for all <em>documented</em> parameters in the configuration file ($ONCONFIG). In other words, it is not simply a copy of whatever happens to be in the configuration file; adding additional parameters to the configuration file does not add anything new to the configuration page.</p>
<p><code>configuration page 包含配置文件 ($ONCONFIG) 中所有已记录参数的值。换句话说，它并非配置文件中内容的简单复制；在配置文件中添加其他参数并不会给 configuration page 添加任何新内容。</code></p>
<p><strong>Seen and unseen</strong></p>
<p>The <strong>oncheck -pr</strong> output above shows an example of the contents of the configuration page. Note that on some platforms, many legitimate parameters in the configuration file do not show up in this report, such as NUMCPUVPS, STACKSIZE, and SHMTOTAL.</p>
<p><code>上面的 oncheck -pr 输出显示了 configuration page 内容的示例。请注意，在某些平台上，configuration page 中的许多合法参数不会显示在此报告中，例如 NUMCPUVPS、STACKSIZE 和 SHMTOTAL。</code></p>
<blockquote>
<p>legitimate 合法的 英[lɪˈdʒɪtɪmət]美[lɪˈdʒɪtɪmət]</p>
</blockquote>
<p>The <strong>onstat -c</strong> command does not use the information from these pages. This command reads the configuration file instead of the reserved page.</p>
<p><code>onstat -c 命令不使用这些页面中的信息。此命令读取配置文件，而不是保留页。</code></p>
<p><strong>Hint</strong></p>
<p>Run the command:</p>
<p>​		oncheck -pP 1 1</p>
<p>and compare that output to the report generated by <strong>oncheck -pr</strong>. Notice that <strong>oncheck -pP</strong>, being a more general page-displaying tool, reveals parameters on the configuration page not displayed by <strong>oncheck -pr</strong>.</p>
<p><code>请注意，oncheck -pP 是一个更通用的页面显示工具，它会显示 oncheck -pr 未显示的配置页面上的参数。</code></p>
<blockquote>
<p>reveals<br>英[rɪˈviːlz] 美[rɪˈviːlz]<br>v.揭示;显示;透露;展示;露出;显出;<br>n.揭示（reveal 的复数）;</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">slot   1:</span><br><span class="line">    0: 52 4f 4f 54 4e 41 4d 45 20 72 6f 6f 74 64 62 73   ROOTNAME rootdbs</span><br><span class="line">   16:  0                                                ................</span><br><span class="line">slot   2:</span><br><span class="line">    0: 52 4f 4f 54 50 41 54 48 20 2f 6f 70 74 2f 67 62   ROOTPATH /opt/gb</span><br><span class="line">   16: 61 73 65 2f 73 74 6f 72 61 67 65 2f 72 6f 6f 74   ase/storage/root</span><br><span class="line">   32: 64 62 73  0                                       dbs.............</span><br><span class="line">slot   3:</span><br><span class="line">    0: 52 4f 4f 54 4f 46 46 53 45 54 20 30  0            ROOTOFFSET 0....</span><br><span class="line">slot   4:</span><br><span class="line">    0: 52 4f 4f 54 53 49 5a 45 20 31 35 37 36 39 36  0   ROOTSIZE 157696.</span><br><span class="line">slot   5:</span><br><span class="line">    0: 4d 49 52 52 4f 52 20 30  0                        MIRROR 0........</span><br></pre></td></tr></table></figure>

<p>上面是 oncheck -pP 1 1 截取部分</p>
<p><strong>The Checkpoint&#x2F;Logical Log Page</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1CKPT &amp; PAGE_2CKPT...</span><br><span class="line">      Using check point page PAGE_2CKPT.</span><br><span class="line"></span><br><span class="line">Time stamp of checkpoint       0x7f7e6b</span><br><span class="line">Time of checkpoint             05/10/2025 05:17:37</span><br><span class="line">Physical <span class="built_in">log</span> begin address     2:53</span><br><span class="line">Physical <span class="built_in">log</span> size              35986 (p)</span><br><span class="line">Physical <span class="built_in">log</span> position at Ckpt  30148</span><br><span class="line">Logical <span class="built_in">log</span> unique identifier  148</span><br><span class="line">Logical <span class="built_in">log</span> position at Ckpt   0xc510c0 (Page 3153, byte 192)</span><br><span class="line">Checkpoint Interval            98</span><br><span class="line">DBspace descriptor page        1:4</span><br><span class="line">Chunk descriptor page          1:7</span><br><span class="line">Mirror chunk descriptor page   1:8</span><br><span class="line"></span><br><span class="line">Log file number                14</span><br><span class="line">Unique identifier              146</span><br><span class="line">Log file flags                 0x5        Log file <span class="keyword">in</span> use</span><br><span class="line">&amp;                                         Log file has been backed up</span><br><span class="line">Physical location              3:29483</span><br><span class="line">Log size                       3270 (p)</span><br><span class="line">Number pages used              3270</span><br><span class="line">Date/Time file filled          04/17/2025 09:10:15</span><br><span class="line">Time stamp                     0x578dde</span><br><span class="line"><span class="comment"># 下边把剩余的所有 Log file number 都列出来了</span></span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The current checkpoint&#x2F;logical log page gives the location, date, and time of the last checkpoint, and the location and current status of the logical logs.</p>
<p><code>当前 checkpoint/logical log page 给出了最后一个检查点的位置、日期和时间，以及逻辑日志的位置和当前状态。</code></p>
<p>Beginning with page 2, the reserved pages are paired. However, only one page out of the pair is current. So when we refer to the primary chunk reserved page, dbspace reserved page, or the checkpoint&#x2F;logical log reserved page, we are talking about the current page of the pair. The current page can be easily found by comparing the timestamps, which is the method used by <strong>oncheck -pr</strong> when deciding which of the pages to display. Notice that at the top of each reserved page output, <strong>oncheck</strong> indicates which page of the pair it has chosen to display.</p>
<p><code>从第 2 页开始，保留页是成对的。但是，每对页中只有一个是当前页。因此，当我们提到 primary chunk 保留页、dbspace 保留页或检查点/逻辑日志保留页时，我们指的是该对中的当前页。可以通过比较时间戳轻松找到当前页，这也是 oncheck -pr 在决定显示哪些页时使用的方法。请注意，在每个保留页输出的顶部，oncheck 都会指示它选择显示的页对中的哪个页。（说的应该是“Using check point page PAGE_2CKPT.”）</code></p>
<p><strong>Hint</strong></p>
<p>Run the commands:</p>
<p>​		oncheck -pP 1 2</p>
<p>and</p>
<p>​		oncheck -pP 1 3</p>
<p>First, determine which of the pages is more current by looking at the timestamps. Then compare your observation with the <strong>oncheck -pr</strong> report.</p>
<p>可能意思是看2和3，哪个stamp数字更大吧</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">oncheck -pP 1 2</span><br><span class="line"></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:2              8343790  5092   20     1800 ROOTRSV      680   1284  0        0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">oncheck -pP 1 3</span><br><span class="line"></span><br><span class="line">addr             stamp    chksum nslots flag <span class="built_in">type</span>         frptr frcnt next     prev</span><br><span class="line">1:3              8355443  7e0e   20     1800 ROOTRSV      680   1284  0        0</span><br></pre></td></tr></table></figure>



<p><strong>A pair of nearly identical pages</strong></p>
<p>You might still be confused about how the two checkpoint&#x2F;logical log pages are split. It is <strong>not</strong> the case that one page contains checkpoint information while the other page contains logical log information. There is checkpoint and logical log information on both pages, as shown here:</p>
<p><code>您可能仍然对两个 checkpoint/logical log page 的划分方式感到困惑。一个页面包含检查点信息，而另一个页面包含逻辑日志信息，这种情况并非如此。两个页面上都包含检查点和逻辑日志信息，如下所示：</code></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505102139970.png" alt="image-20250510213923811"></p>
<p>The difference between the two pages is that one contains up-to-date information, and the other contains information that is one iteration out of date. This is true for all the reserved-page pairs.</p>
<p><code>这两个页面的区别在于，一个页面包含最新信息，而另一个页面包含的信息已经过期一个迭代。所有保留页对都是如此。</code></p>
<p>图上，黑横线是page分割线，黑线下边紧邻是页头，上边紧邻右侧是页尾</p>
<p><strong>The checkpoint structure vs. checkpoint records</strong></p>
<p>It is important to distinguish between the checkpoint <em>structure</em>, found on the checkpoint&#x2F;logical log page, and checkpoint <em>records</em>.</p>
<p><code>必须区分检查点/逻辑日志页面上的 checkpoint structure 和 checkpoint records。</code></p>
<p>Checkpoint records are written to the logical logs. One of the last steps taken by IDS during a checkpoint is to write a checkpoint record to the current logical log file.</p>
<p><code>Checkpoint records 写入逻辑日志。在检查点过程中，IDS 采取的最后一个步骤是向当前逻辑日志文件写入检查点记录。</code></p>
<p>At any given time, there can be many checkpoint records scattered throughout the logical logs on disk. But of those records, only the most recently written record is important to fast recovery. The checkpoint structure*,* on the checkpoint&#x2F;logical log page, contains information that, in the event of a system shutdown or crash, guides fast recovery to this most-important, most-recent checkpoint record.</p>
<p><code>在任意时刻，磁盘上的逻辑日志中可能分布着许多检查点（checkpoint）记录。但在这些记录中，只有最近写入的那条记录对快速恢复最为关键。位于检查点/逻辑日志页上的检查点结构（checkpoint structure）包含了相关信息，在系统关闭或崩溃的情况下，这些信息会引导快速恢复过程定位到这一条最重要、最新的检查点记录。。</code></p>
<blockquote>
<p>scatter 分散 英[ˈskætə(r)] 美[ˈskætər]</p>
<p>throughout 遍及 英[θruːˈaʊt] 美[θruːˈaʊt]</p>
</blockquote>
<p><strong>The Checkpoint Structure</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1CKPT &amp; PAGE_2CKPT...</span><br><span class="line">      Using check point page PAGE_2CKPT.</span><br><span class="line"></span><br><span class="line">Time stamp of checkpoint       0x7f7e6b</span><br><span class="line">Time of checkpoint             05/10/2025 05:17:37</span><br><span class="line">Physical <span class="built_in">log</span> begin address     2:53</span><br><span class="line">Physical <span class="built_in">log</span> size              35986 (p)</span><br><span class="line">Physical <span class="built_in">log</span> position at Ckpt  30148</span><br><span class="line">Logical <span class="built_in">log</span> unique identifier  148</span><br><span class="line">Logical <span class="built_in">log</span> position at Ckpt   0xc510c0 (Page 3153, byte 192)</span><br><span class="line">Checkpoint Interval            98</span><br><span class="line">DBspace descriptor page        1:4</span><br><span class="line">Chunk descriptor page          1:7</span><br><span class="line">Mirror chunk descriptor page   1:8</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>What follows is an item-by-item analysis of the checkpoint structure information displayed by <strong>oncheck -pr</strong>. Indicated along with an explanation of each element is its notation (hex or decimal).</p>
<p><code>下面逐项分析 oncheck -pr 显示的检查点结构信息。每个元素的表示方式（十六进制或十进制）也会一并标出，并附带解释。</code></p>
<p><strong>Time stamp of checkpoint</strong> (hex) – The global system timestamp that is current during the last moments of the checkpoint. Notice that the timestamp on the current checkpoint&#x2F;logical log page is often just one or two ticks higher than the timestamp value stored in the checkpoint structure.</p>
<p><code>检查点最后时刻的全局系统时间戳。请注意，当前 checkpoint/logical log page 上的时间戳往往只比存储在 checkpoint structure 中的时间戳值高一两个刻度。</code></p>
<p>checkpoint&#x2F;logical log page 上的时间戳，指的是页尾的时间戳吧，也就是 oncheck -pP 1 3 的 stamp 值 8355443（0x7F7E73），比0x7f7e6b大一点。</p>
<p><strong>Time of checkpoint</strong> – The true date and time of the last checkpoint, based on the UNIX host’s <strong>localtime</strong> function.</p>
<p><code>上次检查点的真实日期和时间，基于 UNIX 主机的 localtime 函数。</code></p>
<p><strong>Physical log begin address</strong> (decimal:decimal) – This is the location (chunk number and page offset) of the first page in the physical log. You can verify this information using <strong>oncheck -pe</strong>.</p>
<p><code>这是物理日志中第一页的位置（chunk编号和页偏移量）。您可以使用 oncheck -pe 验证此信息。</code></p>
<p>oncheck -pe截选，可以看到，chunk 2，offset 53</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DBspace Usage Report: plog                Owner: gbasedbt  Created: 04/17/2025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Chunk Pathname                             Pagesize(k)  Size(p)  Used(p)  Free(p)</span><br><span class="line">     2 /opt/gbase/storage/ol_gbasedbt1210_1_plog_p_1            2    36045    36039        6</span><br><span class="line"></span><br><span class="line"> Description                                                   Offset(p)  Size(p)</span><br><span class="line"> ------------------------------------------------------------- -------- --------</span><br><span class="line"> RESERVED PAGES                                                       0        2</span><br><span class="line"> CHUNK FREELIST PAGE                                                  2        1</span><br><span class="line"> plog:<span class="string">&#x27;gbasedbt&#x27;</span>.TBLSpace                                             3       50</span><br><span class="line"> PHYSICAL LOG                                                        53    35986</span><br><span class="line"> FREE                                                             36039        6</span><br><span class="line"></span><br><span class="line"> Total Used:    36039</span><br><span class="line"> Total Free:        6</span><br></pre></td></tr></table></figure>

<p><strong>Physical log size</strong> (decimal) – The size, in pages, of the physical log.</p>
<p><code>物理日志的大小（以页为单位）。</code></p>
<p><strong>Physical log position at Ckpt</strong> (decimal) – This is the page offset within the physical log that was current at the time of the last checkpoint, expressed as a number of pages offset from the physical log begin address. The first phase of fast recovery, physical recovery, starts with the page following the one indicated here.</p>
<p><code>这是上一次检查点时物理日志中的页面偏移量，表示为从物理日志起始地址偏移的页数。快速恢复的第一阶段，即物理恢复，从此处所示页面之后的页面开始。</code></p>
<p><strong>Logical log unique identifier</strong> (decimal) – This is the unique ID of the logical log that contains the most recently written checkpoint record.</p>
<p><code>这是包含最近写入的 checkpoint record 的逻辑日志的唯一 ID。</code></p>
<p><strong>Logical log position at Ckpt</strong> (hex) – This is the position within the logical log indicated by the previous element in the checkpoint structure (logical log unique identifier) where the most-recently-written checkpoint record can actually be found. This is also known as the <em>logpos</em>.</p>
<p><code>这是 checkpoint structure 中前一个元素 logical log unique identifier(就上边那个) 所指示的逻辑日志中的位置，在该位置可实际找到最近写入的 checkpoint record。这也称为 logpos。</code></p>
<p><strong>Dbspace descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the dbspace reserved page that was current at the time of the checkpoint. Of course, the timestamps on the two dbspace pages could also be compared to determine which one was more up-to-date.</p>
<p><code>这是检查点时最新的 dbspace 保留页面的位置（chunk编号和偏移量）。当然，也可以通过比较两个 dbspace 页面上的时间戳来确定哪个页面更新。</code></p>
<p><strong>Chunk descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the primary chunk reserved page that was current at the time of the last checkpoint. The same redundancy involved with the previous element of the checkpoint structure applies to this one.</p>
<p><code>这是上次检查点时当前的 primary chunk 保留页的位置（chunk编号和偏移量）。检查点结构的前一个元素所涉及的冗余同样适用于这个元素。</code></p>
<blockquote>
<p>redundancy 冗余 英[rɪˈdʌndənsi] 美[rɪˈdʌndənsi]</p>
</blockquote>
<p><strong>Mirror chunk descriptor page</strong> (decimal:decimal) – This is the location (chunk number and offset) of the mirror chunk reserved page that current at the time of the last checkpoint.</p>
<p><code>这是上次检查点时当前 mirror chunk 保留页的位置（chunk编号和偏移量）。</code></p>
<p><strong>The Logical Log File Structure</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Log file number                14</span><br><span class="line">   Unique identifier              146</span><br><span class="line">   Log file flags                 0x5        Log file <span class="keyword">in</span> use</span><br><span class="line">   &amp;                                         Log file has been backed up</span><br><span class="line">   Physical location              3:29483</span><br><span class="line">   Log size                       3270 (p)</span><br><span class="line">   Number pages used              3270</span><br><span class="line">   Date/Time file filled          04/17/2025 09:10:15</span><br><span class="line">   Time stamp                     0x578dde</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>For every logical log file defined in the system, there is one log file structure in the checkpoint&#x2F;logical log reserved page.</p>
<p><code>对于系统中定义的每个逻辑日志文件，在 checkpoint/logical log 预留页面中有一个日志文件结构。</code></p>
<p>注意，这是最后一次检查点时的逻辑日志文件结构，不是当前的，onstat -l 时，flags 对不上的</p>
<p><strong>Log file number</strong> (decimal) – The number of the log file in the Informix Dynamic Server system. Logical log files are generally used in the order of their log file number.</p>
<p><code>IDS 系统中日志文件的编号。逻辑日志文件通常按其日志文件编号的顺序使用。</code></p>
<p><strong>Unique identifier</strong> (decimal) – This integer is always associated with the particular set of logical log records currently stored in this log file. A zero value means the log file is free.</p>
<p><code>该整数总是与当前存储在该日志文件中的特定逻辑日志记录集合相关联。零值表示日志文件空闲。</code></p>
<p>看不懂说的什么，onstat -l 可以看到这两个数，在同一行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@frh gbase]<span class="comment"># onstat -l</span></span><br><span class="line">……</span><br><span class="line">address          number   flags    uniqid   begin                size     used    %used</span><br><span class="line">4559fa60         14       U-B----  146      3:29483              3270     3270   100.00</span><br><span class="line">4559fac8         13       U-B----  147      3:26213              3270     3270   100.00</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<p><strong>Log containing last checkpoint</strong> (decimal) – This indicates the logical log page number and byte offset into that log where the last checkpoint record was recorded.</p>
<p><code>这表示记录最后一次检查点记录的逻辑日志页码和字节偏移量。</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Log file number                10</span><br><span class="line">Unique identifier              150</span><br><span class="line">Log contains last checkpoint:  Page 1260, byte 192</span><br><span class="line">Log file flags                 0x3        Log file <span class="keyword">in</span> use</span><br><span class="line">&amp;                                         Current <span class="built_in">log</span> file</span><br><span class="line">Physical location              3:16403</span><br><span class="line">Log size                       3270 (p)</span><br><span class="line">Number pages used              1261</span><br><span class="line">Date/Time file filled          04/17/2025 09:12:24</span><br><span class="line">Time stamp                     0x6171d2</span><br><span class="line"></span><br><span class="line">address          number   flags    uniqid   begin                size     used    %used</span><br><span class="line">4559fa60         14       U-B----  146      3:29483              3270     3270   100.00</span><br><span class="line">4559fac8         13       U-B----  147      3:26213              3270     3270   100.00</span><br><span class="line">4559fb30         12       U-B----  148      3:22943              3270     3270   100.00</span><br><span class="line">4559fb98         11       U-B----  149      3:19673              3270     3270   100.00</span><br><span class="line">4559fc00         10       U-B---L  150      3:16403              3270     3270   100.00</span><br><span class="line">4559fc68         9        U-B----  151      3:13133              3270     3270   100.00</span><br></pre></td></tr></table></figure>

<p>必须有L的逻辑日志文件，才有 Log contains last checkpoint</p>
<p><strong>Log file flags</strong> (hex) – With the miracle of the logical OR, up to five different logical log flags, like the page flags described in the previous chapter, can be packed into this one short integer. The individual flag values are:</p>
<p><code>利用逻辑或的神奇功能，可以将最多五个不同的逻辑日志标志（如上一章所述的页面标志）打包到这个短整数中。各个标志值如下</code></p>
<p>0x01 Log file in use，U</p>
<p>0x02 Current log file，L</p>
<p>0x04 Backed up，B</p>
<p>0x08 Newly added (archive required)</p>
<p>0x10 Log has been written to an archive tape</p>
<p>0x20 Log is a temporary log file</p>
<p>Note that <strong>oncheck -pr</strong> is nice enough to print an English translation of all flag values present in the one value shown.</p>
<p><code>请注意，oncheck -pr 非常友好，会在显示的一个值中打印所有标志值的英文翻译。(数字右边就是)</code></p>
<p><strong>Physical location</strong> (decimal:decimal) – This is the physical location (chunk number and offset) of this log file’s first page.</p>
<p><code>这是日志文件第一页的物理位置（chunk编号和偏移量）。就是当前逻辑日志文件第一页在chunk的物理位置</code></p>
<p><strong>Log size</strong> (decimal) – This indicates the size of this log file, in pages.</p>
<p><code>表示该日志文件的大小（以页为单位）。</code></p>
<p><strong>Number pages used</strong> (decimal) – This element of the log file structure is fairly self-explanatory, though not always very accurate, being updated only during a checkpoint along with the rest of the reserved page information (when wrong, it is low). Informix Dynamic Server’s recovery mechanisms do not rely on this value at all.</p>
<p><code> 日志文件结构中的这一元素不言自明，但并不总是非常准确，只有在检查点期间才会与其他保留页信息一起更新（错误时，它的值较低）。IDS 的恢复机制完全不依赖这个值。</code></p>
<p>不懂，先不管</p>
<blockquote>
<p>fairly 相当地 英[ˈfeəli] 美[ˈferli]</p>
<p>self-explanatory 一目了然的 英[ˌself ɪkˈsplænətri] 美[ˌself ɪkˈsplænətɔːri]</p>
</blockquote>
<p><strong>Date&#x2F;time file filled</strong> – This is the date and time, based on the UNIX host’s <strong>localtime</strong>function, when this log file was filled. <strong>12&#x2F;31&#x2F;69 16:00</strong> indicates this element’s value is 0, which means the log file is either free or still in use.</p>
<p><code>根据 UNIX 主机的 localtime 函数，这是日志文件被写满时的日期和时间。&quot;-&quot; 表示此元素的值为 0，这意味着日志文件已空闲或仍在使用中。</code></p>
<p>原文的12&#x2F;31&#x2F;69 16:00不知道是什么，明明显示的是个”-“</p>
<p><strong>Time stamp</strong> (decimal) – This is the value of the global system timestamp when this log file was completed (the log file does not have to be filled to capacity to get a timestamp). A 0 here indicates a log file that is either free, or still in use.</p>
<p><code>这是该日志文件完成时的全局系统时间戳值（日志文件不必写满就可以获得时间戳）。此处的 0 表示日志文件空闲或仍在使用中。</code></p>
<p>说的是 onmode -l 情况吧</p>
<p><strong>Log Unique Identifier Versus Log File Number</strong></p>
<blockquote>
<p>versus 英[ˈvɜːsəs] 美[ˈvɜːrsəs]<br>prep.(表示两队或双方对阵)对，诉，对抗;(比较两种不同想法、选择等)与…相对，与…相比;</p>
</blockquote>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505112026087.png" alt="image-20250511202616915"></p>
<p><strong>Notes:</strong></p>
<p>A logical log file is an area on disk. It is a chunk extent, LOGSIZE kilobytes large, to which log records are written as they are generated. Each log file has a permanent log file number. In the example above, the log file number is 1 for the first log file, 2 for the second log, and 3 for the third log.</p>
<p><code>逻辑日志文件是磁盘上的一个区域。它是一个chunk extent，LOGSIZE 为 KB，日志记录生成后会被写入其中。每个日志文件都有一个永久的日志文件编号。在上例中，第一个日志文件的日志文件编号为 1，第二个日志文件的日志文件编号为 2，第三个日志文件的日志文件编号为 3。</code></p>
<p>In addition, each log file has a unique identifier, which you can think of as a method to uniquely tag the logical log records inside of the log. When a logical log is backed up, it carries its unique identifier with it. The unique identifiers for the logs on disk are incremented, ready for new transaction records.</p>
<p><code>此外，每个日志文件都有一个唯一标识符，可以将其视为唯一标记日志内逻辑日志记录的方法。备份逻辑日志时，日志会携带这个唯一标识符。磁盘上日志的唯一标识符会递增，为新的事务记录做好准备。</code></p>
<p>前半段看不懂，感觉按它意思，唯一标识日志里的逻辑日志记录，备份以后唯一标识递增（变了），而此时日志里内容没变吧，也就是内容没变的情况下，却不能唯一标识了，意思里面内容没用了呗，等新的事物记录写入</p>
<p>In the example above, the newly initialized Informix Dynamic Server system assigns the first log a unique ID of 1, the second log a unique ID of 2, and the third log a unique ID of 3. When these logs are full and you back them up to tape, the unique identifiers for the three logs are changed to 4, 5, and 6. After filling them a second time and backing them up, the unique identifiers are changed to 7, 8, and 9.</p>
<p><code>在上面的示例中，新初始化的 IDS 系统为第一个日志分配了唯一标识符 1，为第二个日志分配了标识符 2，为第三个日志分配了标识符 3。当这些日志被写满并备份到磁带后，这三个日志的唯一标识符会被更改为 4、5 和 6。在第二次写满并备份之后，唯一标识符会更改为 7、8 和 9。</code></p>
<p><strong>The Dbspace Page</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1DBSP &amp; PAGE_2DBSP...</span><br><span class="line">      Using DBspace page PAGE_2DBSP.</span><br><span class="line"></span><br><span class="line">DBspace number                 1</span><br><span class="line">DBspace name                   rootdbs</span><br><span class="line">Flags                          0x40001    No mirror chunks</span><br><span class="line">Number of chunks               1</span><br><span class="line">First chunk                    1</span><br><span class="line">Date/Time created              04/17/2025 08:44:48</span><br><span class="line">Partition table page number    14</span><br><span class="line">Pagesize (k)                   2</span><br><span class="line">Logical Log Unique Id          0</span><br><span class="line">Logical Log Position           0x0</span><br><span class="line">Oldest Logical Log Unique Id   155</span><br><span class="line">Last Logical Log Unique Id     0</span><br><span class="line">Expand Size (Chunk Create)     50.0%</span><br><span class="line">Expand size (Chunk Extend)     10.0%</span><br><span class="line">DBspace archive status</span><br><span class="line"></span><br><span class="line">      Archive Level            0</span><br><span class="line">      Real Time Archive Began  05/12/2025 07:25:01</span><br><span class="line">      Time Stamp Archive Began 8590386</span><br><span class="line">      Logical Log Unique Id    155</span><br><span class="line">      Logical Log Position     0x64f018</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The dbspace structure is easier to understand intuitively than either the checkpoint or the log file structure.</p>
<p><code>与检查点或log file structure相比，dbspace 结构更容易直观地理解。</code></p>
<blockquote>
<p>intuitively 英[ɪnˈtjuːɪtɪvli] 美[ɪnˈtuːɪtɪvli]<br>adv.凭直觉;直觉地，直观地；由直觉而得地;</p>
</blockquote>
<p><strong>Dbspace number</strong> (decimal) – Dbspace numbers are indexed from 1.</p>
<p><strong>Dbspace name</strong> – This is the name given the dbspace when it was created, and the name used in all SQL syntax referring to this dbspace.</p>
<p><code>这是创建 dbspace 时赋予它的名称，也是所有引用该 dbspace 的 SQL 语法中使用的名称。</code></p>
<p><strong>Flags</strong> (hex) – The possible values for dbspace flags are:</p>
<p>0x0001 DBspace has no mirror chunks</p>
<p>0x0002 DBspace uses mirror chunks</p>
<p>0x0004 DBspace has disabled mirror chunks</p>
<p>0x0008 Newly mirrored</p>
<p>Flags specific to blobspaces:</p>
<p>0x0010 DBspace is a BLOBspace</p>
<p>0x0020 BLOBspace resides on removable media</p>
<p>0x0040 BLOBspace resides on optical media</p>
<p>0x0080 BLOBspace has been dropped</p>
<p>0x0100 BLOBspace is the optical STAGEBLOB</p>
<p>Other flags:</p>
<p>0x0200 Space is being physically recovered</p>
<p>0x0400 Space has been physically recovered</p>
<p>0x0800 Space is being logically recovered</p>
<p>0x1000 A table in the dbspace was dropped</p>
<p>0x2000 Temp DBspace</p>
<p>0x4000 Space is being archived</p>
<p>0x8000 Space is an sbspace</p>
<p>0x10000 Either the physical or logical log has changed</p>
<p>按这说的，那应该是0x10001，怎么是0x70001？</p>
<p><strong>Number of chunks</strong> (decimal) – This indicates the total number of chunks in this dbspace (not counting mirror chunks).</p>
<p><code>表示该数据库空间中的chunk总数（不包括镜像chunk）。</code></p>
<p><strong>First chunk</strong> (decimal) – The concept of a <em>first chunk</em> in a dbspace is important internally because a dbspace structure and all its associated primary chunk structures form a linked list. From the <strong>First chunk</strong> element in a dbspace structure, Informix Dynamic Server can quickly find the first primary chunk structure associated with this dbspace. Then, based on the <strong>Next chunk</strong> in dbspace element in each primary chunk structure, Informix Dynamic Server can quickly walk down the rest of the list.</p>
<p><code>dbspace 中的 first chunk 概念在内部非常重要，因为 dbspace 结构及其所有关联的主 chunk 结构构成了一个链表。IDS 可以通过 dbspace 结构中的 First chunk 元素，快速找到与该数据表空间相关联的 first primary chunk structure。然后，根据每个 primary chunk structure 中 dbspace 的 Next chunk 元素，IDS 可以快速找到列表的其余部分。</code></p>
<p><strong>Date&#x2F;time created</strong> – This is the date and time, based on the UNIX <strong>localtime</strong> function, when the dbspace was created.</p>
<p><code>这是创建 dbspace 的日期和时间，基于 UNIX 的 localtime 函数。</code></p>
<p><strong>Partition table page numbe</strong>r – This indicates the location of the first page of the partition partition as a page offset into the first chunk of the dbspace.</p>
<p><code>这表示 partition 第一页的位置，作为 dbspace 第一个 chunk 的页面偏移量。</code></p>
<p>两个连着的partition，多写了一个吧</p>
<p><strong>Pagesize (k)</strong> – This is the page size defined for this dbspace.</p>
<p><strong>Logical Log Unique ID</strong> and <strong>Logical Log Position</strong> – These fields indicate the location of the ADDDBS transaction record for this dbspace.</p>
<p><code>这些字段表示该 dbspace 的 ADDDBS 事务记录的位置。</code></p>
<p>看不懂</p>
<p><strong>Oldest Logical Log Unique ID</strong> and <strong>Last Logical Log Unique ID</strong> – These indicate the unique ID numbers of the oldest and most current logical logs.</p>
<p><code>这表示最旧和最新逻辑日志的唯一 ID 编号。</code></p>
<p><strong>Dbspace archive status</strong> – This displays information about the last backup that was performed that included this dbspace. Information includes the backup level, the start and end time of the backup, and the location of the backup checkpoint record.</p>
<p><code>这将显示上一次执行的包含此 dbspace 的备份信息。信息包括备份级别、备份开始和结束时间以及备份 checkpoint record 的位置。</code></p>
<p>没看出来哪个是结束时间</p>
<p>最后两个逻辑日志相关参数代表 the location of the backup checkpoint record 吧</p>
<p><strong>The Primary Chunk Page</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">   Validating PAGE_1PCHUNK &amp; PAGE_2PCHUNK...</span><br><span class="line">         Using primary chunk page PAGE_1PCHUNK.</span><br><span class="line"></span><br><span class="line">   Chunk number                   1</span><br><span class="line">   Flags                          0x30040    Chunk is online</span><br><span class="line">   Chunk path                     /opt/gbase/storage/rootdbs</span><br><span class="line">   Chunk offset                   0 (p)</span><br><span class="line">   Chunk size                     78848 (p)</span><br><span class="line">   Number of free pages           64144</span><br><span class="line">   DBspace number                 1</span><br><span class="line"></span><br><span class="line">   Chunk number                   2</span><br><span class="line">   Flags                          0x32040    Chunk is online</span><br><span class="line">   &amp;                                         Chunk is extendable</span><br><span class="line">   Chunk path                     /opt/gbase/storage/ol_gbasedbt1210_1_plog_p_1</span><br><span class="line">   Chunk offset                   0 (p)</span><br><span class="line">   Chunk size                     36045 (p)</span><br><span class="line">   Number of free pages           6</span><br><span class="line">   DBspace number                 2</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The primary chunk page contains information about each primary chunk created on the database server.</p>
<p><code>主chunk页面包含在server上创建的每个主chunk的信息。</code></p>
<p><strong>Chunk number</strong> (decimal) – Chunk numbers are indexed from 1, whereas page offsets begin with 0. The lowest possible value for a page address is therefore 1:0.</p>
<p><code>chunk编号的索引从 1 开始，而页面偏移量则从 0 开始。 因此，页面地址的最小值可能是 1:0。</code></p>
<p><strong>Flags</strong> (hex) – Individual chunk flags, ORed together into this one element, have the following values:</p>
<p><code>各个独立的chunk标志通过按位或操作（OR）组合在一起，形成这个元素，具有以下值：</code></p>
<p>0x0010 Mirror chunk</p>
<p>0x0020 Chunk is off-line</p>
<p>0x0040 Chunk is on-line</p>
<p>0x0080 Chunk is being recovered</p>
<p>0x0100 Chunk is newly mirrored</p>
<p>0x0200 Chunk is belongs to a blobspace</p>
<p>0x0400 Chunk is being dropped</p>
<p>0x0800 Chunk is part of an optical stageblob</p>
<p>0x1000 Chunk is inconsistent with the rest of the system</p>
<p>0x2000 Chunk has been chained</p>
<p>0x4000 Chunk belongs to an sbspace</p>
<p><strong>Chunk path</strong> – This is the full pathname to the chunk device or file. </p>
<p><code>这是chunk设备或文件的完整路径名。</code></p>
<p><strong>Chunk offset</strong> (decimal) – This chunk begins at <strong>Chunk offset</strong> <em>pages</em> into <strong>Chunk path</strong>.</p>
<p><code>该chunk从 Chunk path 中偏移 Chunk offset 页的位置开始。</code></p>
<p><strong>Chunk size</strong> (decimal) – This indicates the size of the chunk in <em>pages</em>.</p>
<p><code>这表示数据块的大小，单位为页。</code></p>
<p><strong>Number of free pages</strong> (decimal) – This indicates the total number of pages currently in the chunk free list.</p>
<p>·这表示当前chunk free list的页面总数。·</p>
<p><strong>Dbspace number</strong> (decimal) – This is the unique dbspace number.</p>
<p><code>这是唯一的dbspace编号。</code></p>
<p><strong>The Mirror Chunk Page</strong></p>
<p>没人用 Mirror Chunk 了吧，跳过不看</p>
<p><strong>The Archive Page</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Validating PAGE_1ARCH &amp; PAGE_2ARCH...</span><br><span class="line">         Using archive page PAGE_1ARCH.</span><br><span class="line"></span><br><span class="line">   Archive Level                  0</span><br><span class="line">   Real Time Archive Began        05/12/2025 07:25:01</span><br><span class="line">   Time Stamp Archive Began       0x831432</span><br><span class="line">   Logical Log Unique Id          155</span><br><span class="line">   Logical Log Position           0x64f018</span><br><span class="line"></span><br><span class="line">   Archive Level                  1</span><br><span class="line">   Real Time Archive Began        05/12/2025 07:25:52</span><br><span class="line">   Time Stamp Archive Began       0x8314b5</span><br><span class="line">   Logical Log Unique Id          155</span><br><span class="line">   Logical Log Position           0x656018</span><br><span class="line"></span><br><span class="line">   DR has not been initialized.</span><br></pre></td></tr></table></figure>

<p><strong>Notes:</strong></p>
<p>The archive reserved page is the last in the set of root reserved pages. Up to three archive structures can be present on the page, depending on the level of archives taken on the system. Once a second or third archive structure comes to exist on the page, it is never deleted because a new level-0 archive does not negate the potential importance of a previous level 1 or level 2 archive.</p>
<p><code>存档预留页是root预留页中的最后一个。页面上最多可有三个存档结构，具体取决于系统中存档的级别。一旦页面上出现第二个或第三个存档结构，它将永远不会被删除，因为新的 0 级存档不会否定之前的 1 级或 2 级存档的潜在重要性。</code></p>
<p>看不懂，对应0、1、2级备份吧</p>
<p>New information is recorded in the archive reserved page only when an archive completes successfully.</p>
<p><code>只有当存档成功完成时，存档保留页面才会记录新信息。</code></p>
<p><strong>Archive Level</strong> (decimal) – This can be level 0, 1, or 2.</p>
<p><strong>Real Time Archive Began</strong> – This indicates the date and time of the archive checkpoint as seen by the localtime function on the UNIX host machine.</p>
<p><code>这表示存档检查点的日期和时间，由 UNIX 主机上的 localtime 功能显示。</code></p>
<p>看不懂，什么叫存档检查点？从名字看就是备份时间吧</p>
<p><strong>Time Stamp Archive Began</strong> (decimal) – This is a timestamp associated with the checkpoint that occurred at the start of the archive.</p>
<p><code>这是与存档开始时发生的检查点相关联的时间戳。</code></p>
<p>看不懂</p>
<p><strong>Logical Log Unique Id</strong> (decimal) – This is the unique ID of the logical log that contains the archive checkpoint record.</p>
<p><code>这是包含 archive checkpoint record 的逻辑日志的唯一 ID。</code></p>
<p><strong>Logical Log Position</strong> (hex) – This is the position within the log (logpos) specified by logical log unique ID where the archive checkpoint can be found.</p>
<p><code>这是在逻辑日志唯一 ID 指定的日志 (logpos) 中可以找到 archive checkpoint 的位置。</code></p>
<p><strong>Chunk Free List</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505132122121.png" alt="image-20250513212245968"></p>
<p><strong>Notes:</strong></p>
<p>Every chunk needs a mechanism to track its own available space. Following the last reserved page in each chunk is a chunk free-list page. This page, which can be one of several depending on the fragmentation in the chunk, contains structures pointing to <em>unused</em> extents. Each structure, or <em>free-list entry</em>, contains two elements: the starting page of an unclaimed extent, and the length of the free extent measured in pages.</p>
<p><code>每个 chunk 都需要一种机制来跟踪自己的可用空间。在每个chunk的最后一个预留页之后是一个 chunk free-list page。该页面可以是多个页面之一，取决于 chunk 中的碎片情况，包含指向未使用extent的结构。每个结构或free-list条目包含两个元素：空闲extent的起始页和空闲extent的长度（以页为单位）。</code></p>
<p>“该页面可以是多个页面之一”，多个翻译软件都是这么翻译的，不像人话，意思应该是可能有多个chunk free-list page，如果碎片很多的话，要记录很多的起始和偏移，一页放不下，如果一个碎片都没有，一个起始和偏移就够了。</p>
<blockquote>
<p>unclaimed 英[ˌʌnˈkleɪmd] 美[ˌʌnˈkleɪmd]<br>adj.无人认领的;无人索取的;</p>
</blockquote>
<p><strong>Allocation of space</strong></p>
<p>When an extent is allocated in a chunk, the loss of free space is manifested in either the removal of an entry from the chunk free list, or a modification to one or both elements in an entry there.</p>
<p>当在chunk中分配一个extent时，可用空间的损失表现为从chunk free list中删除一个条目，或修改该条目中的一个或两个元素。</p>
<blockquote>
<p>manifest<br>英[ˈmænɪfest] 美[ˈmænɪfest]<br>vt.表明;显示;显现;清楚显示(尤指情感、态度或品质);使人注意到;<br>adj.明显的;<br>n.(船或飞机的)货单;旅客名单;</p>
<p>以前都按java的<em>MANIFEST</em>.MF理解为：清单</p>
</blockquote>
<p><strong>Freeing space</strong></p>
<p>Informix Dynamic Server frees space when a table is dropped, or in some cases when a table is altered. When free space is reclaimed, a new entry can be added to the chunk free list. If the newly freed space is contiguous with existing free space, only the length element in the associated free-list entry is changed; otherwise, a new entry is created.</p>
<p><code>IDS 会在删除表或在某些情况下更改表时释放空间。当空闲空间被回收时，可以在chunk free list中添加一个新条目。如果新释放的空间与现有的空闲空间毗连，则只更改相关空闲列表条目中的长度元素；否则，将创建一个新条目。</code></p>
<blockquote>
<p>reclaim<br>英[rɪˈkleɪm] 美[rɪˈkleɪm]<br>vt.回收;开垦，利用，改造(荒地);取回;挽救;要求归还;拿回;沙化;荒漠化;重新变为沙漠(或森林等);抛荒;<br>n.开垦;改造;取回;矫正;</p>
</blockquote>
<p><strong>Additional chunk free-list pages</strong></p>
<p>If a chunk becomes so fragmented that the initial chunk free-list page is full of entries, an additional chunk free-list page is allocated. These pages are then chained together in the form of a linked list. Each link in this chain is responsible only for extents between itself and the next chunk free-list page. This design requires a good deal of coordination among the links.</p>
<p><code>如果一个分块变得非常分散，以至于初始chunk free-list page已经满载条目，那么就会分配一个额外的chunk free-list page。然后，这些页面以链表的形式串联起来。链中的每个链接只负责自身和下一个chunk free-list page之间的扩展。这种设计要求链路之间有很好的协调性。</code></p>
<p><strong>Tblspace Tblspace (for Root Dbspace)</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505132157873.png" alt="image-20250513215730788"></p>
<p><strong>Notes:</strong></p>
<p>In the initial chunk of every dbspace, the page following the chunk free list marks the beginning of the tblspace tblspace (partition table). The tblspace tblspace is a collection of pages that describes the complexion and location of each table in the dbspace. In many ways, the tblspace tblspace itself is considered just another table. For example, one of its pages describes the tblspace tblspace!</p>
<p><code>在每个 dbspace 的初始chunk中，数据chunk free list之后的页面标志着 tblspace tblspace（分区表）的开始。tblspace tblspace 是描述 dbspace 中每个表的结构和位置的页面集合。在许多方面，tblspace tblspace 本身就被认为是另一个表。例如，其中一个页面描述了 tblspace tblspace！</code></p>
<blockquote>
<p>complexion<br>英[kəmˈplekʃn] 美[kəmˈplekʃn]<br>n.肤色;面色;气色;(事物的)性质，特性;</p>
<ul>
<li><em>complex</em> 的“复杂性”含义源于“多元素交织”的原始意象。</li>
<li><em>complexion</em> 的中世纪生理学概念认为体液混合决定面色，故从“混合状态”引申为“肤色”。</li>
</ul>
</blockquote>
<p>You can configure the size of the first and subsequent extents for the tblspace tblspace in by setting the TBLTBLFIRST and TBLTBLNEXT configuration parameters. The default value of 0 directs the database server to determine appropriate extent sizes based on the size of the initial dbspace chunk.</p>
<p><code>通过设置 TBLTBLFIRST 和 TBLTBLNEXT 配置参数，可以配置 tblspace tblspace 中第一个和后续extent的大小。默认值 0 会指示server根据初始 dbspace chunk 的大小确定适当的extent大小。</code></p>
<p>Every tblspace in the system has exactly one tblspace tblspace page describing it. For brevity’s sake, we often refer to this special page type as a <em>partition page</em>.</p>
<p><code>系统中的每个 tblspace 都有且只有一个 tblspace tblspace page 来描述它。为了简洁起见，我们通常将这种特殊类型的页面称为 分区页（partition page）。</code></p>
<p>上图大方格那一行page</p>
<p><strong>Partition Number (Partnum)</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505142301023.png" alt="image-20250514230139875"></p>
<p><strong>Notes:</strong></p>
<p>The purpose of a table’s partition number, another 4-byte hexadecimal code, is to guide Informix Dynamic Server to that table’s partition page in the tblspace tblspace. The high-order byte-and-a-half (3 nibbles) of a partnum indicates which dbspace contains the table. Using the value of that byte-and-a-half, Informix Dynamic Server locates the tblspace tblspace for the target dbspace. One of the pages in that tblspace tblspace describes the target table. Informix Dynamic Server locates the correct partition page using the low-order five nibbles of the partnum, which contain a logical page number.</p>
<p><code>表的 partition number 是一个4字节的十六进制代码，其作用是引导 IDS 定位到该表在 tblspace tblspace 中的 partition page。这个 partnum 的高一字节半（3个半字节）用于指示表所在的 dbspace。通过这个高一字节半的值，IDS 可以定位到目标 dbspace 所对应的 tblspace tblspace。该 tblspace tblspace 中的某个页面描述了目标表。IDS 再通过分区号的低五个半字节——即逻辑页码，来定位到正确的 partition page。</code></p>
<blockquote>
<p>nibble 英[ˈnɪbl] 美[ˈnɪbl]</p>
<p>半字节</p>
<p>v.小口咬;一点点地咬(食物);(对…)略微表现出兴趣;<br>n.一小口;小吃;(餐前或聚会中的)点心;</p>
</blockquote>
<p>上上个图，partition number还是3字节，到这边4字节了…</p>
<p>Let us say the <strong>stores_demo:customer</strong> table has a partition number of 0x001000A5. This code means that logical page 0xA5 (165) within the tblspace tblspace for dbspace 1 is the partition page for <strong>stores_demo:customer</strong>.</p>
<p><code>例如，stores_demo:customer 表的分区号为 0x001000A5。这段代码表示，dbspace 1 的 tblspace tblspace 中的逻辑页 0xA5 (165) 是 stores_demo:customer 的 partition page。</code></p>
<p><strong>Partition Page Layout</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505152133530.png" alt="image-20250515213343393"></p>
<p><strong>Notes:</strong></p>
<p>Each partition page uses the following 5-slot format to describe the structure, location, and contents of one table in the dbspace:</p>
<p><code>每个 partition page 使用以下 5 个slot的格式来描述 dbspace 中一个表的结构、位置和内容：</code></p>
<p><strong>•</strong> The partition structure (slot 1) contains 92 bytes of general table information, including the partition number (see next page).</p>
<p><code>partition structure（slot 1）包含 92 个字节的常规表信息，包括分区编号（见下页，往后边看有详细解释）。</code></p>
<p><strong>•</strong> Slot 2 contains information identifying the partition by database name, table owner, table name, and NLS collation sequence (if any).</p>
<p><code>Slot 2 包含用于标识 partition 的信息，包括数据库名称、表拥有者、表名称，以及 NLS 排序规则（如果有的话）。</code></p>
<p><strong>•</strong> Slot 3 contains a descriptive entry for each <em>special</em> column in the table, meaning blobs and VARCHAR types.</p>
<p><code>slot 3 包含表中每个特殊列的描述性条目，即 blobs 和 VARCHAR 类型。</code></p>
<p><strong>•</strong> Slot 4 contains a <em>key descriptor</em> entry for each index key that exists for this table. Therefore, when accessing a particular tblspace, an error such as <em>Illegal key descriptor:</em> <em>too many parts or too long</em> refers to a problem with slot 4 on that table’s partition page, and not with the index itself. Because dropping an index requires the use of its key descriptor, a bad key descriptor can sometimes require the intervention of IBM Informix Technical Support to fix.</p>
<p><code>Slot 4 包含该表中每个索引键的“键描述符”（key descriptor）条目。因此，当访问某个特定的表空间（tblspace）时，若出现类似 非法键描述符（Illegal key descriptor）：part过多或过长（too many parts or too long） 的错误，通常说明该表的分区页上的 Slot 4 出现了问题，而不是索引本身存在问题。由于删除索引时需要使用其键描述符（key descriptor），因此损坏的键描述符有时需要 IBM Informix 技术支持介入才能修复。</code></p>
<p><strong>•</strong> Slot 5 contains extent information. Each 8-byte entry in this slot includes:</p>
<p><code>slot 5 包含 extent 信息。该 slot 中的每个 8 字节条目包括</code></p>
<p>​     <strong>-</strong> the logical page number of that extent’s first page within the tblspace (4 bytes)</p>
<p>​    <code>tblspace 中该 extent 第一页的逻辑页码（4 个字节）</code></p>
<p>​     <strong>-</strong> the page offset of the extent into the dbspace (4 bytes)</p>
<p>​    <code>dbspace 中 extent 的页面偏移量（4 个字节）</code></p>
<p>​    The slot also includes one “on-deck” entry that includes the logical page number for the next extent allocated.</p>
<p>​    <code>slot还包括一个 “on-deck ”条目，其中包括下一个已分配extent的逻辑页码。</code></p>
<p>​	slot 5 看不懂</p>
<p>A table could also have a sixth slot, but it does not appear on the main partition page for that table. The sixth slot is used to describe different versions of extents that result from altering a table in-place. This slot appears on a separate page in the tblspace tblspace.</p>
<p><code>表也可以有第六个slot，但它不会出现在该表的 main partition page 上。第六个 slot 于描述因就地更改表而产生的不同 extent 版本。该 slot 在 tblspace tblspace 中的一个单独页面上。</code></p>
<p>什么叫 main partition page，第一页？</p>
<p><strong>Slot 1: The Partition Structure</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">TBLspace Report <span class="keyword">for</span> testdb:root.t1</span><br><span class="line"></span><br><span class="line">    Physical Address               13:570</span><br><span class="line">    Creation <span class="built_in">date</span>                  05/08/2025 05:05:57</span><br><span class="line">    TBLspace Flags                 902        Row Locking</span><br><span class="line">                                              TBLspace contains VARCHARS</span><br><span class="line">                                              TBLspace use 4 bit bit-maps</span><br><span class="line">    Maximum row size               16</span><br><span class="line">    Number of special columns      1</span><br><span class="line">    Number of keys                 0</span><br><span class="line">    Number of extents              1</span><br><span class="line">    Current serial value           1</span><br><span class="line">    Current SERIAL8 value          1</span><br><span class="line">    Current BIGSERIAL value        1</span><br><span class="line">    Current REFID value            1</span><br><span class="line">    Pagesize (k)                   2</span><br><span class="line">    First extent size              8</span><br><span class="line">    Next extent size               8</span><br><span class="line">    Number of pages allocated      8</span><br><span class="line">    Number of pages used           2</span><br><span class="line">    Number of data pages           1</span><br><span class="line">    Number of rows                 4</span><br><span class="line">    Partition partnum              13631559</span><br><span class="line">    Partition lockid               13631559</span><br><span class="line"></span><br><span class="line">    Extents</span><br><span class="line">         Logical Page     Physical Page        Size Physical Pages</span><br><span class="line">                    0           13:2087           8          8</span><br></pre></td></tr></table></figure>



<p><strong>Notes:</strong></p>
<p>The partition structure is stored in the first slot on every partition page and holds general information about the corresponding table. You can view the partition structure for any table by running the command:</p>
<p><code>partition structure 存储在每个 partition page 的第一个 slot 中，包含相应表的一般信息。运行该命令可以查看任何表的 partition structure：</code></p>
<p>​	oncheck -pt <em>database_name</em>:<em>table_name</em></p>
<p>Instead of a database and table name, you can provide a partition number:</p>
<p>​	oncheck -pt 1048672</p>
<p>The output of this command consists of slightly-massaged versions of the partition structure (slot 1) and the extent structure (slot 5) for the partition page. An example of <strong>oncheck</strong> output for the partition structure is shown in the slide above.</p>
<p><code>该命令的输出包括partition structure（slot 1）和 partition page 的 extent structure（slot 5）的略微简化版本（最后3行）。上面的幻灯片显示了 partition structure 的 oncheck 输出示例。</code></p>
<p>You might recognize some of the general tblspace information stored in the partition structure as table statistics, also stored in system catalogs for use by the optimizer. In fact, during some UPDATE STATISTICS operations, some information from a table’s partition page is copied into system catalogs, while other information must be gathered by reading the tblspace pages themselves. Although the system catalog information can become out of date as the table grows and changes, the information on the partition page should always be accurate. However, the optimizer code is meant to be portable across Informix servers and it, therefore, does not know how to access a partition page. As far as the optimizer is concerned, the only table statistics available are stored in system catalogs.</p>
<p><code>你可能会注意到，partition structure 中存储的一些通用表空间（tblspace）信息，与存储在系统目录（system catalogs）中的表统计信息相似，这些统计信息被优化器（optimizer）用于优化查询。实际上，在某些 </code>UPDATE STATISTICS<code> 操作中，部分表的分区页（partition page）中的信息会被复制到 system catalogs 中，而其他信息则必须通过读取表空间页（tblspace pages）来收集。尽管系统目录中的信息可能会随着表的增长和变化而变得过时，partition page 中的信息应始终是准确的。然而，优化器的代码是为了在不同的 Informix server 之间具备可移植性，因此它并不了解如何访问 partition page。就优化器而言，唯一可用的表统计信息就是存储在 system catalogs 中的那些。</code></p>
<blockquote>
<p>gather 聚集 英[ˈɡæðə(r)] 美[ˈɡæðər]</p>
</blockquote>
<p>前边说，为了简洁，把 tblspace tblspace page 叫做 partition page，那 tblspace pages 是什么？先不管它，好像 Unit 4 有讲</p>
<p><strong>Physical Address</strong> (decimal:decimal) – This is not the partition number, nor is it an address related to any tblspace extent. Unlike the rest of the elements displayed, the physical address is not even part of the partition structure. The oncheck report is simply displaying the physical location (chunk number and page offset) of the partition page from which the rest of the information has been taken.</p>
<p><code>这不是 partition number，也不是与任何 tblspace extent 相关的地址。与显示的其他元素不同，物理地址甚至不是 partition structure 的一部分。oncheck 只是显示 partition page 的物理位置（chunk number 和 page offset），其他信息都是从该页面获取的。</code></p>
<p><strong>Creation date</strong> – This is the date and time this table was created.</p>
<p><code>这是该表的创建日期和时间。</code></p>
<p><strong>TBLSpace Flags</strong> (decimal) – These flags operate as page flags, dbspace flags, and chunk flags do, coagulating in one integer with the help of the logical OR. Individual tblspace flags have the following values and meanings:</p>
<p><code>这些 flags 与 page flags, dbspace flags 和 chunk flags 一样，在逻辑 OR 的帮助下合并为一个整数。各个 tblspace 标志的值和含义如下：</code></p>
<blockquote>
<p>coagulate 英[kəʊˈæɡjuleɪt] 美[koʊˈæɡjuleɪt]<br>v.(使)凝结，凝固;<br>n.（&#x3D;coagulum）凝结物(如血块);<br>adj.&lt;古&gt;凝结的;</p>
</blockquote>
<p>0x0001 Page-level locking</p>
<p><code>页级锁</code></p>
<p>0x0002 Row-level locking</p>
<p><code>行级锁</code></p>
<p>0x0004 Tblspace is a Bundlespace (OnLine secure)</p>
<p>看不懂</p>
<p>0x0008 Partition marked for DDR replication</p>
<p>和ER有关吧，看不懂</p>
<p>0x0010 Partition dropped (shared memory only)</p>
<p>0x0020 System-defined temporary table</p>
<p>0x0040 User-defined temporary table</p>
<p>0x0080 Tblspace used for sorting</p>
<p>0x0100 Contains VARCHAR column(s)</p>
<p>0x0200 Contains BLOBspace BLOB column(s)</p>
<p>0x0400 Contains partition-resident BLOB column(s)</p>
<p>0x0800 Requires 4-bit bitmap</p>
<p>0x1000 Contains optical BLOB column(s)</p>
<p>0x2000 Partition required for system to function - do not drop</p>
<p>0x4000 Temp table being used for special function - do not update</p>
<p>0x8000 Partition is being appended to</p>
<p><strong>Maximum row size</strong> (decimal) – For tables with fixed-length rows, this value is simply the row size in bytes. The concept of a <em>maximum</em> row size becomes necessary only when a tblspace contains VARCHAR columns. Recall that a VARCHAR column is defined with a minimum and a maximum size, in units of characters, which is equivalent to bytes. The maximum size of a VARCHAR column, plus one byte of overhead (in which to store the actual size of the VARCHAR data) is added with the sizes of the other columns in the schema to arrive at this <em>maximum row size</em> figure.</p>
<p><code>对于具有固定长度行的表，该值就是以字节为单位的行大小。只有当 tblspace 包含 VARCHAR 列时，才有必要使用最大行大小的概念。回想一下，VARCHAR 列的最小和最大大小是以字符为单位定义的，相当于字节。VARCHAR 列的最大大小加上一个字节的开销（用于存储 VARCHAR 数据的实际大小），再加上模式中其他列的大小，就得出了最大行大小这个数字。</code></p>
<blockquote>
<p>figure 英[ˈfɪɡə(r)] 美[ˈfɪɡjər]<br>n.图形;人物;人，动物;（书中的）图，表;身材;位数;花样;（远处人的）轮廓;（人、动物的）雕像，塑像;算术;数字符号;字码;(代表数量，尤指官方资料中的)数字;<br>v.是…的部分;计算(数量或成本);认为，认定(某事将发生或属实);是重要部分;</p>
</blockquote>
<p>知乎这回答应该是oracle里schema的概念。IX9111这段中的schema先理解成包含columns的数据库对象吧，如：表</p>
<blockquote>
<p>知乎：</p>
<p>在学习数据库时，会遇到一个让人迷糊的Schema的概念。实际上，<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=schema&zhida_source=entity">schema</a>就是<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E8%B1%A1&zhida_source=entity">数据库对象</a>的集合，这个集合包含了各种对象如：表、视图、<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=72023897&content_type=Answer&match_order=1&q=%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B&zhida_source=entity">存储过程</a>、索引等。</p>
<p>如果把database看作是一个仓库，仓库很多房间（schema），一个schema代表一个房间，table可以看作是每个房间中的储物柜，user是每个schema的主人，有操作数据库中每个房间的权利，就是说每个数据库映射user有每个schema（房间）的钥匙。</p>
</blockquote>
<p><strong>Number of special columns</strong> (decimal) – Blob and VARCHAR columns are considered <em>special</em>, Informix Dynamic Server-only column types.</p>
<p><code>Blob 和 VARCHAR 列被认为是特殊的，仅限 IDS 使用的列类型。</code></p>
<p><strong>Number of keys</strong> (decimal) – The total number of indexes defined for the table. A composite index can be made from several columns, but still has only one index <em>key</em>.</p>
<p><code>为表定义的索引总数。复合索引可以由多个列组成，但仍然只有一个索引键。</code></p>
<p><strong>Number of extents</strong> (decimal) – The number of separate extents allocated to the table. Extent concatenation and doubling, and good tblspace management on the part of the Informix Dynamic Server administrator, tend to keep this number low. As the number of extents for a tblspace grows, not only can data be scattered unpredictably (a performance problem for sequential reads), but the extent slot on the partition page grows. An extent slot can contain only so many entries before it runs out of room. Because other slots on the partition page, such as slot 4, can also grow dynamically, there is no way to publish a maximum number of tblspace extents with any accuracy. Empirical evidence has shown the maximum number of extents on a 2K-page is approximately 190.</p>
<p><code>分配给表的独立extent的数量。extent的拼接与倍增（机制），以及 IDS 管理员对表空间（tblspace）的良好管理，往往能将这一数量保持在较低水平。随着 tblspace 的extent 数量增加，不仅数据会不可预测地分散（对于顺序读取来说是个性能问题），而且 partition page 上的 extent slot 也会增加。在空间耗尽之前，一个 extent slot 只能容纳这么多条目。由于 partition page 上的其他 slot（如 slot 4）也会动态增长，因此无法准确发布 tblspace extents 的最大数量。经验表明，2K 页面上的最大扩展项数量约为 190 个。</code></p>
<p>extent slot 是 slot 5 上 extent list 中的元素？</p>
<blockquote>
<p>scatter 分散 英[ˈskætə(r)] 美[ˈskætər]</p>
<p>predictably 可推断 美[prɪˈdɪktəbli]</p>
<p>empirical 英[ɪmˈpɪrɪkl] 美[ɪmˈpɪrɪkl] adj.经验主义的;以实验(或经验)为依据的;</p>
<p>approximately 大概 英[əˈprɒksɪmətli] 美[əˈprɑːksɪmətli]</p>
</blockquote>
<p><strong>Current serial value</strong> (decimal) – A tblspace can contain only one serial column. If one exists, this is the next value that is used for an insert. If there is no serial column in the table, this value remains 1.</p>
<p><code>一个 tblspace 只能包含一个 serial 列。如果存在 serial 列，则下一个值将用于插入。如果表中没有 serial 列，该值将保持为 1。</code></p>
<p><strong>First extent size</strong> (decimal) – This is the configured EXTENT SIZE, in units of Informix Dynamic Server pages. The units here can be a bit confusing because through SQL, one specifies EXTENT SIZE in kilobytes.</p>
<p><code>这是配置的 EXTENT SIZE，以 IDS page 为单位。这里的单位可能有点令人困惑，因为通过 SQL，我们可以用 KB 来指定 EXTENT SIZE。</code></p>
<p>The default EXTENT SIZE is 8 pages, regardless of the page size. The minimum extent size is 4 pages.</p>
<p><code>无论页面大小如何，默认 extent 大小为 8 页。最小 extent 大小为 4 页。</code></p>
<p><strong>Next extent size</strong> (decimal) – This is the configured NEXT SIZE, also in units of Informix Dynamic Server pages. Note that at the SQL level one specifies NEXT SIZE in units of kilobytes, so like First extent size, the value here is initially either half or one quarter the number used with the NEXT SIZE clause in SQL.</p>
<p><code>这是配置的 NEXT SIZE，也是以 IDS page 为单位。请注意，在 SQL 级别，NEXT SIZE 是以 KB 为单位指定的，因此与 First extent size 一样，这里的值最初是 SQL 中 NEXT SIZE 子句所用数字的一半或四分之一。</code></p>
<blockquote>
<p>chatgpt:</p>
<h3 id="具体解释如下："><a href="#具体解释如下：" class="headerlink" title="具体解释如下："></a>具体解释如下：</h3><ul>
<li>在 SQL 中，<code>NEXT SIZE</code> 是以 <strong>KB（千字节）</strong> 为单位指定的。</li>
<li>在内部，Informix 使用的是 <strong>页（page）</strong> 为单位的存储方式，比如常见的页大小是 <strong>2KB</strong> 或 <strong>4KB</strong>。</li>
</ul>
<h4 id="示例说明："><a href="#示例说明：" class="headerlink" title="示例说明："></a>示例说明：</h4><ul>
<li>如果你的数据库页大小是 <strong>2KB</strong>：<ul>
<li>你在 SQL 中写 <code>NEXT SIZE 64</code>（表示 64KB）；</li>
<li>那么转换成页就是：<code>64KB ÷ 2KB = 32 页</code>；</li>
<li>此时内部记录的 NEXT SIZE 就是 32。</li>
</ul>
</li>
<li>如果页大小是 <strong>4KB</strong>：<ul>
<li>同样的 SQL 指定 <code>NEXT SIZE 64</code>；</li>
<li>内部转换成页就是：<code>64KB ÷ 4KB = 16 页</code>；</li>
<li>所以内部值会是 16。</li>
</ul>
</li>
</ul>
<p>因此：</p>
<p>如果页大小是 2KB，则内部值是 SQL 值的一半；<br>如果页大小是 4KB，则内部值是 SQL 值的四分之一。</p>
</blockquote>
<p>Next extent size can increase over time due to extent size doubling. The size never decreases unless the table is deliberately altered. The default for the next extent size is 8 pages. The minimum extent size is 4 pages.</p>
<p><code>由于 extent 大小的倍增机制，Next extent size 可能会随着时间推移而增加。除非对表进行显式修改，否则该大小不会减少。Next extent size 的默认值是 8 页，最小值为 4 页。</code></p>
<blockquote>
<p>deliberately 故意 英[dɪˈlɪbərətli] 美[dɪˈlɪbərətli]</p>
</blockquote>
<p><strong>Number of pages allocated</strong> (decimal) – This is the total number of pages, whether used or not, contained in the extents allocated to the tblspace.</p>
<p><code>这是分配给表空间（tblspace）的所有 extent 中包含的页数总和，无论这些页是否已被使用。</code></p>
<p><strong>Number of pages used</strong> (decimal) – This is the maximum number of pages that have ever been used in the tblspace.</p>
<p><code>这是 tblspace 中使用过的最大页数。</code></p>
<p><strong>Number of data pages</strong> (decimal) – This is the number of data pages currently in use in the tblspace. When all rows are deleted from a data page, the page is freed for reuse in the tblspace, and the <strong>Number of data pages</strong> element of the partition structure is decremented.</p>
<p><code>这是当前在 tblspace 中使用的数据页数。当从数据页中删除所有行时，该页将被释放以供在 tblspace 中重复使用，并且 partition structure 中的“Number of data pages”元素将减少。</code></p>
<p><strong>Number of rows</strong> (decimal) – This indicates the number of rows in the tblspace.</p>
<p><code>这表示 tblspace 中的行数。</code></p>
<p><strong>Partition partnum</strong> (decimal) – This indicates the partition number of the tblspace.</p>
<p><code>这表示 tblspace 的 partition number。</code></p>
<p><strong>Partition lockid</strong> – It used to be that when you locked an Informix Dynamic Server table, you were really locking a partition number. This works as long as there is a one-to-one correspondence between database tables and Informix Dynamic Server partition numbers. But fragmentation allows many partitions to be associated with one database table. Rather than associate the partnums of every table fragment with a single table lock, Informix Dynamic Server uses this value, the lockid, to represent all table fragments.</p>
<p><code>过去，锁定 IDS 表时，实际上是锁定一个 partition number。只要数据库表和 IDS partition number 之间存在一一对应关系，这种方法就能奏效。但分片允许将许多 partition 与一个数据库表关联起来。IDS 不会将每个表片段的分区号与单个表锁相关联，而是使用 lockid 这个值来代表所有表片段。</code></p>
<p><strong>The Partition Page Location</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171729739.png" alt="image-20250517172857535"></p>
<p><strong>Notes:</strong></p>
<p>Dynamic Server determines the location of a table’s partition page based on that table’s partition number, which is stored in <strong>systables.partnum</strong>. Upon reading a partition page, the database server can check that it has found the correct one by scanning the first 4-byte element in the partition structure. This first element contains the partition number. Here is an example:</p>
<p><code>IDS 根据表的 partition number 确定表的 partition page 位置，partition number 存储在 systables.partnum 中。读取 partition page 时，server 可通过扫描 partition structure 中的第一个 4 字节元素来检查是否找到了正确的 partition page。第一个元素包含 partition number。下面是一个示例：</code></p>
<ol>
<li><p>The database server receives a request to access the <strong>items</strong> table.</p>
<p><code>server 收到访问 items 表的请求。</code></p>
</li>
<li><p>In order to find the partition page for the <strong>items</strong> table, the server must determine its partition number. The database server selects the <strong>partnum</strong> value from <strong>systables</strong>.</p>
<p><code>为了找到 items 表的 partition page，server 必须确定其 partition number。server 从 systables 中查询 partnum 值。</code></p>
</li>
<li><p>Based on the partition number, a hex code comprised of a dbspace number and a logical page number, IDS reads a specific partition page from a specific tblspace tblspace.</p>
<p><code>根据partition number（由 dbspace 编号和逻辑页码组成的十六进制代码），IDS 会从特定的 tblspace tblspace 中读取特定的 partition page。</code></p>
</li>
<li><p>To check its work, the Dynamic Server process reads the first element of the partition structure found in slot 1 on the partition page, comparing the value found there against the partition number selected from <strong>systables</strong> during step 2 above.</p>
<p><code>为检查其工作，server 进程会读取 partition page slot 1 中 partition structure 的第一个元素，并将其中的值与上述第 2 步中从 systables 查询的 partition number 进行比较。</code></p>
</li>
<li><p>If the two partition numbers match, the operation has so far been successful. If they differ, the database server writes an assertion failure message to the message log and returns errors 242 and 135 to the client process.</p>
<p><code>如果两个 partition number 匹配，则操作成功。如果不一致，server 会在消息日志中写入断言失败消息，并向客户进程返回错误 242 和 135。</code></p>
</li>
</ol>
<p><strong>Slot 5: The Extent Slot</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171743215.png" alt="image-20250517174318102"></p>
<p><strong>Notes:</strong></p>
<p>The extent slot, slot 5 of a partition page, is an array of 8-byte entries, each of which describes one extent for the table. The information stored in each 8-byte extent entry consists of two 4-byte values: the logical page number (within the tblspace) of the start of the extent, and the offset of that page into the dbspace.</p>
<p><code>extent slot（partition page 的第 5 slot）是一个 8 字节条目的数组，每个条目描述表的一个 extent。每个 8 字节 extent 条目中存储的信息由两个 4 字节值组成：extent 起始的逻辑页码（在 tblspace 中），以及该页在 dbspace 中的偏移量。</code></p>
<p>For instance, consider the following entry in the extent slot shown in the slide above (the display format is modified to make interpretation easier):</p>
<p><code>例如，请看上面幻灯片中显示的 extent slot 中的以下条目（为便于解释，对显示格式进行了修改）：</code></p>
<p>​		0000 0020 0000 0665</p>
<p>This entry describes an extent whose first page is located on the 1637th (0x665) page of dbspace number 1. With respect to the extent’s tblspace, the extent starts on logical page 32 (0x20).</p>
<p><code>此条目描述了一个 extent，其首页位于 1 号 dbspace 的第 1637 (0x665) 页。对于该 extent 的 tblspace，该范围从逻辑页 32 (0x20) 开始。</code></p>
<p>Every extent slot ends with an <em>on-deck</em> or <em>cap</em> extent entry, one poised to accept the dbspace offset of the next allocated extent. Serving as a kind of cap on the array, the last extent entry contains the logical page number for the next extent to be allocated, and a null value to act as placeholder for the dbspace offset for that extent.</p>
<p><code>每个 extent slot 最后都有一个 on-deck 或 cap  extent条目，准备接受下一个分配 extent 的 dbspace 偏移量。作为数组的一种上限，最后一个 extent 条目包含下一个要分配的 extent 的逻辑页码，以及一个空值，作为该 extent 的 dbspace 偏移量的占位符。</code></p>
<blockquote>
<p>poised 英[pɔɪzd] 美[pɔɪzd]<br>adj. 摆好姿势准备行动的</p>
</blockquote>
<p><strong>Slot 6: Page Versioning</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505171849672.png" alt="image-20250517184920542"></p>
<p><strong>Notes:</strong></p>
<p>If a table is altered and the database server is able to alter the table in-place, then an additional slot is required to handle the versioning of extents in the tblspace.</p>
<p><code>如果更改了表，且 server 能够就地更改表，则需要一个额外的 slot 来处理 tblspace 中 extent 的版本管理。</code></p>
<p>An <em>in-place alter</em> occurs when an ALTER TABLE command is executed and the changes to the table structure do not require a table rebuild. Instead, the database server simply records the change on an additional page in the tblspace tblspace. This page is an extension of the partition page and the only slot on this page is identified as <em>slot 6</em>. The logical page number of the new page is placed in the <strong>pg_next</strong> field in the header of the original <em>partition</em> page.</p>
<p><code>当执行 ALTER TABLE 命令，表结构的更改不需要重建表时，就会发生就地更改。此时，server 只需在 tblspace tblspace 中的一个附加页面上记录更改。该页面是 partition page 的扩展，页面上唯一的 slot 被标识为 slot 6。新页面的逻辑页码放在原始 partition 页头的 pg_next 字段中。</code></p>
<p>chatgpt 和 gemini 都将 Instead 翻译成”此时“，DeelL翻译成”相反“感觉确实不合适</p>
<p>If a row in the altered table is updated and there is room on the page for all rows to be converted to the new version, then all rows are updated and the new version is recorded on the page. If there is not enough room for all rows on the page to be reversioned, then the updated row is altered and moved to a page that only contains rows of the same version. The version number is recorded in the <strong>pg_next</strong> field in the header of each <em>data</em> page.</p>
<p><code>如果修改后的表中的某一行被更新，并且页面上有足够的空间将所有行转换为新版本，那么所有行都会被更新，并且新版本信息会被记录在该页面上。如果页面空间不足，无法对所有行进行版本转换，则更新的那一行会被修改并移动到一个仅包含相同版本行的页面中。版本号会被记录在每个数据页（data page）页头的 pg_next 字段中。</code></p>
<blockquote>
<p>chagpt</p>
<h3 id="一、表结构更改会引入“版本”概念"><a href="#一、表结构更改会引入“版本”概念" class="headerlink" title="一、表结构更改会引入“版本”概念"></a>一、表结构更改会引入“版本”概念</h3><p>当你使用 <code>ALTER TABLE</code>（比如增加列、修改字段类型）修改表结构时，如果数据库支持 <strong>in-place alter</strong>，它不会立即重建整张表，而是通过“版本管理”来处理这种变化。</p>
<p>也就是说：</p>
<ul>
<li>表的旧结构是“版本1”；</li>
<li>修改后生成一个“版本2”的结构；</li>
<li>原先的旧行仍然保持版本1的格式，直到被访问或更新。</li>
</ul>
<hr>
<h3 id="二、为什么更新一行可能会影响整页？"><a href="#二、为什么更新一行可能会影响整页？" class="headerlink" title="二、为什么更新一行可能会影响整页？"></a>二、为什么更新一行可能会影响整页？</h3><p>Informix 之类的数据库系统出于 <strong>存储和性能优化考虑</strong>，往往会这样设计：</p>
<blockquote>
<p><strong>同一个数据页（data page）中尽量只存储相同结构版本的记录。</strong></p>
</blockquote>
<p>这就意味着：</p>
<ol>
<li>如果一页中原本存储的全是版本1的行；</li>
<li>你更新了其中的一行（让它变成了版本2）；</li>
<li>数据库会检查这一页是否有足够空间，把<strong>这整页中的所有行都转换成版本2</strong>；</li>
<li>如果空间够，就一并转换并更新页面元数据；</li>
<li>如果空间不够，只更新这一行，并把它迁移到一个专门存放版本2记录的新页中。</li>
</ol>
<hr>
<h3 id="三、这样做的目的是什么？"><a href="#三、这样做的目的是什么？" class="headerlink" title="三、这样做的目的是什么？"></a>三、这样做的目的是什么？</h3><p>主要是为了：</p>
<ul>
<li><strong>简化行的读取逻辑</strong>：读取时不需要一行一行地判断是哪个版本；</li>
<li><strong>提高性能</strong>：相同版本的行可以共享解析逻辑，减少额外开销；</li>
<li><strong>支持表结构的动态演进</strong>，避免一次性重写整表带来的高成本。</li>
</ul>
</blockquote>
<p>Since a table can be altered several times, the database server uses <em>versioning</em> to keep track of which version of the table is used to describe the pages in an extent that contain updated rows.</p>
<p><code>由于一张表可能会被多次修改，server 使用版本控制（versioning）来跟踪用于描述包含已更新行的 extent 中各页面所对应的表结构版本。</code></p>
<p>Slot 6 contains the following information:</p>
<p> <strong>•</strong> Version number</p>
<p> <strong>•</strong> Number of columns added in this version</p>
<p> <strong>•</strong> Number of pages that contain rows that have not been modified</p>
<p> <strong>•</strong> Logical page number in the tblspace tblspace where descriptor information is stored</p>
<p> <strong>•</strong> Uncompressed size of a row before the table was altered</p>
<p> <strong>•</strong> Uncompressed size of a row after the table was altered</p>
<p><strong>The Physical Log</strong></p>
<p>Some important facts:</p>
<p>– The physical log is used during fast recovery.</p>
<p><code>物理日志用于快速恢复。</code></p>
<p>– In most customer systems, the physical log is set too small causing checkpoints too occur too frequently.</p>
<p><code>在大多数客户的系统中，物理日志设置得过小，导致检查点出现得过于频繁。</code></p>
<p>– It can be moved outside the root dbspace, and usually should be.</p>
<p><code>它可以移到 root dbspace 之外，通常也应该这样做。</code></p>
<p><strong>Notes:</strong></p>
<p>While the physical log might not be of much use in a system that runs perfectly every day of the year, it is crucial to Informix Dynamic Server’s fast recovery mechanism as well as its archiving algorithm, both of which can come in quite handy in the world of power failures and disk crashes that most of us inhabit.</p>
<p><code>虽然物理日志在全年每天都完美运行的系统中可能用处不大，但它对 IDS 的快速恢复机制及其归档算法却至关重要，而在我们大多数人所处的这个充满断电和磁盘崩溃的现实世界中，这两者往往非常有用。</code></p>
<blockquote>
<p>inhabit 英[ɪnˈhæbɪt] 美[ɪnˈhæbɪt]<br>vt.居住在;栖居于;</p>
</blockquote>
<p>The initial size of the physical log is usually much too small, which can cause checkpoints to occur much too frequently. Sizing the physical log too small is a common mistake of novice administrators.</p>
<p><code>物理日志的初始大小通常太小，这可能会导致检查点出现得过于频繁。将物理日志设置得过小是新手管理员常犯的错误。</code></p>
<p><strong>Physical Log Page Structure</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172010750.png" alt="image-20250517201048659"></p>
<p><strong>Notes:</strong></p>
<p>The slide above shows the structure of a physical log page. Pages in the physical log are identical to their pages of origin. The only way to tell that a page came from the physical log is by looking at the page address (offset and chunk). The page contains the address of the original page location and not the physical location within the physical log.</p>
<p><code>上面的幻灯片展示了一个物理日志页的结构。物理日志中的页面与它们原始来源的页面是完全相同的。判断一个页面是否来自物理日志的唯一方法是查看其页地址（偏移量和chunk号）。该页面记录的是原始页面的位置地址，而不是其在物理日志中的实际物理位置。</code></p>
<blockquote>
<p>identical 完全相同的 英[aɪˈdentɪkl] 美[aɪˈdentɪkl]</p>
</blockquote>
<p><strong>Logical Log File Structure</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172017022.png" alt="image-20250517201756936"></p>
<p><strong>Notes:</strong></p>
<p>Each logical log is a string of contiguous log pages. Each page within an individual log is numbered, beginning with 0. The location of that number on the page is shown in the next slide.</p>
<p><code>每个逻辑日志由一串连续的日志页组成。每个日志中的页面都从编号 0 开始。该编号在页面中的位置将在下一张幻灯片中展示。</code></p>
<p>上图就是一个逻辑日志，有一连串的逻辑日志页面，从编号0开始</p>
<p>Keep in mind that a <em>log file</em> is an extent within a chunk that does not go anywhere and is constantly overwritten. A log file serves as the temporary home of a <em>logical log</em>, which is unique. It is the logical log, not the log file, that is backed up to tape.</p>
<p><code>请记住，日志文件（log file）是位于某个 chunk 中的一个 extent，它不会被移动，并且会被不断覆盖。日志文件是某个逻辑日志（logical log）的临时存储位置，而每个逻辑日志都是唯一的。被备份到磁带上的，是逻辑日志，而不是日志文件。</code></p>
<p>A logical log can contain any number of pages from one to the total number available in a log file.</p>
<p><code>一个逻辑日志可以包含任意数量的页面，从1页到日志文件中可用的总页数。</code></p>
<p>Logical log pages are manufactured one after another in the logical log buffer, and written out in series each time the buffer is flushed.</p>
<p><code>逻辑日志页在逻辑日志缓冲区中逐个生成，并在每次刷新缓冲区时按顺序写出。</code></p>
<blockquote>
<p>manufacture<br>英[ˌmænjuˈfæktʃə(r)] 美[ˌmænjuˈfæktʃər]<br>vt.制造;产生(一种物质);生成;(用机器)大量生产;捏造;编造;成批制造;<br>n.批量生产;工业品;大量制造;</p>
</blockquote>
<p><strong>Logical Log Page Structure</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172036583.png" alt="image-20250517203607494"></p>
<p><strong>Notes:</strong></p>
<p>The structure of a logical log page, as pictured above, might suggest the sequential method by which log records are generally accessed. Note for example that the page has no slot table. (The length of each record is stored within the record itself.) Note also that logical log data is very fluid, spilling from one page onto the next without fanfare (though a record must be fully contained within a log file). Even the page header has a few surprises.</p>
<p><code>如上图所示，逻辑日志页的结构可能暗示了日志记录通常是以顺序方式访问的。比如，请注意该页面没有 slot table，因为每条记录的长度是保存在记录本身中的。还要注意，逻辑日志数据非常灵活，可以自然地从一个页面延伸到下一个页面（不过一条记录必须完整地存储在同一个日志文件中）。甚至页头也有一些惊喜。</code></p>
<blockquote>
<p>fluid英[ˈfluːɪd] 美[ˈfluːɪd]<br>n.液体;流体;液;<br>adj.流体的;流动的;不稳定的;易变的;流畅优美的;</p>
<p>spilling 英[ˈspɪlɪŋ] 美[ˈspɪlɪŋ]<br>v.(使)洒出，泼出，溢出;涌出;蜂拥而出;<br>n.木片，纸捻；洒出量；摔下，跌落;（Spilling）（挪、英、美）施皮林（人名）;</p>
<p>fanfare 英[ˈfænfeə(r)] 美[ˈfænfer]<br>n.大张旗鼓;号角花彩，号角齐鸣(欢迎仪式等上奏的响亮短曲);(为庆祝而在媒体上的)喧耀;</p>
</blockquote>
<p><strong>pg_nslots</strong></p>
<p>This is unused, since there is no real concept of slots on a log page.</p>
<p><code>这是未使用的，因为日志页面上没有真正的slot概念。</code></p>
<p><strong>pg_frcnt</strong></p>
<p>This is always zero, even for pages that are not full (note that <strong>pg_frptr</strong> is accurate). The reason has more to do with coincidence than design.</p>
<p><code>即使页面未满，该值也始终为0（请注意，pg_frptr 是准确的）。其原因更多是巧合，而非设计。</code></p>
<p>下面解释为什么是0</p>
<blockquote>
<p>coincidence 巧合 英[kəʊˈɪnsɪdəns] 美[koʊˈɪnsɪdəns]</p>
</blockquote>
<p>Log pages within the log buffer are allowed to fill to the last byte, usually continuing the last record on the next page. So a large number of log pages are truly full, especially when buffered logging is used exclusively.</p>
<p><code>日志缓冲区内的日志页可以填满到其最后一个字节，通常会将最后一条记录延续到下一页。因此，大量的日志页会真正地被完全填满，尤其是在只使用（或：专门采用）缓冲日志记录（buffered logging）的情况下。</code></p>
<p>However, an early buffer flush, forced by a checkpoint or a commit record for a database with unbuffered logging, for example, tend to come at a time when the last page in the buffer is only partly full. Once flushed to the log file, a log page cannot be changed; additional records cannot be added to it. The reason even these pages have a <strong>pg_frcnt</strong> of 0 is this: just before the log buffer is flushed, the flushing process sets the value of <strong>pg_frcnt</strong> on the last page in the buffer to 0, making the page look artificially full in order to prevent another engine process from writing to the page while the I&#x2F;O is being performed.</p>
<p><code>然而，例如由检查点 或 采用非缓冲日志记录的数据库的提交记录 所触发的提前缓冲区刷新，往往发生在缓冲区最后一页仅部分填充之时。日志页一旦刷新到日志文件便无法更改，也不能再向其添加额外记录。即便这些页面仅部分填充，其 pg_frcnt 值也为0，原因如下：在日志缓冲区刷新前夕，刷新进程会将缓冲区最后一页的 pg_frcnt 值设为0，从而人为地将该页标记为“已满”，以防止在I/O操作执行期间，其他引擎进程尝试写入该页。</code></p>
<p><strong>pg_next</strong></p>
<p>On a logical log page, this element of the page header contains the unique ID of the logical log.</p>
<p><code>在逻辑日志页面上，页头的这一元素包含逻辑日志的唯一 ID。</code></p>
<p><strong>pg_prev</strong></p>
<p>On a logical log page, this element of the page header contains the page offset (similar to a logical page number) of the log page. Note that this is the offset within the log, and as always, page offsets begin with 0.</p>
<p><code>在逻辑日志页中，页头的这一元素包含日志页的页面偏移量（类似于逻辑页码）。请注意，这是在日志中的偏移量，而页面偏移量总是以 0 开始。</code></p>
<p><strong>Logical Log Position (Logpos)</strong></p>
<p><img src="https://gcore.jsdelivr.net/gh/frh16/imghost/img/202505172120865.png" alt="image-20250517212040764"></p>
<p><strong>Notes:</strong></p>
<p>Log records are uniquely addressed only within a particular logical log. The address used is called a <em>logical log position</em>, or <em>logpos</em> for short. It is a 4-byte integer code that describes the position of a log record in terms of a page offset and a byte offset. The page offset is with respect to the beginning of the log, and is indexed from 0. The byte offset is with respect to the beginning of the page, and is also indexed from 0, though because of the space taken by the page header, this value should never be less than 0x018.</p>
<p><code>日志记录只能在特定逻辑日志中唯一寻址。使用的地址称为 logical log position，简称 logpos。它是一个 4 字节整数代码，用页面偏移和字节偏移来描述日志记录的位置。页面偏移量相对于日志的起始位置，索引从 0 开始。 字节偏移量相对于页面的起始位置，索引也从 0 开始，但由于页面头占用了空间，该值不应小于 0x018。</code></p>
<p><strong>Hint</strong></p>
<p>Assume you are told a logical log record is located in a logical log with a unique ID of 234 and a logpos of 0x12018. How would you find it? Using the more current of your two checkpoint&#x2F;logical log reserved pages in the root chunk, you could find the physical address of log number 234. Once at that page, you would offset 0x12 pages into the log to find the correct log page, then 0x018 bytes into that page to find the log record.</p>
<p><code>假设有一条逻辑日志记录位于逻辑日志中，其唯一 ID 为 234，logpos 为 0x12018。你将如何找到它？使用 root chunk 中两个 checkpoint/logical log 保留页面中的最新页面，可以找到日志编号 234 的物理地址。找到该页面后，在日志中偏移 0x12 页，找到正确的日志页，然后在该页中偏移 0x018 字节，找到日志记录。</code></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> fengrh
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>